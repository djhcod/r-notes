[
  {
    "objectID": "intro.html#本书编写环境概况",
    "href": "intro.html#本书编写环境概况",
    "title": "前言",
    "section": "本书编写环境概况",
    "text": "本书编写环境概况\n\nR版本：R 4.3.2\nRStudio版本：2023.09.1+494\n操作系统：macOS 14.1.1\n硬件：MacBook Pro (14-inch, 2023)\n\n本书基于Quarto创建。"
  },
  {
    "objectID": "intro.html#r学习资源推荐",
    "href": "intro.html#r学习资源推荐",
    "title": "前言",
    "section": "R学习资源推荐",
    "text": "R学习资源推荐\n\n在线书籍：\n\nR Graphics Cookbook, 2nd edition：https://r-graphics.org\nR for Data Science (2e)：https://r4ds.hadley.nz\nQuarto Guide：https://quarto.org/docs/guide/\nHappy Git and GitHub for the useR：https://happygitwithr.com\nBookdown：https://bookdown.org\n\n\n\n论坛/网站：\n\nR CODER：https://r-coder.com\nStack Overflow：https://stackoverflow.com\nR-Bloggers：https://www.r-bloggers.com\nPosit Cheatsheets：https://posit.co/resources/cheatsheets/\nKaggle：https://www.kaggle.com/code?language=R\nThe R Graph Gallery：https://r-graph-gallery.com\nPosit Community：https://community.rstudio.com"
  },
  {
    "objectID": "r_basic/r_basics.html",
    "href": "r_basic/r_basics.html",
    "title": "R语言基础",
    "section": "",
    "text": "本章主要介绍R语言的环境配置以及数据的导入、导出等R语言的基本操作。"
  },
  {
    "objectID": "r_basic/environment_configuration.html#更新r",
    "href": "r_basic/environment_configuration.html#更新r",
    "title": "2  Rstudio环境配置",
    "section": "2.1 更新R",
    "text": "2.1 更新R\n在R原软件中逐个运行下面的代码（仅适用Windows系统）。macOS直接打开https://cran.r-project.org/bin/macosx/下载最新版本的R覆盖安装，重启RStudio即可完成R的更新，原R包都在。\n\ninstall.packages(\"installr\")\nlibrary(installr)\nupdateR()"
  },
  {
    "objectID": "r_basic/environment_configuration.html#更新r包",
    "href": "r_basic/environment_configuration.html#更新r包",
    "title": "2  Rstudio环境配置",
    "section": "2.2 更新R包",
    "text": "2.2 更新R包\n运行下面的代码或通过右下角的Packages选项卡进行R包的更新\n\nold.packages() # 检查是否有需要更新的R包\nupdate.packages(ask = F) # 更新所有R包\nnews(package = \"limma\") # 参看R包的更新内容\nBiocManager::valid() # 查看是否有需要更新的bioconductor包。根据提示安装更新"
  },
  {
    "objectID": "r_basic/environment_configuration.html#从bioconductor安装r包",
    "href": "r_basic/environment_configuration.html#从bioconductor安装r包",
    "title": "2  Rstudio环境配置",
    "section": "2.3 从bioconductor安装R包",
    "text": "2.3 从bioconductor安装R包\n\nBiocManager::install(\"biomaRt\",update = TRUE,ask = FALSE)"
  },
  {
    "objectID": "r_basic/environment_configuration.html#更改当前r脚本运行目录",
    "href": "r_basic/environment_configuration.html#更改当前r脚本运行目录",
    "title": "2  Rstudio环境配置",
    "section": "2.4 更改当前R脚本运行目录",
    "text": "2.4 更改当前R脚本运行目录\n\nsetwd(\"/Users/totoshihiro/Library/Mobile Documents/com~apple~CloudDocs/Documents/科研/医学统计学/数据基本处理与标准化\")\ngetwd()#查看当前R脚本运行目录"
  },
  {
    "objectID": "r_basic/environment_configuration.html#环境查看和清理",
    "href": "r_basic/environment_configuration.html#环境查看和清理",
    "title": "2  Rstudio环境配置",
    "section": "2.5 环境查看和清理",
    "text": "2.5 环境查看和清理\n\nrm(mydata)\nrm(list = ls())#移除当前环境中的所有对象\ncat(\"\\014\")#清空所有输出结果\nsessionInfo()#收集有关当前R项目的信息\ndetach(\"package:dplyr\", unload=TRUE) #清除当前加载的程序包"
  },
  {
    "objectID": "r_basic/environment_configuration.html#自动安装所需的r包",
    "href": "r_basic/environment_configuration.html#自动安装所需的r包",
    "title": "2  Rstudio环境配置",
    "section": "2.6 自动安装所需的R包",
    "text": "2.6 自动安装所需的R包\n\npackages &lt;-c(\"GEOquery\", \"limma\",\"ggplot2\", \"pheatmap\")#列出所需的R包\n\n#检查所需的R包是否已安装，若未安装则从CRAN或Bioconductor安装包\npackagecheck &lt;- function(x) {\n  if (!require(\"BiocManager\")) {\n    install.packages(\"BiocManager\")\n  } else if (!require(x, character.only = T)) {\n    CRANpackages &lt;- available.packages()\n    if (x %in% rownames(CRANpackages)) {\n      install.packages(x)\n    } else {\n      BiocManager::install(x, update = TRUE, ask = FALSE)\n    }\n  }\n}\nlapply(packages, packagecheck)"
  },
  {
    "objectID": "r_basic/environment_configuration.html#自动整理代码",
    "href": "r_basic/environment_configuration.html#自动整理代码",
    "title": "2  Rstudio环境配置",
    "section": "2.7 自动整理代码",
    "text": "2.7 自动整理代码\nThe tidyverse style guide对代码编写时的规范格式进行了详细说明。通过styler包可以实现对代码的自动整理，有助于保持不同项目之间的代码风格一致，并促进协作。安装styler后通过运行下面的命令即可自动整理当前打开的文档的代码。\n\ninstall.packages(\"styler\")\nstyler:::style_active_file()\n\n也可以用通过打开Rstudio的插件（Addins），选择”Style active file”来实现对当前R脚本的代码整理。或者选择一段代码后，点击”Style selection”来对选中的代码进行整理。\n\n\n\nFigure 2.1: Rstudio插件"
  },
  {
    "objectID": "r_basic/environment_configuration.html#rstudio主题",
    "href": "r_basic/environment_configuration.html#rstudio主题",
    "title": "2  Rstudio环境配置",
    "section": "2.8 Rstudio主题",
    "text": "2.8 Rstudio主题\nrsthemes包提供了多种额外的主题。\n\n该包通过r-universe进行安装：\n\ninstall.packages(\n  \"rsthemes\",\n  repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption(\"repos\"))\n)\n\n然后安装主题：\n\nrsthemes::install_rsthemes()\n\n使用：\n\n# 列出所有来自rsthemes的主题\nrsthemes::list_rsthemes()\n\n# 依次尝试所有主题\nrsthemes::try_rsthemes()\n\n# 只尝试浅色主题\nrsthemes::try_rsthemes(\"light\")\n\n通过Tools &gt; Global Options &gt; Appearance也可以浏览和应用这些主题。\n安装该包后还会在Rstudio的插件中显示，可以方便的进行深色和浅色模式的切换。要实现这一点，需要打开R的配置文件（~/.Rprofile），可以通过下面的方式快速打开：\n\nusethis::edit_r_profile()\n\n然后将下面的代码粘贴进配置文件：\n\nif (interactive()) {\n  rsthemes::set_theme_light(\"Chrome\") # 默认的浅色主题\n  rsthemes::set_theme_dark(\"Cobalt\") # 默认的深色主题\n  rsthemes::set_theme_favorite( # 再添加一些主题作为备选\n    c(\n      \"GitHub {rsthemes}\",\n      \"Material Palenight {rsthemes}\"\n    )\n  )\n}\n\n现在就可以通过点击插件中的”Toggle Dark Mode”来一键切换深色和浅色主题了（Figure 2.1 ）。同时，点击”Next Favorite Theme”可以切换上面设置的set_theme_favorite()里面的主题。"
  },
  {
    "objectID": "r_basic/data_input_output.html#读取csv数据文件",
    "href": "r_basic/data_input_output.html#读取csv数据文件",
    "title": "3  数据的读取与输出",
    "section": "3.1 读取CSV数据文件",
    "text": "3.1 读取CSV数据文件\nread.csv或read.table均可\n\ncsvdata&lt;-read.csv(\"ovary_data.csv\",#相对路径\n                  header=T,#第一行是否是列名\n                  sep=\",\",#字段分隔符。文件每行上的值由此字符分隔。read.table的默认值为sep=“”，表示分隔符为‘空白’，即一个或多个空格、制表符、换行符或回车。read.csv的默认值为sep=\",\"，表示分隔符为英文逗号\n                  stringsAsFactors=F)#是否将字符向量转换为因子\ncsvdata&lt;-read.table(\"ovary_data.csv\",header=T,sep=\",\", \n                    row.names=\"patientID\", \n                    colClasses=c(\"character\", \"character\", \"character\",\"numeric\", \"numeric\", \"numeric\")) #指定每一列的变量类型\n\nread.table参数含义：\n\nas.is：该参数用于确定read.table()函数读取字符型数据时是否转换为因子型变量。当其取值为FALSE时，该函数将把字符型数据转换为因子型数据，取值为TRUE时，仍将其保留为字符型数据。"
  },
  {
    "objectID": "r_basic/data_input_output.html#读取spss文件",
    "href": "r_basic/data_input_output.html#读取spss文件",
    "title": "3  数据的读取与输出",
    "section": "3.2 读取SPSS文件",
    "text": "3.2 读取SPSS文件\n\nlibrary(foreign)\nsavdata&lt;-read.spss(\"lweight.sav\",to.data.frame=T)#需要将.sav格式数据转换成数据框"
  },
  {
    "objectID": "r_basic/data_input_output.html#读取excel文件",
    "href": "r_basic/data_input_output.html#读取excel文件",
    "title": "3  数据的读取与输出",
    "section": "3.3 读取Excel文件",
    "text": "3.3 读取Excel文件\nMacOS 首选 gdata 包（因自带perl语言）；Windows首选 xlsx 包\n\nlibrary(gdata)\nxlsdata&lt;-read.xls(\"ovary_data.xlsx\",\n                  sheet=1)#要读取的工作表的名称或编号"
  },
  {
    "objectID": "r_basic/data_input_output.html#读取txt文件",
    "href": "r_basic/data_input_output.html#读取txt文件",
    "title": "3  数据的读取与输出",
    "section": "3.4 读取txt文件",
    "text": "3.4 读取txt文件\n\nrefGene&lt;-read.table(\"refGene.txt\",header=F,sep = \"\\t\")"
  },
  {
    "objectID": "r_basic/data_input_output.html#读取自带数据集",
    "href": "r_basic/data_input_output.html#读取自带数据集",
    "title": "3  数据的读取与输出",
    "section": "3.5 读取自带数据集",
    "text": "3.5 读取自带数据集\n\ndata(Arthritis, package=\"vcd\")\n#或\nmydata &lt;- vcd::Arthritis"
  },
  {
    "objectID": "r_basic/data_input_output.html#下载和读取压缩包",
    "href": "r_basic/data_input_output.html#下载和读取压缩包",
    "title": "3  数据的读取与输出",
    "section": "3.6 下载和读取压缩包",
    "text": "3.6 下载和读取压缩包\n\n解压.zip文件\n\nunzip(\"test.zip\",#压缩包的位置及文件名\n      files = \"ferroptosis_suppressor.csv\",\n      overwrite = T)#解压后是否覆盖同名文件\n\n\n\n解压.tar文件\n\nuntar(\"test.tar\",#压缩包的位置及文件名\n      files = \"ferroptosis_suppressor.csv\")#提取指定文件，忽略则解压压缩包内的所有文件\n\n\n\n下载和解压.gz或.bz2文件\n这两个压缩文件与前面的相比，是最与众不同的，因为这两种后缀的文件，可以称之为压缩文件，也可以直接作为一个数据文件进行读取。\n\n#下载gz文件\ndownload.file(\"http://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/refGene.txt.gz\"#下载地址\n              ,destfile=\"refGene.txt.gz\")#文件名，注意需要添加后缀名\n#直接以数据的形式读取.gz文件\nmydata&lt;-read.table(\"refGene.txt.gz\")"
  },
  {
    "objectID": "r_basic/data_input_output.html#列出指定目录中的文件",
    "href": "r_basic/data_input_output.html#列出指定目录中的文件",
    "title": "3  数据的读取与输出",
    "section": "3.7 列出指定目录中的文件",
    "text": "3.7 列出指定目录中的文件\n\nlist.files(\"folder_name\",#需要列出的文件所在的路径,若忽略此项则列出当前工作路径下的所有文件\n          pattern = \"\\\\.docx$\",#列出当前目录中以.docx结尾的文件（列出以G开头的文件\"^G\"）\n          full.names = T)#FALSE：仅输出文件名；TRUE(默认)：输出路径+文件名"
  },
  {
    "objectID": "r_basic/data_input_output.html#生成数据框",
    "href": "r_basic/data_input_output.html#生成数据框",
    "title": "3  数据的读取与输出",
    "section": "3.8 生成数据框",
    "text": "3.8 生成数据框\n\nframdata &lt;- data.frame(y=c(6, 8, 12, 14, 14, 15, 17, 22, 24, 23),\n                       x1=c(2, 5, 4, 3, 4, 6, 7, 5, 8, 9),\n                       x2=c(14, 12, 12, 13, 7, 8, 7, 4, 6, 5))\nframdata\n\n#使用文本编辑器直接在窗口中编辑数据。macOS需要安装XQuartz（www.xquartz.org）才能运行此代码。\nframdata &lt;- edit(framdata)"
  },
  {
    "objectID": "r_basic/data_input_output.html#导出表格",
    "href": "r_basic/data_input_output.html#导出表格",
    "title": "3  数据的读取与输出",
    "section": "3.9 导出表格",
    "text": "3.9 导出表格\n\n导出csv文件\n\nwrite.csv(mydata,\n          row.names=F,#是否输出行名称\n          \"mydata.csv\")\n\n\n\n导出excel文件\n\nlibrary(openxlsx2)\nwrite_xlsx(coxtable1,\"coxtable1.xlsx\")"
  },
  {
    "objectID": "r_basic/basic_data_function.html#数据展示",
    "href": "r_basic/basic_data_function.html#数据展示",
    "title": "\n4  数据处理基本函数\n",
    "section": "\n4.1 数据展示",
    "text": "4.1 数据展示\n载入示例数据：\n\nmydata &lt;- readRDS(\"data/lms_ess.rds\")\n\n展示最大值、最小值、平均数、中位数、缺失值数量\n\nsummary(mydata)\n\n   year           year2          age            race                 marriage  \n 2010:111   2010-2011:216   Min.   :23.00   White :554   Married         :386  \n 2011:105   2012-2013:217   1st Qu.:48.00   Black : 99   Single/Unmarried:166  \n 2012:118   2014-2016:300   Median :55.00   Others: 76   Others          :148  \n 2013: 99                   Mean   :55.77   NA's  :  4   NA's            : 33  \n 2014:100                   3rd Qu.:64.00                                      \n 2015:101                   Max.   :95.00                                      \n 2016: 99                                                                      \n                                    grade            grade2      tumor_size   \n Well differentiated; Grade I          : 58   Low-grade :181   Min.   :  4.0  \n Moderately differentiated; Grade II   :123   High-grade:323   1st Qu.: 60.0  \n Poorly differentiated; Grade III      :105   Gx        :229   Median : 95.0  \n Undifferentiated; anaplastic; Grade IV:218                    Mean   :107.9  \n NA's                                  :229                    3rd Qu.:135.0  \n                                                               Max.   :950.0  \n                                                               NA's   :79     \n  his      T_stage   T_stage_plus N_stage    M_stage   figo       figo_plus  \n LMS:448   T1:499   T1b    :340   N0  :680   M0:628   I  :442   IB     :290  \n ESS:285   T2:131   T1a    :114   N1  : 49   M1:105   II : 82   IA     :109  \n           T3: 85   T2a    : 67   NA's:  4            III: 89   IVB    :105  \n           T4: 18   T3a    : 57                       IV :120   IIIA   : 39  \n                    T2b    : 55                                 IIIC   : 32  \n                    T1     : 45                                 (Other): 30  \n                    (Other): 55                                 NA's   :128  \n        peri         surg       alnd       plnd       lnd        rad     \n Negtive  :674   TH+BSO:629   No  :586   No  :417   No  :412   No  :609  \n Malignant: 59   TH    : 47   Yes :111   Yes :282   Yes :288   Yes :117  \n                 RH/EH : 57   NA's: 36   NA's: 34   NA's: 33   NA's:  7  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n   chem     dead     status         time                    income   \n No  :365   0:365   0   :365   Min.   :  2.00   &lt;$60,000       :186  \n Yes :314   1:368   1   :332   1st Qu.: 15.00   $60,000-$74,999:293  \n NA's: 54           2   : 29   Median : 43.00   &gt;$75,000       :254  \n                    NA's:  7   Mean   : 47.53                        \n                               3rd Qu.: 76.00                        \n                               Max.   :119.00                        \n                                                                     \n\n\n展示变量数量和样本数量\n展示变量（列）数\n\ndim(mydata)[2]#dim()函数获取数据的维度，即行、列数。所以[1]输出行数，[2]输出列数\n\n[1] 26\n\nncol(mydata)#另一种方式\n\n[1] 26\n\n\n展示行数\n\ndim(mydata)[1]\n\n[1] 733\n\n#或者\nnrow(mydata)\n\n[1] 733\n\n\n综合展示\n\nprint(paste0(\"该数据集有 \",dim(mydata)[1],\" 个样本； \",dim(mydata)[2],\" 个变量\"))\n\n[1] \"该数据集有 733 个样本； 26 个变量\"\n\n\n展示所有变量名\n\ncolnames(mydata)\n\n [1] \"year\"         \"year2\"        \"age\"          \"race\"         \"marriage\"    \n [6] \"grade\"        \"grade2\"       \"tumor_size\"   \"his\"          \"T_stage\"     \n[11] \"T_stage_plus\" \"N_stage\"      \"M_stage\"      \"figo\"         \"figo_plus\"   \n[16] \"peri\"         \"surg\"         \"alnd\"         \"plnd\"         \"lnd\"         \n[21] \"rad\"          \"chem\"         \"dead\"         \"status\"       \"time\"        \n[26] \"income\"      \n\n#或者通过dput函数将所有变量名输出为向量\ndput(names(mydata))\n\nc(\"year\", \"year2\", \"age\", \"race\", \"marriage\", \"grade\", \"grade2\", \n\"tumor_size\", \"his\", \"T_stage\", \"T_stage_plus\", \"N_stage\", \"M_stage\", \n\"figo\", \"figo_plus\", \"peri\", \"surg\", \"alnd\", \"plnd\", \"lnd\", \"rad\", \n\"chem\", \"dead\", \"status\", \"time\", \"income\")\n\n\n展示所有行名称\n\n```{r}\n#| eval: false\nrownames(mydata)\n```\n\n展示某个变量的所有值及其频数\n\ntable(mydata$his)\n\n\nLMS ESS \n448 285 \n\nhist(mydata$age,col=\"coral\")#以直方图的形式展示\n\n\n\n\n展示缺失值的构成\n加载案例数据：这里用VIM包内自带的sleep数据集为例进行演示。该数据集显示了两种安眠药对10名患者的影响(与对照组相比，睡眠时间的增加量)。其中就包含了很多缺失值。\n\ndata(sleep, package=\"VIM\")\nhead(sleep)\n\n   BodyWgt BrainWgt NonD Dream Sleep Span Gest Pred Exp Danger\n1 6654.000   5712.0   NA    NA   3.3 38.6  645    3   5      3\n2    1.000      6.6  6.3   2.0   8.3  4.5   42    3   1      3\n3    3.385     44.5   NA    NA  12.5 14.0   60    1   1      1\n4    0.920      5.7   NA    NA  16.5   NA   25    5   2      3\n5 2547.000   4603.0  2.1   1.8   3.9 69.0  624    3   5      4\n6   10.550    179.5  9.1   0.7   9.8 27.0  180    4   4      4\n\n\n首先展示缺失值的比例。\n\n左侧直方图展示单个变量的缺失比例，其中NonD缺失比例大于20%。\n右侧直方图展示各个变量的缺失模式。如第一行表示NonD、Dream和Span 3个变量共同缺失的比例为1.6%。NonD的缺失比例=1.6%+3.2%+3.2%+14.5%=22.5%。所有变量均无缺失值的个案占67.7%\n\n输出的结果部分同样展示了各个变量缺失的具体比例\n\nlibrary(VIM)\naggr_plot&lt;-aggr(sleep,\n                prop=T,\n                numbers=T,\n                sortVars=TRUE,\n                gap=2,\n                ylab=c(\"Histogram of missing data\",\"Pattern\"))\n\n\n\n\n\n Variables sorted by number of missings: \n Variable      Count\n     NonD 0.22580645\n    Dream 0.19354839\n    Sleep 0.06451613\n     Span 0.06451613\n     Gest 0.06451613\n  BodyWgt 0.00000000\n BrainWgt 0.00000000\n     Pred 0.00000000\n      Exp 0.00000000\n   Danger 0.00000000\n\n\n展示缺失值的数量。输出的结果部分展示了各个变量缺失的具体数量。\n\naggr_plot&lt;-aggr(sleep,\n                prop=F,\n                numbers=T,\n                sortVars=TRUE,\n                gap=2,\n                ylab=c(\"Histogram of missing data\",\"Pattern\"))\n\n\n\n\n\n Variables sorted by number of missings: \n Variable Count\n     NonD    14\n    Dream    12\n    Sleep     4\n     Span     4\n     Gest     4\n  BodyWgt     0\n BrainWgt     0\n     Pred     0\n      Exp     0\n   Danger     0\n\n\n以表格的形式展示各个变量的缺失模式（同右侧图形）\n\nsummary(aggr_plot)\n\n\n Missings per variable: \n Variable Count\n  BodyWgt     0\n BrainWgt     0\n     NonD    14\n    Dream    12\n    Sleep     4\n     Span     4\n     Gest     4\n     Pred     0\n      Exp     0\n   Danger     0\n\n Missings in combinations of variables: \n        Combinations Count   Percent\n 0:0:0:0:0:0:0:0:0:0    42 67.741935\n 0:0:0:0:0:0:1:0:0:0     3  4.838710\n 0:0:0:0:0:1:0:0:0:0     2  3.225806\n 0:0:0:0:0:1:1:0:0:0     1  1.612903\n 0:0:1:0:1:0:0:0:0:0     2  3.225806\n 0:0:1:1:0:0:0:0:0:0     9 14.516129\n 0:0:1:1:0:1:0:0:0:0     1  1.612903\n 0:0:1:1:1:0:0:0:0:0     2  3.225806\n\n\n通过marginplot分析缺失值。空心的湖蓝色圆圈表示非缺失值，红色实心圆圈表示缺失值，深红色实心圆圈表示两个变量均缺失。图左侧的红色箱型图显示了在保留NonD缺失值的情况下Dream的分布，蓝色箱型图显示了删除NonD缺失值后Dream的分布。图表底部的框图正好相反，反映了在保留和删除Dreamq缺失值的情况下NonD的分布情况。如果数据是完全随机缺失(MCAR : missing completely at random)，那么红色和蓝色箱型图将十分接近\n\nmarginplot(sleep[3:4])\n\n\n\n\n删除所有缺失值\n\nsleep&lt;-na.omit(sleep)"
  },
  {
    "objectID": "r_basic/basic_data_function.html#数据整理",
    "href": "r_basic/basic_data_function.html#数据整理",
    "title": "\n4  数据处理基本函数\n",
    "section": "\n4.2 数据整理",
    "text": "4.2 数据整理\n排序\n\nlibrary(dplyr)\nmydata &lt;- arrange(mydata, age)#按照某列升序排序\nmydata$age[1:10]\n\n [1] 23 24 24 24 26 27 27 27 27 28\n\nmydata &lt;- arrange(mydata, desc(age))#按照某列降序排序\nmydata$age[1:10]\n\n [1] 95 92 89 87 85 85 85 84 82 82\n\nmydata &lt;- arrange(mydata, his, tumor_size)#根据多列排序\nmydata[1:5,c(\"his\", \"tumor_size\")]\n\n  his tumor_size\n1 LMS         10\n2 LMS         12\n3 LMS         12\n4 LMS         15\n5 LMS         17\n\nmydata[445:455,c(\"his\", \"tumor_size\")]\n\n    his tumor_size\n445 LMS         NA\n446 LMS         NA\n447 LMS         NA\n448 LMS         NA\n449 ESS          4\n450 ESS          5\n451 ESS          5\n452 ESS          9\n453 ESS         10\n454 ESS         10\n455 ESS         12\n\n\n也可用自带base包内的order()函数排序：\n\nmydata &lt;- mydata[order(mydata$age),]\nmydata &lt;- mydata[order(-mydata$age),]\nmydata &lt;- mydata[order(mydata$age, mydata$his, mydata$tumor_size),]\n\n重新命名行、列\n重新命名变量（列）\n\nnames(mydata) &lt;- c(\"N\",\"patient_ID\",\"diagnosis\") # 连续命名\ncolnames(mydata)[2] &lt;- 'patient_ID'# 重新命名指定列名\n\n设置行名\n\nrownames(mydata) &lt;- mydata$ID # 将ID列设置为行名（注意不能有重复值）\n\n数据筛选\n提取某几列数据形成新的数据集\n\nvnumber &lt;- mydata[, 4:16] # 提取第4-16列的数据形成新的“vnumber”数据集\nvnumber &lt;- mydata[,c(2:12,16)] # 提取2-12列和第16列的数据\n\n提取指定行数的数据\n\nmydata_less &lt;- mydata[1:100, ]#提取1-100行的数据\n\n筛选数据\n筛选出低级别、接受了放疗的病例，并生成新的”new_data”数据集\n\n#方法一\nnew_data&lt;-subset(mydata,grade == \"Well differentiated; Grade I\" & rad == \"Yes\")\nnew_data[,c(\"grade\", \"rad\")]\n\n                           grade rad\n140 Well differentiated; Grade I Yes\n160 Well differentiated; Grade I Yes\n486 Well differentiated; Grade I Yes\n541 Well differentiated; Grade I Yes\n593 Well differentiated; Grade I Yes\n697 Well differentiated; Grade I Yes\n\n#也可用“｜”（或者），“！”（NOT）连接\n\n#方法二\nnew_data &lt;- mydata[which((mydata$grade == \"Well differentiated; Grade I\") &\n                           (mydata$rad == \"Yes\")),] \nnew_data[,c(\"grade\", \"rad\")]\n\n                           grade rad\n140 Well differentiated; Grade I Yes\n160 Well differentiated; Grade I Yes\n486 Well differentiated; Grade I Yes\n541 Well differentiated; Grade I Yes\n593 Well differentiated; Grade I Yes\n697 Well differentiated; Grade I Yes\n\n\n合并两个数据集\n纵向合并\n即增加个案，要求两个数据集具有相同的列名及列数\n\nrbind_data &lt;- rbind(mydata, mydata2)\n\n横向合并\n直接通过cbind()函数合并数据集，要求两个数据集具有相同的行数及顺序\n\ntotal &lt;- cbind(dataframeA, dataframeB)\n\n以某一列（如学号等）匹配两个数据集\n详细解读：https://blog.csdn.net/chongbaikaishi/article/details/115740560\n\n# 以\"probe_id\"为匹配标准匹配探针id和gene symbol\nexptab1 &lt;- merge(x = ids,\n                 y = expset1,#x、y为要合并的数据框或者对象\n                 by =\"probe_id\", #指定以哪一列为标准匹配两个数据集。\n                                 #如果有多个匹配项，则所有可能的匹配项各贡献一行。\n                 all.x=F,#是否将没有匹配到y数据集的行也保留下来，并以NA替代。\n                         #默认为FALSE，只有x与y数据框相匹配的行会被包含在输出结果中\n                 all.y=F)#与上面类似\n\n如果两个数据集要用来匹配的列的列名不同则可用by.x和by.y指定。如下面的代码就是用id2symbol数据集中的ENSEMBL列去匹配rawcount数据集中的GeneID列\n\nrawcount &lt;- merge(id2symbol,\n                  rawcount,\n                  by.x=\"ENSEMBL\",\n                  by.y=\"GeneID\",\n                  all.y=T)#对于没有匹配到的GeneID以NA替代\n\n\n去重（保留唯一值）\n生成带有重复值的示例数据\n\nset.seed(123)\nmydata = data.frame(ID = c(1:10,9,4,4,9,9,2), y = rnorm(16))\nmydata &lt;- rbind(mydata, mydata)\nmydata\n\n   ID           y\n1   1 -0.56047565\n2   2 -0.23017749\n3   3  1.55870831\n4   4  0.07050839\n5   5  0.12928774\n6   6  1.71506499\n7   7  0.46091621\n8   8 -1.26506123\n9   9 -0.68685285\n10 10 -0.44566197\n11  9  1.22408180\n12  4  0.35981383\n13  4  0.40077145\n14  9  0.11068272\n15  9 -0.55584113\n16  2  1.78691314\n17  1 -0.56047565\n18  2 -0.23017749\n19  3  1.55870831\n20  4  0.07050839\n21  5  0.12928774\n22  6  1.71506499\n23  7  0.46091621\n24  8 -1.26506123\n25  9 -0.68685285\n26 10 -0.44566197\n27  9  1.22408180\n28  4  0.35981383\n29  4  0.40077145\n30  9  0.11068272\n31  9 -0.55584113\n32  2  1.78691314\n\n\n通过duplicated()函数检查某一列是否有重复值，及有多少重复值\n\ntable(duplicated(mydata$ID))\n\n\nFALSE  TRUE \n   10    22 \n\n\n通过unique()函数去除完全相同的行。unique()函数：一行的所有数据都相同认定为重复\n\nmydata &lt;- unique(mydata)\nmydata\n\n   ID           y\n1   1 -0.56047565\n2   2 -0.23017749\n3   3  1.55870831\n4   4  0.07050839\n5   5  0.12928774\n6   6  1.71506499\n7   7  0.46091621\n8   8 -1.26506123\n9   9 -0.68685285\n10 10 -0.44566197\n11  9  1.22408180\n12  4  0.35981383\n13  4  0.40077145\n14  9  0.11068272\n15  9 -0.55584113\n16  2  1.78691314\n\n\n通过distinct()函数，去除ID列重复的数据\n\nlibrary(dplyr)\nmydata &lt;- distinct(mydata, # 需要去重的数据集名称\n                   ID, # 按照哪一列去重（可为多个条件）\n                   .keep_all = T) # 去重后保留所有列\nmydata\n\n   ID           y\n1   1 -0.56047565\n2   2 -0.23017749\n3   3  1.55870831\n4   4  0.07050839\n5   5  0.12928774\n6   6  1.71506499\n7   7  0.46091621\n8   8 -1.26506123\n9   9 -0.68685285\n10 10 -0.44566197\n\n\n变量的赋值/替换\n\nsavdata$low &lt;- ifelse(savdata$low ==\"低出生体重\", 1, 0)#将结局变量low赋值为0和1\nmydata[is.na(mydata)] &lt;- \"Unknown\"#替换缺失值\n\n当需要对一个数据集的多个变量进行转换时，可通过within(data, {expression})函数将括号内的操作限定到当前数据集中，避免”$“的反复使用，简化代码。函数within()与函数with()类似，不同的是within()允许你修改数据框:\n\nmydata &lt;- within(mydata, {\n  ID &lt;- ifelse(ID &lt; 5, \"A\", \"B\")\n  y &lt;- ifelse(y &lt; 0, \"A\", \"B\")\n})\nmydata\n\n   ID y\n1   A A\n2   A A\n3   A B\n4   A B\n5   B B\n6   B B\n7   B B\n8   B A\n9   B A\n10  B A\n\n\n转换变量类型\n将结局变量转换成因子变量,ordered=F,用于定义无序多分类变量，起到设置哑变量的作用；ordered=T用于定义有序多分类变量。如果变量的取值以英文字符表示，那么默认以变量首字母的顺序编号赋值；如果变量的取值已经转换成数字，那么默认按照编号的大小依次赋值。可以通过指定”levels”选项来覆盖默认排序。\n\nsavdata$stage &lt;- factor(savdata$stage, \n                        levels = c(1,2,3,4),\n                        labels = c(\"I\",\"II\",\"III\",\"IV\"),\n                        ordered = T)\nsavdata$stage &lt;- relevel(savdata$stage,ref=\"IV\") # 设置因子的参照水平，仅限无序因子变量\n\n通过lapply函数批量转换因子变量\n\nmydata[2:14] &lt;- lapply(mydata[2:14], factor) # 转换几个连续列的因子变量\n\n批量转换多个指定因子变量\n\ncatvars&lt;-c(\"year\", \"race\", \"single\", \"grade\", \"T_stage\", \"N_stage\", \"M_stage\",\n           \"surgery\", \"lymphadenectomy\", \"radiotherapy\", \"chemotherapy\")\nmydata[catvars] &lt;- lapply(mydata[catvars], factor)\n\n转换为数值型变量\n\nmydata$grade &lt;- as.numeric(mydata$grade)\nmydata = lapply(mydata, as.numeric) # 将所有的变量转换成数值型\n\n哑变量设置\n\n# 因种族为无序多分类变量，需要设置三个哑变量（race1～3）\nsavdata$race1 &lt;- ifelse(savdata$race == \"白种人\", 1, 0)\nsavdata$race2 &lt;- ifelse(savdata$race == \"黑种人\", 1, 0)\nsavdata$race3 &lt;- ifelse(savdata$race == \"其他种族\", 1, 0)"
  },
  {
    "objectID": "r_basic/basic_data_function.html#数学函数",
    "href": "r_basic/basic_data_function.html#数学函数",
    "title": "\n4  数据处理基本函数\n",
    "section": "\n4.3 数学函数",
    "text": "4.3 数学函数\n\nabs(-4) #取绝对值\n\n[1] 4\n\nsqrt(16) #开平方根\n\n[1] 4\n\nlog(4,base=2) #取2为底的对数\n\n[1] 2\n\nlog10(100) #取10为底的对数\n\n[1] 2\n\nlog(2) #取2的自然对数\n\n[1] 0.6931472\n\nexp(2) #取e的指数函数\n\n[1] 7.389056\n\n#设置小数位数\nceiling(3.14159) #取不小于x的最小整数（有小数点一律进一位）\n\n[1] 4\n\nfloor(3.99999) #取不大于x的最大整数（忽略小数点）\n\n[1] 3\n\nsprintf(\"%0.3f\", 3.14159) #四舍五入保留3位小数\n\n[1] \"3.142\"\n\nround(3.14159,digits=3) #同上。注意该函数在处理科学计数法时无法有效保留目标小数位数\n\n[1] 3.142"
  },
  {
    "objectID": "r_basic/basic_data_function.html#管道操作符的使用",
    "href": "r_basic/basic_data_function.html#管道操作符的使用",
    "title": "\n4  数据处理基本函数\n",
    "section": "\n4.4 管道操作符(%>%)的使用",
    "text": "4.4 管道操作符(%&gt;%)的使用\n％&gt;％为来自dplyr包的管道操作符（pipe operator)，我们可以将其理解为车间里的流水线，经过前一步加工的产品才能进入后一步进一步加工，其作用是将上一步的结果直接传参给下一步的函数，从而省略了中间的赋值步骤，可以大量减少内存中的对象，节省内存。\n\n将%&gt;%左边的对象传递给右边的函数，作为第一个选项的设置（或剩下唯一一个选项的设置）。\na %&gt;% f(b)等同于f(a,b)；b% &gt; %f(a,.,c)等同于f(a,b,c)\n\n【例一】\n比如我们要算f(x)=sin((x+1)^2)在x=4的值，可以分为以下三步：\n\n计算a = x+1的值；\n计算b = a^2的值；\n计算c = sin(b)的值\n\n这样一来，c就是我们需要的最终结果了。用R语言管道传参，只需要这样写：\n\nf1 &lt;- function(x){return(x+1)}\nf2 &lt;- function(x){return(x^2)}\nf3 &lt;- function(x){return(sin(x))}\nlibrary(dplyr)\nx &lt;- 1\ny &lt;- x %&gt;% f1 %&gt;% f2 %&gt;% f3\nprint(y)\n\n[1] -0.7568025\n\n\n【例二】\n\nf1 &lt;- function(x,y){return(x+y)}\nf2 &lt;- function(x,y,z){return(x*y+z)}\nx &lt;- 2\ny &lt;- 3\nz &lt;- 4\nx %&gt;% f1(y)\n\n[1] 5\n\ny %&gt;% f2(x,.,5)\n\n[1] 11\n\nz %&gt;% f2(x,y,.)\n\n[1] 10\n\n\n【例三】日期合并\n\ndate &lt;- as.Date('2017-6-22')+0:14\nhour &lt;- sample(1:24, 15)\nmin &lt;- sample(1:60, 15)\nsecond &lt;- sample(1:60, 15)\ndat &lt;- data.frame(date,hour,min,second)\ndat\n\n         date hour min second\n1  2017-06-22   19  23     18\n2  2017-06-23    4  27     33\n3  2017-06-24   14  53     57\n4  2017-06-25   17   7     27\n5  2017-06-26   11  58     25\n6  2017-06-27    7  59     38\n7  2017-06-28   12  32     21\n8  2017-06-29   15  38     15\n9  2017-06-30   16  25     41\n10 2017-07-01   10  34     47\n11 2017-07-02   13  29     26\n12 2017-07-03   24   5     31\n13 2017-07-04    9   8     16\n14 2017-07-05   18  12     30\n15 2017-07-06   21  13      6\n\nlibrary(tidyr)\ndatstd &lt;- dat %&gt;% unite(\"datehour\",date,hour,sep = ' ',remove = T) %&gt;% unite(\"datetime\",datehour,min,second,sep = ':',remove = T)\ndatstd\n\n              datetime\n1  2017-06-22 19:23:18\n2   2017-06-23 4:27:33\n3  2017-06-24 14:53:57\n4   2017-06-25 17:7:27\n5  2017-06-26 11:58:25\n6   2017-06-27 7:59:38\n7  2017-06-28 12:32:21\n8  2017-06-29 15:38:15\n9  2017-06-30 16:25:41\n10 2017-07-01 10:34:47\n11 2017-07-02 13:29:26\n12  2017-07-03 24:5:31\n13   2017-07-04 9:8:16\n14 2017-07-05 18:12:30\n15  2017-07-06 21:13:6"
  },
  {
    "objectID": "r_basic/basic_data_function.html#apply函数家族",
    "href": "r_basic/basic_data_function.html#apply函数家族",
    "title": "\n4  数据处理基本函数\n",
    "section": "\n4.5 apply函数家族",
    "text": "4.5 apply函数家族\n主要应用apply()函数。apply()以数据帧或矩阵作为输入，并以向量、列表或数组的形式给出输出。apply()函数主要用于避免显式使用循环结构。与之类似的lapply()函数返回与输入列表对象长度相似的列表对象，其中的每个元素都是应用指定函数到列表中相应元素的结果，其作用相当于避免了for循环的使用，更适合转换数据类型等操作。\n生成案例数据\n\nmydata&lt;-matrix(1:9,ncol = 3,nrow=6)#生成一个3列、6行的矩阵数据\nmydata[3,3]&lt;-NA#生成一个缺失值\nmydata&lt;-as.data.frame(mydata)#如果要生成新的一列需要转换为数据框形式\nmydata\n\n  V1 V2 V3\n1  1  7  4\n2  2  8  5\n3  3  9 NA\n4  4  1  7\n5  5  2  8\n6  6  3  9\n\n\n计算mydata数据集中每一行的均值并添加到每一行后面\n\nmydata$Row_Means&lt;-apply(mydata,\n                        MARGIN=1,#1:对每行进行运算；2:对列进行运算；MARGIN=c(1,2)对行、列运算\n                        mean,#要应用的函数\n                        na.rm=T)#是否忽略缺失值\nmydata\n\n  V1 V2 V3 Row_Means\n1  1  7  4         4\n2  2  8  5         5\n3  3  9 NA         6\n4  4  1  7         4\n5  5  2  8         5\n6  6  3  9         6\n\n\n对mydata的第一列和第二列数据求均值\n\nmydata$Row_Means12&lt;-apply(mydata[,c(1:2)],MARGIN=1,mean,na.rm=T)\nmydata\n\n  V1 V2 V3 Row_Means Row_Means12\n1  1  7  4         4         4.0\n2  2  8  5         5         5.0\n3  3  9 NA         6         6.0\n4  4  1  7         4         2.5\n5  5  2  8         5         3.5\n6  6  3  9         6         4.5\n\n\n对mydata的每一列进行求和运算\n\nCol_Sums&lt;-apply(mydata,MARGIN=2,sum,na.rm=T)\nmydata&lt;-rbind(mydata,Col_Sums)\nmydata\n\n  V1 V2 V3 Row_Means Row_Means12\n1  1  7  4         4         4.0\n2  2  8  5         5         5.0\n3  3  9 NA         6         6.0\n4  4  1  7         4         2.5\n5  5  2  8         5         3.5\n6  6  3  9         6         4.5\n7 21 30 33        30        25.5"
  },
  {
    "objectID": "r_basic/basic_data_function.html#自定义函数",
    "href": "r_basic/basic_data_function.html#自定义函数",
    "title": "\n4  数据处理基本函数\n",
    "section": "\n4.6 自定义函数",
    "text": "4.6 自定义函数\nR语言可以自定义函数，也可以使用其自带的函数。\nR语言中，自定义函数的一般格式为：\n函数名 &lt;- function（输入1，……，输入n）{\n     函数体\n     return（返回值）\n}\n其中，return并不是必需的，默认函数体最后一行的值作为返回值，即return完全可以换成”返回值”。下面以判断score为优良及格差的代码进行讲解。案例来源：https://zhuanlan.zhihu.com/p/441710174。\n首先对于不用函数的情况\n\nscore = 73\nif(score &gt;= 90){\n  res = \"优\"\n  }else if(score &gt;=70){\n    res = \"良\"\n    }else if(score &gt;= 60){\n      res = \"及格\"\n      }else{\n        res = \"不及格\"\n        }\nres#输出判断结果\n\n[1] \"良\"\n\n\n接下来我们自定义一个scorejudge()函数实现对单个成绩对判断。实际上就是把上面的代码封装起来\n\nscorejudge&lt;-function(x){\n  if(score &gt;= 90){\n    res = \"优\"\n    }else if(score &gt;=70){\n      res = \"良\"\n      }else if(score &gt;= 60){\n        res = \"及格\"\n        }else{\n          res = \"不及格\"\n          }\n  paste0(\"该同学的分数等级为\",res)\n  }\nscorejudge(score)#就像调用R自带函数一样调用我们自己编写的函数\n\n[1] \"该同学的分数等级为良\"\n\n\n如若想要同时查询多个分数，则需要对原来的代码进行修改，加入for循环语句\n\nscorejudge&lt;-function(x){\n  n = length(x)#首先确定循环次数，即x中有多少个分数，下面的for循环就要运行多少次\n  res = vector(\"character\",n)#建立一个和输入的分数个数相同的空向量，用来放每次for循环的输出结果\n  for(i in 1:n){\n    if(x[i] &gt;= 90){\n      res[i] = paste0(i,\"号同学的分数等级为\",\"优\")\n      } else if(x[i] &gt;=70){\n        res[i] = paste0(i,\"号同学的分数等级为\",\"良\")\n        } else if(x[i] &gt;= 60){\n          res[i] = paste0(i,\"号同学的分数等级为\",\"及格\")\n          } else{\n            res[i] = paste0(i,\"号同学的分数等级为\",\"不及格\")\n          }\n    }\n  res #输出最终的res向量\n  }\nscorejudge(c(34,67,89,95))\n\n[1] \"1号同学的分数等级为不及格\" \"2号同学的分数等级为及格\"  \n[3] \"3号同学的分数等级为良\"     \"4号同学的分数等级为优\""
  },
  {
    "objectID": "r_basic/character.html#字符串的截取",
    "href": "r_basic/character.html#字符串的截取",
    "title": "\n5  字符的处理\n",
    "section": "\n5.1 字符串的截取",
    "text": "5.1 字符串的截取\n\nsubstr(\" A BC\",\n       1,#从第几个字符开始截取\n       3)#截取多少个字符\n\n[1] \" A \"\n\nsubstring(\" A BC\", 1, 3)\n\n[1] \" A \"\n\n\nsubstr()对含有空格和特殊字符如下划线的支持不好，这种情况可采用stringr包内的字符分割函数str_split()来实现。下面实现从”A_B_C”中截取”B”：\n\nlibrary(stringr)\nstr_split(\"A_B_C\",\n          \"_\",#按照什么标志切割字符\n          simplify = T)[,2] #这里把\"A_B_C\"切开后，“B\"应该位于第二个，所以通过[,2]取第二个元素\n\n[1] \"B\"\n\nstr_sub(\"A_B_C\",\n        1,\n        2)\n\n[1] \"A_\""
  },
  {
    "objectID": "r_basic/character.html#字符串的替换gsub函数",
    "href": "r_basic/character.html#字符串的替换gsub函数",
    "title": "\n5  字符的处理\n",
    "section": "\n5.2 字符串的替换（gsub函数）",
    "text": "5.2 字符串的替换（gsub函数）\n\ngsub(\"B\",#需要替换的原字符\n     \"F\",#替换成什么\n     'A_B_C_b', #替换目标\n     ignore.case=F) #是否忽略大小写。默认为FALSE\n\n[1] \"A_F_C_b\"\n\n#删掉某些字符\ngsub(\"B\",\"\",'A_B_C')\n\n[1] \"A__C\"\n\n\n\n#使用正则表达式进行高级替换\n#多个相同字符，只替换开头的字符，在目标字符左侧加“^”\ngsub(\"^B\",\"A\",'B_B_B')\n\n[1] \"A_B_B\"\n\n#多个相同字符，只替换结尾字符，在目标字符右侧加“$”\ngsub(\"B$\",\"A\",'B_B_B')\n\n[1] \"B_B_A\"\n\n#把目标字符及目标字符后面的一个字符替换掉\ngsub('D.','X',\"ABCDEFG\")\n\n[1] \"ABCXFG\"\n\n#把目标字符及目标字符后面的2个字符替换掉\ngsub('D..','X',\"ABCDEFG\")\n\n[1] \"ABCXG\"\n\n#把D及D后面的字符全部替换掉\ngsub('D.*','X',\"ABCDEFG\")\n\n[1] \"ABCX\"\n\n#替换空格，使用“\\\\s”\ngsub(\"\\\\s\",\"_\",\"A B C\")\n\n[1] \"A_B_C\"\n\n#替换不同字符，使用“|”\ngsub('B|D|G','X',\"ABCDEFG\")\n\n[1] \"AXCXEFX\"\n\n#模糊匹配替换\ngsub('[0-9]','X',\"1A2B3C4D5\")\n\n[1] \"XAXBXCXDX\"\n\ngsub('[A-Z]','X',\"1A2B3C4D5\")\n\n[1] \"1X2X3X4X5\"\n\n\n\n#大小写转换\ntoupper(\"abc\") #转换成大写\n\n[1] \"ABC\"\n\ntolower(\"ABC\") #转换成小写\n\n[1] \"abc\""
  },
  {
    "objectID": "r_basic/character.html#字符的连接",
    "href": "r_basic/character.html#字符的连接",
    "title": "\n5  字符的处理\n",
    "section": "\n5.3 字符的连接",
    "text": "5.3 字符的连接\n\npaste(\"hello\", \"world\", \"!\", sep = \" \")\n\n[1] \"hello world !\"\n\npaste(\"x\",1:3,sep=\"M\")\n\n[1] \"xM1\" \"xM2\" \"xM3\"\n\n\nunite()函数的使用\n构建案例数据\n\na1 &lt;- rep(1,5) # 重复“1” 5次\na2 &lt;- rep(2,5)\na3 &lt;- rep(3,5)\nA &lt;- data.frame(a1,a2,a3)\nA\n\n  a1 a2 a3\n1  1  2  3\n2  1  2  3\n3  1  2  3\n4  1  2  3\n5  1  2  3\n\n\n现在想对生成的数据框A里面的a1,a2和a3列进行合并，形成新”a123”列，其中a1与a2用”~“连接，a2与a3列用”/“连接。\n首先对数据A的列a1,a2合并为新列a12，用”~“连接。\n\nlibrary(tidyr)\nA1 &lt;- unite(A,#目标数据集\n            \"a12\",#新列的名称\n            a1,a2,#需要合并的列名(若用“:”连接则表示合并两列及之间的所有列)\n            sep = '~',#指定连接符\n            remove=F)#是否移除原始列\n\n#或者\nA1 &lt;- A %&gt;% unite(\"a12\",a1,a2,sep = '~',remove=F)\nA1\n\n  a12 a1 a2 a3\n1 1~2  1  2  3\n2 1~2  1  2  3\n3 1~2  1  2  3\n4 1~2  1  2  3\n5 1~2  1  2  3\n\n\n然后对A1里面的a12列与a3列用”/“连接，形成新列”a123”\n\nA2 &lt;- unite(A1,\"a123\",a12,a3,sep = '/',remove=F)\nA2\n\n   a123 a12 a1 a2 a3\n1 1~2/3 1~2  1  2  3\n2 1~2/3 1~2  1  2  3\n3 1~2/3 1~2  1  2  3\n4 1~2/3 1~2  1  2  3\n5 1~2/3 1~2  1  2  3\n\n#也可以用管道传参一步搞定\nA2 &lt;- A %&gt;% \n  unite(a12,a1,a2,sep = '~',remove=F) %&gt;% \n  unite(a123,a12,a3,sep = '/',remove=F)\nA2\n\n   a123 a12 a1 a2 a3\n1 1~2/3 1~2  1  2  3\n2 1~2/3 1~2  1  2  3\n3 1~2/3 1~2  1  2  3\n4 1~2/3 1~2  1  2  3\n5 1~2/3 1~2  1  2  3"
  },
  {
    "objectID": "r_basic/character.html#字符查找",
    "href": "r_basic/character.html#字符查找",
    "title": "\n5  字符的处理\n",
    "section": "\n5.4 字符查找",
    "text": "5.4 字符查找\n%in%指令\n它会把每个字符串当成判断的最小单位，所以不能用来判断/查找”长字符串中是否含有特定的短字符串”\n\ny &lt;- c(\"中国四川\",\"中国北京\",\"中国安徽\",\"北京天安门\")\ny\n\n[1] \"中国四川\"   \"中国北京\"   \"中国安徽\"   \"北京天安门\"\n\n\"中国四川\" %in% y\n\n[1] TRUE\n\n\"中国\" %in% y\n\n[1] FALSE\n\n\ngrep()函数\ngrep的全称是global search regular expression and print out the line,可以通过正则表达式搜索文本，并把匹配的行打印出来。所谓正则表达式，就是用某种模式去匹配一类字符串的一个公式，很多文本编辑器或者程序语言都支持该方式进行字符串的操作。下面我们用该函数首先查找y中是否有包含”北京”字样的条目，并返回其所在位置：\n\ngrep(\"北京\", #需要找找的字符\n     y,#从哪里查找\n     ignore.case=F,#是否忽略大小写，默认为FALSE\n     value=F,#默认为FALSE，表示返回匹配到的字符所在的位置；TRUE则返回查找到的值\n     invert=F)#如果为TRUE，则返回未匹配到的字符的值或位置。\n\n[1] 2 4\n\n\n查找y中包含”北京”的条目有哪些：\n\ngrep(\"北京\", y, ignore.case = F, value = T, invert = F)\n\n[1] \"中国北京\"   \"北京天安门\"\n\n\n从framdata数据集中，提取NAME包含了”TR”的个案，形成新的TR_data数据集。\n生成演示数据\n\nframdata &lt;- data.frame(ID = c(6, 8, 12, 14, 14, 15, 17, 22, 24, 23),\n                       NAME = c(\"A_CT\", \"B_CT\", \"C_CT\", \"D_CT\", \"E_TR\", \"F_TR\",\n                                \"G_TR\", \"H_TR\", \"I_TR\", \"J_TR\"),\n                       VALUE = c(14, 12, 12, 13, 7, 8, 7, 4, 6, 5))\nframdata\n\n   ID NAME VALUE\n1   6 A_CT    14\n2   8 B_CT    12\n3  12 C_CT    12\n4  14 D_CT    13\n5  14 E_TR     7\n6  15 F_TR     8\n7  17 G_TR     7\n8  22 H_TR     4\n9  24 I_TR     6\n10 23 J_TR     5\n\n\n利用该函数返回framdata中NAME列中包含了”TR”的行号\n\ngrep(\"TR\", framdata$NAME, ignore.case = F, value = F, invert = F)\n\n[1]  5  6  7  8  9 10\n\n\n下面最终实现上述目的\n\nTR_data &lt;- framdata[grep(\"TR\", framdata$NAME),]\nTR_data\n\n   ID NAME VALUE\n5  14 E_TR     7\n6  15 F_TR     8\n7  17 G_TR     7\n8  22 H_TR     4\n9  24 I_TR     6\n10 23 J_TR     5\n\n\ngrepl()函数\ngrep()和grepl()这两个函数最大的区别在于grep()返回找到的位置，grepl返回【是否】包含要查找的内容的逻辑向量。\n\ngrepl(\"北京\", y)\n\n[1] FALSE  TRUE FALSE  TRUE\n\nany(grepl(\"北京\", y))#只要y中有包含了“北京”的项目就返回一个\"TRUE\"\n\n[1] TRUE"
  },
  {
    "objectID": "single_cell/seurat/seurat.html#changes-in-seurat-v5",
    "href": "single_cell/seurat/seurat.html#changes-in-seurat-v5",
    "title": "Seurat v5官方文档",
    "section": "Changes in Seurat v5",
    "text": "Changes in Seurat v5\nWe are excited to release Seurat v5 on CRAN, where it is now the default version for new installs. Seurat v5 is designed to be backwards compatible with Seurat v4 so existing code will continue to run, but we have made some changes to the software that will affect user results. We note that users who aim to reproduce their previous workflows in Seurat v4 can still install this version using the instructions on our install page.\nIn particular, we have made changes to:\n\nSeurat Object and Assay class:\nSeurat v5 now includes support for additional assay and data types, including on-disk matrices. To facilitate this, we have introduced an updated Seurat v5 assay. Briefly, Seurat v5 assays store data in layers (previously referred to as ‘slots’).\nFor example, these layers can store: raw counts (layer='counts'), normalized data (layer='data'), or z-scored/variance-stabilized data (layer='scale.data').\nData can be accessed using the $ accessor (i.e. obj[[\"RNA\"]]$counts), or the `LayerData function (i.e. LayerData(obj, assay=\"RNA\", layer='counts').\nWe’ve designed these updates to minimize changes for users. Existing Seurat functions and workflows from v4 continue to work in v5. For example, the command GetAssayData(obj, assay=\"RNA\", slot='counts'), will run successfully in both Seurat v4 and Seurat v5.\nIntegration workflow:\nSeurat v5 introduces a streamlined integration ( Chapter 11 ) and data transfer ( Chapter 12 ) workflows that performs integration in low-dimensional space, and improves speed and memory efficiency. The results of integration are not identical between the two workflows, but users can still run the v4 integration workflow in Seurat v5 if they wish.\nIn previous versions of Seurat, the integration workflow required a list of multiple Seurat objects as input. In Seurat v5, all the data can be kept as a single object, but prior to integration, users can simply split the layers. See ( Chapter 10 ) for more information.\nDifferential expression:\nSeurat v5 now uses the presto package (from the Korunsky and Raychaudhari labs), when available, to perform differential expression analysis. Using presto can dramatically speed up DE testing, and we encourage users to install it.\nIn addition, in Seurat v5 we implement a pseudocount (when calculating log-FC) at the group level instead of the cell level. As a result, users will observe higher logFC estimates in v5 - but should note that these estimates may be more unstable - particularly for genes that are very lowly expressed in one of the two groups. We gratefully acknowledge feedback from the McCarthy and Pachter labs on this topic.\nSCTransform v2:\nIn (Choudhary and Satija 2022), we implement an updated version 2 of sctransform. This is now the default version when running SCTransform in Seurat v5. Users who wish to run the previous workflow can set the vst.flavor = \"v1\" argument in the SCTransform function.\nPseudobulk analysis:\nOnce a single-cell dataset has been analyzed to annotate cell subpopulations, pseudobulk analyses (i.e. aggregating together cells within a given subpopulation and sample) can reduce noise, improve quantification of lowly expressed genes, and reduce the size of the data matrix. In Seurat v5, we encourage the use of the AggregateExpression function to perform pseudobulk analysis.\nCheck out Chapter 14 as well as  pancreatic/healthy PBMC comparison, for examples of how to use AggregateExpression to perform robust differential expression of scRNA-seq data from multiple different conditions.\n\n\n\n\n\n\n\nChoudhary, Saket, and Rahul Satija. 2022. “Comparison and Evaluation of Statistical Error Models for scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9."
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html#标准seurat流程",
    "href": "single_cell/seurat/seurat_command_list.html#标准seurat流程",
    "title": "\n6  Seurat常用函数清单\n",
    "section": "\n6.1 标准Seurat流程：",
    "text": "6.1 标准Seurat流程：\n\npbmc &lt;- NormalizeData(object = pbmc)\npbmc &lt;- FindVariableFeatures(object = pbmc)\npbmc &lt;- ScaleData(object = pbmc)\npbmc &lt;- RunPCA(object = pbmc)\npbmc &lt;- FindNeighbors(object = pbmc, dims = 1:30)\npbmc &lt;- FindClusters(object = pbmc)\npbmc &lt;- RunUMAP(object = pbmc, dims = 1:30)\nDimPlot(object = pbmc, reduction = \"umap\")\n\n采用SCtransform标准化时的流程：\n\npbmc &lt;- SCTransform(object = pbmc)\npbmc &lt;- RunPCA(object = pbmc)\npbmc &lt;- FindNeighbors(object = pbmc, dims = 1:30)\npbmc &lt;- FindClusters(object = pbmc)\npbmc &lt;- RunUMAP(object = pbmc, dims = 1:30)\nDimPlot(object = pbmc, reduction = \"umap\")\n\n或者通过管道函数：\n\npbmc &lt;- SCTransform(pbmc) %&gt;%\n    RunPCA() %&gt;%\n    FindNeighbors(dims = 1:30) %&gt;%\n    FindClusters() %&gt;%\n    RunUMAP(dims = 1:30)"
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html#提取seurat对象内的各数据",
    "href": "single_cell/seurat/seurat_command_list.html#提取seurat对象内的各数据",
    "title": "\n6  Seurat常用函数清单\n",
    "section": "\n6.2 提取Seurat对象内的各数据：",
    "text": "6.2 提取Seurat对象内的各数据：\n获取所有细胞的barcode：\n\ncolnames(pbmc)\nCells(pbmc) # 效果同上\n\n获取所有的基因（feature）名：\n\nFeatures(pbmc)\nrownames(pbmc) # 同上\n\n获取细胞和基因的数量：\n\nncol(pbmc) # 细胞数量\nnrow(pbmc) # 基因（feature）数量\n\nList of object layers：\n\nLayers(pbmc)\n\n获取运行FindVariableFeatures函数之后的高变基因列表（ Section 7.4 ）：\n\nVariableFeatures(pbmc)"
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html#细胞注释信息cell-identities设置",
    "href": "single_cell/seurat/seurat_command_list.html#细胞注释信息cell-identities设置",
    "title": "\n6  Seurat常用函数清单\n",
    "section": "\n6.3 细胞注释信息（cell identities）设置",
    "text": "6.3 细胞注释信息（cell identities）设置\n查看cell identities：\n\nIdents(pbmc)\ntable(Idents(pbmc))\n\n将meta.data中的”seurat_clusters”列设置为cell identities：\n\nIdents(object = pbmc) &lt;- \"seurat_clusters\"\n\n将目前的cell identities保存到meta.data新的一列中：\n\npbmc[[\"old.ident\"]] &lt;- Idents(pbmc) # 将目前的cell identities储存到meta.data的\"old.ident\"列中\n\n重命名某个细胞注释：\n\npbmc &lt;- RenameIdents(object = pbmc, \n                     `FCGR3A+ Mono` = \"monocyte\")"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#seurat对象构建",
    "href": "single_cell/seurat/seurat_tutorial.html#seurat对象构建",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.1 Seurat对象构建",
    "text": "7.1 Seurat对象构建\n数据源是来自10X Genomics的外周血单核细胞（peripheral blood mononuclear cells，PBMC）数据集。该数据集基于Illumina NextSeq 500平台对2700个单细胞进行了测序。数据可在此链接下载。\n\n\n10X数据的标准文件\n\n该数据已经通过cellranger上游数据处理流程的处理，返回的数据是一个由唯一分子识别（unique molecular identified，UMI）构成的count矩阵。该矩阵中的值表示在每个细胞（列）中检测到的每个特征（即基因；行）的分子数量。数据以10X的标准形式储存，包括：\n\n\nbarcode文件：细胞条码。\n\n\n\ngenes文件：基因名文件。\n\n\nmatrix文件：表达矩阵（稀疏矩阵）。\n\n\nlibrary(Seurat)\n\n# 读取PBMC数据集\npbmc.data &lt;- Read10X(data.dir = \"data/filtered_gene_bc_matrices/hg19\")\n# Initialize the Seurat object with the raw (non-normalized data).\npbmc &lt;- CreateSeuratObject(counts = pbmc.data, \n                           project = \"pbmc3k\", \n                           min.cells = 3, \n                           min.features = 200)\npbmc\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 0 variable features)\n 1 layer present: counts\n\n\n\n\n\n\n\n\nCaution\n\n\n\n有的cellranger处理数据以h5文件格式输出，需要使用seurat中的Read10X_h5()函数读取该格式。"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#质控",
    "href": "single_cell/seurat/seurat_tutorial.html#质控",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.2 质控",
    "text": "7.2 质控\n在 (Ilicic et al. 2016) 中概括了目前常用的单细胞数据分析中识别低质量细胞的标准，包括：\n\n\nThe number of unique genes detected in each cell.\n\nLow-quality cells or empty droplets will often have very few genes\nCell doublets or multiplets may exhibit an aberrantly high gene count\n\n\nSimilarly, the total number of molecules detected within a cell (correlates strongly with unique genes)\n\nThe percentage of reads that map to the mitochondrial genome\n\nLow-quality / dying cells often exhibit extensive mitochondrial contamination\nWe calculate mitochondrial QC metrics with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features\nWe use the set of all genes starting with MT- as a set of mitochondrial genes\n\n\n\n计算线粒体基因比例\n通过PercentageFeatureSet函数计算每个细胞中线粒体基因的比例，并将其返回到Seurat对象的meta.data中，形成一个新列”percent.mt”。\n\npbmc[[\"percent.mt\"]] &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\")\n# Show QC metrics for the first 5 cells\nhead(pbmc@meta.data, 5)\n\n                 orig.ident nCount_RNA nFeature_RNA percent.mt\nAAACATACAACCAC-1     pbmc3k       2419          779  3.0177759\nAAACATTGAGCTAC-1     pbmc3k       4903         1352  3.7935958\nAAACATTGATCAGC-1     pbmc3k       3147         1129  0.8897363\nAAACCGTGCTTCCG-1     pbmc3k       2639          960  1.7430845\nAAACCGTGTATGCG-1     pbmc3k        980          521  1.2244898\n\n\n可视化质控指标\n通过VlnPlot函数绘制小提琴图展示每个细胞中UMI（nCount_RNA）、基因（percent.mt）和线粒体基因（percent.mt）的数量。\n\n# Visualize QC metrics as a violin plot\nVlnPlot(pbmc, \n        features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), \n        ncol = 3)\n\n\n\n\n通过FeatureScatter函数展示UMI和线粒体基因数量多关系、UMI和总基因数量多关系。\n\nplot1 &lt;- FeatureScatter(pbmc, \n                        feature1 = \"nCount_RNA\", \n                        feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(pbmc, \n                        feature1 = \"nCount_RNA\", \n                        feature2 = \"nFeature_RNA\")\nplot1 + plot2\n\n\n\n\n过滤细胞\n在本案例中使用的质控标准：\n\nfilter cells that have unique feature counts over 2,500 or less than 200\nfilter cells that have &gt;5% mitochondrial counts\n\n\npbmc &lt;- subset(pbmc, \n               subset = nFeature_RNA &gt; 200 & nFeature_RNA &lt; 2500 & percent.mt &lt; 5)\npbmc\n\nAn object of class Seurat \n13714 features across 2638 samples within 1 assay \nActive assay: RNA (13714 features, 0 variable features)\n 1 layer present: counts"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#标准化normalizing",
    "href": "single_cell/seurat/seurat_tutorial.html#标准化normalizing",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.3 标准化（Normalizing）",
    "text": "7.3 标准化（Normalizing）\nAfter removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. 标准化的方法是每个细胞中的基因表达量除以该细胞的基因总表达量，然后乘以比例因子（通常是1000），最后将这个结果取对数。\n\npbmc &lt;- NormalizeData(pbmc, \n                      normalization.method = \"LogNormalize\", \n                      scale.factor = 10000)\n\nIn Seurat v5, Normalized values are stored in pbmc[[\"RNA\"]]$data：\n\n\n\n\n\n\n\nTip\n\n\n\nWhile this method of normalization is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that each cell originally contains the same number of RNA molecules. We and others have developed alternative workflows for the single cell preprocessing that do not make these assumptions.\nSCTransform() normalization workflow 就是这样的一种工作流. 针对这一方法的原始文献：(Choudhary and Satija 2022a) 。基于SCTransform的数据标准化流程中，无需使用上面的NormalizeData, 和下面的FindVariableFeatures和ScaleData函数。详见后面的章节（ Chapter 9 ）。"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#sec-识别高变基因",
    "href": "single_cell/seurat/seurat_tutorial.html#sec-识别高变基因",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.4 识别高变基因（highly variable features）",
    "text": "7.4 识别高变基因（highly variable features）\nWe next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). We and others (Brennecke et al. 2013) have found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.\nOur procedure in Seurat is described in detail here (Stuart et al. 2019) , and improves on previous versions by directly modeling the mean-variance relationship inherent in single-cell data, and is implemented in the FindVariableFeatures() function. By default, we return 2,000 features per dataset. These will be used in downstream analysis, like PCA.\n\npbmc &lt;- FindVariableFeatures(pbmc, \n                             selection.method = \"vst\", \n                             nfeatures = 2000)\n\n# Identify the 10 most highly variable genes\ntop10 &lt;- head(VariableFeatures(pbmc), 10)\n\n# plot variable features with and without labels\nplot1 &lt;- VariableFeaturePlot(pbmc)\nplot1\nLabelPoints(plot = plot1, points = top10, repel = TRUE)\n\n\n\n\n\n(A) 前2000个高变基因\n\n\n\n\n\n(B) 前2000个高变基因（标注了前10个高变基因）\n\n\n\nFigure 7.1: 识别高变基因"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#sec-scaledata",
    "href": "single_cell/seurat/seurat_tutorial.html#sec-scaledata",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.5 归一化（Scaling）",
    "text": "7.5 归一化（Scaling）\nNext, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function:\n\nShifts the expression of each gene, so that the mean expression across cells is 0（每个基因在所有细胞的平均表达量为0）\nScales the expression of each gene, so that the variance across cells is 1. This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate\n\n\npbmc &lt;- ScaleData(pbmc)\n\nThe results of this are stored in pbmc[[\"RNA\"]]$scale.data:\n\nScaleData函数默认情况下使用FindVariableFeatures函数确定的高变基因作为scale依据。可以通过features参数来自定义scale依据，比如这里我们可以让所有基因都参与scale：\n\n# 不运行\nall.genes &lt;- rownames(pbmc)\npbmc &lt;- ScaleData(pbmc, features = all.genes)\n\n\n\n\n\n\n\n去除单细胞数据中的非期望变异来源\n\n\n\nIn Seurat, we also use the ScaleData() function to remove unwanted sources of variation from a single-cell dataset. For example, we could ‘regress out’ heterogeneity associated with (for example) cell cycle stage, or mitochondrial contamination i.e.:\n\npbmc &lt;- ScaleData(pbmc, vars.to.regress = \"percent.mt\")\n\nHowever, particularly for advanced users who would like to use this functionality, we strongly recommend the use of our new normalization workflow, SCTransform(). The method is described in our paper (Choudhary and Satija 2022b). As with ScaleData(), the function SCTransform() also includes a vars.to.regress parameter."
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#线性降维",
    "href": "single_cell/seurat/seurat_tutorial.html#线性降维",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.6 线性降维",
    "text": "7.6 线性降维\nNext we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset (if you do want to use a custom subset of features, make sure you pass these to ScaleData first).\n\npbmc &lt;- RunPCA(pbmc, \n               features = VariableFeatures(object = pbmc))\n\nFor the first principal components, Seurat outputs a list of genes with the most positive and negative loadings, representing modules of genes that exhibit either correlation (or anti-correlation) across single-cells in the dataset.\n\n# PC_ 1 \n# Positive:  CST3, TYROBP, LST1, AIF1, FTL, FTH1, LYZ, FCN1, S100A9, TYMP \n#      FCER1G, CFD, LGALS1, LGALS2, SERPINA1, S100A8, CTSS, IFITM3, SPI1, CFP \n#      PSAP, IFI30, COTL1, SAT1, S100A11, NPC2, GRN, LGALS3, GSTP1, PYCARD \n# Negative:  MALAT1, LTB, IL32, IL7R, CD2, B2M, ACAP1, CTSW, STK17A, CD27 \n#      CD247, CCL5, GIMAP5, GZMA, AQP3, CST7, TRAF3IP3, SELL, GZMK, HOPX \n#      MAL, MYC, ITM2A, ETS1, LYAR, GIMAP7, KLRG1, NKG7, ZAP70, BEX2 \n\n完成PCA分析的Seurat对象：\n\n降维可视化\nSeurat provides several useful ways of visualizing both cells and features that define the PCA, including VizDimReduction(), DimPlot(), and DimHeatmap() .\n\nVizDimLoadings(pbmc, dims = 1:2, reduction = \"pca\")\n\n\n\n\n\nDimPlot(pbmc, reduction = \"pca\") + NoLegend()\n\n\n\n\nIn particular DimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores.\nSetting cells to a number, will plot the ‘extreme’ cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets.\n\nDimHeatmap(pbmc, dims = 1, cells = 1000, balanced = TRUE)\n\n\n\n\n通过dims参数指定一个范围内的主成分，可以用来决定在后续的分析中应该包括哪些主成分。\n\nDimHeatmap(pbmc, dims = 1:15, cells = 1000, balanced = TRUE)\n\n\n\n\n决定后续分析的主成分\nTo overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many components should we choose to include? 10? 20? 100?\nIn Macosko et al (Macosko et al. 2015a), we implemented a resampling test inspired by the JackStraw procedure. While still available in Seurat, this is a slow and computationally expensive procedure, and we is no longer routinely used in single cell analysis.\nAn alternative heuristic method generates an ‘Elbow plot’: a ranking of principle components based on the percentage of variance explained by each one. In this example, we can observe an ‘elbow’ around PC9-10, suggesting that the majority of true signal is captured in the first 10 PCs.\n\nElbowPlot(pbmc)\n\n\n\n\n\n\n\n\n\n\nIdentifying the true dimensionality of a dataset\n\n\n\n\n\nIdentifying the true dimensionality of a dataset can be challenging/uncertain for the user. We therefore suggest these multiple approaches for users. The first is more supervised, exploring PCs to determine relevant sources of heterogeneity, and could be used in conjunction with GSEA for example. The second (ElbowPlot). The third is a heuristic that is commonly used, and can be calculated instantly. In this example, we might have been justified in choosing anything between PC 7-12 as a cutoff.\nWe chose 10 here, but encourage users to consider the following:\n\nDendritic cell and NK aficionados may recognize that genes strongly associated with PCs 12 and 13 define rare immune subsets (i.e. MZB1 is a marker for plasmacytoid DCs). However, these groups are so rare, they are difficult to distinguish from background noise for a dataset of this size without prior knowledge.\nWe encourage users to repeat downstream analyses with a different number of PCs (10, 15, or even 50!). As you will observe, the results often do not differ dramatically.\nWe advise users to err on the higher side when choosing this parameter（建议选择偏高的主成分数量）. For example, performing downstream analyses with only 5 PCs does significantly and adversely affect results."
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#细胞聚类cluster",
    "href": "single_cell/seurat/seurat_tutorial.html#细胞聚类cluster",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.7 细胞聚类（cluster）",
    "text": "7.7 细胞聚类（cluster）\nSeurat applies a graph-based clustering approach, building upon initial strategies in Macosko et al (Macosko et al. 2015b). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. However, our approach to partitioning the cellular distance matrix into clusters has dramatically improved. Our approach was heavily inspired by recent manuscripts which applied graph-based clustering approaches to scRNA-seq data and CyTOF data (Levine et al. 2015). Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.\nAs in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 10 PCs).\nTo cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM (Blondel et al. 2008), to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets.\n\npbmc &lt;- FindNeighbors(pbmc, dims = 1:10)\npbmc &lt;- FindClusters(pbmc, resolution = 0.5)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 2638\nNumber of edges: 95905\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8735\nNumber of communities: 9\nElapsed time: 0 seconds\n\n\nThe clusters can be found using the Idents() function. 或者通过seurat@active.ident获取。\n\n# Look at cluster IDs of the first 5 cells\nhead(Idents(pbmc), 5)\n\nAAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n               0                3                2                1 \nAAACCGTGTATGCG-1 \n               6 \nLevels: 0 1 2 3 4 5 6 7 8\n\n# 等价于：head(pbmc@active.ident, 5)\n# 类似于：pbmc@meta.data[[\"seurat_clusters\"]][1:5]\n\n现在的meta.data中出现了RNA_snn_res.0.5列和seurat_clusters列，分别代表了在分辨率为0.5的情况下的细胞cluster id以及目前激活的cluster id。由于目前只有一个0.5的分辨率，所以这两列是一样的。\n\nhead(pbmc@meta.data)\n\n                 orig.ident nCount_RNA nFeature_RNA percent.mt RNA_snn_res.0.5\nAAACATACAACCAC-1     pbmc3k       2419          779  3.0177759               0\nAAACATTGAGCTAC-1     pbmc3k       4903         1352  3.7935958               3\nAAACATTGATCAGC-1     pbmc3k       3147         1129  0.8897363               2\nAAACCGTGCTTCCG-1     pbmc3k       2639          960  1.7430845               1\nAAACCGTGTATGCG-1     pbmc3k        980          521  1.2244898               6\nAAACGCACTGGTAC-1     pbmc3k       2163          781  1.6643551               2\n                 seurat_clusters\nAAACATACAACCAC-1               0\nAAACATTGAGCTAC-1               3\nAAACATTGATCAGC-1               2\nAAACCGTGCTTCCG-1               1\nAAACCGTGTATGCG-1               6\nAAACGCACTGGTAC-1               2"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#非线性降维",
    "href": "single_cell/seurat/seurat_tutorial.html#非线性降维",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.8 非线性降维",
    "text": "7.8 非线性降维\nSeurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots.\nWhile we and others have routinely found 2D visualization techniques like tSNE and UMAP to be valuable tools for exploring datasets, all visualization techniques have limitations, and cannot fully represent the complexity of the underlying data. In particular, these methods aim to preserve local distances in the dataset (i.e. ensuring that cells with very similar gene expression profiles co-localize), but often do not preserve more global relationships. We encourage users to leverage techniques like UMAP for visualization, but to avoid drawing biological conclusions solely on the basis of visualization techniques.\n\n\n\n\n\n\nCaution\n\n\n\n需要先进行线性降维RunPCA，再进行非线性降维RunUMAP。因为RunUMAP默认将PCA的结果作为输入（reduction = \"pca\"）。\n\n\n\npbmc &lt;- RunUMAP(pbmc, reduction = \"pca\", dims = 1:10)\n\n可以看到在Seurat对象的reductions中多了umap项：\n\n非线性降维可视化\n\nDimPlot(pbmc, reduction = \"umap\")\n\n\n\n\nYou can save the object at this point so that it can easily be loaded back in without having to rerun the computationally intensive steps performed above, or easily shared with collaborators.\n\nsaveRDS(pbmc, file = \"output/pbmc_tutorial.rds\")"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#寻找细胞群间的差异表达基因cluster-biomarkers",
    "href": "single_cell/seurat/seurat_tutorial.html#寻找细胞群间的差异表达基因cluster-biomarkers",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.9 寻找细胞群间的差异表达基因（cluster biomarkers）",
    "text": "7.9 寻找细胞群间的差异表达基因（cluster biomarkers）\nSeurat can help you find markers that define clusters via differential expression (DE). By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers() automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.\nIn Seurat v5, we use the presto package (as described here and available for installation here), to dramatically improve the speed of DE analysis, particularly for large datasets. For users who are not using presto, you can examine the documentation for this function (?FindMarkers) to explore the min.pct and logfc.threshold parameters, which can be increased in order to increase the speed of DE testing.\nFind all markers of cluster 2：\n\ncluster2.markers &lt;- FindMarkers(pbmc, ident.1 = 2)\nhead(cluster2.markers, n = 5)\n\n            p_val avg_log2FC pct.1 pct.2    p_val_adj\nLTB  1.709675e-83   1.330256 0.982 0.647 2.344648e-79\nIL32 5.076510e-83   1.242930 0.947 0.471 6.961926e-79\nLDHB 2.467055e-68   1.044820 0.967 0.615 3.383320e-64\nCD3D 1.817480e-66   1.058609 0.920 0.438 2.492492e-62\nIL7R 8.698894e-61   1.389909 0.744 0.333 1.192966e-56\n\n\nFind all markers distinguishing cluster 5 from clusters 0 and 3：\n\ncluster5.markers &lt;- FindMarkers(pbmc, ident.1 = 5, ident.2 = c(0, 3))\nhead(cluster5.markers, n = 5)\n\n                      p_val avg_log2FC pct.1 pct.2     p_val_adj\nFCGR3A        5.972471e-204   6.795991 0.975 0.041 8.190647e-200\nIFITM3        5.671364e-195   6.201036 0.975 0.048 7.777708e-191\nCFD           2.389538e-193   6.081028 0.937 0.038 3.277012e-189\nCD68          1.800066e-189   5.472200 0.925 0.036 2.468611e-185\nRP11-290F20.3 6.852416e-189   6.390800 0.843 0.015 9.397404e-185\n\n\nFind markers for every cluster compared to all remaining cells, report only the positive ones：\n\npbmc.markers &lt;- FindAllMarkers(pbmc, only.pos = TRUE)\nlibrary(dplyr)\npbmc.markers %&gt;%\n    group_by(cluster) %&gt;%\n    filter(avg_log2FC &gt; 1)\n\n# A tibble: 7,024 × 7\n# Groups:   cluster [9]\n       p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n 1 5.32e-114       1.19 0.912 0.591 7.29e-110 0       LDHB     \n 2 1.31e- 83       2.35 0.439 0.11  1.79e- 79 0       CCR7     \n 3 2.61e- 78       1.06 0.85  0.403 3.58e- 74 0       CD3D     \n 4 5.89e- 55       1.03 0.731 0.398 8.07e- 51 0       CD3E     \n 5 3.91e- 50       2.11 0.338 0.104 5.36e- 46 0       LEF1     \n 6 2.53e- 47       1.23 0.624 0.36  3.47e- 43 0       NOSIP    \n 7 5.11e- 46       2.04 0.335 0.109 7.01e- 42 0       PRKCQ-AS1\n 8 5.49e- 43       1.51 0.438 0.186 7.52e- 39 0       PIK3IP1  \n 9 9.17e- 41       2.73 0.199 0.04  1.26e- 36 0       FHIT     \n10 1.26e- 33       1.32 0.39  0.177 1.72e- 29 0       TCF7     \n# ℹ 7,014 more rows\n\n\nSeurat has several tests for differential expression which can be set with the test.use parameter (see Section 14.4.3 for details). 默认是用的”wilcox”方法。For example, the ROC test（test.use = \"roc\"） returns the ‘classification power’ for any individual marker (ranging from 0 - random, to 1 - perfect)：\n\ncluster0.markers &lt;- FindMarkers(pbmc, \n                                ident.1 = 0, \n                                logfc.threshold = 0.25, \n                                test.use = \"roc\", \n                                only.pos = TRUE)\nhead(cluster0.markers)\n\n      myAUC  avg_diff power avg_log2FC pct.1 pct.2\nRPS6  0.828 0.4737648 0.656  0.6898595 1.000 0.995\nRPS12 0.827 0.5065637 0.654  0.7396535 1.000 0.991\nRPL32 0.822 0.4338741 0.644  0.6330085 0.999 0.995\nRPS27 0.819 0.4971128 0.638  0.7261693 0.999 0.992\nRPS14 0.814 0.4354967 0.628  0.6367519 1.000 0.994\nRPS25 0.809 0.5345947 0.618  0.7911714 0.997 0.975"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#可视化marker基因的表达",
    "href": "single_cell/seurat/seurat_tutorial.html#可视化marker基因的表达",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.10 可视化marker基因的表达",
    "text": "7.10 可视化marker基因的表达\nWe include several tools for visualizing marker expression. VlnPlot() (shows expression probability distributions across clusters), and FeaturePlot() (visualizes feature expression on a tSNE or PCA plot) are our most commonly used visualizations. We also suggest exploring RidgePlot(), CellScatter(), and DotPlot() as additional methods to view your dataset.\n小提琴图：\n\nVlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\"))\n\n\n\n\nYou can plot raw counts as well（layer = \"counts\"）：\n\nVlnPlot(pbmc, \n        features = c(\"NKG7\", \"PF4\"), \n        layer = \"counts\", # Layer to pull expression data from (e.g. \"counts\" or \"data\")\n        log = TRUE)\n\n\n\n\nUMAP图：\n\nFeaturePlot(pbmc,\n            features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\",\n                         \"PPBP\", \"CD8A\"))\n\n\n\n\n热图：\nDoHeatmap() generates an expression heatmap for given cells and features. In this case, we are plotting the top 20 markers (or all markers if less than 20) for each cluster.\n\npbmc.markers %&gt;%\n  group_by(cluster) %&gt;%\n  filter(avg_log2FC &gt; 1) %&gt;%\n  slice_head(n = 10) %&gt;% # 选取开头的10行\n  ungroup() -&gt; top10\nDoHeatmap(pbmc, features = top10$gene) + NoLegend()"
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#细胞注释",
    "href": "single_cell/seurat/seurat_tutorial.html#细胞注释",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.11 细胞注释",
    "text": "7.11 细胞注释\n本案例使用的细胞注释：\n\n\nCluster ID\nMarkers\nCell Type\n\n\n\n0\nIL7R, CCR7\nNaive CD4+ T\n\n\n1\nCD14, LYZ\nCD14+ Mono\n\n\n2\nIL7R, S100A4\nMemory CD4+\n\n\n3\nMS4A1\nB\n\n\n4\nCD8A\nCD8+ T\n\n\n5\nFCGR3A, MS4A7\nFCGR3A+ Mono\n\n\n6\nGNLY, NKG7\nNK\n\n\n7\nFCER1A, CST3\nDC\n\n\n8\nPPBP\nPlatelet\n\n\n\n目前的pbmc@active.ident（或Idents(pbmc)）和meta.data中的”seurat_clusters”列储存了激活的分群信息：\n\nIdents(pbmc) %&gt;% head()\n\nAAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n               0                3                2                1 \nAAACCGTGTATGCG-1 AAACGCACTGGTAC-1 \n               6                2 \nLevels: 0 1 2 3 4 5 6 7 8\n\n\n通过上面表格的注释依据对细胞群重命名，将命名信息储存在”new.cluster.ids”中，然后返回到meta.data中，形成新的”new.cluster.ids”列：\n\nnew.cluster.ids &lt;- c(\"Naive CD4 T\", \"CD14+ Mono\", \"Memory CD4 T\", \"B\", \"CD8 T\", \n                     \"FCGR3A+ Mono\", \"NK\", \"DC\", \"Platelet\")\nnames(new.cluster.ids) &lt;- levels(pbmc)\npbmc &lt;- RenameIdents(pbmc, new.cluster.ids)\nDimPlot(pbmc, \n        reduction = \"umap\", \n        label = TRUE, \n        pt.size = 0.5) + \n  NoLegend()\n\n\n\n\n目前的分群信息：\n\nIdents(pbmc) %&gt;% head()\n\nAAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n     Naive CD4 T                B     Memory CD4 T       CD14+ Mono \nAAACCGTGTATGCG-1 AAACGCACTGGTAC-1 \n              NK     Memory CD4 T \n9 Levels: Naive CD4 T CD14+ Mono Memory CD4 T B CD8 T FCGR3A+ Mono NK ... Platelet\n\n\nDimPlot基于ggplot2绘图框架，所以可以用ggplot2语法对图像进行自定义调整：\n\nlibrary(ggplot2)\nDimPlot(pbmc, \n        reduction = \"umap\", \n        label = TRUE, \n        label.size = 4.5) + \n  xlab(\"UMAP 1\") + \n  ylab(\"UMAP 2\") +\n  theme(axis.title = element_text(size = 18), \n        legend.text = element_text(size = 18)) + \n  guides(colour = guide_legend(override.aes = list(size = 10)))\n\n\n\n\n保存Seurat对象：\n\nsaveRDS(pbmc, file = \"output/pbmc3k_final.rds\")\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      dplyr_1.1.4        Seurat_5.0.1       SeuratObject_5.0.1\n[5] sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.4           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.4         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.11            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.0    zoo_1.8-12             R.utils_2.12.3        \n [46] sctransform_0.4.1      httpuv_1.6.12          Matrix_1.6-3          \n [49] splines_4.3.2          igraph_1.5.1           tidyselect_1.2.0      \n [52] abind_1.4-5            rstudioapi_0.15.0      yaml_2.3.7            \n [55] spatstat.random_3.2-1  codetools_0.2-19       miniUI_0.1.1.1        \n [58] spatstat.explore_3.2-5 listenv_0.9.0          lattice_0.22-5        \n [61] tibble_3.2.1           plyr_1.8.9             withr_2.5.2           \n [64] shiny_1.8.0            ROCR_1.0-11            evaluate_0.23         \n [67] Rtsne_0.16             future_1.33.0          fastDummies_1.7.3     \n [70] survival_3.5-7         polyclip_1.10-6        fitdistrplus_1.1-11   \n [73] pillar_1.9.0           KernSmooth_2.23-22     plotly_4.10.3         \n [76] generics_0.1.3         RcppHNSW_0.5.0         munsell_0.5.0         \n [79] scales_1.2.1           globals_0.16.2         xtable_1.8-4          \n [82] glue_1.6.2             lazyeval_0.2.2         tools_4.3.2           \n [85] data.table_1.14.8      RSpectra_0.16-1        RANN_2.6.1            \n [88] leiden_0.4.3.1         dotCall64_1.1-0        cowplot_1.1.1         \n [91] grid_4.3.2             tidyr_1.3.0            colorspace_2.1-0      \n [94] nlme_3.1-163           patchwork_1.1.3        cli_3.6.1             \n [97] spatstat.sparse_3.0-3  spam_2.10-0            fansi_1.0.5           \n[100] viridisLite_0.4.2      uwot_0.1.16            gtable_0.3.4          \n[103] R.methodsS3_1.8.2      digest_0.6.33          progressr_0.14.0      \n[106] ggrepel_0.9.4          farver_2.1.1           htmlwidgets_1.6.3     \n[109] R.oo_1.25.0            htmltools_0.5.7        lifecycle_1.0.4       \n[112] httr_1.4.7             mime_0.12              MASS_7.3-60           \n\n\n\n\n\n\n\n\n\n\n\nBlondel, Vincent D, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. “Fast Unfolding of Communities in Large Networks.” Journal of Statistical Mechanics: Theory and Experiment 2008 (10): P10008. https://doi.org/10.1088/1742-5468/2008/10/p10008.\n\n\nBrennecke, Philip, Simon Anders, Jong Kyoung Kim, Aleksandra A Kołodziejczyk, Xiuwei Zhang, Valentina Proserpio, Bianka Baying, et al. 2013. “Accounting for Technical Noise in Single-Cell RNA-Seq Experiments.” Nature Methods 10 (11): 1093–95. https://doi.org/10.1038/nmeth.2645.\n\n\nChoudhary, Saket, and Rahul Satija. 2022a. “Comparison and Evaluation of Statistical Error Models for scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.\n\n\n———. 2022b. “Comparison and Evaluation of Statistical Error Models for scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.\n\n\nIlicic, Tomislav, Jong Kyoung Kim, Aleksandra A. Kolodziejczyk, Frederik Otzen Bagger, Davis James McCarthy, John C. Marioni, and Sarah A. Teichmann. 2016. “Classification of Low Quality Cells from Single-Cell RNA-Seq Data.” Genome Biology 17 (1). https://doi.org/10.1186/s13059-016-0888-1.\n\n\nLevine, Jacob H., Erin F. Simonds, Sean C. Bendall, Kara L. Davis, El-ad D. Amir, Michelle D. Tadmor, Oren Litvin, et al. 2015. “Data-Driven Phenotypic Dissection of AML Reveals Progenitor-Like Cells That Correlate with Prognosis.” Cell 162 (1): 184–97. https://doi.org/10.1016/j.cell.2015.05.047.\n\n\nMacosko, Evan Z., Anindita Basu, Rahul Satija, James Nemesh, Karthik Shekhar, Melissa Goldman, Itay Tirosh, et al. 2015a. “Highly Parallel Genome-Wide Expression Profiling of Individual Cells Using Nanoliter Droplets.” Cell 161 (5): 1202–14. https://doi.org/10.1016/j.cell.2015.05.002.\n\n\n———, et al. 2015b. “Highly Parallel Genome-Wide Expression Profiling of Individual Cells Using Nanoliter Droplets.” Cell 161 (5): 1202–14. https://doi.org/10.1016/j.cell.2015.05.002.\n\n\nStuart, Tim, Andrew Butler, Paul Hoffman, Christoph Hafemeister, Efthymia Papalexi, William M. Mauck, Yuhan Hao, Marlon Stoeckius, Peter Smibert, and Rahul Satija. 2019. “Comprehensive Integration of Single-Cell Data.” Cell 177 (7): 1888–1902.e21. https://doi.org/10.1016/j.cell.2019.05.031."
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#种可视化marker-gene的方法",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#种可视化marker-gene的方法",
    "title": "\n8  Seurat中的数据可视化方法\n",
    "section": "\n8.1 5种可视化marker gene的方法",
    "text": "8.1 5种可视化marker gene的方法\n定义要检查的marker gene：\n\nfeatures &lt;- c(\"LYZ\", \"CCL5\", \"IL32\", \"PTPRCAP\", \"FCGR3A\", \"PF4\")\n\nRidge plots\nRidge plots - from ggridges. Visualize single cell expression distributions in each cluster\n\nlibrary(Seurat)\nRidgePlot(pbmc3k.final, features = features, ncol = 2)\n\n\n\n\nViolin plot\n\nVlnPlot(pbmc3k.final, features = features)\n\n\n\n\nViolin plots can be split on some variable. Simply add the splitting variable to object metadata and pass it to the split.by argument. 通过添加split.by参数，展示marker gene在不同的样本组别中的表达。\n\nVlnPlot(pbmc3k.final, \n        features = \"percent.mt\", \n        split.by = \"groups\")\n\n\n\n\nFeature plot\nVisualize feature expression in low-dimensional space\n\nFeaturePlot(pbmc3k.final, features = features)\n\n\n\n\n对FeaturePlot的进一步修饰\n原始图像：\n\nFeaturePlot(pbmc3k.final, features = \"MS4A1\")\n\n\n\n\nAdjust the contrast in the plot。通过min.cutoff和max.cutoff调整颜色范围。\n\nFeaturePlot(pbmc3k.final, features = \"MS4A1\", \n            min.cutoff = 1, max.cutoff = 3)\n\n\n\n\nCalculate feature-specific contrast levels based on quantiles of non-zero expression. Particularly useful when plotting multiple markers。\n\nFeaturePlot(pbmc3k.final, \n            features = c(\"MS4A1\", \"PTPRCAP\"), \n            min.cutoff = \"q10\", \n            max.cutoff = \"q90\")\n\n\n\n\nVisualize co-expression of two features simultaneously。添加blend = TRUE。\n\nFeaturePlot(pbmc3k.final, \n            features = c(\"MS4A1\", \"CD79A\"), \n            blend = TRUE)\n\n\n\n\n通过添加split.by参数，来按照不同的样本组别来分别展示marker gene的表达。\n\nFeaturePlot(pbmc3k.final, \n            features = c(\"MS4A1\", \"CD79A\"), \n            split.by = \"groups\")\n\n\n\n\nDot plots\nThe size of the dot corresponds to the percentage of cells expressing the feature in each cluster. The color represents the average expression level\n\nDotPlot(pbmc3k.final, \n        features = features) + \n  RotatedAxis()\n\n\n\n\n通过添加split.by参数，来按照不同的样本组别来分别展示marker gene的表达。\n\nDotPlot(pbmc3k.final, \n        features = features, \n        split.by = \"groups\") + \n  RotatedAxis()\n\n\n\n\nHeatmap\n\nDoHeatmap(subset(pbmc3k.final, downsample = 100), \n          features = features, \n          size = 3)\n\n\n\n\nDoHeatmap now shows a grouping bar, splitting the heatmap into groups or clusters. This can be changed with the group.by parameter. 默认的group.by为细胞分群信息，即按照细胞的分群作为分组依据来绘制热图：\n\nDoHeatmap(pbmc3k.final, \n          features = VariableFeatures(pbmc3k.final)[1:30], \n          cells = 1:1000, \n          size = 4, # 分组文字的大小\n          angle = 45) +  # 分组文字角度\n  NoLegend()\n\n\n\n\n我们用meta.data中的任何列作为分群依据。例如这里的”groups”列：\n\ncolnames(pbmc3k.final@meta.data)\n\n[1] \"orig.ident\"         \"nCount_RNA\"         \"nFeature_RNA\"      \n[4] \"seurat_annotations\" \"percent.mt\"         \"RNA_snn_res.0.5\"   \n[7] \"seurat_clusters\"    \"groups\"            \n\nDoHeatmap(pbmc3k.final, \n          features = VariableFeatures(pbmc3k.final)[1:30], \n          group.by = \"groups\",\n          cells = 1:1000, \n          size = 4, # 分组文字的大小\n          angle = 0) +  # 分组文字角度\n  NoLegend()"
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#细胞分群图",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#细胞分群图",
    "title": "\n8  Seurat中的数据可视化方法\n",
    "section": "\n8.2 细胞分群图",
    "text": "8.2 细胞分群图\n\nDimPlot(pbmc3k.final, reduction = \"pca\")\n\n\n\nDimPlot(pbmc3k.final, reduction = \"umap\")\n\n\n\n\n进一步修饰\n\nlibrary(ggplot2)\nDimPlot(pbmc3k.final, reduction = \"umap\") + \n  labs(title = \"Clustering of 2,700 PBMCs\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.4           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.4         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.11            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.0    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.12          Matrix_1.6-3           splines_4.3.2         \n [49] igraph_1.5.1           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.7             spatstat.random_3.2-1 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             withr_2.5.2            shiny_1.8.0           \n [64] ROCR_1.0-11            evaluate_0.23          Rtsne_0.16            \n [67] future_1.33.0          fastDummies_1.7.3      survival_3.5-7        \n [70] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [73] KernSmooth_2.23-22     plotly_4.10.3          generics_0.1.3        \n [76] RcppHNSW_0.5.0         munsell_0.5.0          scales_1.2.1          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.6.2            \n [82] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.8     \n [85] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [88] dotCall64_1.1-0        cowplot_1.1.1          grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-163          \n [94] patchwork_1.1.3        cli_3.6.1              spatstat.sparse_3.0-3 \n [97] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[100] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[103] digest_0.6.33          progressr_0.14.0       ggrepel_0.9.4         \n[106] farver_2.1.1           htmlwidgets_1.6.3      htmltools_0.5.7       \n[109] lifecycle_1.0.4        httr_1.4.7             mime_0.12             \n[112] MASS_7.3-60"
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#载入数据",
    "href": "single_cell/seurat/sctransform.html#载入数据",
    "title": "9  基于SCTransform的单细胞数据标准化",
    "section": "\n9.1 载入数据",
    "text": "9.1 载入数据\n\nlibrary(Seurat)\npbmc_data &lt;- Read10X(data.dir = \"data/filtered_gene_bc_matrices/hg19\")\npbmc &lt;- CreateSeuratObject(counts = pbmc_data)\npbmc\n\nAn object of class Seurat \n32738 features across 2700 samples within 1 assay \nActive assay: RNA (32738 features, 0 variable features)\n 1 layer present: counts"
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#质控",
    "href": "single_cell/seurat/sctransform.html#质控",
    "title": "9  基于SCTransform的单细胞数据标准化",
    "section": "\n9.2 质控",
    "text": "9.2 质控\n这里的质控步骤只简单的计算了线粒体基因的比例。\n\npbmc &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\", col.name = \"percent.mt\")\nhead(pbmc@meta.data, 5)\n\n                    orig.ident nCount_RNA nFeature_RNA percent.mt\nAAACATACAACCAC-1 SeuratProject       2421          781  3.0152829\nAAACATTGAGCTAC-1 SeuratProject       4903         1352  3.7935958\nAAACATTGATCAGC-1 SeuratProject       3149         1131  0.8891712\nAAACCGTGCTTCCG-1 SeuratProject       2639          960  1.7430845\nAAACCGTGTATGCG-1 SeuratProject        981          522  1.2232416"
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#运行sctransform",
    "href": "single_cell/seurat/sctransform.html#运行sctransform",
    "title": "9  基于SCTransform的单细胞数据标准化",
    "section": "\n9.3 运行SCTransform\n",
    "text": "9.3 运行SCTransform\n\n\nSCTransform替代了传统单细胞数据分析流程中的NormalizeData()、ScaleData()和FindVariableFeatures()函数的功能，因此不再需要运行这些函数。\nDuring normalization, we can also remove confounding sources of variation, for example, mitochondrial mapping percentage。SCTransform也可以移除一些非期望变异来源，如线粒体基因的比例。这在传统的单细胞数据分析流程中由ScaleData来完成（ Section 7.5 ）。\nIn Seurat v5, SCT v2 is applied by default. You can revert to v1 by setting vst.flavor = 'v1'\nSCTransform的运算调用了glmGamPoi包以显著提升运算速度。所以事先需要通过BiocManager安装该包。\n\n\n# BiocManager::install(\"glmGamPoi\")\npbmc &lt;- SCTransform(pbmc, \n                    vars.to.regress = \"percent.mt\", \n                    verbose = FALSE)\n\nTransformed data will be available in the SCT assay, which is set as the default after running SCTransform：\n\n\npbmc[[\"SCT\"]]$scale.data contains the residuals (normalized values), and is used directly as input to PCA. Please note that this matrix is non-sparse, and can therefore take up a lot of memory if stored for all genes. To save memory, we store these values only for variable genes, by setting the return.only.var.genes = TRUE by default in the SCTransform() function call.\nTo assist with visualization and interpretation, we also convert Pearson residuals back to ‘corrected’ UMI counts. You can interpret these as the UMI counts we would expect to observe if all cells were sequenced to the same depth. If you want to see exactly how we do this, please look at the correct function here.\nThe ‘corrected’ UMI counts are stored in pbmc[[\"SCT\"]]$counts. We store log-normalized versions of these corrected counts in pbmc[[\"SCT\"]]$data, which are very helpful for visualization."
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#降维",
    "href": "single_cell/seurat/sctransform.html#降维",
    "title": "9  基于SCTransform的单细胞数据标准化",
    "section": "\n9.4 降维",
    "text": "9.4 降维\n\npbmc &lt;- RunPCA(pbmc, verbose = FALSE)\npbmc &lt;- RunUMAP(pbmc, dims = 1:30, verbose = FALSE)\n\n降维可视化：\n\nVizDimLoadings(pbmc, dims = 1:2, reduction = \"pca\")\n\n\n\nDimPlot(pbmc, reduction = \"umap\")\n\n\n\nDimHeatmap(pbmc, dims = 1:15, cells = 1000, balanced = TRUE)\n\n\n\nElbowPlot(pbmc)"
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#聚类",
    "href": "single_cell/seurat/sctransform.html#聚类",
    "title": "9  基于SCTransform的单细胞数据标准化",
    "section": "\n9.5 聚类",
    "text": "9.5 聚类\n\npbmc &lt;- FindNeighbors(pbmc, dims = 1:30, verbose = FALSE)\npbmc &lt;- FindClusters(pbmc, verbose = FALSE)\nDimPlot(pbmc, label = TRUE)\n\n\n\n\n根据Seurat细胞分群官方教程（ Section 7.6.2 ），这个数据集”we can observe an ‘elbow’ around PC9-10, suggesting that the majority of true signal is captured in the first 10 PCs”。因此在FindNeighbors函数中指定了dims = 1:10。但是这里的FindNeighbors函数指定了更多的主成分（dims = 1:30）。下面的内容对此作出了解释：\n\n\n\n\n\n\nWhy can we choose more PCs when using sctransform?\n\n\n\n\n\nIn the Seurat细胞分群官方教程，we focus on 10 PCs for this dataset, though we highlight that the results are similar with higher settings for this parameter. Interestingly, we’ve found that when using SCTransform, we often benefit by pushing this parameter even higher. We believe this is because the SCTransform workflow performs more effective normalization, strongly removing technical effects from the data.\nEven after standard log-normalization, variation in sequencing depth is still a confounding factor (see Figure 1), and this effect can subtly influence higher PCs. In SCTransform, this effect is substantially mitigated (see Figure 3). This means that higher PCs are more likely to represent subtle, but biologically relevant, sources of heterogeneity – so including them may improve downstream analysis.\nIn addition, SCTransform returns 3,000 variable features by default, instead of 2,000. The rationale is similar, the additional variable features are less likely to be driven by technical differences across cells, and instead may represent more subtle biological fluctuations. In general, we find that results produced with SCTransform are less dependent on these parameters (indeed, we achieve nearly identical results when using all genes in the transcriptome, though this does reduce computational efficiency). This can help users generate more robust results, and in addition, enables the application of standard analysis pipelines with identical parameter settings that can quickly be applied to new datasets."
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#marker基因可视化",
    "href": "single_cell/seurat/sctransform.html#marker基因可视化",
    "title": "9  基于SCTransform的单细胞数据标准化",
    "section": "\n9.6 Marker基因可视化",
    "text": "9.6 Marker基因可视化\nUsers can individually annotate clusters based on canonical markers. However, the SCTransform normalization reveals sharper biological distinctions compared to the standard Seurat workflow（ Chapter 7 ）, in a few ways:\n\nClear separation of at least 3 CD8 T cell populations (naive, memory, effector), based on CD8A, GZMK, CCL5, CCR7 expression\nClear separation of three CD4 T cell populations (naive, memory, IFN-activated) based on S100A4, CCR7, IL32, and ISG15\nAdditional developmental sub-structure in B cell cluster, based on TCL1A, FCER2\nAdditional separation of NK cells into CD56dim vs. bright clusters, based on XCL1 and FCGR3A\n\n小提琴图：\n\nVlnPlot(pbmc, \n        features = c(\"CD8A\", \"GZMK\", \"CCL5\", \"S100A4\", \"ANXA1\", \"CCR7\", \"ISG15\", \"CD3D\"),\n    pt.size = 0.2, \n    ncol = 4)\n\n\n\n\nUMAP图：\n\nFeaturePlot(pbmc, \n            features = c(\"CD8A\", \"GZMK\", \"CCL5\", \"S100A4\", \"ANXA1\", \"CCR7\"), \n            pt.size = 0.2,\n            ncol = 3)\n\n\n\n\n\nFeaturePlot(pbmc, \n            features = c(\"CD3D\", \"ISG15\", \"TCL1A\", \"FCER2\", \"XCL1\", \"FCGR3A\"), \n            pt.size = 0.2,\n            ncol = 3)\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.7              magrittr_2.0.3             \n  [5] spatstat.utils_3.0-4        farver_2.1.1               \n  [7] rmarkdown_2.25              zlibbioc_1.48.0            \n  [9] vctrs_0.6.4                 ROCR_1.0-11                \n [11] DelayedMatrixStats_1.24.0   spatstat.explore_3.2-5     \n [13] RCurl_1.98-1.13             S4Arrays_1.2.0             \n [15] htmltools_0.5.7             SparseArray_1.2.2          \n [17] sctransform_0.4.1           parallelly_1.36.0          \n [19] KernSmooth_2.23-22          htmlwidgets_1.6.3          \n [21] ica_1.0-3                   plyr_1.8.9                 \n [23] plotly_4.10.3               zoo_1.8-12                 \n [25] igraph_1.5.1                mime_0.12                  \n [27] lifecycle_1.0.4             pkgconfig_2.0.3            \n [29] Matrix_1.6-3                R6_2.5.1                   \n [31] fastmap_1.1.1               GenomeInfoDbData_1.2.11    \n [33] MatrixGenerics_1.14.0       fitdistrplus_1.1-11        \n [35] future_1.33.0               shiny_1.8.0                \n [37] digest_0.6.33               colorspace_2.1-0           \n [39] patchwork_1.1.3             S4Vectors_0.40.1           \n [41] tensor_1.5                  RSpectra_0.16-1            \n [43] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [45] labeling_0.4.3              progressr_0.14.0           \n [47] fansi_1.0.5                 spatstat.sparse_3.0-3      \n [49] httr_1.4.7                  polyclip_1.10-6            \n [51] abind_1.4-5                 compiler_4.3.2             \n [53] withr_2.5.2                 fastDummies_1.7.3          \n [55] R.utils_2.12.3              MASS_7.3-60                \n [57] DelayedArray_0.28.0         tools_4.3.2                \n [59] lmtest_0.9-40               httpuv_1.6.12              \n [61] future.apply_1.11.0         goftest_1.2-3              \n [63] R.oo_1.25.0                 glmGamPoi_1.14.0           \n [65] glue_1.6.2                  nlme_3.1-163               \n [67] promises_1.2.1              grid_4.3.2                 \n [69] Rtsne_0.16                  cluster_2.1.4              \n [71] reshape2_1.4.4              generics_0.1.3             \n [73] gtable_0.3.4                spatstat.data_3.0-3        \n [75] R.methodsS3_1.8.2           tidyr_1.3.0                \n [77] data.table_1.14.8           XVector_0.42.0             \n [79] utf8_1.2.4                  BiocGenerics_0.48.1        \n [81] spatstat.geom_3.2-7         RcppAnnoy_0.0.21           \n [83] ggrepel_0.9.4               RANN_2.6.1                 \n [85] pillar_1.9.0                stringr_1.5.1              \n [87] spam_2.10-0                 RcppHNSW_0.5.0             \n [89] later_1.3.1                 splines_4.3.2              \n [91] dplyr_1.1.4                 lattice_0.22-5             \n [93] survival_3.5-7              deldir_2.0-2               \n [95] tidyselect_1.2.0            miniUI_0.1.1.1             \n [97] pbapply_1.7-2               knitr_1.45                 \n [99] gridExtra_2.3               IRanges_2.36.0             \n[101] SummarizedExperiment_1.32.0 scattermore_1.2            \n[103] stats4_4.3.2                xfun_0.41                  \n[105] Biobase_2.62.0              matrixStats_1.1.0          \n[107] stringi_1.8.2               lazyeval_0.2.2             \n[109] yaml_2.3.7                  evaluate_0.23              \n[111] codetools_0.2-19            tibble_3.2.1               \n[113] cli_3.6.1                   uwot_0.1.16                \n[115] xtable_1.8-4                reticulate_1.34.0          \n[117] munsell_0.5.0               Rcpp_1.0.11                \n[119] GenomeInfoDb_1.38.1         globals_0.16.2             \n[121] spatstat.random_3.2-1       png_0.1-8                  \n[123] parallel_4.3.2              ellipsis_0.3.2             \n[125] ggplot2_3.4.4               dotCall64_1.1-0            \n[127] sparseMatrixStats_1.14.0    bitops_1.0-7               \n[129] listenv_0.9.0               viridisLite_0.4.2          \n[131] scales_1.2.1                ggridges_0.5.4             \n[133] crayon_1.5.2                leiden_0.4.3.1             \n[135] purrr_1.0.2                 rlang_1.1.2                \n[137] cowplot_1.1.1              \n\n\n\n\n\n\n\n\n\n\n\nChoudhary, Saket, and Rahul Satija. 2022. “Comparison and Evaluation of Statistical Error Models for scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.\n\n\nLause, Jan, Philipp Berens, and Dmitry Kobak. 2021. “Analytic Pearson Residuals for Normalization of Single-Cell RNA-Seq UMI Data.” Genome Biology 22 (1). https://doi.org/10.1186/s13059-021-02451-7."
  },
  {
    "objectID": "single_cell/seurat/integration.html#数据读取和分层",
    "href": "single_cell/seurat/integration.html#数据读取和分层",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.1 数据读取和分层",
    "text": "10.1 数据读取和分层\n\n\n\n\n\n\n在线读取（可能需要全局代理）\n\n\n\n\n\n\n```{r}\n#| eval: false\nlibrary(Seurat)\nlibrary(SeuratData)\nInstallData(\"ifnb\")\nifnb &lt;- LoadData(\"ifnb\")\n```\n\n\n\n\n从本地下载好的数据读取：\n\nifnb &lt;- readRDS(\"data/pbmc_ifnb.rds\")\nifnb\n\nAn object of class Seurat \n14053 features across 13999 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 2 layers present: counts, data\n\nhead(ifnb@meta.data, 5)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\n\n\n\nThe object contains data from human PBMC from two conditions, interferon-stimulated and control cells (stored in the stim column in the object metadata). We will aim to integrate the two conditions together, so that we can jointly identify cell subpopulations across datasets, and then explore how each group differs across conditions\nIn previous versions of Seurat, we would require the data to be represented as two different Seurat objects. In Seurat v5, we keep all the data in one object, but simply split it into multiple ‘layers’. To learn more about layers, check out our Seurat object interaction vignette.\n\n\n\n\n\n\nImportant\n\n\n\nSeurat v5 assays store data in layers. These layers can store:\n\nraw, un-normalized counts (layer='counts')\nnormalized data (layer='data')\nz-scored/variance-stabilized data (layer='scale.data').\n\n\n\nsplit the RNA measurements into two layers one for control cells, one for stimulated cells:\n\nlibrary(Seurat)\nifnb[[\"RNA\"]] &lt;- split(ifnb[[\"RNA\"]], \n                       f = ifnb$stim) # 按照meta.data中的“stim”列进行分割\nifnb\n\nAn object of class Seurat \n14053 features across 13999 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 4 layers present: counts.CTRL, counts.STIM, data.CTRL, data.STIM\n\n\n现在可以发现ifnb被分为了4个layer，此前是2个layer（counts和data）："
  },
  {
    "objectID": "single_cell/seurat/integration.html#不进行整合的情况下的数据处理",
    "href": "single_cell/seurat/integration.html#不进行整合的情况下的数据处理",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.2 不进行整合的情况下的数据处理",
    "text": "10.2 不进行整合的情况下的数据处理\n进行标准的数据处理流程：\n\nifnb &lt;- NormalizeData(ifnb)\nifnb &lt;- FindVariableFeatures(ifnb)\nifnb &lt;- ScaleData(ifnb)\nifnb &lt;- RunPCA(ifnb)\nifnb &lt;- FindNeighbors(ifnb, dims = 1:30, reduction = \"pca\")\nifnb &lt;- FindClusters(ifnb, \n                     resolution = 2, \n                     cluster.name = \"unintegrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 13999\nNumber of edges: 555146\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8153\nNumber of communities: 26\nElapsed time: 1 seconds\n\nifnb &lt;- RunUMAP(ifnb, \n                dims = 1:30, \n                reduction = \"pca\", \n                reduction.name = \"umap.unintegrated\")\n\n分别按照样本分组（“stim”）和细胞聚类情况（“seurat_clusters”）着色绘制UMAP图：\n\nDimPlot(ifnb, \n        reduction = \"umap.unintegrated\", \n        group.by = c(\"stim\", \"seurat_clusters\"))\n\n\n\nFigure 10.1: 未整合时的细胞分群情况（左：按照刺激条件着色；右：按照细胞聚类情况着色）\n\n\n\n可以发现：The resulting clusters are defined both by cell type and stimulation condition, which creates challenges for downstream analysis."
  },
  {
    "objectID": "single_cell/seurat/integration.html#进行数据整合",
    "href": "single_cell/seurat/integration.html#进行数据整合",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.3 进行数据整合",
    "text": "10.3 进行数据整合\nWe now aim to integrate data from the two conditions, so that cells from the same cell type/subpopulation will cluster together.\nWe often refer to this procedure as intergration/alignment. When aligning two genome sequences together, identification of shared/homologous regions can help to interpret differences between the sequences as well. Similarly for scRNA-seq integration, our goal is not to remove biological differences across conditions, but to learn shared cell types/states in an initial step-specifically because that will enable us to compare control stimulated and control profiles for these individual cell types.\nThe Seurat v5 integration procedure aims to return a single dimensional reduction that captures the shared sources of variance across multiple layers, so that cells in a similar biological state will cluster. The method returns a dimensional reduction (i.e. integrated.cca) which can be used for visualization and unsupervised clustering analysis. For evaluating performance, we can use cell type labels that are pre-loaded in the seurat_annotations metadata column.\n\n# 整合，比较耗时间，进度条会一直显示0%直至运算完成\nifnb &lt;- IntegrateLayers(object = ifnb, \n                        method = CCAIntegration, \n                        orig.reduction = \"pca\", \n                        new.reduction = \"integrated.cca\", # 整合后新的降维数据的名称\n                        verbose = FALSE)\n\n# 整合后重新合并layer\nifnb[[\"RNA\"]] &lt;- JoinLayers(ifnb[[\"RNA\"]])\n\n可以看到经过整合的Seurat对象的降维（“reduction”）中多出了整合后的降维（“integrated.cca”）：\n\n整合后重新聚类、降维\n\n# 重新聚类\nifnb &lt;- FindNeighbors(ifnb, \n                      reduction = \"integrated.cca\", #更改降维来源为\"integrated.cca\"\n                      dims = 1:30)\nifnb &lt;- FindClusters(ifnb, resolution = 1)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 13999\nNumber of edges: 590406\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8448\nNumber of communities: 18\nElapsed time: 1 seconds\n\n# 重新降维\nifnb &lt;- RunUMAP(ifnb, \n                dims = 1:30, \n                reduction = \"integrated.cca\") #更改降维来源为\"integrated.cca\"\n\n# Visualization：\nDimPlot(ifnb, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\nFigure 10.2: 整合后的细胞分群情况（左：按照刺激条件着色；右：按照细胞聚类情况着色）\n\n\n\n可以看到和 Figure 10.1 相比，在整合后，细胞就只按照细胞类型进行聚类了。\n也可以按照刺激条件（“stim”）绘制分面图，分别展示刺激组和对照组的细胞分群情况：\n\nDimPlot(ifnb, reduction = \"umap\", split.by = \"stim\")\n\n\n\n\n可以看到，和上面的结论一致，两种条件下的细胞分群基本一致。"
  },
  {
    "objectID": "single_cell/seurat/integration.html#鉴定保守的cell-marker",
    "href": "single_cell/seurat/integration.html#鉴定保守的cell-marker",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.4 鉴定保守的cell marker",
    "text": "10.4 鉴定保守的cell marker\nTo identify canonical cell type marker genes that are conserved across conditions, we provide the FindConservedMarkers() function. This function performs differential gene expression testing for each dataset/group and combines the p-values using meta-analysis methods from the MetaDE R package. For example, we can calculated the genes that are conserved markers irrespective of stimulation condition in cluster 6 (NK cells).\nFindConservedMarkers函数会调用metap包，metap包需要multtest包，所以需要先安装这两个依赖包：\n\nBiocManager::install('multtest')\ninstall.packages('metap')\n\n\n# 这里的meta.data已经提前注释好了细胞类型（储存在\"seurat_annotations\"列中）。\n# 将细胞类型注释指定为\"seurat_annotations\"\nIdents(ifnb) &lt;- \"seurat_annotations\"\n\nnk.markers &lt;- FindConservedMarkers(ifnb, \n                                   ident.1 = \"NK\", \n                                   grouping.var = \"stim\", \n                                   verbose = FALSE)\nhead(nk.markers)\n\n      CTRL_p_val CTRL_avg_log2FC CTRL_pct.1 CTRL_pct.2 CTRL_p_val_adj\nGNLY           0        6.854586      0.943      0.046              0\nNKG7           0        5.358881      0.953      0.085              0\nGZMB           0        5.078135      0.839      0.044              0\nCLIC3          0        5.765314      0.601      0.024              0\nCTSW           0        5.307246      0.537      0.030              0\nKLRD1          0        5.261553      0.507      0.019              0\n      STIM_p_val STIM_avg_log2FC STIM_pct.1 STIM_pct.2 STIM_p_val_adj max_pval\nGNLY           0        6.435910      0.956      0.059              0        0\nNKG7           0        4.971397      0.950      0.081              0        0\nGZMB           0        5.151924      0.897      0.060              0        0\nCLIC3          0        5.505208      0.623      0.031              0        0\nCTSW           0        5.240729      0.592      0.035              0        0\nKLRD1          0        4.852457      0.555      0.027              0        0\n      minimump_p_val\nGNLY               0\nNKG7               0\nGZMB               0\nCLIC3              0\nCTSW               0\nKLRD1              0\n\n\n在实际分析中，鉴定这些保守的cell marker主要用来辅助对cluster的注释：you can perform these same analysis on the unsupervised clustering results (stored in seurat_clusters), and use these conserved markers to annotate cell types in your dataset.\n可视化cell markers的表达\nThe DotPlot() function with the split.by parameter can be useful for viewing conserved cell type markers across conditions, showing both the expression level and the percentage of cells in a cluster expressing any given gene. Here we plot 2-3 strong marker genes for each of our 14 clusters.\n\n# NEEDS TO BE FIXED AND SET ORDER CORRECTLY\nIdents(ifnb) &lt;- factor(Idents(ifnb), \n                       levels = c(\"pDC\", \"Eryth\", \"Mk\", \"DC\", \"CD14 Mono\", \"CD16 Mono\", \n                                  \"B Activated\", \"B\", \"CD8 T\", \"NK\", \"T activated\", \n                                  \"CD4 Naive T\", \"CD4 Memory T\"))\n\nmarkers.to.plot &lt;- c(\"CD3D\", \"CREM\", \"HSPH1\", \"SELL\", \"GIMAP5\", \"CACYBP\", \"GNLY\", \"NKG7\",\n                     \"CCL5\", \"CD8A\", \"MS4A1\", \"CD79A\", \"MIR155HG\", \"NME1\", \"FCGR3A\", \n                     \"VMO1\", \"CCL2\", \"S100A9\", \"HLA-DQA1\", \"GPR183\", \"PPBP\", \"GNG11\",\n                     \"HBA2\", \"HBB\", \"TSPAN13\", \"IL3RA\", \"IGJ\", \"PRSS57\")\nDotPlot(ifnb, \n        features = markers.to.plot, \n        cols = c(\"blue\", \"red\"), \n        dot.scale = 8, \n        split.by = \"stim\") +\n  RotatedAxis()"
  },
  {
    "objectID": "single_cell/seurat/integration.html#sec-识别不同样本类型间的差异基因",
    "href": "single_cell/seurat/integration.html#sec-识别不同样本类型间的差异基因",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.5 识别不同样本类型间的差异基因",
    "text": "10.5 识别不同样本类型间的差异基因\nNow that we’ve aligned the stimulated and control cells, we can start to do comparative analyses and look at the differences induced by stimulation.\nWe can aggregate cells of a similar type and condition together to create “pseudobulk” profiles using the AggregateExpression command（通过AggregateExpression命令将同一类型的细胞按照不同的处理条件合并起来，形成一个假的组织水平的测序数据。本例中，细胞被注释为13种细胞类型，而处理条件为”STIM”和”CTRL”，因此总共会被合并成13*2=26个类别，将每一个类别看作是一个样本，这样就形成了一个所谓的假的组织水平的测序数据）.\n\naggregate_ifnb &lt;- AggregateExpression(ifnb, \n                                      group.by = c(\"seurat_annotations\", \"stim\"), \n                                      return.seurat = TRUE)\naggregate_ifnb\n\nAn object of class Seurat \n14053 features across 26 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 3 layers present: counts, data, scale.data\n\nhead(aggregate_ifnb@meta.data, 5)\n\n                         orig.ident seurat_annotations stim\nCD14 Mono_CTRL       CD14 Mono_CTRL          CD14 Mono CTRL\nCD14 Mono_STIM       CD14 Mono_STIM          CD14 Mono STIM\nCD4 Naive T_CTRL   CD4 Naive T_CTRL        CD4 Naive T CTRL\nCD4 Naive T_STIM   CD4 Naive T_STIM        CD4 Naive T STIM\nCD4 Memory T_CTRL CD4 Memory T_CTRL       CD4 Memory T CTRL\n\ncolnames(aggregate_ifnb) # 可以看到现在的表达矩阵的列（即样本）为细胞类型+处理条件\n\n [1] \"CD14 Mono_CTRL\"    \"CD14 Mono_STIM\"    \"CD4 Naive T_CTRL\" \n [4] \"CD4 Naive T_STIM\"  \"CD4 Memory T_CTRL\" \"CD4 Memory T_STIM\"\n [7] \"CD16 Mono_CTRL\"    \"CD16 Mono_STIM\"    \"B_CTRL\"           \n[10] \"B_STIM\"            \"CD8 T_CTRL\"        \"CD8 T_STIM\"       \n[13] \"T activated_CTRL\"  \"T activated_STIM\"  \"NK_CTRL\"          \n[16] \"NK_STIM\"           \"DC_CTRL\"           \"DC_STIM\"          \n[19] \"B Activated_CTRL\"  \"B Activated_STIM\"  \"Mk_CTRL\"          \n[22] \"Mk_STIM\"           \"pDC_CTRL\"          \"pDC_STIM\"         \n[25] \"Eryth_CTRL\"        \"Eryth_STIM\"       \n\n\n\nAs an initial exploratory analysis, we can compare pseudobulk profiles of two cell types (naive CD4 T cells, and CD14 monocytes), and compare their gene expression profiles before and after stimulation. We highlight genes that exhibit dramatic responses to interferon stimulation.\n\nlibrary(ggplot2)\nlibrary(cowplot)\ntheme_set(theme_cowplot())\n\n# genes that exhibit dramatic responses to interferon stimulation\ngenes.to.label = c(\"ISG15\", \"LY6E\", \"IFI6\", \"ISG20\", \"MX1\", \"IFIT2\", \"IFIT1\", \"CXCL10\",\n                   \"CCL8\")\n\np1 &lt;- CellScatter(aggregate_ifnb, \n                  \"CD14 Mono_CTRL\", \"CD14 Mono_STIM\", \n                  highlight = genes.to.label)\nLabelPoints(plot = p1, \n                  points = genes.to.label, \n                  repel = TRUE)\n\np3 &lt;- CellScatter(aggregate_ifnb, \n                  \"CD4 Naive T_CTRL\", \"CD4 Naive T_STIM\", \n                  highlight = genes.to.label)\nLabelPoints(plot = p3, \n                  points = genes.to.label, \n                  repel = TRUE)\n\n\n\n\n\n(A) CD14 Mono细胞中的基因在对照组和刺激组之间的表达量散点图\n\n\n\n\n\n(B) CD4 Naive T细胞中的基因在对照组和刺激组之间的表达量散点图\n\n\n\nFigure 10.3: CD14 Mono和CD4 Naive T细胞中的基因在对照组和刺激组之间的表达量散点图\n\n\n\n\nAs you can see, many of the same genes are upregulated (位于对角线上方) in both of these cell types and likely represent a conserved interferon response pathway, though CD14 monocytes exhibit a stronger transcriptional response.\n\n正式差异分析\nWe can now ask what genes change in different conditions for cells of the same type.\n\nFirst, we create a column in the meta.data slot to hold both the cell type and stimulation information and switch the current ident to that column.\nThen we use FindMarkers() to find the genes that are different between stimulated and control B cells. Notice that many of the top genes that show up here are the same as the ones we plotted earlier as core interferon response genes. Additionally, genes like CXCL10 which we saw were specific to monocyte and B cell interferon response show up as highly significant in this list as well.\n\n\nifnb$celltype.stim &lt;- paste(ifnb$seurat_annotations, ifnb$stim, sep = \"_\")\nIdents(ifnb) &lt;- \"celltype.stim\"\n\n# 寻找对照组和刺激组之间在B细胞中的差异基因\nb.interferon.response &lt;- FindMarkers(ifnb, \n                                     ident.1 = \"B_STIM\", \n                                     ident.2 = \"B_CTRL\", \n                                     verbose = FALSE)\nhead(b.interferon.response, n = 15)\n\n                p_val avg_log2FC pct.1 pct.2     p_val_adj\nISG15   5.387767e-159  5.0588481 0.998 0.233 7.571429e-155\nIFIT3   1.945114e-154  6.1124940 0.965 0.052 2.733468e-150\nIFI6    2.503565e-152  5.4933132 0.965 0.076 3.518260e-148\nISG20   6.492570e-150  3.0549593 1.000 0.668 9.124009e-146\nIFIT1   1.951022e-139  6.2320388 0.907 0.029 2.741772e-135\nMX1     6.897626e-123  3.9798482 0.905 0.115 9.693234e-119\nLY6E    2.825649e-120  3.7907800 0.898 0.150 3.970885e-116\nTNFSF10 4.007285e-112  6.5802175 0.786 0.020 5.631437e-108\nIFIT2   2.672552e-108  5.5525558 0.786 0.037 3.755738e-104\nB2M      5.283684e-98  0.6104044 1.000 1.000  7.425161e-94\nPLSCR1   4.634658e-96  3.8010721 0.793 0.113  6.513085e-92\nIRF7     2.411149e-94  3.1992949 0.835 0.187  3.388388e-90\nCXCL10   3.708508e-86  8.0906108 0.651 0.010  5.211566e-82\nUBE2L6   5.547472e-83  2.5167981 0.851 0.297  7.795863e-79\nPSMB9    1.716262e-77  1.7715351 0.937 0.568  2.411863e-73\n\n\nPlease note that p-values obtained from this analysis should be interpreted with caution, as these tests treat each cell as an independent replicate, and ignore inherent correlations between cells originating from the same sample. As discussed here (Crowell et al. 2020), DE tests across multiple conditions should expressly utilize multiple samples/replicates, and can be performed after aggregating (‘pseudobulking’) cells from the same sample and subpopulation together. We do not perform this analysis here, as there is a single replicate in the data, but please see our vignette comparing healthy and diabetic samples as an example for how to perform DE analysis across conditions.\nAnother useful way to visualize these changes in gene expression is with the split.by option to the FeaturePlot() or VlnPlot() function. This will display FeaturePlots of the list of given genes, split by a grouping variable (stimulation condition here).\n\nFeaturePlot(ifnb, \n            features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\"), \n            split.by = \"stim\", \n            max.cutoff = 3, \n            cols = c(\"grey\", \"red\"), \n            reduction = \"umap\")\n\n\n\n\n\nplots &lt;- VlnPlot(ifnb,\n        features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\", \"LYZ\"),\n        split.by = \"stim\",\n        group.by = \"seurat_annotations\",\n        pt.size = 0,\n        combine = FALSE) # 由于VlnPlot绘制组图时没有图例，所以这里取消绘制组图\nlibrary(patchwork)\nwrap_plots(plots = plots, ncol = 2) # 将plots列表组合成组图\n\n\n\n\n\n\nGenes such as CD3D and GNLY are canonical cell type markers (for T cells and NK/CD8 T cells) that are virtually unaffected by interferon stimulation and display similar gene expression patterns in the control and stimulated group.\nIFI6 and ISG15, on the other hand, are core interferon response genes and are upregulated accordingly in all cell types.\n\nCD14 and CXCL10 are genes that show a cell type specific interferon response.\n\nCD14 expression decreases after stimulation in CD14 monocytes, which could lead to misclassification in a supervised analysis framework, underscoring the value of integrated analysis.如果用于识别细胞类型的marker本身在不同的样本类型（处理 vs. 对照、恶性组织 vs. 正常组织）中存在表达量的差异，那么就会导致对细胞类型判断的错误。而本篇的数据整合则能够避免出现这种情况。\nCXCL10 shows a distinct upregulation in monocytes and B cells after interferon stimulation but not in other cell types."
  },
  {
    "objectID": "single_cell/seurat/integration.html#执行sctransform标准化流程之后的整合",
    "href": "single_cell/seurat/integration.html#执行sctransform标准化流程之后的整合",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.6 执行SCTransform标准化流程之后的整合",
    "text": "10.6 执行SCTransform标准化流程之后的整合\nAs an alternative to log-normalization, Seurat also includes support for preprocessing of scRNA-seq using the SCTransform workflow（ Chapter 9 ）. The IntegrateLayers function also supports SCTransform-normalized data, by setting the normalization.method parameter, as shown below.\n不进行整合的情况下的数据分析\n\n# 重新载入原始的Seurat对象ifnb\nifnb &lt;- readRDS(\"data/pbmc_ifnb.rds\")\n\n# 同样先拆分数据集，然后进行无整合情况下的降维\nifnb[[\"RNA\"]] &lt;- split(ifnb[[\"RNA\"]], f = ifnb$stim)\nifnb &lt;- SCTransform(ifnb)\nifnb &lt;- RunPCA(ifnb)\nifnb &lt;- RunUMAP(ifnb, dims = 1:30)\nDimPlot(ifnb, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\nFigure 10.4: 未整合时的细胞分群情况（左：按照刺激条件着色；右：按照细胞聚类情况着色）\n\n\n\n可以看到，如果不进行整合，不同样本（STIM vs. STIM）的细胞类型差异很大。\n进行整合\n同样通过IntegrateLayers函数进行数据整合，只不过需要将默认的标准化方法由”LogNormalize”指定为”SCT”（normalization.method = \"SCT\"）：\n\nifnb &lt;- IntegrateLayers(object = ifnb, \n                        method = CCAIntegration, \n                        normalization.method = \"SCT\", \n                        verbose = F)\n\n\n可以看到经过整合的现在的Seurat对象中除了”RNA”的assay还由”SCT”的assay。同时，降维（“reduction”）中多出了整合后的降维（“integrated.dr”）。\n整合后聚类\n\nifnb &lt;- FindNeighbors(ifnb, \n                      reduction = \"integrated.dr\", #更改降维来源为\"integrated.dr\"\n                      dims = 1:30)\nifnb &lt;- FindClusters(ifnb, \n                     resolution = 0.6)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 13999\nNumber of edges: 527905\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9058\nNumber of communities: 19\nElapsed time: 1 seconds\n\nifnb &lt;- RunUMAP(ifnb, \n                dims = 1:30, \n                reduction = \"integrated.dr\")\nDimPlot(ifnb, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\n\n可以看到和 Figure 10.4 相比，整合后在样本间的细胞类型基本均匀分布。\n差异表达分析\n对于SCTransform处理的数据首先要通过PrepSCTFindMarkers函数来预处理，然后再进行差异分析，基本内容和 Section 10.5.1 一致。\n\nifnb &lt;- PrepSCTFindMarkers(ifnb)\nifnb$celltype.stim &lt;- paste(ifnb$seurat_annotations, \n                            ifnb$stim, \n                            sep = \"_\")\nIdents(ifnb) &lt;- \"celltype.stim\"\nb.interferon.response &lt;- FindMarkers(ifnb, \n                                     ident.1 = \"B_STIM\", \n                                     ident.2 = \"B_CTRL\", \n                                     verbose = FALSE)\nhead(b.interferon.response, n = 15)\n\n                p_val avg_log2FC pct.1 pct.2     p_val_adj\nISG15   1.505650e-159  5.1597242 0.998 0.229 2.003417e-155\nIFIT3   4.128835e-154  6.2281506 0.961 0.052 5.493827e-150\nIFI6    2.493020e-153  5.6458391 0.965 0.076 3.317212e-149\nISG20   9.385626e-152  3.1715979 1.000 0.666 1.248851e-147\nIFIT1   2.447118e-139  6.2614957 0.904 0.029 3.256136e-135\nMX1     2.111944e-124  4.1490465 0.900 0.115 2.810153e-120\nLY6E    2.930414e-122  3.9278136 0.898 0.150 3.899209e-118\nTNFSF10 1.104024e-112  6.8254288 0.785 0.020 1.469014e-108\nIFIT2   3.491368e-108  5.5668205 0.783 0.037 4.645615e-104\nB2M      3.405403e-98  0.6074989 1.000 1.000  4.531229e-94\nIRF7     1.114291e-96  3.3721350 0.834 0.187  1.482675e-92\nPLSCR1   3.364901e-96  4.0217697 0.783 0.111  4.477338e-92\nUBE2L6   1.155610e-85  2.6732717 0.849 0.295  1.537655e-81\nCXCL10   5.689834e-84  8.0923962 0.639 0.010  7.570893e-80\nPSMB9    2.304426e-81  1.8684260 0.937 0.568  3.066269e-77\n\n\n\nFeaturePlot(ifnb, \n            features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\"), \n            split.by = \"stim\", \n            max.cutoff = 3, \n            cols = c(\"grey\", \"red\"), \n            reduction = \"umap\")\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] patchwork_1.1.3    cowplot_1.1.1      ggplot2_3.4.4      Seurat_5.0.1      \n[5] SeuratObject_5.0.1 sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] mathjaxr_1.6-0              RColorBrewer_1.1-3         \n  [3] rstudioapi_0.15.0           jsonlite_1.8.7             \n  [5] magrittr_2.0.3              TH.data_1.1-2              \n  [7] spatstat.utils_3.0-4        farver_2.1.1               \n  [9] rmarkdown_2.25              zlibbioc_1.48.0            \n [11] vctrs_0.6.4                 multtest_2.58.0            \n [13] ROCR_1.0-11                 DelayedMatrixStats_1.24.0  \n [15] spatstat.explore_3.2-5      RCurl_1.98-1.13            \n [17] S4Arrays_1.2.0              htmltools_0.5.7            \n [19] plotrix_3.8-4               SparseArray_1.2.2          \n [21] sctransform_0.4.1           parallelly_1.36.0          \n [23] KernSmooth_2.23-22          htmlwidgets_1.6.3          \n [25] ica_1.0-3                   sandwich_3.0-2             \n [27] plyr_1.8.9                  plotly_4.10.3              \n [29] zoo_1.8-12                  igraph_1.5.1               \n [31] mime_0.12                   lifecycle_1.0.4            \n [33] pkgconfig_2.0.3             Matrix_1.6-3               \n [35] R6_2.5.1                    fastmap_1.1.1              \n [37] GenomeInfoDbData_1.2.11     MatrixGenerics_1.14.0      \n [39] rbibutils_2.2.16            fitdistrplus_1.1-11        \n [41] future_1.33.0               shiny_1.8.0                \n [43] digest_0.6.33               numDeriv_2016.8-1.1        \n [45] colorspace_2.1-0            S4Vectors_0.40.1           \n [47] tensor_1.5                  RSpectra_0.16-1            \n [49] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [51] labeling_0.4.3              progressr_0.14.0           \n [53] fansi_1.0.5                 spatstat.sparse_3.0-3      \n [55] httr_1.4.7                  TFisher_0.2.0              \n [57] polyclip_1.10-6             abind_1.4-5                \n [59] compiler_4.3.2              withr_2.5.2                \n [61] mutoss_0.1-13               fastDummies_1.7.3          \n [63] MASS_7.3-60                 DelayedArray_0.28.0        \n [65] tools_4.3.2                 lmtest_0.9-40              \n [67] metap_1.9                   httpuv_1.6.12              \n [69] future.apply_1.11.0         qqconf_1.3.2               \n [71] goftest_1.2-3               glmGamPoi_1.14.0           \n [73] glue_1.6.2                  nlme_3.1-163               \n [75] promises_1.2.1              grid_4.3.2                 \n [77] Rtsne_0.16                  cluster_2.1.4              \n [79] reshape2_1.4.4              generics_0.1.3             \n [81] gtable_0.3.4                spatstat.data_3.0-3        \n [83] tidyr_1.3.0                 sn_2.1.1                   \n [85] data.table_1.14.8           XVector_0.42.0             \n [87] utf8_1.2.4                  BiocGenerics_0.48.1        \n [89] spatstat.geom_3.2-7         RcppAnnoy_0.0.21           \n [91] ggrepel_0.9.4               RANN_2.6.1                 \n [93] pillar_1.9.0                stringr_1.5.1              \n [95] spam_2.10-0                 RcppHNSW_0.5.0             \n [97] later_1.3.1                 splines_4.3.2              \n [99] dplyr_1.1.4                 lattice_0.22-5             \n[101] survival_3.5-7              deldir_2.0-2               \n[103] tidyselect_1.2.0            miniUI_0.1.1.1             \n[105] pbapply_1.7-2               knitr_1.45                 \n[107] gridExtra_2.3               IRanges_2.36.0             \n[109] SummarizedExperiment_1.32.0 scattermore_1.2            \n[111] stats4_4.3.2                xfun_0.41                  \n[113] Biobase_2.62.0              matrixStats_1.1.0          \n[115] stringi_1.8.2               lazyeval_0.2.2             \n[117] yaml_2.3.7                  evaluate_0.23              \n[119] codetools_0.2-19            tibble_3.2.1               \n[121] cli_3.6.1                   uwot_0.1.16                \n[123] xtable_1.8-4                reticulate_1.34.0          \n[125] Rdpack_2.6                  munsell_0.5.0              \n[127] GenomeInfoDb_1.38.1         Rcpp_1.0.11                \n[129] globals_0.16.2              spatstat.random_3.2-1      \n[131] png_0.1-8                   parallel_4.3.2             \n[133] ellipsis_0.3.2              dotCall64_1.1-0            \n[135] sparseMatrixStats_1.14.0    bitops_1.0-7               \n[137] listenv_0.9.0               viridisLite_0.4.2          \n[139] mvtnorm_1.2-3               scales_1.2.1               \n[141] ggridges_0.5.4              crayon_1.5.2               \n[143] leiden_0.4.3.1              purrr_1.0.2                \n[145] rlang_1.1.2                 multcomp_1.4-25            \n[147] mnormt_2.1.1               \n\n\n\n\n\n\n\n\n\n\n\nCrowell, Helena L., Charlotte Soneson, Pierre-Luc Germain, Daniela Calini, Ludovic Collin, Catarina Raposo, Dheeraj Malhotra, and Mark D. Robinson. 2020. “Muscat Detects Subpopulation-Specific State Transitions from Multi-Sample Multi-Condition Single-Cell Transcriptomics Data.” Nature Communications 11 (1). https://doi.org/10.1038/s41467-020-19894-4."
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#加载数据",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#加载数据",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.1 加载数据",
    "text": "11.1 加载数据\n\n\n\n\n\n\n在线读取（可能需要全局代理）\n\n\n\n\n\n\n```{r}\n#| eval: false\nlibrary(SeuratData)\nInstallData(\"pbmcsca\")\nlibrary(Seurat)\nobj &lt;- LoadData(\"pbmcsca\")\n```\n\n\n\n\n从本地下载好的数据读取：\n\nlibrary(Seurat)\nobj &lt;- readRDS(\"data/pbmcsca.rds\")\nobj\n\nAn object of class Seurat \n33694 features across 31021 samples within 1 assay \nActive assay: RNA (33694 features, 0 variable features)\n 2 layers present: counts, data\n\ncolnames(obj)[1:8]\n\n[1] \"pbmc1_SM2_Cell_108\" \"pbmc1_SM2_Cell_115\" \"pbmc1_SM2_Cell_133\"\n[4] \"pbmc1_SM2_Cell_142\" \"pbmc1_SM2_Cell_143\" \"pbmc1_SM2_Cell_144\"\n[7] \"pbmc1_SM2_Cell_146\" \"pbmc1_SM2_Cell_148\"\n\nrownames(obj)[1:5]\n\n[1] \"TSPAN6\"   \"TNMD\"     \"DPM1\"     \"SCYL3\"    \"C1orf112\"\n\nhead(obj@meta.data, 5)\n\n                   orig.ident nCount_RNA nFeature_RNA nGene   nUMI\npbmc1_SM2_Cell_108      pbmc1     437125         2200  2200 437125\npbmc1_SM2_Cell_115      pbmc1     335596         2438  2438 335596\npbmc1_SM2_Cell_133      pbmc1     302204         1874  1874 302204\npbmc1_SM2_Cell_142      pbmc1     377420         2480  2480 377420\npbmc1_SM2_Cell_143      pbmc1     385514         2196  2196 385514\n                         percent.mito Cluster         CellType Experiment\npbmc1_SM2_Cell_108 0.0297434465355702       0 Cytotoxic T cell      pbmc1\npbmc1_SM2_Cell_115 0.0311521658159055       0 Cytotoxic T cell      pbmc1\npbmc1_SM2_Cell_133 0.0431128105727693       0 Cytotoxic T cell      pbmc1\npbmc1_SM2_Cell_142 0.0260323569927476       0 Cytotoxic T cell      pbmc1\npbmc1_SM2_Cell_143 0.0404759383962183       0 Cytotoxic T cell      pbmc1\n                       Method\npbmc1_SM2_Cell_108 Smart-seq2\npbmc1_SM2_Cell_115 Smart-seq2\npbmc1_SM2_Cell_133 Smart-seq2\npbmc1_SM2_Cell_142 Smart-seq2\npbmc1_SM2_Cell_143 Smart-seq2\n\ntable(obj$Method)\n\n\n  10x Chromium (v2) 10x Chromium (v2) A 10x Chromium (v2) B   10x Chromium (v3) \n               3362                3222                3222                3222 \n           CEL-Seq2            Drop-seq             inDrops            Seq-Well \n                526                6584                6584                3773 \n         Smart-seq2 \n                526 \n\n\nThe object contains data from nine different batches (stored in the Method column in the object metadata), representing seven different technologies. We will aim to integrate the different batches together."
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#数据质控",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#数据质控",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.2 数据质控",
    "text": "11.2 数据质控\n过滤低质量细胞：\n\nobj &lt;- subset(obj, nFeature_RNA &gt; 1000)\n\n这个地方为了验证后面整合的效果对细胞类型提前进行了注释。\n\ntable(obj$CellType)\n\n\n                     B cell              CD14+ monocyte \n                       1525                        1557 \n             CD16+ monocyte                 CD4+ T cell \n                        404                        3018 \n           Cytotoxic T cell              Dendritic cell \n                       2791                         281 \n              Megakaryocyte         Natural killer cell \n                          9                         763 \nPlasmacytoid dendritic cell                  Unassigned \n                         78                           8"
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#分割数据",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#分割数据",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.3 分割数据",
    "text": "11.3 分割数据\nIn previous versions of Seurat, if we want to integrate this data, we would require the data to be represented as nine different Seurat objects. When using Seurat v5 assays, we can instead keep all the data in one object, but simply split the layers:\n\nobj[[\"RNA\"]] &lt;- split(obj[[\"RNA\"]], f = obj$Method)\nobj\n\nAn object of class Seurat \n33694 features across 10434 samples within 1 assay \nActive assay: RNA (33694 features, 0 variable features)\n 18 layers present: counts.Smart-seq2, counts.CEL-Seq2, counts.10x_Chromium_v2_A, counts.10x_Chromium_v2_B, counts.10x_Chromium_v3, counts.Drop-seq, counts.Seq-Well, counts.inDrops, counts.10x_Chromium_v2, data.Smart-seq2, data.CEL-Seq2, data.10x_Chromium_v2_A, data.10x_Chromium_v2_B, data.10x_Chromium_v3, data.Drop-seq, data.Seq-Well, data.inDrops, data.10x_Chromium_v2\n\n\nAfter splitting, there are now 18 layers (a counts and data layer for each batch)."
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#未整合情况下的标准scrna-seq分析流程",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#未整合情况下的标准scrna-seq分析流程",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.4 未整合情况下的标准scRNA-seq分析流程",
    "text": "11.4 未整合情况下的标准scRNA-seq分析流程\n标准化、找高变基因、归一化、降维\nWe can now run a standard scRNA-seq analysis (i.e. without integration). Note that since the data is split into layers, normalization and variable feature identification is performed for each batch independently (a consensus set of variable features is automatically identified).\n\nobj &lt;- NormalizeData(obj)\nobj &lt;- FindVariableFeatures(obj)\nobj &lt;- ScaleData(obj)\nobj &lt;- RunPCA(obj)\nobj &lt;- RunUMAP(obj, \n               dims = 1:30, \n               reduction = \"pca\", \n               reduction.name = \"umap.unintegrated\") # name to store dimensional reduction in the Seurat object\n\n聚类、可视化\nWe can now visualize the results of a standard analysis without integration. Note that cells are grouping both by cell type and by underlying method. While a UMAP analysis is just a visualization of this, clustering this dataset would return predominantly batch-specific clusters. Especially if previous cell-type annotations were not available, this would make downstream analysis extremely challenging.\n\nobj &lt;- FindNeighbors(obj, dims = 1:30, reduction = \"pca\")\nobj &lt;- FindClusters(obj, resolution = 2, cluster.name = \"unintegrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10434\nNumber of edges: 412660\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8981\nNumber of communities: 48\nElapsed time: 0 seconds\n\nDimPlot(obj, \n        reduction = \"umap.unintegrated\", \n        group.by = c(\"Method\", \"CellType\"))\n\n\n\n\n可以看到，不同的测序技术间的细胞类型差异较大。因此需要对数据进行整合。"
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#数据整合",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#数据整合",
    "title": "\n11  Seurat v5单细胞数据整合分析\n",
    "section": "\n11.5 数据整合",
    "text": "11.5 数据整合\nSeurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches:\n\nAnchor-based CCA integration (method=CCAIntegration)\nAnchor-based RPCA integration (method=RPCAIntegration)\nHarmony (method=HarmonyIntegration)\nFastMNN (method= FastMNNIntegration)\nscVI (method=scVIIntegration)\n\nNote that our anchor-based RPCA integration represents a faster and more conservative (less correction) method for integration. For interested users, we discuss this method in more detail in our previous RPCA vignette.\nYou can find more detail on each method, and any installation prerequisites, in Seurat’s documentation (for example, ?HarmonyIntegration). For example, harmony整合需要先安装harmony包（install.packages(\"harmony\")）；scVI integration requires reticulate which can be installed from CRAN (install.packages(\"reticulate\")) as well as scvi-tools and its dependencies installed in a conda environment. Please see scVI installation instructions here.\nEach of the following lines perform a new integration using a single line of code:\n（这里我们选择其中的CCAIntegration和HarmonyIntegration两种方式分别对数据进行整合，整合后后的降维信息分别储存在”integrated.cca”和”harmony”中）\n\nobj &lt;- IntegrateLayers(\n  object = obj,\n  method = CCAIntegration,\n  orig.reduction = \"pca\",\n  new.reduction = \"integrated.cca\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = RPCAIntegration,\n  orig.reduction = \"pca\", \n  new.reduction = \"integrated.rpca\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n```\n\n\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = HarmonyIntegration,\n  orig.reduction = \"pca\", \n  new.reduction = \"harmony\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n[4] \"harmony\"          \n\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = FastMNNIntegration,\n  new.reduction = \"integrated.mnn\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n```\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = scVIIntegration,\n  new.reduction = \"integrated.scvi\",\n  conda_env = \"../miniconda3/envs/scvi-env\", \n  verbose = FALSE\n)\nnames(obj@reductions)\n```"
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#重新降维聚类可视化",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#重新降维聚类可视化",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.6 重新降维、聚类、可视化",
    "text": "11.6 重新降维、聚类、可视化\nCCAIntegration：\n\nobj &lt;- RunUMAP(obj, \n               reduction = \"integrated.cca\", \n               dims = 1:30, \n               reduction.name = \"umap.cca\")\nobj &lt;- FindNeighbors(obj, reduction = \"integrated.cca\", dims = 1:30)\nobj &lt;- FindClusters(obj, resolution = 2, cluster.name = \"cca_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10434\nNumber of edges: 617481\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8039\nNumber of communities: 26\nElapsed time: 1 seconds\n\ncolnames(obj@meta.data)\n\n [1] \"orig.ident\"            \"nCount_RNA\"            \"nFeature_RNA\"         \n [4] \"nGene\"                 \"nUMI\"                  \"percent.mito\"         \n [7] \"Cluster\"               \"CellType\"              \"Experiment\"           \n[10] \"Method\"                \"unintegrated_clusters\" \"seurat_clusters\"      \n[13] \"cca_clusters\"         \n\np1 &lt;- DimPlot(obj,\n              reduction = \"umap.cca\",\n              group.by = c(\"Method\", \"CellType\", \"cca_clusters\"),\n              combine = FALSE, \n              label.size = 2)\n\nHarmonyIntegration：\n\nobj &lt;- RunUMAP(obj, \n               reduction = \"harmony\", \n               dims = 1:30, \n               reduction.name = \"umap.harmony\")\nobj &lt;- FindNeighbors(obj, reduction = \"harmony\", dims = 1:30)\nobj &lt;- FindClusters(obj, resolution = 2, cluster.name = \"harmony_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10434\nNumber of edges: 455235\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.7917\nNumber of communities: 25\nElapsed time: 1 seconds\n\ncolnames(obj@meta.data)\n\n [1] \"orig.ident\"            \"nCount_RNA\"            \"nFeature_RNA\"         \n [4] \"nGene\"                 \"nUMI\"                  \"percent.mito\"         \n [7] \"Cluster\"               \"CellType\"              \"Experiment\"           \n[10] \"Method\"                \"unintegrated_clusters\" \"seurat_clusters\"      \n[13] \"cca_clusters\"          \"harmony_clusters\"     \n\np2 &lt;- DimPlot(obj,\n              reduction = \"umap.harmony\",\n              group.by = c(\"Method\", \"CellType\", \"harmony_clusters\"),\n              combine = FALSE, \n              label.size = 2)\n\n合并UMAP图：\n\nlibrary(patchwork)\nwrap_plots(c(p1, p2), ncol = 2, byrow = F)"
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#检验细胞类型marker基因的表达",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#检验细胞类型marker基因的表达",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.7 检验细胞类型marker基因的表达",
    "text": "11.7 检验细胞类型marker基因的表达\nWe hope that by simplifying the process of performing integrative analysis, users can more carefully evaluate the biological information retained in the integrated dataset. For example, users can compare the expression of biological markers based on different clustering solutions, or visualize one method’s clustering solution on different UMAP visualizations.\n\nlibrary(ggplot2)\np1 &lt;- VlnPlot(obj,\n              features = \"rna_CD8A\", \n              group.by = \"unintegrated_clusters\",\n              pt.size = 0) + \n  NoLegend() + \n  ggtitle(\"CD8A - Unintegrated Clusters\")\np2 &lt;- VlnPlot(obj, \n              \"rna_CD8A\",\n              group.by = \"cca_clusters\",\n              pt.size = 0) + \n  NoLegend() + \n  ggtitle(\"CD8A - CCA Clusters\")\np3 &lt;- VlnPlot(obj, \n              \"rna_CD8A\",\n              group.by = \"harmony_clusters\",\n              pt.size = 0) + \n  NoLegend() + \n  ggtitle(\"CD8A - harmony Clusters\")\np1 | p2 | p3"
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#重新合并layers",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#重新合并layers",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.8 重新合并layers",
    "text": "11.8 重新合并layers\nOnce integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always resplit the layers in case you would like to reperform integrative analysis.\n\nobj &lt;- JoinLayers(obj)\nobj\n\nAn object of class Seurat \n33694 features across 10434 samples within 1 assay \nActive assay: RNA (33694 features, 2000 variable features)\n 3 layers present: data, counts, scale.data\n 6 dimensional reductions calculated: pca, umap.unintegrated, integrated.cca, harmony, umap.cca, umap.harmony"
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#对sctransform处理后的数据的整合",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#对sctransform处理后的数据的整合",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.9 对SCTransform处理后的数据的整合",
    "text": "11.9 对SCTransform处理后的数据的整合\nUsers can also perform integration using sctransform-normalized data (see Chapter 9 for more information), by first running SCTransform normalization, and then setting the normalization.method argument in IntegrateLayers（和 Section 10.6.2 中一样）。\n\nrm(list = ls())\n#重新载入数据、质控、分割\nobj &lt;- readRDS(\"data/pbmcsca.rds\")\nobj &lt;- subset(obj, nFeature_RNA &gt; 1000)\nobj[[\"RNA\"]] &lt;- split(obj[[\"RNA\"]], f = obj$Method)\n# 执行SCTransform\nobj &lt;- SCTransform(obj)\n# 降维\nobj &lt;- RunPCA(obj, npcs = 30, verbose = F)\n# 整合\n#options(future.globals.maxSize = 3e+09)\nobj &lt;- IntegrateLayers(object = obj,\n                       method = CCAIntegration,\n                       normalization.method = \"SCT\",\n                       orig.reduction = \"pca\",\n                       new.reduction = \"integrated.cca\",\n                       verbose = F)\n# 重新降维、聚类、可视化\nobj &lt;- RunUMAP(obj, \n               dims = 1:30, \n               reduction = \"integrated.cca\", \n               reduction.name = \"umap.cca\")\nobj &lt;- FindNeighbors(obj, dims = 1:30, reduction = \"integrated.cca\")\nobj &lt;- FindClusters(obj, resolution = 2, cluster.name = \"cca_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10434\nNumber of edges: 499367\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8342\nNumber of communities: 26\nElapsed time: 0 seconds\n\nDimPlot(obj,\n        reduction = \"umap.cca\",\n        group.by = c(\"Method\", \"cca_clusters\"),\n        label.size = 1)\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      patchwork_1.1.3    Seurat_5.0.1       SeuratObject_5.0.1\n[5] sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.4           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         utf8_1.2.4            \n [19] promises_1.2.1         rmarkdown_2.25         purrr_1.0.2           \n [22] xfun_0.41              jsonlite_1.8.7         goftest_1.2-3         \n [25] later_1.3.1            spatstat.utils_3.0-4   irlba_2.3.5.1         \n [28] parallel_4.3.2         cluster_2.1.4          R6_2.5.1              \n [31] ica_1.0-3              stringi_1.8.2          RColorBrewer_1.1-3    \n [34] spatstat.data_3.0-3    reticulate_1.34.0      parallelly_1.36.0     \n [37] lmtest_0.9-40          scattermore_1.2        Rcpp_1.0.11           \n [40] knitr_1.45             tensor_1.5             future.apply_1.11.0   \n [43] zoo_1.8-12             sctransform_0.4.1      httpuv_1.6.12         \n [46] Matrix_1.6-3           splines_4.3.2          igraph_1.5.1          \n [49] tidyselect_1.2.0       abind_1.4-5            rstudioapi_0.15.0     \n [52] yaml_2.3.7             spatstat.random_3.2-1  codetools_0.2-19      \n [55] miniUI_0.1.1.1         spatstat.explore_3.2-5 listenv_0.9.0         \n [58] lattice_0.22-5         tibble_3.2.1           plyr_1.8.9            \n [61] withr_2.5.2            shiny_1.8.0            ROCR_1.0-11           \n [64] evaluate_0.23          Rtsne_0.16             future_1.33.0         \n [67] fastDummies_1.7.3      survival_3.5-7         polyclip_1.10-6       \n [70] fitdistrplus_1.1-11    pillar_1.9.0           KernSmooth_2.23-22    \n [73] plotly_4.10.3          generics_0.1.3         RcppHNSW_0.5.0        \n [76] munsell_0.5.0          scales_1.2.1           globals_0.16.2        \n [79] xtable_1.8-4           glue_1.6.2             lazyeval_0.2.2        \n [82] tools_4.3.2            data.table_1.14.8      RSpectra_0.16-1       \n [85] RANN_2.6.1             leiden_0.4.3.1         dotCall64_1.1-0       \n [88] cowplot_1.1.1          grid_4.3.2             tidyr_1.3.0           \n [91] colorspace_2.1-0       nlme_3.1-163           cli_3.6.1             \n [94] spatstat.sparse_3.0-3  spam_2.10-0            fansi_1.0.5           \n [97] viridisLite_0.4.2      dplyr_1.1.4            uwot_0.1.16           \n[100] gtable_0.3.4           digest_0.6.33          progressr_0.14.0      \n[103] ggrepel_0.9.4          htmlwidgets_1.6.3      htmltools_0.5.7       \n[106] lifecycle_1.0.4        httr_1.4.7             mime_0.12             \n[109] MASS_7.3-60           \n\n\n\n\n\n\n\n\n\n\n\nDing, Jiarui, Xian Adiconis, Sean K. Simmons, Monika S. Kowalczyk, Cynthia C. Hession, Nemanja D. Marjanovic, Travis K. Hughes, et al. 2020. “Systematic Comparison of Single-Cell and Single-Nucleus RNA-Sequencing Methods.” Nature Biotechnology 38 (6): 737–46. https://doi.org/10.1038/s41587-020-0465-8."
  },
  {
    "objectID": "single_cell/seurat/mapping_and_annotating_query_datasets.html#构建参考数据集",
    "href": "single_cell/seurat/mapping_and_annotating_query_datasets.html#构建参考数据集",
    "title": "12  基于参考集的细胞注释",
    "section": "\n12.1 构建参考数据集",
    "text": "12.1 构建参考数据集\nFor the purposes of this example, we’ve chosen human pancreatic islet cell datasets produced across four technologies, CelSeq (GSE81076) CelSeq2 (GSE85241), Fluidigm C1 (GSE86469), and SMART-Seq2 (E-MTAB-5061). For convenience, we distribute this dataset through our SeuratData package. The metadata contains the technology (tech column) and cell type annotations (celltype column) for each cell in the four datasets.\n数据读取\n\n\n\n\n\n\n在线读取（可能需要全局代理）\n\n\n\n\n\n\n```{r}\n#| eval: false\nlibrary(SeuratData)\nInstallData(\"panc8\")\nlibrary(Seurat)\npanc8 &lt;- LoadData(\"panc8\")\n```\n\n\n\n\n从本地下载好的数据读取：\n\npanc8 &lt;- readRDS(\"data/panc8.rds\")\npanc8\n\nAn object of class Seurat \n34363 features across 14890 samples within 1 assay \nActive assay: RNA (34363 features, 0 variable features)\n 2 layers present: counts, data\n\ncolnames(panc8)[1:5]\n\n[1] \"D101_5\"  \"D101_7\"  \"D101_10\" \"D101_13\" \"D101_14\"\n\nrownames(panc8)[1:5]\n\n[1] \"A1BG-AS1\" \"A1BG\"     \"A1CF\"     \"A2M-AS1\"  \"A2ML1\"   \n\nhead(panc8@meta.data, 5)\n\n        orig.ident nCount_RNA nFeature_RNA   tech replicate assigned_cluster\nD101_5        D101   4615.810         1986 celseq    celseq             &lt;NA&gt;\nD101_7        D101  29001.563         4209 celseq    celseq             &lt;NA&gt;\nD101_10       D101   6707.857         2408 celseq    celseq             &lt;NA&gt;\nD101_13       D101   8797.224         2964 celseq    celseq             &lt;NA&gt;\nD101_14       D101   5032.558         2264 celseq    celseq             &lt;NA&gt;\n        celltype dataset\nD101_5     gamma  celseq\nD101_7    acinar  celseq\nD101_10    alpha  celseq\nD101_13    delta  celseq\nD101_14     beta  celseq\n\ntable(panc8$tech)\n\n\n    celseq    celseq2 fluidigmc1     indrop  smartseq2 \n      1004       2285        638       8569       2394 \n\n\n可以看到，该数据包含了5种单细胞转录组测序技术获得的单细胞数据。\nAs a demonstration, we will use a subset of technologies to construct a reference. We will then map the remaining datasets onto this reference. we will use data from 2 technologies (celseq2和smartseq2) for the reference。\n\nlibrary(Seurat)\npancreas.ref &lt;- subset(panc8, tech %in% c(\"celseq2\", \"smartseq2\"))\n# 按照不同的测序技术将表达矩阵分为不同的layer\npancreas.ref[[\"RNA\"]] &lt;- split(pancreas.ref[[\"RNA\"]], \n                               f = pancreas.ref$tech)\n\n\n数据预处理\n标准化、找高变基因、归一化、降维、聚类、可视化：\n\npancreas.ref &lt;- NormalizeData(pancreas.ref)\npancreas.ref &lt;- FindVariableFeatures(pancreas.ref)\npancreas.ref &lt;- ScaleData(pancreas.ref)\npancreas.ref &lt;- RunPCA(pancreas.ref)\npancreas.ref &lt;- FindNeighbors(pancreas.ref, dims = 1:30)\npancreas.ref &lt;- FindClusters(pancreas.ref)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 4679\nNumber of edges: 174953\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9180\nNumber of communities: 19\nElapsed time: 0 seconds\n\npancreas.ref &lt;- RunUMAP(pancreas.ref, dims = 1:30)\nDimPlot(pancreas.ref, group.by = c(\"celltytpe\", \"tech\"))\n\n\n\n\n\nDimPlot(pancreas.ref, split.by = \"tech\")\n\n\n\n\n可以看到，不同的测序技术间的细胞类型差异较大。因此需要对数据进行整合，方法同 Chapter 10 一致。\n\npancreas.ref &lt;- IntegrateLayers(object = pancreas.ref, \n                                method = CCAIntegration, \n                                orig.reduction = \"pca\",\n                                new.reduction = \"integrated.cca\", \n                                verbose = FALSE)\n# 重新聚类\npancreas.ref &lt;- FindNeighbors(pancreas.ref, \n                              reduction = \"integrated.cca\",#更改降维来源为\"integrated.cca\"\n                              dims = 1:30)\npancreas.ref &lt;- FindClusters(pancreas.ref)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 4679\nNumber of edges: 190152\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8680\nNumber of communities: 15\nElapsed time: 0 seconds\n\n# 重新降维\npancreas.ref &lt;- RunUMAP(pancreas.ref, \n                        reduction = \"integrated.cca\", #更改降维来源为\"integrated.cca\"\n                        dims = 1:30)\nDimPlot(pancreas.ref, group.by = c(\"tech\", \"celltype\"))\n\n\n\nDimPlot(pancreas.ref, split.by = \"tech\")\n\n\n\n\n可以看到，和此前相比，整合后不再有不同测序技术间细胞类型的差异。"
  },
  {
    "objectID": "single_cell/seurat/mapping_and_annotating_query_datasets.html#基于参考集的细胞注释",
    "href": "single_cell/seurat/mapping_and_annotating_query_datasets.html#基于参考集的细胞注释",
    "title": "12  基于参考集的细胞注释",
    "section": "\n12.2 基于参考集的细胞注释",
    "text": "12.2 基于参考集的细胞注释\nSeurat also supports the projection of reference data (or meta data) onto a query object. While many of the methods are conserved (both procedures begin by identifying anchors), there are two important distinctions between data transfer and integration:\n\nIn data transfer, Seurat does not correct or modify the query expression data.\nIn data transfer, Seurat has an option (set by default) to project the PCA structure of a reference onto the query, instead of learning a joint structure with CCA. We generally suggest using this option when projecting data between scRNA-seq datasets.\n\n\nSeurat支持将参考数据集的注释信息（meta.data）映射到查询数据集上。基于Seurat的数据注释映射（data transfer）和上面的数据整合（integration）之间许多步骤都是类似的（例如这两个过程都是从识别锚点开始的），但它们之间有两个重要的区别:\n\n\n在data transfer中，Seurat不矫正或修改待查询数据集的表达矩阵。\n在 data transfer中，Seurat有一个选项（默认设置），可以将参考基因集的PCA结构投影到查询对象上，而不是使用CCA学习联合结构。\n\n\nAfter finding anchors, we use the TransferData() function to classify the query cells based on reference data (a vector of reference cell type labels). TransferData() returns a matrix with predicted IDs and prediction scores, which we can add to the query metadata.\n这里为了演示，还是选取panc8中的两个测序技术（“fluidigmc1”和”celseq”）的数据作为查询数据集。\n\npancreas.query &lt;- subset(panc8, tech %in% c(\"fluidigmc1\", \"celseq\"))\n# 标准化查询数据集\npancreas.query &lt;- NormalizeData(pancreas.query)\n# 寻找transfer锚点\npancreas.anchors &lt;- FindTransferAnchors(reference = pancreas.ref, \n                                        query = pancreas.query, \n                                        dims = 1:30,\n                                        reference.reduction = \"pca\")\n# 映射数据\npredictions &lt;- TransferData(anchorset = pancreas.anchors, \n                            refdata = pancreas.ref$celltype, \n                            dims = 1:30)\ndim(predictions)\n\n[1] 1642   15\n\npredictions[1:5, 1:3]\n\n        predicted.id prediction.score.alpha prediction.score.endothelial\nD101_5         gamma                      0                            0\nD101_7        acinar                      0                            0\nD101_10        alpha                      1                            0\nD101_13        delta                      0                            0\nD101_14         beta                      0                            0\n\n\n\n可以看到映射之后生成的predictions是一个数据框，将查询数据集中的每一个细胞和预测的细胞类型（predicted.id）一一对应，并给出了这种预测的分数。\n\n接下来，只需将predictions作为metadata添加到查询数据集：\n\npancreas.query &lt;- AddMetaData(pancreas.query, \n                              metadata = predictions)\ncolnames(pancreas.query@meta.data)\n\n [1] \"orig.ident\"                          \"nCount_RNA\"                         \n [3] \"nFeature_RNA\"                        \"tech\"                               \n [5] \"replicate\"                           \"assigned_cluster\"                   \n [7] \"celltype\"                            \"dataset\"                            \n [9] \"predicted.id\"                        \"prediction.score.alpha\"             \n[11] \"prediction.score.endothelial\"        \"prediction.score.delta\"             \n[13] \"prediction.score.beta\"               \"prediction.score.ductal\"            \n[15] \"prediction.score.acinar\"             \"prediction.score.mast\"              \n[17] \"prediction.score.gamma\"              \"prediction.score.activated_stellate\"\n[19] \"prediction.score.macrophage\"         \"prediction.score.quiescent_stellate\"\n[21] \"prediction.score.epsilon\"            \"prediction.score.schwann\"           \n[23] \"prediction.score.max\"               \n\ntable(pancreas.query$predicted.id)\n\n\n            acinar activated_stellate              alpha               beta \n               262                 39                436                419 \n             delta             ductal        endothelial              gamma \n                73                330                 19                 41 \n        macrophage               mast            schwann \n                15                  2                  6 \n\n\n\n现在的查询数据集中就多出了映射后的细胞注释信息。\n\nBecause we have the original label annotations from our full integrated analysis, we can evaluate how well our predicted cell type annotations match the full reference.\n\ntable(pancreas.query$predicted.id == pancreas.query$celltype)\n\n\nFALSE  TRUE \n   63  1579 \n\n\n\nIn this example, we find that there is a high agreement in cell type classification, with over 96%（1579/1642） of cells being labeled correctly.\n\nTo verify this further, we can examine some canonical cell type markers for specific pancreatic islet cell populations.\n\nVlnPlot(pancreas.query, \n        c(\"REG1A\", \"PPY\", \"SST\", \"GHRL\", \"VWF\", \"SOX10\"), \n        group.by = \"predicted.id\")\n\n\n\n\n\nNote that even though some of these cell types are only represented by one or two cells (e.g. epsilon cells), we are still able to classify them correctly.\n\nUMAP映射\nWe also enable projection of a query onto the reference UMAP structure. This can be achieved by computing the reference UMAP model and then calling MapQuery() instead of TransferData().\n\npancreas.ref &lt;- RunUMAP(pancreas.ref, \n                        dims = 1:30, \n                        reduction = \"integrated.cca\", \n                        return.model = TRUE)\npancreas.query &lt;- MapQuery(anchorset = pancreas.anchors, \n                           query = pancreas.query, \n                           reference = pancreas.ref, \n                           refdata = list(celltype = \"celltype\"), #需要transfer的参考数据集的列\n                           reference.reduction = \"pca\", \n                           reduction.model = \"umap\")\n\n可以看到现在的查询数据集pancreas.query中有了降维信息（reduction）。这些信息实际上是映射的参考数据集pancreas.ref的降维信息：\n\n\n\n\n\n\n\nWhat is MapQuery doing?\n\n\n\n\n\nMapQuery()打包了三个函数的功能: TransferData(), IntegrateEmbeddings(), and ProjectUMAP(). TransferData() is used to transfer cell type labels and impute the ADT values; IntegrateEmbeddings() is used to integrate reference with query by correcting the query’s projected low-dimensional embeddings; and finally ProjectUMAP() is used to project the query data onto the UMAP structure of the reference. 所以，运行MapQuery()的效果和运行下面的脚本一样:\n\npancreas.query &lt;- TransferData(anchorset = pancreas.anchors, \n                               reference = pancreas.ref, \n                               query = pancreas.query,\n                               refdata = list(celltype = \"celltype\"))\npancreas.query &lt;- IntegrateEmbeddings(anchorset = pancreas.anchors, \n                                      reference = pancreas.ref, \n                                      query = pancreas.query,\n                                      new.reduction.name = \"ref.pca\")\npancreas.query &lt;- ProjectUMAP(query = pancreas.query, \n                              query.reduction = \"ref.pca\", \n                              reference = pancreas.ref,\n                              reference.reduction = \"pca\", \n                              reduction.model = \"umap\")\n\n\n\n\nWe can now visualize the query cells alongside our reference.\n\nlibrary(ggplot2)\nDimPlot(pancreas.ref, \n        reduction = \"umap\", \n        group.by = \"celltype\", \n        label = TRUE, \n        label.size = 6,\n        repel = TRUE) + \n  NoLegend() + \n  ggtitle(\"Reference annotations\")\nDimPlot(pancreas.query, \n        reduction = \"ref.umap\", \n        group.by = \"predicted.celltype\", \n        label = TRUE,\n        label.size = 6, \n        repel = TRUE) + \n  NoLegend() + \n  ggtitle(\"Query transferred labels\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n本篇主要介绍了基于单细胞转录组测序（scRNA-seq）数据的参考数据集的制作和映射。Seurat现在还提供了一种’bridge integration’的方法，可以将其他单细胞组学数据（如scATAC-seq、scDNAme、CyTOF）映射到scRNA-seq参考数据集上。详见：Dictionary Learning for cross-modality integration。\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.4           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.4         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.11            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.0    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.12          Matrix_1.6-3           splines_4.3.2         \n [49] igraph_1.5.1           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.7             spatstat.random_3.2-1 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             withr_2.5.2            shiny_1.8.0           \n [64] ROCR_1.0-11            evaluate_0.23          Rtsne_0.16            \n [67] future_1.33.0          fastDummies_1.7.3      survival_3.5-7        \n [70] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [73] KernSmooth_2.23-22     plotly_4.10.3          generics_0.1.3        \n [76] RcppHNSW_0.5.0         munsell_0.5.0          scales_1.2.1          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.6.2            \n [82] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.8     \n [85] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [88] dotCall64_1.1-0        cowplot_1.1.1          grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-163          \n [94] patchwork_1.1.3        cli_3.6.1              spatstat.sparse_3.0-3 \n [97] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[100] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[103] digest_0.6.33          progressr_0.14.0       ggrepel_0.9.4         \n[106] farver_2.1.1           htmlwidgets_1.6.3      htmltools_0.5.7       \n[109] lifecycle_1.0.4        httr_1.4.7             mime_0.12             \n[112] MASS_7.3-60"
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#数据读取和预处理",
    "href": "single_cell/seurat/cell_cycle_regression.html#数据读取和预处理",
    "title": "13  消除细胞周期的影响",
    "section": "\n13.1 数据读取和预处理",
    "text": "13.1 数据读取和预处理\n创建Seurat对象\n\n# Read in the expression matrix \nexp.mat &lt;- read.table(file = \"data/cell_cycle_vignette_files/nestorawa_forcellcycle_expressionMatrix.txt\",\n                      header = TRUE, \n                      as.is = TRUE, #保留字符型变量\n                      row.names = 1)\n# Create our Seurat object and complete the initalization steps\nlibrary(Seurat)\nmarrow &lt;- CreateSeuratObject(counts = Matrix::Matrix(as.matrix(exp.mat), \n                                                     sparse = T))\nmarrow\n\nAn object of class Seurat \n24193 features across 774 samples within 1 assay \nActive assay: RNA (24193 features, 0 variable features)\n 1 layer present: counts\n\nhead(marrow@meta.data, 5)\n\n         orig.ident nCount_RNA nFeature_RNA\nProg_013       Prog    2563089        10211\nProg_019       Prog    3030620         9991\nProg_031       Prog    1293487        10192\nProg_037       Prog    1357987         9599\nProg_008       Prog    4079891        10540\n\nmarrow &lt;- NormalizeData(marrow)\nmarrow &lt;- FindVariableFeatures(marrow, selection.method = \"vst\")\nmarrow &lt;- ScaleData(marrow, features = rownames(marrow))\n\n获取细胞周期marker基因列表\nA list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat. We can segregate this list into markers of G2/M phase and markers of S phase\n\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n降维\nIf we run a PCA on our object, using the variable genes we found in FindVariableFeatures() above, we see that while most of the variance can be explained by lineage, PC8 and PC10 are split on cell-cycle genes including TOP2A and MKI67. We will attempt to regress this signal from the data, so that cell-cycle heterogeneity does not contribute to PCA or downstream analysis.\n\nmarrow &lt;- RunPCA(marrow, \n                 features = VariableFeatures(marrow), \n                 ndims.print = 6:10, \n                 nfeatures.print = 10)\nDimHeatmap(marrow, dims = c(8, 10))"
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#消除细胞周期的影响",
    "href": "single_cell/seurat/cell_cycle_regression.html#消除细胞周期的影响",
    "title": "13  消除细胞周期的影响",
    "section": "\n13.2 消除细胞周期的影响",
    "text": "13.2 消除细胞周期的影响\n计算细胞周期评分\nFirst, we assign each cell a score, based on its expression of G2/M and S phase markers. These marker sets should be anticorrelated in their expression levels, and cells expressing neither are likely not cycling and in G1 phase.\n\n\n\n\n\n\n细胞周期\n\n\n\n\n\n细胞周期（cell cycle），是指能持续分裂的真核细胞从一次有丝分裂结束后，再到下一次分裂结束的循环过程（准确来说只要有DNA复制，不管是不是有丝分裂它都有细胞周期。生殖细胞无细胞周期。)。\n细胞周期的划分\n总的看来，细胞周期通常可划分为分裂间期（I期）和分裂期（M期），分裂间期是物质准备和积累阶段，分裂期则是细胞增殖的实施过程。整个周期表示为 I期→M期。\n其中分裂间期（I期）又常常可以划分为DNA合成前期（G1），DNA合成期（S）和DNA合成后期（G2）。在此期间的任务主要是完成染色质中的DNA复制和相关蛋白质的合成。将I期细分之后，整个细胞周期可以表示为：G1期→S期→G2期→M期。\n细胞进入G1期可能出现三种情况，其中暂不继续增殖，如骨髓干细胞和处于不利状态下的癌细胞，但在某些刺激下，这些细胞又可以继续生长分裂，因此有人把这种非增殖状态的G1期细胞称为G0期细胞。以区别处于增殖状态的G1期细胞。 而分裂期通常分作分裂前期(Prophase)、前中期(Prometaphase)、中期(Metaphase)、后期(Anaphase)和末期(Telophase)5个阶段，在此期间进行细胞物质的平均分配并形成两个新的细胞。\n\n\n\n\n\n\n\n\n状态\n阶段\n缩写\n描述\n\n\n\n休息\nG0期\nG0\n细胞离开周期并停止分裂的阶段。\n\n\n间期\nG1期\nG1\nG1检查点控制机制确保一切准备好进行DNA合成。\n\n\n合成\nS\nS\nDNA复制发生在这个阶段。\n\n\nG2期\nG2\n\nG2\n在DNA合成和有丝分裂之间的差距期间，细胞将继续增长。 G2检查点控制机制确保一切准备好进入M（有丝分裂）阶段并分裂。\n\n\n细胞分裂\n有丝分裂\nM\n细胞生长停止，细胞能量集中在有序地分裂成两个子细胞。有丝分裂中期的检查点（Metaphase Checkpoint）确保细胞可以完成细胞分裂。\n\n\n\n\n\n\n\nWe assign scores in the CellCycleScoring() function, which stores S and G2/M scores in object meta data, along with the predicted classification of each cell in either G2M, S or G1 phase. CellCycleScoring() can also set the identity of the Seurat object to the cell-cycle phase by passing set.ident = TRUE (the original identities are stored as old.ident). Please note that Seurat does not use the discrete classifications (G2M/G1/S) in downstream cell cycle regression. Instead, it uses the quantitative scores for G2M and S phase. However, we provide our predicted classifications in case they are of interest.\nWe score single cells based on the scoring strategy described in (Tirosh et al. 2016). See ?AddModuleScore() in Seurat for more information, this function can be used to calculate supervised module scores for any gene list.\n\nmarrow &lt;- CellCycleScoring(marrow, \n                           s.features = s.genes, \n                           g2m.features = g2m.genes, \n                           set.ident = TRUE)\ntable(Idents(marrow))\n\n\n G1 G2M   S \n287 168 319 \n\n# view cell cycle scores and phase assignments\nhead(marrow@meta.data)\n\n         orig.ident nCount_RNA nFeature_RNA     S.Score  G2M.Score Phase\nProg_013       Prog    2563089        10211 -0.14248691 -0.4680395    G1\nProg_019       Prog    3030620         9991 -0.16915786  0.5851766   G2M\nProg_031       Prog    1293487        10192 -0.34627038 -0.3971879    G1\nProg_037       Prog    1357987         9599 -0.44270212  0.6820229   G2M\nProg_008       Prog    4079891        10540  0.55854051  0.1284359     S\nProg_014       Prog    2569783        10788  0.07116218  0.3166073   G2M\n         old.ident\nProg_013      Prog\nProg_019      Prog\nProg_031      Prog\nProg_037      Prog\nProg_008      Prog\nProg_014      Prog\n\n\n可视化细胞周期的影响\n可视化细胞周期marker的表达分布：\n\nRidgePlot(marrow, \n          features = c(\"PCNA\", \"TOP2A\", \"MCM6\", \"MKI67\"), \n          ncol = 2)\n\n\n\n\n以细胞周期marker为计算依据运行PCA：\n\nmarrow &lt;- RunPCA(marrow, features = c(s.genes, g2m.genes))\nDimPlot(marrow)\n\n\n\n\n\nThe PCA running on cell cycle genes reveals, unsurprisingly, that cells separate entirely by phase.\n\n这个PCA图也可以用ggplot2的语法进一步修改：\n\nlibrary(ggplot2)\nDimPlot(marrow) + \n  theme(axis.title = element_text(size = 18), \n        legend.text = element_text(size = 18)) +\n  guides(colour = guide_legend(override.aes = list(size = 10)))\n\n\n\n\n回归（regress out）细胞周期评分\nWe now attempt to subtract (‘regress out’) this source of heterogeneity from the data. For users of Seurat v1.4, this was implemented in RegressOut. However, as the results of this procedure are stored in the scaled data slot (therefore overwriting the output of ScaleData()), we now merge this functionality into the ScaleData() function itself.\nFor each gene, Seurat models the relationship between gene expression and the S and G2M cell cycle scores. The scaled residuals of this model represent a ‘corrected’ expression matrix, that can be used downstream for dimensional reduction.\n\nmarrow &lt;- ScaleData(marrow, \n                    vars.to.regress = c(\"S.Score\", \"G2M.Score\"), \n                    features = rownames(marrow))\n\nNow, a PCA on the variable genes no longer returns components associated with cell cycle:\n\nmarrow &lt;- RunPCA(marrow, \n                 features = VariableFeatures(marrow), \n                 nfeatures.print = 10)\n\nWhen running a PCA on only cell cycle genes, cells no longer separate by cell-cycle phase:\n\nmarrow &lt;- RunPCA(marrow, \n                 features = c(s.genes, g2m.genes))\nDimPlot(marrow)\n\n\n\n\nAs the best cell cycle markers are extremely well conserved across tissues and species, we have found this procedure to work robustly and reliably on diverse datasets."
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#消除细胞周期的影响同时保留增殖细胞与静止细胞的区分",
    "href": "single_cell/seurat/cell_cycle_regression.html#消除细胞周期的影响同时保留增殖细胞与静止细胞的区分",
    "title": "13  消除细胞周期的影响",
    "section": "\n13.3 消除细胞周期的影响同时保留增殖细胞与静止细胞的区分",
    "text": "13.3 消除细胞周期的影响同时保留增殖细胞与静止细胞的区分\nThe procedure above removes all signal associated with cell cycle. In some cases, we’ve found that this can negatively impact downstream analysis, particularly in differentiating processes (like murine hematopoiesis), where stem cells are quiescent and differentiated cells are proliferating (or vice versa). In this case, regressing out all cell cycle effects can blur the distinction between stem and progenitor cells as well.\nAs an alternative, we suggest regressing out the difference between the G2/M and S phase scores. This means that signals separating non-cycling cells and cycling cells will be maintained, but differences in cell cycle phase among proliferating cells (which are often uninteresting), will be regressed out of the data\n\nmarrow$CC.Difference &lt;- marrow$S.Score - marrow$G2M.Score\nmarrow &lt;- ScaleData(marrow, \n                    vars.to.regress = \"CC.Difference\", \n                    features = rownames(marrow))\n\nCell cycle effects strongly mitigated in PCA：\n\nmarrow &lt;- RunPCA(marrow, \n                 features = VariableFeatures(marrow), \n                 nfeatures.print = 10)\n\nWhen running a PCA on cell cycle genes, actively proliferating cells remain distinct from G1 cells however, within actively proliferating cells, G2M and S phase cells group together：\n\nmarrow &lt;- RunPCA(marrow, features = c(s.genes, g2m.genes))\nDimPlot(marrow)\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-1          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.4           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.4         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.11            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.0    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.12          Matrix_1.6-3           splines_4.3.2         \n [49] igraph_1.5.1           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.7             spatstat.random_3.2-1 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             withr_2.5.2            shiny_1.8.0           \n [64] ROCR_1.0-11            evaluate_0.23          Rtsne_0.16            \n [67] future_1.33.0          fastDummies_1.7.3      survival_3.5-7        \n [70] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [73] KernSmooth_2.23-22     plotly_4.10.3          generics_0.1.3        \n [76] RcppHNSW_0.5.0         munsell_0.5.0          scales_1.2.1          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.6.2            \n [82] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.8     \n [85] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [88] dotCall64_1.1-0        cowplot_1.1.1          grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-163          \n [94] patchwork_1.1.3        cli_3.6.1              spatstat.sparse_3.0-3 \n [97] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[100] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[103] digest_0.6.33          progressr_0.14.0       ggrepel_0.9.4         \n[106] farver_2.1.1           htmlwidgets_1.6.3      htmltools_0.5.7       \n[109] lifecycle_1.0.4        httr_1.4.7             mime_0.12             \n[112] MASS_7.3-60           \n\n\n\n\n\n\n\n\n\n\n\nNestorowa, Sonia, Fiona K. Hamey, Blanca Pijuan Sala, Evangelia Diamanti, Mairi Shepherd, Elisa Laurenti, Nicola K. Wilson, David G. Kent, and Berthold Göttgens. 2016. “A Single-Cell Resolution Map of Mouse Hematopoietic Stem and Progenitor Cell Differentiation.” Blood 128 (8): e20–31. https://doi.org/10.1182/blood-2016-05-716480.\n\n\nTirosh, Itay, Benjamin Izar, Sanjay M. Prakadan, Marc H. Wadsworth, Daniel Treacy, John J. Trombetta, Asaf Rotem, et al. 2016. “Dissecting the Multicellular Ecosystem of Metastatic Melanoma by Single-Cell RNA-Seq.” Science 352 (6282): 189–96. https://doi.org/10.1126/science.aad0501."
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#数据读取和预处理",
    "href": "single_cell/seurat/de_vignette.html#数据读取和预处理",
    "title": "14  差异表达分析",
    "section": "\n14.1 数据读取和预处理",
    "text": "14.1 数据读取和预处理\nThis vignette highlights some example workflows for performing differential expression in Seurat. For demonstration purposes, we will be using the interferon-beta stimulated human PBMCs dataset (Kang et al. 2017) that is available via the SeuratData package.\n\n\n\n\n\n\n在线读取（可能需要全局代理）\n\n\n\n\n\n\nlibrary(Seurat)\nlibrary(SeuratData)\nInstallData(\"ifnb\")\nifnb &lt;- LoadData(\"ifnb\")\n\n\n\n\n从本地下载好的数据读取：\n\nlibrary(Seurat)\nifnb &lt;- readRDS(\"data/pbmc_ifnb.rds\")\nifnb\n\nAn object of class Seurat \n14053 features across 13999 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 2 layers present: counts, data\n\nhead(ifnb@meta.data, 5)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\n\ntable(ifnb$seurat_annotations) # 这里的数据已经提前注释好了细胞类型\n\n\n   CD14 Mono  CD4 Naive T CD4 Memory T    CD16 Mono            B        CD8 T \n        4362         2504         1762         1044          978          814 \n T activated           NK           DC  B Activated           Mk          pDC \n         633          619          472          388          236          132 \n       Eryth \n          55 \n\n# 标准化\nifnb &lt;- NormalizeData(ifnb)"
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#寻找细胞类型之间的差异基因",
    "href": "single_cell/seurat/de_vignette.html#寻找细胞类型之间的差异基因",
    "title": "14  差异表达分析",
    "section": "\n14.2 寻找细胞类型之间的差异基因",
    "text": "14.2 寻找细胞类型之间的差异基因\n\n\n\n\n\n\nCaution\n\n\n\nFor a much faster implementation of the Wilcoxon Rank Sum Test,(default method for FindMarkers) please install the presto package:\n\ndevtools::install_github('immunogenomics/presto')\n\n\n\nFind DE features between CD16 Mono and CD1 Mono：\n\nIdents(ifnb) &lt;- \"seurat_annotations\"\nmonocyte.de.markers &lt;- FindMarkers(ifnb, \n                                   ident.1 = \"CD16 Mono\", \n                                   ident.2 = \"CD14 Mono\")\n# view results\nnrow(monocyte.de.markers)\n\n[1] 6835\n\nhead(monocyte.de.markers)\n\n       p_val avg_log2FC pct.1 pct.2 p_val_adj\nVMO1       0   5.700274 0.778 0.084         0\nMS4A4A     0   3.349751 0.748 0.143         0\nFCGR3A     0   3.281942 0.982 0.418         0\nPLAC8      0   3.268470 0.636 0.124         0\nCXCL16     0   2.014758 0.938 0.475         0\nMS4A7      0   2.386436 0.978 0.558         0\n\n\nThe results data frame has the following columns :\n\np_val : p-value (unadjusted)\navg_log2FC : log fold-change of the average expression between the two groups. Positive values indicate that the feature is more highly expressed in the first group.\npct.1 : The percentage of cells where the feature is detected in the first group\npct.2 : The percentage of cells where the feature is detected in the second group\np_val_adj : Adjusted p-value, based on Bonferroni correction using all features in the dataset.\n\nIf the ident.2 parameter is omitted or set to NULL, FindMarkers() will test for differentially expressed features between the group specified by ident.1 and all other cells. Additionally, the parameter only.pos can be set to TRUE to only search for positive markers, i.e. features that are more highly expressed in the ident.1 group.\n\nmonocyte.de.markers &lt;- FindMarkers(ifnb, \n                                   ident.1 = \"CD16 Mono\", \n                                   ident.2 = NULL, \n                                   only.pos = TRUE)\nnrow(monocyte.de.markers)\n\n[1] 2354\n\nhead(monocyte.de.markers)\n\n       p_val avg_log2FC pct.1 pct.2 p_val_adj\nFCGR3A     0   4.532656 0.982 0.168         0\nMS4A7      0   3.806350 0.978 0.216         0\nCXCL16     0   3.274267 0.938 0.196         0\nVMO1       0   6.254651 0.778 0.044         0\nMS4A4A     0   4.747731 0.748 0.055         0\nLST1       0   2.927351 0.912 0.228         0"
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#sec-寻找不同样本类型间同一细胞类型内的差异基因",
    "href": "single_cell/seurat/de_vignette.html#sec-寻找不同样本类型间同一细胞类型内的差异基因",
    "title": "14  差异表达分析",
    "section": "\n14.3 寻找不同样本类型间同一细胞类型内的差异基因",
    "text": "14.3 寻找不同样本类型间同一细胞类型内的差异基因\nSince this dataset contains treatment information (control versus stimulated with interferon-beta), we can also ask what genes change in different conditions for cells of the same type.\n\nFirst, we create a column in the meta.data slot to hold both the cell type and treatment information and switch the current Idents to that column.\n\n\nifnb$celltype.stim &lt;- paste(ifnb$seurat_annotations, ifnb$stim, sep = \"_\")\ntable(ifnb$celltype.stim)\n\n\n B Activated_CTRL  B Activated_STIM            B_CTRL            B_STIM \n              185               203               407               571 \n   CD14 Mono_CTRL    CD14 Mono_STIM    CD16 Mono_CTRL    CD16 Mono_STIM \n             2215              2147               507               537 \nCD4 Memory T_CTRL CD4 Memory T_STIM  CD4 Naive T_CTRL  CD4 Naive T_STIM \n              859               903               978              1526 \n       CD8 T_CTRL        CD8 T_STIM           DC_CTRL           DC_STIM \n              352               462               258               214 \n       Eryth_CTRL        Eryth_STIM           Mk_CTRL           Mk_STIM \n               23                32               115               121 \n          NK_CTRL           NK_STIM          pDC_CTRL          pDC_STIM \n              298               321                51                81 \n T activated_CTRL  T activated_STIM \n              300               333 \n\nIdents(ifnb) &lt;- \"celltype.stim\"\n\n\nThen we use FindMarkers() to find the genes that are different between control and stimulated CD14 monocytes.\n\n\nmono.de &lt;- FindMarkers(ifnb, \n                       ident.1 = \"CD14 Mono_STIM\", \n                       ident.2 = \"CD14 Mono_CTRL\", \n                       verbose = FALSE)\nnrow(mono.de)\n\n[1] 6956\n\nhead(mono.de, n = 10)\n\n        p_val avg_log2FC pct.1 pct.2 p_val_adj\nIFIT1       0   7.319139 0.985 0.033         0\nCXCL10      0   8.036564 0.984 0.035         0\nRSAD2       0   6.741673 0.988 0.045         0\nTNFSF10     0   6.991279 0.989 0.047         0\nIFIT3       0   6.883785 0.992 0.056         0\nIFIT2       0   7.179929 0.961 0.039         0\nCXCL11      0   8.624208 0.932 0.012         0\nCCL8        0   9.134191 0.918 0.017         0\nIDO1        0   5.455898 0.965 0.089         0\nMX1         0   5.059052 0.960 0.093         0\n\n\nHowever, the p-values obtained from this analysis should be interpreted with caution, because these tests treat each cell as an independent replicate and ignore inherent correlations between cells originating from the same sample. Such analyses have been shown to find a large number of false positive associations, as has been demonstrated by (Squair et al. 2021), (Zimmerman, Espeland, and Langefeld 2021), (Junttila, Smolander, and Elo 2022), and others. Below, we show how pseudobulking can be used to account for such within-sample correlation."
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#pseudobulking后的差异分析",
    "href": "single_cell/seurat/de_vignette.html#pseudobulking后的差异分析",
    "title": "14  差异表达分析",
    "section": "\n14.4 pseudobulking后的差异分析",
    "text": "14.4 pseudobulking后的差异分析\nTo pseudobulk, we will use AggregateExpression() to sum together gene counts of all the cells from the same sample for each cell type. This results in one gene expression profile per sample and cell type. We can then perform DE analysis using DESeq2 on the sample level. This treats the samples, rather than the individual cells, as independent observations. 参考前面的 Section 10.5 。\n准备样本信息\nFirst, we need to retrieve the sample information for each cell. This is not loaded in the metadata, so we will load it from the Github repo of the source data for the original paper.\n\n\n\n\n\n\nAdd sample information to the dataset\n\n\n\n\n\n\n```{r}\n#| eval: false\n\n# 从GitHub仓库读取（可能需要代理）\n# load the inferred sample IDs of each cell\nctrl &lt;- read.table(url(\"https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye1.ctrl.8.10.sm.best\"), head = T, stringsAsFactors = F)\nstim &lt;- read.table(url(\"https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye2.stim.8.10.sm.best\"), head = T, stringsAsFactors = F)\n```\n\n\n# 这里提前下载好了两个样本信息文件，所以直接从本地读取\nctrl &lt;- readRDS(\"data/inferred_sample_ids_ctrl.rds\")\nstim &lt;- readRDS(\"data/inferred_sample_ids_stim.rds\")\ninfo &lt;- rbind(ctrl, stim)\ninfo$BARCODE[1:5]\n\n[1] \"AAACATACAATGCC-1\" \"AAACATACATTTCC-1\" \"AAACATACCAGAAA-1\" \"AAACATACCAGCTA-1\"\n[5] \"AAACATACCATGCA-1\"\n\ncolnames(ifnb)[1:5]\n\n[1] \"AAACATACATTTCC.1\" \"AAACATACCAGAAA.1\" \"AAACATACCTCGCT.1\" \"AAACATACCTGGTA.1\"\n[5] \"AAACATACGATGAA.1\"\n\n# 可以看到两者的barcode形式不一致\n# rename the cell IDs by substituting the '-' into '.'\ninfo$BARCODE &lt;- gsub(pattern = \"\\\\-\", replacement = \"\\\\.\", info$BARCODE)\ninfo$BARCODE[1:5]\n\n[1] \"AAACATACAATGCC.1\" \"AAACATACATTTCC.1\" \"AAACATACCAGAAA.1\" \"AAACATACCAGCTA.1\"\n[5] \"AAACATACCATGCA.1\"\n\n# only keep the cells with high-confidence sample ID\ninfo &lt;- info[grep(pattern = \"SNG\", x = info$BEST), ]\n\n# remove cells with duplicated IDs in both ctrl and stim groups\ninfo &lt;- info[!duplicated(info$BARCODE) & !duplicated(info$BARCODE, fromLast = T), ]\n\n# now add the sample IDs to ifnb \nrownames(info) &lt;- info$BARCODE\ninfo &lt;- info[, c(\"BEST\"), drop = F]\nnames(info) &lt;- c(\"donor_id\")\nifnb &lt;- AddMetaData(ifnb, metadata = info)\n\n# remove cells without donor IDs\nifnb$donor_id[is.na(ifnb$donor_id)] &lt;- \"unknown\"\nifnb &lt;- subset(ifnb, subset = donor_id != \"unknown\")\n\n\n\n\n可以看到，现在的meta.dat中多了样本信息列（donor_id），记录了每个细胞来自哪个患者：\n\nhead(ifnb@meta.data, 5)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\n                     celltype.stim donor_id\nAAACATACATTTCC.1    CD14 Mono_CTRL SNG-1016\nAAACATACCAGAAA.1    CD14 Mono_CTRL SNG-1256\nAAACATACCTCGCT.1    CD14 Mono_CTRL SNG-1256\nAAACATACCTGGTA.1          pDC_CTRL SNG-1039\nAAACATACGATGAA.1 CD4 Memory T_CTRL SNG-1488\n\ntable(ifnb$donor_id)\n\n\n SNG-101 SNG-1015 SNG-1016 SNG-1039  SNG-107 SNG-1244 SNG-1256 SNG-1488 \n    1197     3116     1438      663      652     1998     2363     2241 \n\n\n执行pseudobulking\n按照治疗分组（STIM vs. CTRL）、患者IDs、细胞类型（seurat_annotations）3个条件，执行pseudobulking (AggregateExpression)。\n\npseudo_ifnb &lt;- AggregateExpression(ifnb, \n                                   assays = \"RNA\", \n                                   return.seurat = T, \n                                   group.by = c(\"stim\", \"donor_id\", \"seurat_annotations\"))\npseudo_ifnb\n\nAn object of class Seurat \n14053 features across 206 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 3 layers present: counts, data, scale.data\n\nhead(pseudo_ifnb@meta.data) # 可以看到现在的表达矩阵的列（即样本）为治疗分组+患者IDs+细胞类型\n\n                                         orig.ident stim donor_id\nCTRL_SNG-101_CD14 Mono       CTRL_SNG-101_CD14 Mono CTRL  SNG-101\nCTRL_SNG-101_CD4 Naive T   CTRL_SNG-101_CD4 Naive T CTRL  SNG-101\nCTRL_SNG-101_CD4 Memory T CTRL_SNG-101_CD4 Memory T CTRL  SNG-101\nCTRL_SNG-101_CD16 Mono       CTRL_SNG-101_CD16 Mono CTRL  SNG-101\nCTRL_SNG-101_B                       CTRL_SNG-101_B CTRL  SNG-101\nCTRL_SNG-101_CD8 T               CTRL_SNG-101_CD8 T CTRL  SNG-101\n                          seurat_annotations\nCTRL_SNG-101_CD14 Mono             CD14 Mono\nCTRL_SNG-101_CD4 Naive T         CD4 Naive T\nCTRL_SNG-101_CD4 Memory T       CD4 Memory T\nCTRL_SNG-101_CD16 Mono             CD16 Mono\nCTRL_SNG-101_B                             B\nCTRL_SNG-101_CD8 T                     CD8 T\n\n\n然后我们在meta.data中增加一列，记录治疗分组（STIM vs. CTRL）+ 细胞类型，这是用于差异分析的分组依据。这和 Section 14.3 的第一步是一样的。\n\npseudo_ifnb$celltype.stim &lt;- paste(pseudo_ifnb$seurat_annotations, \n                                   pseudo_ifnb$stim, \n                                   sep = \"_\")\npseudo_ifnb$celltype.stim[1:5]\n\n   CTRL_SNG-101_CD14 Mono  CTRL_SNG-101_CD4 Naive T CTRL_SNG-101_CD4 Memory T \n         \"CD14 Mono_CTRL\"        \"CD4 Naive T_CTRL\"       \"CD4 Memory T_CTRL\" \n   CTRL_SNG-101_CD16 Mono            CTRL_SNG-101_B \n         \"CD16 Mono_CTRL\"                  \"B_CTRL\" \n\n\n执行差异分析\nNext, we perform DE testing on the pseudobulk level for CD14 monocytes, and compare it against the previous single-cell-level DE results.\n\n\n\n\n\n\n安装DESeq2包\n\n\n\n\n\n由于pseudobulking后的FindMarkers差异分析需要采用DESeq2包提供的方法，所以需要提前安装DESeq2包：\n\n```{r}\n#| eval: false\nBiocManager::install(\"DESeq2\")\n```\n\n\n\n\n\nIdents(pseudo_ifnb) &lt;- \"celltype.stim\"\n\nbulk.mono.de &lt;- FindMarkers(object = pseudo_ifnb, \n                            ident.1 = \"CD14 Mono_STIM\", \n                            ident.2 = \"CD14 Mono_CTRL\",\n                            test.use = \"DESeq2\") # 指定差异分析方法为\"DESeq2\"\nhead(bulk.mono.de, n = 15)\n\n                 p_val avg_log2FC pct.1 pct.2     p_val_adj\nIL1RN    3.701542e-275   6.160156     1     1 5.201777e-271\nIFITM2   1.955626e-250   4.318976     1     1 2.748242e-246\nSSB      2.699554e-203   3.066647     1     1 3.793683e-199\nNT5C3A   2.239898e-198   5.412972     1     1 3.147729e-194\nRTCB     5.700554e-162   3.133362     1     1 8.010989e-158\nRABGAP1L 4.743010e-161   5.562364     1     1 6.665352e-157\nDYNLT1   9.735640e-159   2.402726     1     1 1.368150e-154\nPLSCR1   3.191691e-146   2.676047     1     1 4.485284e-142\nISG20    9.664488e-145   5.443114     1     1 1.358151e-140\nNAPA     2.858013e-144   1.977719     1     1 4.016365e-140\nDDX58    5.957026e-142   4.640111     1     1 8.371409e-138\nHERC5    6.333722e-133   5.266515     1     1 8.900780e-129\nOASL     3.892853e-130   3.946745     1     1 5.470627e-126\nEIF2AK2  6.636434e-128   3.940167     1     1 9.326180e-124\nTMEM50A  6.731955e-117   1.355947     1     1 9.460416e-113\n\n\n\n\n\n\n\n\nFindMarkers支持的差异分析方法\n\n\n\n\n\nWe also support many other DE tests using other methods. For completeness, the following tests are currently supported:\n\n“wilcox” : Wilcoxon rank sum test (default, using ‘presto’ package)\n“wilcox_limma” : Wilcoxon rank sum test (using ‘limma’ package)\n“bimod” : Likelihood-ratio test for single cell feature expression, (McDavid et al., Bioinformatics, 2013)\n“roc” : Standard AUC classifier\n“t” : Student’s t-test\n“poisson” : Likelihood ratio test assuming an underlying negative binomial distribution. Use only for UMI-based datasets\n“negbinom” : Likelihood ratio test assuming an underlying negative binomial distribution. Use only for UMI-based datasets\n“LR” : Uses a logistic regression framework to determine differentially expressed genes. Constructs a logistic regression model predicting group membership based on each feature individually and compares this to a null model with a likelihood ratio test.\n“MAST” : GLM-framework that treates cellular detection rate as a covariate (Finak et al, Genome Biology, 2015) (Installation instructions)\n“DESeq2” : DE based on a model using the negative binomial distribution (Love et al, Genome Biology, 2014) (Installation instructions) For MAST and DESeq2, please ensure that these packages are installed separately in order to use them as part of Seurat. Once installed, use the test.use parameter can be used to specify which DE test to use.\n\n\n# Test for DE features using the MAST package\n# BiocManager::install('limma')\nIdents(ifnb) &lt;- \"seurat_annotations\"\nhead(FindMarkers(ifnb, \n                 ident.1 = \"CD14 Mono\", \n                 ident.2 = \"CD16 Mono\", \n                 test.use = \"wilcox_limma\"))\n\n               p_val avg_log2FC pct.1 pct.2     p_val_adj\nVMO1    0.000000e+00  -5.689802 0.084 0.777  0.000000e+00\nMS4A4A  0.000000e+00  -3.356037 0.141 0.747  0.000000e+00\nFCGR3A  0.000000e+00  -3.279465 0.418 0.982  0.000000e+00\nMS4A7   0.000000e+00  -2.390652 0.557 0.978  0.000000e+00\nRPS19   0.000000e+00  -1.321132 0.965 0.999  0.000000e+00\nFTL    1.636254e-307   1.318127 1.000 1.000 2.299427e-303\n\n\n\n\n\n比较单细胞水平和pseudobulk水平的差异表达分析\n接下来，我们可以比较一下单细胞水平的差异表达分析的P值和pseudobulk水平的P值：\n\nnames(bulk.mono.de) &lt;- paste0(names(bulk.mono.de), \".bulk\") # 重命名列\nbulk.mono.de$gene &lt;- rownames(bulk.mono.de)\n\nnames(mono.de) &lt;- paste0(names(mono.de), \".sc\")\nmono.de$gene &lt;- rownames(mono.de)\n\nmerge_dat &lt;- merge(mono.de, bulk.mono.de, by = \"gene\")\nmerge_dat &lt;- merge_dat[order(merge_dat$p_val.bulk), ]\n\n# 查看在两种差异分析方法中P值都有意义的基因名\ncommon &lt;- merge_dat$gene[which(merge_dat$p_val.bulk &lt; 0.05 & \n                                merge_dat$p_val.sc &lt; 0.05)]\n# 查看在pseudobulk水平P&gt;0.05但是在单细胞水平P&lt;0.05的基因名：\nonly_sc &lt;- merge_dat$gene[which(merge_dat$p_val.bulk &gt; 0.05 & \n                                  merge_dat$p_val.sc &lt; 0.05)]\n# 查看在pseudobulk水平P&lt;0.05但是在单细胞水平P&gt;0.05的基因名：\nonly_bulk &lt;- merge_dat$gene[which(merge_dat$p_val.bulk &lt; 0.05 & \n                                    merge_dat$p_val.sc &gt; 0.05)]\nprint(paste0('# 在两种差异分析方法中P值都&lt;0.05的基因有: ',length(common), \"个\"))\n\n[1] \"# 在两种差异分析方法中P值都&lt;0.05的基因有: 3519个\"\n\nprint(paste0('# 仅在单细胞水平差异分析中P值&lt;0.05的基因有: ',length(only_sc), \"个\"))\n\n[1] \"# 仅在单细胞水平差异分析中P值&lt;0.05的基因有: 1649个\"\n\nprint(paste0('# 仅在pseudobulk水平差异分析中P值&lt;0.05的基因有: ',length(only_bulk), \"个\"))\n\n[1] \"# 仅在pseudobulk水平差异分析中P值&lt;0.05的基因有: 204个\"\n\n\n\nWe can see that while the p-values are correlated between the single-cell and pseudobulk data, the single-cell p-values are often smaller and suggest higher levels of significance. In particular, there are 3,519 genes with evidence of differential expression (prior to multiple hypothesis testing) in both analyses, 1,649 genes that only appear to be differentially expressed in the single-cell analysis, and just 204 genes that only appear to be differentially expressed in the bulk analysis. We can investigate these discrepancies using VlnPlot.\n\n接下来，我们通过小提琴图来检查两种方法中的Top共同差异基因在在刺激组和对照组的表达水平：\n\n# create a new column to annotate sample-condition-celltype in the single-cell dataset\nifnb$donor_id.stim &lt;- paste0(ifnb$stim, \"-\", ifnb$donor_id)\nhead(ifnb@meta.data)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\nAAACATACGGCATT.1 IMMUNE_CTRL       1581          557 CTRL          CD14 Mono\n                     celltype.stim donor_id donor_id.stim\nAAACATACATTTCC.1    CD14 Mono_CTRL SNG-1016 CTRL-SNG-1016\nAAACATACCAGAAA.1    CD14 Mono_CTRL SNG-1256 CTRL-SNG-1256\nAAACATACCTCGCT.1    CD14 Mono_CTRL SNG-1256 CTRL-SNG-1256\nAAACATACCTGGTA.1          pDC_CTRL SNG-1039 CTRL-SNG-1039\nAAACATACGATGAA.1 CD4 Memory T_CTRL SNG-1488 CTRL-SNG-1488\nAAACATACGGCATT.1    CD14 Mono_CTRL SNG-1015 CTRL-SNG-1015\n\ntable(ifnb$celltype.stim)\n\n\n B Activated_CTRL  B Activated_STIM            B_CTRL            B_STIM \n              176               198               403               554 \n   CD14 Mono_CTRL    CD14 Mono_STIM    CD16 Mono_CTRL    CD16 Mono_STIM \n             2167              2086               494               521 \nCD4 Memory T_CTRL CD4 Memory T_STIM  CD4 Naive T_CTRL  CD4 Naive T_STIM \n              849               876               960              1497 \n       CD8 T_CTRL        CD8 T_STIM           DC_CTRL           DC_STIM \n              349               451               255               208 \n       Eryth_CTRL        Eryth_STIM           Mk_CTRL           Mk_STIM \n               22                32               110               114 \n          NK_CTRL           NK_STIM          pDC_CTRL          pDC_STIM \n              295               310                49                79 \n T activated_CTRL  T activated_STIM \n              291               322 \n\nIdents(ifnb) &lt;- \"celltype.stim\"\n# 这里我们检查p_val.bulk最小的前两个Top差异基因\nprint(merge_dat[merge_dat$gene %in% common[1:2], c('gene','p_val.sc','p_val.bulk')])\n\n       gene p_val.sc    p_val.bulk\n2785  IL1RN        0 3.701542e-275\n2739 IFITM2        0 1.955626e-250\n\n# 在细胞类型水平（CD14 Mono）查看这两个Top差异基因在刺激组和对照组的表达水平\nVlnPlot(ifnb, \n        features = common[1:2], \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"stim\") \n\n\n\n# 在样本（患者）水平查看这两个Top差异基因在刺激组和对照组的表达水平\nVlnPlot(ifnb, \n        features = common[1:2], \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"donor_id.stim\", \n        ncol = 1) \n\n\n\n\n\nIn both the pseudobulk and single-cell analyses, the p-values for these two genes are astronomically small. For both of these genes, when just comparing all stimulated CD4 monocytes to all control CD4 monocytes across samples, we see much higher expression in the stimulated cells. When breaking down these cells by sample, we continue to see consistently higher expression levels in the stimulated samples compared to the control samples; in other words, this finding is not driven by just one or two samples. Because of this consistency, we find this signal in both analyses.\n\nBy contrast, we can examine examples of genes that are only DE under the single-cell analysis.\n\nprint(merge_dat[merge_dat$gene %in% c('SRGN','HLA-DRA'), \n                c('gene','p_val.sc','p_val.bulk')])\n\n        gene     p_val.sc p_val.bulk\n5710    SRGN 4.025076e-21  0.1823188\n2603 HLA-DRA 4.989863e-09  0.1851302\n\nVlnPlot(ifnb, \n        features = c('SRGN','HLA-DRA'), \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"stim\") \n\n\n\nVlnPlot(ifnb, \n        features = c('SRGN','HLA-DRA'), \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"donor_id.stim\", \n        ncol = 1) \n\n\n\n\n\nHere, SRGN and HLA-DRA both have very small p-values in the single-cell analysis (on the orders of 10−21 and 10−9), but much larger p-values around 0.18 in the pseudobulk analysis. While there appears to be a difference between control and simulated cells when ignoring sample information, the signal is much weaker on the sample level, and we can see notable variability from sample to sample.\n\n所以，从这个例子中可以看出pseudobulk后的差异分析的结果更加准确。\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.5           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.6         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    limma_3.58.1          \n [37] reticulate_1.34.0      parallelly_1.36.0      lmtest_0.9-40         \n [40] scattermore_1.2        Rcpp_1.0.11            knitr_1.45            \n [43] tensor_1.5             future.apply_1.11.0    zoo_1.8-12            \n [46] sctransform_0.4.1      httpuv_1.6.12          Matrix_1.6-4          \n [49] splines_4.3.2          igraph_1.5.1           tidyselect_1.2.0      \n [52] abind_1.4-5            rstudioapi_0.15.0      yaml_2.3.7            \n [55] spatstat.random_3.2-2  codetools_0.2-19       miniUI_0.1.1.1        \n [58] spatstat.explore_3.2-5 listenv_0.9.0          lattice_0.22-5        \n [61] tibble_3.2.1           plyr_1.8.9             withr_2.5.2           \n [64] shiny_1.8.0            ROCR_1.0-11            evaluate_0.23         \n [67] Rtsne_0.16             future_1.33.0          fastDummies_1.7.3     \n [70] survival_3.5-7         polyclip_1.10-6        fitdistrplus_1.1-11   \n [73] pillar_1.9.0           KernSmooth_2.23-22     plotly_4.10.3         \n [76] generics_0.1.3         RcppHNSW_0.5.0         ggplot2_3.4.4         \n [79] munsell_0.5.0          scales_1.3.0           globals_0.16.2        \n [82] xtable_1.8-4           glue_1.6.2             lazyeval_0.2.2        \n [85] tools_4.3.2            data.table_1.14.8      RSpectra_0.16-1       \n [88] RANN_2.6.1             leiden_0.4.3.1         dotCall64_1.1-1       \n [91] cowplot_1.1.1          grid_4.3.2             tidyr_1.3.0           \n [94] colorspace_2.1-0       nlme_3.1-164           patchwork_1.1.3       \n [97] presto_1.0.0           cli_3.6.1              spatstat.sparse_3.0-3 \n[100] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[103] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[106] digest_0.6.33          progressr_0.14.0       ggrepel_0.9.4         \n[109] farver_2.1.1           htmlwidgets_1.6.3      htmltools_0.5.7       \n[112] lifecycle_1.0.4        httr_1.4.7             statmod_1.5.0         \n[115] mime_0.12              MASS_7.3-60           \n\n\n\n\n\n\n\n\n\n\n\nJunttila, Sini, Johannes Smolander, and Laura L Elo. 2022. “Benchmarking Methods for Detecting Differential States Between Conditions from Multi-Subject Single-Cell RNA-Seq Data.” Briefings in Bioinformatics 23 (5). https://doi.org/10.1093/bib/bbac286.\n\n\nKang, Hyun Min, Meena Subramaniam, Sasha Targ, Michelle Nguyen, Lenka Maliskova, Elizabeth McCarthy, Eunice Wan, et al. 2017. “Multiplexed Droplet Single-Cell RNA-Sequencing Using Natural Genetic Variation.” Nature Biotechnology 36 (1): 89–94. https://doi.org/10.1038/nbt.4042.\n\n\nSquair, Jordan W., Matthieu Gautier, Claudia Kathe, Mark A. Anderson, Nicholas D. James, Thomas H. Hutson, Rémi Hudelle, et al. 2021. “Confronting False Discoveries in Single-Cell Differential Expression.” Nature Communications 12 (1). https://doi.org/10.1038/s41467-021-25960-2.\n\n\nZimmerman, Kip D., Mark A. Espeland, and Carl D. Langefeld. 2021. “A Practical Solution to Pseudoreplication Bias in Single-Cell Studies.” Nature Communications 12 (1). https://doi.org/10.1038/s41467-021-21038-1."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/00_intro.html",
    "href": "single_cell/scRNA-seq_online/00_intro.html",
    "title": "scRNA-seq_online学习材料",
    "section": "",
    "text": "本节内容来自Mary Piper等编写的scRNA-seq_online: scRNA-seq Lessons from HCBC (first release)\n代码文件下载自GitHub仓库：scRNA-seq_online\n在线版本：https://hbctraining.github.io/scRNA-seq_online/\nGitHub仓库更新日期：2023年12月13日\n\nThis repository has teaching materials for a hands-on Introduction to single-cell RNA-seq analysis workshop. This workshop will instruct participants on how to design a single-cell RNA-seq experiment, and how to efficiently manage and analyze the data starting from count matrices. This will be a hands-on workshop in which we will focus on using the Seurat package using R/RStudio. Working knowledge of R is required or completion of the Introduction to R workshop.\n\nLearning Objectives\n\nExplain common considerations when designing a single-cell RNA-seq experiment\nDiscuss the steps involved in taking raw single-cell RNA-sequencing data and generating a count (gene expression) matrix\nCompute and assess QC metrics at every step in the workflow\nCluster cells based on expression data and derive the identity of the different cell types present\nPerform integration of different sample conditions"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/01_intro_to_scRNA-seq.html#why-single-cell-rna-seq",
    "href": "single_cell/scRNA-seq_online/01_intro_to_scRNA-seq.html#why-single-cell-rna-seq",
    "title": "15  单细胞测序技术介绍",
    "section": "15.1 Why single-cell RNA-seq",
    "text": "15.1 Why single-cell RNA-seq\nAcross human tissues there is an incredible diversity of cell types, states, and interactions. To better understand these tissues and the cell types present, single-cell RNA-seq (scRNA-seq) offers a glimpse into what genes are being expressed at the level of individual cells.\n\nThis exciting and cutting-edge method can be used to:\n\nexplore which cell types are present in a tissue\nidentify unknown/rare cell types or states\nelucidate the changes in gene expression during differentiation processes or across time or states\nidentify genes that are differentially expressed in particular cell types between conditions (e.g. treatment or disease)\nexplore changes in expression among a cell type while incorporating spatial, regulatory, and/or protein information\n\n\n\nSingle cell vs Bulk RNA Sequencing: The face-off。来源：Introduction to Single Cell RNA-sequencing: a practical guide\n\nPopular methods to address some of the more common investigations include:"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/01_intro_to_scRNA-seq.html#challenges-of-scrna-seq-analysis",
    "href": "single_cell/scRNA-seq_online/01_intro_to_scRNA-seq.html#challenges-of-scrna-seq-analysis",
    "title": "15  单细胞测序技术介绍",
    "section": "15.2 Challenges of scRNA-seq analysis",
    "text": "15.2 Challenges of scRNA-seq analysis\nPrior to scRNA-seq, transcriptome analysis was performed using bulk RNA-seq, which is a straight-forward method for comparing the averages of cellular expression. This method can be a good choice if looking at comparative transcriptomics (e.g. samples of the same tissue from different species), and for quantifying expression signatures in disease studies. It also has potential for the discovery of disease biomarkers if you are not expecting or not concerned about cellular heterogeneity in the sample.\nWhile bulk RNA-seq can explore differences in gene expression between conditions (e.g. treatment or disease), the differences at the cellular level are not adequately captured. For instance, in the images below, if analyzed in bulk (left) we would not detect the correct association between the expression of gene A and gene B. However, if we properly group the cells by cell type or cell state, we can see the correct correlation between the genes.\n\n\nImage credit: Trapnell, C. Defining cell types and states with single-cell genomics, Genome Research 2015 (doi: https://dx.doi.org/10.1101/gr.190595.115)\n\nDespite scRNA-seq being able to capture expression at the cellular level, sample generation and library preparation is more expensive and the analysis is much more complicated and more difficult to interpret. The complexity of analysis of scRNA-seq data involves:\n\nLarge volume of data\nLow depth of sequencing per cell\nTechnical variability across cells/samples\nBiological variability across cells/samples\n\nWe will explore each of these complexities in more detail below:\n\nLarge volume of data\nExpression data from scRNA-seq experiments represent tens or hundreds of thousands of reads for thousands of cells. The data output is much larger, requiring higher amounts of memory to analyze, larger storage requirements, and more time to run the analyses.\n\n\nLow depth of sequencing per cell\nFor the droplet-based methods of scRNA-seq, the depth of sequencing is shallow, often detecting only 10-50% of the transcriptome per cell. This results in cells showing zero counts for many of the genes. However, in a particular cell, a zero count for a gene could either mean that the gene was not being expressed or the transcripts were just not detected. Across cells, genes with higher levels of expression tend to have fewer zeros. Due to this feature, many genes will not be detected in any cell and gene expression will be highly variable between cells.\n\n\n\n\n\n\nZero-inflated?\n\n\n\n\n\nscRNA-seq data is often referred to as zero-inflated; however, recent analyses suggest that it does not contain more zeros than what would be expected given the sequencing depth (Valentine Svensson’s blog post). A more recent paper discussing modeling of scRNA-seq data is also available (Sarkar and Stephens 2021).\n\n\n\n\n\nBiological variability across cells/samples\nUninteresting sources of biological variation can result in gene expression between cells being more similar/different than the actual biological cell types/states, which can obscure the cell type identities. Uninteresting sources of biological variation (unless part of the experiment’s study) include:\n\nTranscriptional bursting: Gene transcription is not turned on all of the time for all genes. Time of harvest will determine whether gene is on or off in each cell.\nVarying rates of RNA processing: Different RNAs are processed at different rates.\nContinuous or discrete cell identities (e.g. the pro-inflammatory potential of each individual T cell): Continuous phenotypes are by definition variable in gene expression, and separating the continuous from the discrete can sometimes be difficult.\nEnvironmental stimuli: The local environment of the cell can influence the gene expression depending on spatial position, signaling molecules, etc.\nTemporal changes: Fundamental fluxuating cellular processes, such as cell cycle, can affect the gene expression profiles of individual cells.\n\n\n\nImage credit: Wagner, A, et al. Revealing the vectors of cellular identity with single-cell genomics, Nat Biotechnol. 2016 (doi:https://dx.doi.org/10.1038%2Fnbt.3711)\n\n\n\nTechnical variability across cells/samples\nTechnical sources of variation can result in gene expression between cells being more similar/different based on technical sources instead of biological cell types/states, which can obscure the cell type identities. Technical sources of variation include:\n\nCell-specific capture efficiency: Different cells will have differing numbers of transcripts captured resulting in differences in sequencing depth (e.g. 10-50% of transcriptome).\nLibrary quality: Degraded RNA, low viability/dying cells, lots of free floating RNA, poorly dissociated cells, and inaccurate quantitation of cells can result in low quality metrics\nAmplification bias: During the amplification step of library preparation, not all transcripts are amplified to the same level.\nBatch effects: Batch effects are a significant issue for scRNA-Seq analyses, since you can see significant differences in expression due solely to the batch effect.\n\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\n\nTo explore the issues generated by poor batch study design, they are highlighted nicely in this paper.\n\n\n\n\n\n\nHow to know whether you have batches?\n\n\n\n\nWere all RNA isolations performed on the same day?\nWere all library preparations performed on the same day?\nDid the same person perform the RNA isolation/library preparation for all samples?\nDid you use the same reagents for all samples?\nDid you perform the RNA isolation/library preparation in the same location?\n\nIf any of the answers is ‘No’, then you have batches.\n\n\nBest practices regarding batches:\n\nDesign the experiment in a way to avoid batches, if possible.\nIf unable to avoid batches:\n\nDo NOT confound your experiment by batch:\n\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\n\nDO split replicates of the different sample groups across batches (在不同批次中对不同的样品组进行拆分重复). The more replicates the better (definitely more than 2), if doing DE across conditions or making conclusions at the population level. If using inDrops, which prepares a single library at a time, alternate the sample groups (e.g. don’t prepare all control libraries first, then prepare all treatment libraries).\n\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\n\nDO include batch information in your experimental metadata. During the analysis, we can regress out variation due to batch or integrate across batches, so it doesn’t affect our results if we have that information."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/01_intro_to_scRNA-seq.html#conclusions",
    "href": "single_cell/scRNA-seq_online/01_intro_to_scRNA-seq.html#conclusions",
    "title": "15  单细胞测序技术介绍",
    "section": "15.3 Conclusions",
    "text": "15.3 Conclusions\nWhile scRNA-seq is a powerful and insightful method for the analysis of gene expression with single-cell resolution, there are many challenges and sources of variation that can make the analysis of the data complex or limited. Throughout the analysis of scRNA-seq data, we will try to account for or regress out variation due to the various sources of uninteresting variation in our data.\nOverall, we recommend the following:\n\nDo not perform single-cell RNA-seq unless it is necessary for the experimental question of interest. Could you answer the question using bulk sequencing, which is simpler and less costly? Perhaps FACS sorting the samples could allow for bulk analysis?\nUnderstand the details of the experimental question you wish to address. The recommended library preparation method and analysis workflow can vary based on the specific experiment.\nAvoid technical sources of variability, if possible:\n\nDiscuss experimental design with experts prior to the initiation of the experiment\nIsolate RNA from samples at same time\nPrepare libraries at same time or alternate sample groups to avoid batch confounding\nDo not confound sample groups by sex, age, or batch\n\n\n\n\n\n\n\n\nHow does single-nucleus RNA-seq (snRNA-seq) compare to single-cell RNA-seq?\n\n\n\n\n\nsnRNA-seq analyzes the expression profiles from nuclei, instead of intact cells. As you may expect, fewer transcripts are detected from the nuclei (~7,000 genes), compared to intact cells (~11,000 genes). In some situations (depending on your research materials and goals), snRNA-seq can be the preferred method as opposed to scRNA-seq.\nSome advantages of snRNA-seq include:\n\nWorks well with hard-to-isolate samples (for example, adipocytes), as well as frozen tissues\nReduces transcriptional artifacts from the isolation process\nProvides less biased cellular coverage\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n进一步了解单细胞测序技术的样本处理、平台类型、过程等，参阅：Introduction to Single Cell RNA-sequencing: a practical guide。\n\n\n\n\n\n\n\n\nSarkar, Abhishek, and Matthew Stephens. 2021. “Separating Measurement and Expression Models Clarifies Confusion in Single-Cell RNA Sequencing Analysis.” Nature Genetics 53 (6): 770–77. https://doi.org/10.1038/s41588-021-00873-4."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#end-reads-includes-all-droplet-based-methods",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#end-reads-includes-all-droplet-based-methods",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.1 3’-end reads (includes all droplet-based methods)",
    "text": "16.1 3’-end reads (includes all droplet-based methods)\nFor the analysis of scRNA-seq data, it is helpful to understand what information is present in each of the reads and how we use it moving forward through the analysis.\nFor the 3’-end sequencing methods, reads originating from different molecules of the same transcript would have originated only from the 3’ end of the transcripts, so would have a high likelihood of having the same sequence. However, the PCR step during library preparation could also generate read duplicates. To determine whether a read is a biological or technical duplicate, these methods use unique molecular identifiers, or UMIs.\n\nReads with different UMIs mapping to the same transcript were derived from different molecules and are biological duplicates - each read should be counted.\nReads with the same UMI originated from the same molecule and are technical duplicates - the UMIs should be collapsed to be counted as a single read.\nIn image below, the reads for ACTB should be collapsed and counted as a single read, while the reads for ARL1 should each be counted.\n\n\n\nImage credit: modified from Macosko EZ et al. Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets, Cell 2015 (https://doi.org/10.1016/j.cell.2015.05.002)_\n\nSo we know that we need to keep track of the UMIs, but what other information do we need to properly quantify the expression in each gene in each of the cells in our samples? Regardless of droplet method, the following are required for proper quantification at the cellular level:\n\n\nImage credit: Sarah Boswell, Director of the Single Cell Sequencing Core at HMS\n\n\nSample index: determines which sample the read originated from\n\nAdded during library preparation - needs to be documented\n\nCellular barcode: determines which cell the read originated from\n\nEach library preparation method has a stock of cellular barcodes used during the library preparation\n\nUnique molecular identifier (UMI): determines which transcript molecule the read originated from\n\nThe UMI will be used to collapse PCR duplicates\n\nSequencing read1: the Read1 sequence (red top arrow)\nSequencing read2: the Read2 sequence (purple bottom arrow)"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#single-cell-rna-seq-workflow",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#single-cell-rna-seq-workflow",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.2 Single-cell RNA-seq workflow",
    "text": "16.2 Single-cell RNA-seq workflow\nThe scRNA-seq method will determine how to parse the barcodes and UMIs from the sequencing reads. So, although a few of the specific steps will slightly differ, the overall workflow will generally follow the same steps regardless of method. The general workflow is shown below:\n\n\nImage credit: Luecken, MD and Theis, FJ. Current best practices in single‐cell RNA‐seq analysis: a tutorial, Mol Syst Biol 2019 (doi: https://doi.org/10.15252/msb.20188746)_\n\nThe steps of the workflow are:\n\nGeneration of the count matrix (method-specific steps): formating reads, demultiplexing samples, mapping and quantification\nQuality control of the raw counts: filtering of poor quality cells\nClustering of filtered counts: clustering cells based on similarities in transcriptional activity (cell types = different clusters)\nMarker identification and cluster annotation: identifying gene markers for each cluster and annotating known cell type clusters\nOptional downstream steps\n\nRegardless of the analysis being done, conclusions about a population based on a single sample per condition are not trustworthy. BIOLOGICAL REPLICATES ARE STILL NEEDED! That is, if you want to make conclusions that correspond to the population and not just the single sample."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#generation-of-count-matrix",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#generation-of-count-matrix",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.3 Generation of count matrix",
    "text": "16.3 Generation of count matrix\nWe are going to start by discussing the first part of this workflow, which is generating the count matrix from the raw sequencing data. We will focus on the 3’ end sequencing used by droplet-based methods, such as inDrops, 10X Genomics, and Drop-seq.\n\nAfter sequencing, the sequencing facility will either output the raw sequencing data as BCL or FASTQ format or will generate the count matrix. If the reads are in BCL format, then we will need to convert to FASTQ format. There is a useful command-line tool called bcl2fastq that can easily perform this conversion.\n\nNOTE: We do not demultiplex at this step in the workflow. You may have sequenced 6 samples, but the reads for all samples may be present all in the same BCL or FASTQ file.\n\nThe generation of the count matrix from the raw sequencing data will go through similar steps for many of the scRNA-seq methods.\n\nalevin is a command-line tool that estimates expression of scRNA-seq data for which the 3’ ends of transcripts were sequenced. umi-tools and zUMIs are additional tools that can perform these processes. These tools incorporate collapsing of UMIs to correct for amplification bias. The steps in this process include the following:\n\nFormatting reads and filtering noisy cellular barcodes\nDemultiplexing the samples\nMapping/pseudo-mapping to transcriptome\nCollapsing UMIs and quantification of reads\n\nIf using 10X Genomics library preparation method, then the Cell Ranger pipeline would be used for all of the above steps."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#formatting-reads-and-filtering-noisy-cellular-barcodes",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#formatting-reads-and-filtering-noisy-cellular-barcodes",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.4 1. Formatting reads and filtering noisy cellular barcodes",
    "text": "16.4 1. Formatting reads and filtering noisy cellular barcodes\nThe FASTQ files can then be used to parse out the cell barcodes, UMIs, and sample barcodes. For droplet-based methods, many of the cellular barcodes will match a low number of reads (&lt; 1000 reads) due to:\n\nencapsulation of free floating RNA from dying cells\nsimple cells (RBCs, etc.) expressing few genes\ncells that failed for some reason\n\nThese excess barcodes need to be filtered out of the sequence data prior to read alignment. To do this filtering, the ‘cellular barcode’ and the ‘molecular barcode’ are extracted and saved for each cell. For example, if using ‘umis’ tools, the information is added to the header line for each read, with the following format:\n@HWI-ST808:130:H0B8YADXX:1:1101:2088:2222:CELL_GGTCCA:UMI_CCCT\nAGGAAGATGGAGGAGAGAAGGCGGTGAAAGAGACCTGTAAAAAGCCACCGN\n+\n@@@DDBD&gt;=AFCF+&lt;CAFHDECII:DGGGHGIGGIIIEHGIIIGIIDHII#\nKnown cellular barcodes used in the library preparation method should be known, and unknown barcodes would be dropped, while allowing for an acceptable number of mismatches to the known cellular barcodes."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#demultiplexing-sample-reads",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#demultiplexing-sample-reads",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.5 2. Demultiplexing sample reads",
    "text": "16.5 2. Demultiplexing sample reads\nThe next step of the process is to demultiplex the samples, if sequencing more than a single sample. This is the one step of this process not handled by the ‘umis’ tools, but is accomplished by ‘zUMIs’. We would need to parse the reads to determine the sample barcode associated with each cell."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#mappingpseudo-mapping-to-cdnas",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#mappingpseudo-mapping-to-cdnas",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.6 3. Mapping/pseudo-mapping to cDNAs",
    "text": "16.6 3. Mapping/pseudo-mapping to cDNAs\nTo determine which gene the read originated from, the reads are aligned using traditional (STAR) or light-weight methods (Kallisto/RapMap)."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#collapsing-umis-and-quantification-of-reads",
    "href": "single_cell/scRNA-seq_online/02_SC_generation_of_count_matrix.html#collapsing-umis-and-quantification-of-reads",
    "title": "16  单细胞RNA测序—从raw data到count matrix",
    "section": "16.7 4. Collapsing UMIs and quantification of reads",
    "text": "16.7 4. Collapsing UMIs and quantification of reads\nThe duplicate UMIs are collapsed, and only the unique UMIs are quantified using a tool like Kallisto or featureCounts. The resulting output is a cell by gene matrix of counts:\n\n\nImage credit: extracted from Lafzi et al. Tutorial: guidelines for the experimental design of single-cell RNA sequencing studies, Nature Protocols 2018 (https://doi.org/10.1038/s41596-018-0073-y)_\n\nEach value in the matrix represents the number of reads in a cell originating from the corresponding gene. Using the count matrix, we can explore and filter the data, keeping only the higher quality cells."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#exploring-the-example-dataset",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#exploring-the-example-dataset",
    "title": "\n17  数据导入与Seurat对象构建\n",
    "section": "\n17.1 Exploring the example dataset",
    "text": "17.1 Exploring the example dataset\nFor this workshop we will be working with a single-cell RNA-seq dataset which is part of a larger study from (Kang et al. 2017). In this paper, the authors present a computational algorithm that harnesses genetic variation (eQTL) to determine the genetic identity of each droplet containing a single cell (singlet) and identify droplets containing two cells from different individuals (doublets).\nThe data used to test their algorithm is comprised of pooled Peripheral Blood Mononuclear Cells (PBMCs) taken from eight lupus patients, split into control and interferon beta-treated (stimulated) conditions.\n\n\nImage credit: Kang et al, 2017\n\nRaw data\nThis dataset is available on GEO (GSE96583), however the available counts matrix lacked mitochondrial reads, so we downloaded the BAM files from the SRA (SRP102802). These BAM files were converted back to FASTQ files, then run through Cell Ranger to obtain the count data that we will be using.\n\nNOTE: The count data for this dataset is also freely available from 10X Genomics and is used in the Seurat tutorial.\n\nMetadata\nIn addition to the raw data, we also need to collect information about the data; this is known as metadata. There is often a temptation to just start exploring the data, but it is not very meaningful if we know nothing about the samples that this data originated from.\nSome relevant metadata for our dataset is provided below:\n\nThe libraries were prepared using 10X Genomics version 2 chemistry\nThe samples were sequenced on the Illumina NextSeq 500\n\nPBMC samples from eight individual lupus patients were separated into two aliquots each.\n\nOne aliquot of PBMCs was activated by 100 U/mL of recombinant IFN-β for 6 hours.\nThe second aliquot was left untreated.\nAfter 6 hours, the eight samples for each condition were pooled together in two final pools (stimulated cells and control cells). We will be working with these two, pooled samples. (We did not demultiplex the samples because SNP genotype information was used to demultiplex in the paper and the barcodes/sample IDs were not readily available for this data. Generally, you would demultiplex and perform QC on each individual sample rather than pooling the samples.)\n\n\n12,138 and 12,167 cells were identified (after removing doublets) for control and stimulated pooled samples, respectively.\n\nSince the samples are PBMCs, we will expect immune cells, such as:\n\nB cells\nT cells\nNK cells\nmonocytes\nmacrophages\npossibly megakaryocytes\n\n\n\nIt is recommended that you have some expectation regarding the cell types you expect to see in a dataset prior to performing the QC. This will inform you if you have any cell types with low complexity (lots of transcripts from a few genes) or cells with higher levels of mitochondrial expression. This will enable us to account for these biological factors during the analysis workflow.\nNone of the above cell types are expected to be low complexity or anticipated to have high mitochondrial content."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#loading-single-cell-rna-seq-count-data",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#loading-single-cell-rna-seq-count-data",
    "title": "\n17  数据导入与Seurat对象构建\n",
    "section": "\n17.2 Loading single-cell RNA-seq count data",
    "text": "17.2 Loading single-cell RNA-seq count data\nRegardless of the technology or pipeline used to process your raw single-cell RNA-seq sequence data, the output with quantified expression will generally be the same. That is, for each individual sample you will have the following three files:\n\na file with the cell IDs, representing all cells quantified\na file with the gene IDs, representing all genes quantified\na matrix of counts per gene for every cell\n\nWe can explore these files by clicking the data/ctrl_raw_feature_bc_matrix folder:\n1. barcodes.tsv\n\nThis is a text file which contains all cellular barcodes present for that sample. Barcodes are listed in the order of data presented in the matrix file (i.e. these are the column names).\n\n2. features.tsv\n\nThis is a text file which contains the identifiers of the quantified genes. The source of the identifier can vary depending on what reference (i.e. Ensembl, NCBI, UCSC) you use in the quantification methods, but most often these are official gene symbols. The order of these genes corresponds to the order of the rows in the matrix file (i.e. these are the row names).\n\n3. matrix.mtx\n\nThis is a text file which contains a matrix of count values. The rows are associated with the gene IDs above and columns correspond to the cellular barcodes. Note that there are many zero values in this matrix.\n\nLoading this data into R requires us to use functions that allow us to efficiently combine these three files into a single count matrix. However, instead of creating a regular matrix data structure, the functions we will use create a sparse matrix to reduce the amount of memory (RAM), processing capacity (CPU) and storage required to work with our huge count matrix.\nDifferent methods for reading in data include:\n\n\nreadMM(): This function is from the Matrix package and will convert our standard matrix into a sparse matrix. The features.tsv file and barcodes.tsv must first be individually loaded into R and then they can be combined. For specific code and instructions on how to do this please see these additional material.\n\nRead10X(): This function is from the Seurat package and will use the Cell Ranger output directory as input, directly. With this method individual files do not need to be loaded in, instead the function will load and combine them into a sparse matrix. We will be using this function to load in our data!\nReading in a single sample\nAfter processing 10X data using its proprietary software Cell Ranger, you will have an outs directory (always). Within this directory you will find a number of different files including the files listed below:\n\n\nweb_summary.html: report that explores different QC metrics, including the mapping metrics, filtering thresholds, estimated number of cells after filtering, and information on the number of reads and genes per cell after filtering.\nBAM alignment files: files used for visualization of the mapped reads and for re-creation of FASTQ files, if needed\n\nfiltered_feature_bc_matrix: folder containing all files needed to construct the count matrix using data filtered by Cell Ranger\n\n\nraw_feature_bc_matrix: folder containing all files needed to construct the count matrix using the raw unfiltered data\n\n\nWhile Cell Ranger performs filtering on the expression counts (see note below), we wish to perform our own QC and filtering because we want to account for the biology of our experiment/biological system. Given this we are only interested in the raw_feature_bc_matrix folder in the Cell Ranger output.\n\n\n\n\n\n\nWhy do we not use the filtered_feature_bc_matrix folder?\n\n\n\n\n\nThe filtered_feature_bc_matrix uses internal filtering criteria by Cell Ranger, and we do not have control of what cells to keep or abandon.\nThe filtering performed by Cell Ranger when generating the filtered_feature_bc_matrix is often good; however, sometimes data can be of very high quality and the Cell Ranger filtering process can remove high quality cells. In addition, it is generally preferable to explore your own data while taking into account the biology of the experiment for applying thresholds during filtering. For example, if you expect a particular cell type in your dataset to be smaller and/or not as transcriptionally active as other cell types in your dataset, these cells have the potential to be filtered out. However, with Cell Ranger v3 they have tried to account for cells of different sizes (for example, tumor vs infiltrating lymphocytes), and now may not filter as many low quality cells as needed.\n\n\n\nIf we had a single sample, we could generate the count matrix and then subsequently create a Seurat object:\n\nlibrary(Seurat)\n# Read in 10X data for a single sample (output is a sparse matrix)\nctrl_counts &lt;- Read10X(data.dir = \"data/ctrl_raw_feature_bc_matrix\")\n\n# Turn count matrix into a Seurat object (output is a Seurat object)\nctrl &lt;- CreateSeuratObject(counts = ctrl_counts,\n                           project = \"pbmc_ctrl\",\n                           min.features = 100)\n\n\n\n\n\n\n\nNote\n\n\n\nThe min.features argument specifies the minimum number of genes that need to be detected per cell. This argument will filter out poor quality cells that likely just have random barcodes encapsulated without any cell present. Usually, cells with less than 100 genes detected are not considered for analysis.\n\n\nSeurat automatically creates some metadata for each of the cells when you use the Read10X() function to read in data. This information is stored in the meta.data slot within the Seurat object.\n\n# Explore the metadata\nhead(ctrl@meta.data)\n\n                 orig.ident nCount_RNA nFeature_RNA\nAAACATACAATGCC-1  pbmc_ctrl       2344          874\nAAACATACATTTCC-1  pbmc_ctrl       3125          896\nAAACATACCAGAAA-1  pbmc_ctrl       2578          725\nAAACATACCAGCTA-1  pbmc_ctrl       3261          979\nAAACATACCATGCA-1  pbmc_ctrl        746          362\nAAACATACCTCGCT-1  pbmc_ctrl       3519          866\n\n\nWhat do the columns of metadata mean?\n\n\norig.ident: this often contains the sample identity if known。通过CreateSeuratObject中的project参数可以指定，默认是”SeuratProject”\n\nnCount_RNA: number of UMIs per cell\n\nnFeature_RNA: number of genes detected per cell\nReading in multiple samples with a for loop\n\nIn practice, you will likely have several samples that you will need to read in data for, and that can get tedious and error-prone if you do it one at a time. So, to make the data import into R more efficient we can use a for loop, which will iterate over a series of commands for each of the inputs given and create seurat objects for each of our samples.\nToday we will use it to iterate over the two sample folders and execute two commands for each sample as we did above for a single sample - (1) read in the count data (Read10X()) and (2) create the Seurat objects from the read in data (CreateSeuratObject()):\n\nfor (file in c(\"ctrl_raw_feature_bc_matrix\", \"stim_raw_feature_bc_matrix\")){\n        seurat_data &lt;- Read10X(data.dir = paste0(\"data/\", file))\n        seurat_obj &lt;- CreateSeuratObject(counts = seurat_data, \n                                         min.features = 100, \n                                         project = file)\n        assign(file, seurat_obj)\n}\n\nThe last command assigns the Seurat object created (seurat_obj) to a new variable. In this way, when we iterate and move on to the next sample in our input we will not overwrite the Seurat object created in the previous iteration.\nNow that we have created both of these objects, let’s take a quick look at the metadata:\n\nhead(ctrl_raw_feature_bc_matrix@meta.data)\n\n                                 orig.ident nCount_RNA nFeature_RNA\nAAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nAAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nAAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nAAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nAAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nAAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n\nhead(stim_raw_feature_bc_matrix@meta.data)\n\n                                 orig.ident nCount_RNA nFeature_RNA\nAAACATACCAAGCT-1 stim_raw_feature_bc_matrix       1221          606\nAAACATACCCCTAC-1 stim_raw_feature_bc_matrix       1782          807\nAAACATACCCGTAA-1 stim_raw_feature_bc_matrix       1451          605\nAAACATACCCTCGT-1 stim_raw_feature_bc_matrix       1549          747\nAAACATACGAGGTG-1 stim_raw_feature_bc_matrix       1303          558\nAAACATACGCGAAG-1 stim_raw_feature_bc_matrix       5445         1330\n\n\nNext, we need to merge these objects together into a single Seurat object. This will make it easier to run the QC steps for both sample groups together and enable us to easily compare the data quality for all the samples.\nWe can use the merge() function from the Seurat package to do this:\n\n# Create a merged Seurat object\nmerged_seurat &lt;- merge(x = ctrl_raw_feature_bc_matrix, \n                       y = stim_raw_feature_bc_matrix, \n                       add.cell.id = c(\"ctrl\", \"stim\"))\n\n合并前的每个样本的数据被存储在合并后的Seurat对象的不同layer中：\n\nBecause the same cell IDs can be used for different samples, we add a sample-specific prefix to each of our cell IDs using the add.cell.id argument.\n\n\n\n\n\n\nWhat if I am merging more than two samples?\n\n\n\n\n\nSeurat now has functionality to merge many samples together. You can do this quite easily by adding all sample objects to the y argument in a vector format. An example is provided below:\n\n```{r}\n#| eval: false\nmerged_seurat &lt;- merge(x = ctrl_raw_feature_bc_matrix, \n                      y = c(stim1_raw_feature_bc_matrix, \n                            stim2_raw_feature_bc_matrix, \n                            stim3_raw_feature_bc_matrix),\n                      add.cell.id = c(\"ctrl\", \"stim1\", \"stim2\", \"stim3\"))\n```\n\n\n\n\nIf we look at the metadata of the merged object we should be able to see the prefixes in the rownames:\n\n# Check that the merged object has the appropriate sample-specific prefixes\nhead(merged_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n\ntail(merged_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nstim_TTTGCATGCGACAT-1 stim_raw_feature_bc_matrix        620          295\nstim_TTTGCATGCTAAGC-1 stim_raw_feature_bc_matrix       1641          545\nstim_TTTGCATGGGACGA-1 stim_raw_feature_bc_matrix       1233          518\nstim_TTTGCATGGTGAGG-1 stim_raw_feature_bc_matrix       1084          469\nstim_TTTGCATGGTTTGG-1 stim_raw_feature_bc_matrix        818          432\nstim_TTTGCATGTCTTAC-1 stim_raw_feature_bc_matrix       1104          438\n\n# 保存\nsaveRDS(merged_seurat, file = \"output/merged_seurat.rds\")\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.5           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         utf8_1.2.4            \n [19] promises_1.2.1         rmarkdown_2.25         purrr_1.0.2           \n [22] xfun_0.41              jsonlite_1.8.7         goftest_1.2-3         \n [25] later_1.3.1            spatstat.utils_3.0-4   irlba_2.3.5.1         \n [28] parallel_4.3.2         cluster_2.1.6          R6_2.5.1              \n [31] ica_1.0-3              stringi_1.8.2          RColorBrewer_1.1-3    \n [34] spatstat.data_3.0-3    reticulate_1.34.0      parallelly_1.36.0     \n [37] lmtest_0.9-40          scattermore_1.2        Rcpp_1.0.11           \n [40] knitr_1.45             tensor_1.5             future.apply_1.11.0   \n [43] zoo_1.8-12             R.utils_2.12.3         sctransform_0.4.1     \n [46] httpuv_1.6.12          Matrix_1.6-4           splines_4.3.2         \n [49] igraph_1.5.1           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.7             spatstat.random_3.2-2 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             shiny_1.8.0            ROCR_1.0-11           \n [64] evaluate_0.23          Rtsne_0.16             future_1.33.0         \n [67] fastDummies_1.7.3      survival_3.5-7         polyclip_1.10-6       \n [70] fitdistrplus_1.1-11    pillar_1.9.0           KernSmooth_2.23-22    \n [73] plotly_4.10.3          generics_0.1.3         RcppHNSW_0.5.0        \n [76] ggplot2_3.4.4          munsell_0.5.0          scales_1.3.0          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.6.2            \n [82] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.8     \n [85] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [88] dotCall64_1.1-1        cowplot_1.1.1          grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-164          \n [94] patchwork_1.1.3        cli_3.6.1              spatstat.sparse_3.0-3 \n [97] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[100] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[103] R.methodsS3_1.8.2      digest_0.6.33          progressr_0.14.0      \n[106] ggrepel_0.9.4          htmlwidgets_1.6.3      R.oo_1.25.0           \n[109] htmltools_0.5.7        lifecycle_1.0.4        httr_1.4.7            \n[112] mime_0.12              MASS_7.3-60           \n\n\n\n\n\n\n\n\n\n\n\nKang, Hyun Min, Meena Subramaniam, Sasha Targ, Michelle Nguyen, Lenka Maliskova, Elizabeth McCarthy, Eunice Wan, et al. 2017. “Multiplexed Droplet Single-Cell RNA-Sequencing Using Natural Genetic Variation.” Nature Biotechnology 36 (1): 89–94. https://doi.org/10.1038/nbt.4042."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#计算质控指标-generating-quality-metrics",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#计算质控指标-generating-quality-metrics",
    "title": "18  质控",
    "section": "\n18.1 计算质控指标 (Generating quality metrics)",
    "text": "18.1 计算质控指标 (Generating quality metrics)\nWhen data is loaded into Seurat and the initial object is created, there is some basic metadata asssembled for each of the cells in the count matrix. To take a close look at this metadata, let’s view the data frame stored in the meta.data slot of our merged_seurat object:\n\nlibrary(Seurat)\nmerged_seurat &lt;- readRDS(\"output/merged_seurat.rds\")\nmerged_seurat\n\nAn object of class Seurat \n33538 features across 31444 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 2 layers present: counts.ctrl_raw_feature_bc_matrix, counts.stim_raw_feature_bc_matrix\n\nhead(merged_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n\n\nIn order to create the appropriate plots for the quality control analysis, we need to calculate some additional metrics. These include:\n\n\nnumber of genes detected per UMI (novelty score): this metric will give us an idea of the complexity of our dataset (more genes detected per UMI, more complex our data)\n\nmitochondrial ratio: this metric will give us a percentage of cell reads originating from the mitochondrial genes\n\nNovelty score\nThis value is quite easy to calculate, as we take the log10 of the number of genes detected per cell and the log10 of the number of UMIs per cell, then divide the log10 number of genes by the log10 number of UMIs. The novelty score and how it relates to complexity of the RNA species, is described in more detail later in this lesson.\n\n# Add number of genes per UMI for each cell to metadata\nmerged_seurat$log10GenesPerUMI &lt;- log10(merged_seurat$nFeature_RNA) / log10(merged_seurat$nCount_RNA)\nhead(merged_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI\nctrl_AAACATACAATGCC-1        0.8728630\nctrl_AAACATACATTTCC-1        0.8447596\nctrl_AAACATACCAGAAA-1        0.8384933\nctrl_AAACATACCAGCTA-1        0.8512622\nctrl_AAACATACCATGCA-1        0.8906861\nctrl_AAACATACCTCGCT-1        0.8283053\n\nsummary(merged_seurat$log10GenesPerUMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.5490  0.8565  0.8739  0.8734  0.8907  0.9785 \n\n\nMitochondrial Ratio\nSeurat has a convenient function that allows us to calculate the proportion of transcripts mapping to mitochondrial genes. The PercentageFeatureSet() function takes in a pattern argument and searches through all gene identifiers in the dataset for that pattern. Since we are looking for mitochondrial genes, we are searching any gene identifiers that begin with the pattern “MT-”. For each cell, the function takes the sum of counts across all genes (features) belonging to the “Mt-” set, and then divides by the count sum for all genes (features). This value is multiplied by 100 to obtain a percentage value.\n\n\n\n\n\n\nNote\n\n\n\nFor our analysis, rather than using a percentage value we would prefer to work with the ratio value. As such, we will reverse that last step performed by the function by taking the output value and dividing by 100.\n\n\n\n# Compute percent mito ratio\nmerged_seurat$mitoRatio &lt;- PercentageFeatureSet(object = merged_seurat, pattern = \"^MT-\")\nmerged_seurat$mitoRatio &lt;- merged_seurat@meta.data$mitoRatio / 100\nsummary(merged_seurat$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01422 0.01993 0.02174 0.02696 0.39940 \n\nboxplot(merged_seurat$mitoRatio)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pattern provided (“^MT-”) works for human gene names. You may need to adjust the pattern argument depending on your organism of interest. Additionally, if you weren’t using gene names as the gene ID then this function wouldn’t work as we have used it above as the pattern will not suffice. Since there are caveats to using this function, it is advisable to manually compute this metric. If you are interested, we have code available to compute this metric on your own.\n\n\nAdditional metadata columns\nWe are a now all set with quality metrics required for assessing our data. However, we would like to include some additional information that would be useful to have in our metadata including cell IDs and condition information.\nWhen we added columns of information to our metadata file above, we simply added it directly to the metadata slot in the Seurat object using the $ operator.\nWe’ll add a new column for cell identifiers. This information is currently located in the row names of our metadata dataframe. We will keep the rownames as is and duplicate it into a new column called cells:\n\n# Add cell IDs to metadata\nmerged_seurat$cells &lt;- rownames(merged_seurat@meta.data)\n\nYou should see that each cell ID has a ctrl_ or stim_ prefix as we had specified when we merged the Seurat objects. We can use this prefix to create a new column indicating which condition each cell is classfied under. We will call this column sample:\n\n# Create sample column\nlibrary(stringr)\nmerged_seurat$sample &lt;- str_split(rownames(merged_seurat@meta.data),\n                                  \"_\",\n                                  simplify = TRUE)\ntable(merged_seurat$sample)\n\n\n ctrl  stim \n15688 15756 \n\nhead(merged_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n\n\nNow you are all setup with the metrics you need to assess the quality of your data! Your final metadata table will have rows that correspond to each cell, and columns with information about those cells.\n\n# 保存\nsaveRDS(merged_seurat, file = \"output/merged_filtered_seurat.rds\")"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#质量评价-assessing-the-quality-metrics",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#质量评价-assessing-the-quality-metrics",
    "title": "18  质控",
    "section": "\n18.2 质量评价 (Assessing the quality metrics)",
    "text": "18.2 质量评价 (Assessing the quality metrics)\nNow that we have generated the various metrics to assess, we can explore them with visualizations. We will assess various metrics and then decide on which cells are low quality and should be removed from the analysis:\n\nCell counts\nUMI counts per cell\nGenes detected per cell\nComplexity (novelty score)\nMitochondrial counts ratio\n\n\n\n\n\n\n\nWhy aren’t we checking for doublets?\n\n\n\n\n\nIn single-cell RNA sequencing experiments, doublets are generated from two cells. They typically arise due to errors in cell sorting or capture, especially in droplet-based protocols involving thousands of cells. Doublets are obviously undesirable when the aim is to characterize populations at the single-cell level. In particular, they can incorrectly suggest the existence of intermediate populations or transitory states that do not actually exist. Thus, it is desirable to remove doublet libraries so that they do not compromise interpretation of the results.\nWhy aren’t we checking for doublets? Many workflows use maximum thresholds for UMIs or genes, with the idea that a much higher number of reads or genes detected indicate multiple cells. While this rationale seems to be intuitive, it is not accurate. Also, many of the tools used to detect doublets tend to get rid of cells with intermediate or continuous phenotypes, although they may work well on datasets with very discrete cell types. Scrublet is a popular tool for doublet detection, but we haven’t adequately benchmarked it yet. Currently, we recommend not including any thresholds at this point in time. When we have identified markers for each of the clusters, we suggest exploring the markers to determine whether the markers apply to more than one cell type.\n\n\n\nCell counts\nThe cell counts are determined by the number of unique cellular barcodes detected. For this experiment, between 12,000 -13,000 cells are expected.\nIn an ideal world, you would expect the number of unique cellular barcodes to correpsond to the number of cells you loaded. However, this is not the case as capture rates of cells are only a proportion of what is loaded. For example, the inDrops cell capture efficiency is higher (70-80%) compared to 10X which is between 50-60%.\n\n\n\n\n\n\nNote\n\n\n\nThe capture efficiency could appear much lower if the cell concentration used for library preparation was not accurate. Cell concentration should NOT be determined by FACS machine or Bioanalyzer (these tools are not accurate for concentration determination), instead use a hemocytometer or automated cell counter for calculation of cell concentration.\n\n\nThe cell numbers can also vary by protocol, producing cell numbers that are much higher than what we loaded. For example, during the inDrops protocol, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. Similarly, with the 10X protocol there is a chance of obtaining only a barcoded bead in the emulsion droplet (GEM) and no actual cell. Both of these, in addition to the presence of dying cells can lead to a higher number of cellular barcodes than cells.\n\n# Visualize the number of cell counts per sample\nlibrary(ggplot2)\nmerged_seurat@meta.data %&gt;% \n    ggplot(aes(x = sample, fill = sample)) + \n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n    theme(plot.title = element_text(hjust = 0.5, face = \"bold\")) +\n    ggtitle(\"NCells\")\n\n\n\n\nWe see over 15,000 cells per sample, which is quite a bit more than the 12-13,000 expected. It is clear that we likely have some junk ‘cells’ present.\nUMI counts (transcripts) per cell\nThe UMI counts per cell should generally be above 500, that is the low end of what we expect. If UMI counts are between 500-1000 counts, it is usable but the cells probably should have been sequenced more deeply.\n\n# Visualize the number UMIs/transcripts per cell\nmerged_seurat@meta.data %&gt;% \n    ggplot(aes(color = sample, x = nCount_RNA, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    ylab(\"Cell density\") +\n    geom_vline(xintercept = 500)\n\n\n\n\nWe can see that majority of our cells in both samples have 1000 UMIs or greater, which is great.\nGenes detected per cell\nWe have similar expectations for gene detection as for UMI detection, although it may be a bit lower than UMIs. For high quality data, the proportional histogram should contain a single large peak that represents cells that were encapsulated. If we see a small shoulder to the left of the major peak (not present in our data), or a bimodal distribution of the cells, that can indicate a couple of things:\n\nIt might be that there are a set of cells that failed for some reason.\nIt could also be that there are biologically different types of cells (i.e. quiescent cell populations, less complex cells of interest), and/or one type is much smaller than the other (i.e. cells with high counts may be cells that are larger in size).\n\nTherefore, this threshold should be assessed with other metrics that we describe in this lesson.\n\n# Visualize the distribution of genes detected per cell via histogram\nmerged_seurat@meta.data %&gt;% \n    ggplot(aes(color = sample, x = nFeature_RNA, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    theme_classic() +\n    scale_x_log10() + \n    geom_vline(xintercept = 250)\n\n\n\n\nComplexity\nWe can evaluate each cell in terms of how complex the RNA species are by using a measure called the novelty score. The novelty score is computed by taking the ratio of nGenes over nUMI. If there are many captured transcripts (high nUMI) and a low number of genes detected in a cell, this likely means that you only captured a low number of genes and simply sequenced transcripts from those lower number of genes over and over again. These low complexity (low novelty) cells could represent a specific cell type (i.e. red blood cells which lack a typical transcriptome), or could be due to an artifact or contamination. Generally, we expect the novelty score to be above 0.80 for good quality cells.\n\n# Visualize the overall complexity of the gene expression by visualizing the genes detected per UMI (novelty score)\nmerged_seurat@meta.data %&gt;%\n    ggplot(aes(x = log10GenesPerUMI, color = sample, fill=sample)) +\n    geom_density(alpha = 0.2) +\n    theme_classic() +\n    geom_vline(xintercept = 0.8)\n\n\n\n\nMitochondrial counts ratio\nThis metric can identify whether there is a large amount of mitochondrial contamination from dead or dying cells. We define poor quality samples for mitochondrial counts as cells which surpass the 0.2 mitochondrial ratio mark, unless of course you are expecting this in your sample.\n\n# Visualize the distribution of mitochondrial gene expression detected per cell\nmerged_seurat@meta.data %&gt;% \n    ggplot(aes(color = sample, x = mitoRatio, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 0.2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nReads per cell is another metric that can be useful to explore; however, the workflow used would need to save this information to assess. Generally, with this metric you hope to see all of the samples with peaks in relatively the same location between 10,000 and 100,000 reads per cell.\n\n\nVisualize QC metrics as a violin plot:\n\nVlnPlot(merged_seurat, \n        features = c(\"nFeature_RNA\", \"nCount_RNA\", \"log10GenesPerUMI\", \"mitoRatio\"), \n        ncol = 4,\n        pt.size = 0)\n\n\n\n\nJoint filtering effects\nConsidering any of these QC metrics in isolation can lead to misinterpretation of cellular signals. For example, cells with a comparatively high fraction of mitochondrial counts may be involved in respiratory processes and may be cells that you would like to keep. Likewise, other metrics can have other biological interpretations. A general rule of thumb when performing QC is to set thresholds for individual metrics to be as permissive as possible, and always consider the joint effects of these metrics. In this way, you reduce the risk of filtering out any viable cell populations.\nTwo metrics that are often evaluated together are the number of UMIs and the number of genes detected per cell. Here, we have plotted the number of genes versus the number of UMIs coloured by the fraction of mitochondrial reads. Jointly visualizing the count and gene thresholds and additionally overlaying the mitochondrial fraction, gives a summarized persepective of the quality per cell.\n\n# Visualize the correlation between genes detected and number of UMIs and determine whether strong presence of cells with low numbers of genes/UMIs\nmerged_seurat@meta.data %&gt;% \n    ggplot(aes(x = nCount_RNA, y = nFeature_RNA, color = mitoRatio)) + \n    geom_point() + \n    scale_colour_gradient(low = \"gray90\", high = \"black\") +\n    stat_smooth(method = lm) +\n    scale_x_log10() + \n    scale_y_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 500) +\n    geom_hline(yintercept = 250) +\n    facet_wrap(~sample)\n\n\n\n\nGood cells will generally exhibit both higher number of genes per cell and higher numbers of UMIs (upper right quadrant of the plot). Cells that are poor quality are likely to have low genes and UMIs per cell, and correspond to the data points in the bottom left quadrant of the plot. With this plot we also evaluate the slope of the line, and any scatter of data points in the bottom right hand quadrant of the plot. These cells have a high number of UMIs but only a few number of genes. These could be dying cells, but also could represent a population of a low complexity celltype (i.e red blood cells).\nMitochondrial read fractions are only high in particularly low count cells with few detected genes (darker colored data points). This could be indicative of damaged/dying cells whose cytoplasmic mRNA has leaked out through a broken membrane, and thus, only mRNA located in the mitochondria is still conserved. We can see from the plot, that these cells are filtered out by our count and gene number thresholds."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#细胞基因过滤-filtering",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#细胞基因过滤-filtering",
    "title": "18  质控",
    "section": "\n18.3 细胞/基因过滤 (Filtering)",
    "text": "18.3 细胞/基因过滤 (Filtering)\nCell-level filtering\nNow that we have visualized the various metrics, we can decide on the thresholds to apply which will result in the removal of low quality cells. Often the recommendations mentioned earlier are a rough guideline, and the specific experiment needs to inform the exact thresholds chosen. We will use the following thresholds:\n\nnUMI &gt; 500\nnGene &gt; 250\nlog10GenesPerUMI &gt; 0.8\nmitoRatio &lt; 0.2\n\nTo filter, we wil go back to our Seurat object and use the subset() function:\n\n# Filter out low quality cells using selected thresholds - these will change with experiment\nfiltered_seurat &lt;- subset(x = merged_seurat, \n                          subset= (nCount_RNA &gt;= 500) & \n                                  (nFeature_RNA &gt;= 250) & \n                                  (log10GenesPerUMI &gt; 0.80) & \n                                  (mitoRatio &lt; 0.20))\npaste0(\"质控过滤掉了\", ncol(merged_seurat) - ncol(filtered_seurat), \"个细胞\")\n\n[1] \"质控过滤掉了1815个细胞\"\n\n\nGene-level filtering\nWithin our data we will have many genes with zero counts. These genes can dramatically reduce the average expression for a cell and so we will remove them from our data. We will start by identifying which genes have a zero count in each cell:\n\nLayers(filtered_seurat)\n\n[1] \"counts.ctrl_raw_feature_bc_matrix\" \"counts.stim_raw_feature_bc_matrix\"\n\n# 在seurat V5中不同样本的数据被放到不同的layer中，为了方便后面计数基因，所以先将layer合并\nfiltered_seurat &lt;- JoinLayers(filtered_seurat)\nLayers(filtered_seurat)\n\n[1] \"counts\"\n\n# Extract counts\ncounts &lt;- filtered_seurat@assays[[\"RNA\"]]@layers[[\"counts\"]]\n\nNow, we will perform some filtering by prevalence. If a gene is only expressed in a handful of cells, it is not particularly meaningful as it still brings down the averages for all other cells it is not expressed in. For our data we choose to keep only genes which are expressed in 10 or more cells. By using this filter, genes which have zero counts in all cells will effectively be removed.\n\n# Only keeping those genes expressed in more than 10 cells\nkeep_genes &lt;- rownames(filtered_seurat)[rowSums(counts &gt; 0) &gt;= 10]\n\npaste0(\"过滤掉了\", nrow(filtered_seurat) - length(keep_genes), \"个基因；剩余\", \n       length(keep_genes), \"个基因\")\n\n[1] \"过滤掉了19473个基因；剩余14065个基因\"\n\n# 过滤基因\nfiltered_seurat &lt;- subset(filtered_seurat, \n                          features = keep_genes)\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#重新质量评价-re-assess-qc-metrics",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#重新质量评价-re-assess-qc-metrics",
    "title": "18  质控",
    "section": "\n18.4 重新质量评价 (Re-assess QC metrics)",
    "text": "18.4 重新质量评价 (Re-assess QC metrics)\nAfter performing the filtering, it’s recommended to look back over the metrics to make sure that your data matches your expectations and is good for downstream analysis.\n\n# Cell counts\nfiltered_seurat@meta.data %&gt;% \n    ggplot(aes(x = sample, fill = sample)) + \n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n    theme(plot.title = element_text(hjust = 0.5, face = \"bold\")) +\n    ggtitle(\"NCells\")\n# UMI counts\nfiltered_seurat@meta.data %&gt;% \n    ggplot(aes(color = sample, x = nCount_RNA, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    ylab(\"Cell density\") +\n    geom_vline(xintercept = 500)\n# Genes detected\nfiltered_seurat@meta.data %&gt;% \n    ggplot(aes(color = sample, x = nFeature_RNA, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    theme_classic() +\n    scale_x_log10() + \n    geom_vline(xintercept = 250)\n# UMIs vs genes\nfiltered_seurat@meta.data %&gt;%\n    ggplot(aes(x = log10GenesPerUMI, color = sample, fill=sample)) +\n    geom_density(alpha = 0.2) +\n    theme_classic() +\n    geom_vline(xintercept = 0.8)\n# Mitochondrial counts ratio\nfiltered_seurat@meta.data %&gt;% \n    ggplot(aes(color = sample, x = mitoRatio, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 0.2)\n# Novelty\nfiltered_seurat@meta.data %&gt;%\n    ggplot(aes(x = log10GenesPerUMI, color = sample, fill=sample)) +\n    geom_density(alpha = 0.2) +\n    theme_classic() +\n    geom_vline(xintercept = 0.8)\n# Joint filtering effects\nfiltered_seurat@meta.data %&gt;% \n    ggplot(aes(x = nCount_RNA, y = nFeature_RNA, color = mitoRatio)) + \n    geom_point() + \n    scale_colour_gradient(low = \"gray90\", high = \"black\") +\n    stat_smooth(method = lm) +\n    scale_x_log10() + \n    scale_y_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 500) +\n    geom_hline(yintercept = 250) +\n    facet_wrap(~sample)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n问题：\n\n\n\n\n\n1. Report the number of cells left for each sample, and comment on whether the number of cells removed is high or low. Can you give reasons why this number is still not ~12K (which is how many cells were loaded for the experiment)?\nThere are just under 15K cells left for both the control and stim cells. The number of cells removed is reasonably low.\nWhile it would be ideal to have 12K cells, we do not expect that due to the lower capture efficiency (i.e. the number of actual cells encapsulated within droplets containing barcodes) of these technologies. If we still see higher than expected numbers of cells after filtering, this means we could afford to filter more stringently (but we don’t necessarily have to).\n2. After filtering for nGene per cell, you should still observe a small shoulder to the right of the main peak. What might this shoulder represent?\nThis peak could represent a biologically distinct population of cells. It could be a set a of cells that share some properties and as a consequence exhibit more diversity in its transcriptome (with the larger number of genes detected).\n3. When plotting the nGene against nUMI do you observe any data points in the bottom right quadrant of the plot? What can you say about these cells that have been removed?\nThe cells that were removed were those with high nUMI but low numbers of genes detected. These cells had many captured transcripts but represent only a small number of genes. These low complexity cells could represent a specific cell type (i.e. red blood cells which lack a typical transcriptome), or could be due to some other strange artifact or contamination."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#saving-filtered-cells",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#saving-filtered-cells",
    "title": "18  质控",
    "section": "\n18.5 Saving filtered cells",
    "text": "18.5 Saving filtered cells\nBased on these QC metrics we would identify any failed samples and move forward with our filtered cells. Often we iterate through the QC metrics using different filtering criteria; it is not necessarily a linear process. When satisfied with the filtering criteria, we would save our filtered cell object for clustering and marker identification.\n\nsaveRDS(filtered_seurat, file=\"output/seurat_filtered.rds\")"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#exploring-a-poor-quality-sample",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#exploring-a-poor-quality-sample",
    "title": "18  质控",
    "section": "\n18.6 Exploring a Poor Quality Sample",
    "text": "18.6 Exploring a Poor Quality Sample\nThe data we are working with is pretty good quality. If you are interested in knowing what ‘bad’ data might look like when performing QC, we have some materials here where we explore similar QC metrics of a poor quality sample.\nCell counts\nThe cell counts are determined by the number of unique cellular barcodes detected. During the droplet-based protocols, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. We often see all possible combinations of cellular barcodes at a low level, leading to a higher number of cellular barcodes than cells.\nYou expect the number of unique cellular barcodes to be often greater than the number of seuqenced cells due to some hydrogels having more than one cellular barcode. The yellow sample below seems to have at least double the number of cellular barcodes as the other samples.\n\nUMI counts per cell\nThe number of UMIs per cell tends to be very low for the Unsorted sample (yellow). The other samples have good numbers of UMIs per cell, indicating a problem only with the Unsorted sample. Using this cutoff, we will lose the majority of the Unsorted cells.\n\nGenes detected per cell\nSeeing gene detection in the range of 500-5000 is normal for inDrop/10X analyses. However, expectations can vary depending on the complexity of the cells expected in the experiment. Similar expectations for gene detection as for UMI detection.\nAll samples other than the Unsorted sample have a good number of genes detected (with medians between 1,000 - 3,000 genes), which correspond to the numbers of UMIs per cell for each sample. However, the Unsorted sample has a very low median number of genes per cell, indicating a sample failure.\n\nUMIs vs. genes detected\nPoor quality cells are likely to have low genes and UMIs per cell. Therefore, a poor sample is likely to have cells in the lower left of the graph. Good cells should exhibit both higher number of genes per cell and higher numbers of UMIs. We also expect similar lines with similar slopes for all samples.\nThe Unsorted sample has many cells with few UMIs and low number of genes per cell. The other samples look fine.\n\nMitochondrial counts ratio\nPoor quality samples for mitochondrial counts would have larger peaks above the 0.1 mitochondrial ratio mark, unless it is expected based on sample type.\nThere was just a very low number of genes detected for the Unsorted sample, so mitochondrial expression appears higher mainly due to this fact. The poor quality of the Unsorted sample does not appear to be due to dead or dying cells. The other samples have little mitochondrial expression, although hPSC sample has a bit more than the Sorted samples. Since the hPSC sample was expected to have cell types with higher levels of mitochondrial expression, it may have been advisable to not to use a threshold for this metric.\n\nNovelty\nWe can see the samples where we sequenced each cell less have a higher overall novelty, that is because we have not started saturated the sequencing for any given gene for these samples. Outlier cells in these samples might be cells that we have a less complex RNA species than other cells. Sometimes we can detect contamination with low complexity cell types like red blood cells via this metric.\nAll of the samples look fine for complexity, except for the Unsorted sample, so it is unlikely that there is contamination with low complexity cell types in these of the samples. The Unsorted sample has a larger shoulder than desired, but is not bad by this metric.\n\nFiltered results\nOne main plot to look at to determine the success of the filtering criteria is the number of cell counts. The number of cells to expect depends on the library preparation method, but for inDrops we see ~80% or less of the total sequenced cells per sample and for 10X it is often ~50% or less.\n\nIn addition, it is a good idea to explore all of the quality plots for the filtered data. All plots should be much improved for the number of reads per cell, genes detected, UMIs per cell, mitochondrial ratio, and novelty. Since the Unsorted sample was a poor quality sample, the filter will remove a large number of the cells for this sample; in this case all cells except 1 were filtered out.\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      stringr_1.5.1      Seurat_5.0.1       SeuratObject_5.0.1\n[5] sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         mgcv_1.9-0             png_0.1-8             \n [13] vctrs_0.6.5            reshape2_1.4.4         pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.6         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.11            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.0    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.12          Matrix_1.6-4           splines_4.3.2         \n [49] igraph_1.5.1           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.7             spatstat.random_3.2-2 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             withr_2.5.2            shiny_1.8.0           \n [64] ROCR_1.0-11            evaluate_0.23          Rtsne_0.16            \n [67] future_1.33.0          fastDummies_1.7.3      survival_3.5-7        \n [70] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [73] KernSmooth_2.23-22     plotly_4.10.3          generics_0.1.3        \n [76] RcppHNSW_0.5.0         munsell_0.5.0          scales_1.3.0          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.6.2            \n [82] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.8     \n [85] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [88] dotCall64_1.1-1        cowplot_1.1.1          grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-164          \n [94] patchwork_1.1.3        cli_3.6.1              spatstat.sparse_3.0-3 \n [97] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[100] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[103] digest_0.6.33          progressr_0.14.0       ggrepel_0.9.4         \n[106] farver_2.1.1           htmlwidgets_1.6.3      htmltools_0.5.7       \n[109] lifecycle_1.0.4        httr_1.4.7             mime_0.12             \n[112] MASS_7.3-60"
  },
  {
    "objectID": "quarto_foundation/quarto_foundation.html",
    "href": "quarto_foundation/quarto_foundation.html",
    "title": "Quarto基础",
    "section": "",
    "text": "Quarto是一个支持多种编程语言的新一代R Markdown，拥有多个新的特性和功能，同时能够兼容和渲染大多数现有的.rmd文件，而无需额外修改。Quarto可通过多种IDEs编辑，包括VS Code和RStudio。文档的后缀为.qmd。\n\n目前，Quarto还处于起步和不断发展的阶段，针对其的学习资源还十分有限，尤其是中文资源更加匮乏，因此有了汇总和编写本章的动机。本章内容主要参考了Quarto的官方指南，并提取了其中我认为在将来的编写中会经常使用的技巧并加以汇总。这本学习笔记即全程采用Quarto编写。\n本章的逻辑结构：首先介绍Quarto文档的全局设置，即YAML语法（ Chapter 22 ）；然后介绍图片的设置（ Chapter 23 ），包括插入的图片和代码块运行后产生的图片；随后介绍如何实现对图、表等的交叉引用（ Chapter 24 ）；随后介绍其他几种内容的插入（ Chapter 25 ）；随后，介绍创建和编辑Quarto Books的方法（ Chapter 26 ）；最后，介绍如何将Quarto项目的源代码通过Git上传到GitHub以及如何将编译好的Quarto Book通过GitHub Pages进行发布（ Chapter 27 ）。\n有关Quarto的详细信息，参考：https://quarto.org.\n\n\n\n\n\n\n\nTip\n\n\n\n快捷键：\n\n插入代码块：Option+Command+I（macOS）；Ctrl+Alt+I（Windows）。\n插入各类对象：Command+/；或者当光标位于新的一行开头时，直接输入/。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#project设置",
    "href": "quarto_foundation/yaml_settings.html#project设置",
    "title": "22  YAML设置",
    "section": "\n22.1 project设置",
    "text": "22.1 project设置\nproject在编写Quarto Book或者Quarto Websites时使用，因为要创建这些类型的Quarto项目需要通过新建一个Quarto Project来进行，因此YAML中的project项就定义了项目的类型是Quarto Book还是Quarto Websites，以及其他项目的基本设定。并且这些类型的Quarto项目会在根目录中生成一个”_quarto.yml”文件，对于YAML的配置在这个独立的文件中进行，从而将项目内的多个.qmd文档合并编译成一个Quarto Book或者Quarto Websites。\n\n---\nproject:\n  type: book\n  output-dir: \"docs\" \n  execute-dir: project \n---\n\n\n\nproject：项目类型。定义了项目编译后的文档类型，包括”default”, “website”（Quarto Websites）和”book”（Quarto Book）。这里我们在新建项目时选择了Quarto Books，所以这里自动填写了”books”。\n\n\noutput-dir：输出文件夹。编译后的HTML文件、PDF文件以及运行code chunk后产生的图像、数据等的输出文件夹。上面的例子中将输出文件夹指定为”docs”文件夹可以方便将输出的HTML文件通过GitHub Pages发布（详见 Chapter 27 ）。\nexecute-dir：在编译时，各个qmd文件内的code chunk脚本运行的根目录，默认是”file”，即当前qmd文档所在目录，可设置为 “project”，这样在编译过程中执行代码块时会将运行根目录设置为项目根目录。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#标题作者日期信息",
    "href": "quarto_foundation/yaml_settings.html#标题作者日期信息",
    "title": "22  YAML设置",
    "section": "\n22.2 标题/作者/日期信息",
    "text": "22.2 标题/作者/日期信息\n对于HTML的编译，这些信息会展示在文档的开头部分。\n\n---\ntitle: Quarto学习笔记\nsubtitle: 面向多编程语言的新一代R Markdown\nauthor: 杜俊宏\ndate: 2023/11/10\ndate-modified: now\ndate-format: \"YYYY[年]M[月]D[日] HH:mm\"\nauthor-title: 作者\npublished-title: 写作日期\n---\n\n\ntitle：标题。\nsubtitle：副标题。在标题下方以较小字号展示。\nauthor：作者姓名。\nauthor-title：作者栏的标签。默认标签为”AUTHOR”\ndate：文档发行日期。日期既可以手动添加，如”2023/11/10”，也可以通过now（输出样式：2023年11月11日 19:01）或today（输出样式：2023年11月11日）自动生成日期。\ndate-modified：文档的修改日期。\ndate-format：日期格式。\npublished-title：修改date的标签，默认是”PUBLISHED DATE”。\n\n\ndate-format的设置\ndate-format通过以下关键词来定义日期格式：\n\n\n\n\n\n\n\nStyle\nDescription\nExample\n\n\n\nfull\nA full date that includes the weekday name\nMonday, March 7, 2005\n\n\nlong\nA long date that includes a wide month name\nMarch 7, 2005\n\n\nmedium\nA medium date\nMar 7, 2005\n\n\nshort\nA short date with a numeric month\n3/7/05\n\n\niso\nA short date in ISO format\n2005-03-07\n\n\n\n也可以通过以下语法更加灵活的定义日期格式：\n\n\n\n\n\n\n\normat String\nOutput\nDescription\n\n\n\nYY\n18\nTwo-digit year\n\n\nYYYY\n2018\n四位数年份\n\n\nM\n1-12\nThe month, beginning at 1\n\n\nMM\n01-12\n两位数月份\n\n\nMMM\nJan-Dec\nThe abbreviated month name\n\n\nMMMM\nJanuary-December\nThe full month name\n\n\nD\n1-31\nThe day of the month\n\n\nDD\n01-31\n两位数日期\n\n\nd\n0-6\nThe day of the week, with Sunday as 0\n\n\ndd\nSu-Sa\nThe min name of the day of the week\n\n\nddd\nSun-Sat\nThe short name of the day of the week\n\n\ndddd\nSunday-Saturday\nThe name of the day of the week\n\n\nH\n0-23\nThe hour\n\n\nHH\n00-23\n两位数小时，24小时制\n\n\nh\n1-12\nThe hour, 12-hour clock\n\n\nhh\n01-12\nThe hour, 12-hour clock, 2-digits\n\n\nm\n0-59\nThe minute\n\n\nmm\n00-59\n两位数分钟\n\n\ns\n0-59\nThe second\n\n\nss\n00-59\nThe second, 2-digits\n\n\nSSS\n000-999\nThe millisecond, 3-digits\n\n\nZ\n+05:00\nThe offset from UTC, ±HH:mm\n\n\nA\nAM PM\n\n\n\na\nam pm\n\n\n\nDo\n1st 2nd … 31st\nDay of Month with ordinal\n\n\n\n可以通过”[]“添加自定义字符。通过这些语法，可以定制符合中文语法的日期格式，如：date-format: \"YYYY[年]M[月]D[日] HH:mm\"\n\n\n\n\n\n\nTip\n\n\n\n关于日期的详细指南，详见：https://quarto.org/docs/reference/dates.html。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-theme主题设置",
    "href": "quarto_foundation/yaml_settings.html#sec-theme主题设置",
    "title": "19  YAML设置",
    "section": "\n19.3 theme主题设置",
    "text": "19.3 theme主题设置\ntheme定义了编译文档的主题。可以直接调用Quarto内置的Bootswatch主题，如”default”、“cerulean”和”cosmo”等，也可以通过Sassy Cascading Style Sheets (SCSS)文件来自定义主题。theme参数既可以在YAML中直接定义，也可以在不同的format内定义，这样可以对不同的编译格式应用不同的主题。关于Quarto主题的详细指南，参考Quarto Guide。\n\n---\nformat: \n  html:\n    theme: flatly\n---\n\nQuarto的HTML文档默认使用Bootstrap 5样式输出（theme: default）。Quarto内置了来自Bootswatch项目的25个主题。下面列出了可用的主题。关于这些主题的介绍详见：https://bootswatch.com。\n\n个人认为比较美观、清晰的主题有：Cosmo、Flatly、Lux和Darkly。可以通过light和dark分别设置一套亮色主题和一套深色主题，如：\n\n---\nformat: \n  html:\n    theme:\n      light: flatly\n      dark: darkly\n---\n\n这样，在输出的HTML网页的右上角会出现一个亮色/深色模式的切换开关。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-toc目录设置",
    "href": "quarto_foundation/yaml_settings.html#sec-toc目录设置",
    "title": "19  YAML设置",
    "section": "\n19.4 toc目录设置",
    "text": "19.4 toc目录设置\n和theme一样toc同样可以在YAML中直接定义，也可以在不同的format内定义。\n\n---\ntoc: true\ntoc-title: Contents\ntoc-depth: 2 \ntoc-expand: 2 \ntoc-location: left\n---\n\n\ntoc：是否显示目录。\ntoc-title：目录的标题。\ntoc-depth：设置目录显示的最低层级（默认为显示到3级标题）。\ntoc-expand：在一开始目录显示到多少级，默认显示到一级标题。当向下浏览内容时目录会自动展开到toc-depth所设置的层级。设置为true时，则在一开始就展开所有目录；设置为false则在一开始折叠所有目录。\ntoc-location：设置目录的位置。默认在右侧（right）,可以设置为left或body（在文稿最开头显示）。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-number-sections标题编号设置",
    "href": "quarto_foundation/yaml_settings.html#sec-number-sections标题编号设置",
    "title": "22  YAML设置",
    "section": "\n22.5 number-sections标题编号设置",
    "text": "22.5 number-sections标题编号设置\n和theme一样number-sections同样可以在YAML中直接定义，也可以在不同的format内定义。\n\nnumber-sections: true\nnumber-depth: 3\n\n\nnumber-sections：设置为true时会给各级标题编号。默认为false。\nnumber-depth：编号的最低标题层级。默认给所有级别的标题编号。\n{.unnumbered}：如果想要某一个标题不编号，则把这行命令粘贴到该标题后面。如”第三章{.unnumbered}“。\n{.unlisted}：将某个标题设置为不在目录中列出。如”第三章{.unlisted}“。如果想要某个标题既不编号也不在目录中列出就可以这样写：”标题{.unnumbered .unlisted}“。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#排版设置",
    "href": "quarto_foundation/yaml_settings.html#排版设置",
    "title": "22  YAML设置",
    "section": "\n22.6 排版设置",
    "text": "22.6 排版设置\n主要定义了图/表标题的位置、参考文献/脚注的位置、页面大小和页边距等。可以在YAML中直接定义，也可以在不同的format内定义。\n\n---\nfig-cap-location: bottom\ntbl-cap-location: top\nreference-location: margin \ncitation-location: document  \n---\n\n\n\nfig-cap-location：图片标题的位置。默认在图片底部（bottom）。\n\ntbl-cap-location：表格标题的位置。默认在表格上方（top）。\n\nreference-location：脚注的默认展示位置。默认为文档最后 (document)。\n\ncitation-location：参考文献的默认展示位置。默认为文档最后 (document)。\n\n\n\nTable 22.1: 图/表标题位置、参考文献/脚注的位置设置\n\n\n\n\n\nOption\nDescription\n\n\n\nreference-location\nWhere to place footnotes. Defaults to document.\n[document | section | block | margin ]\n\n\ncitation-location\nWhere to place citations. Defaults to document.\n[document | margin ]\n\n\ncap-location\nWhere to place figure and table captions. Defaults to bottom for figures and top for tables. | [top | bottom | margin]\n\n\nfig-cap-location\nWhere to place figure captions. Defaults to bottom.\n[top | bottom | margin]\n\n\ntbl-cap-location\nWhere to place table captions. Defaults to top.\n[top | bottom | margin]"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#execute代码块执行设置",
    "href": "quarto_foundation/yaml_settings.html#execute代码块执行设置",
    "title": "22  YAML设置",
    "section": "\n22.7 execute代码块执行设置",
    "text": "22.7 execute代码块执行设置\nexecute用来指定代码块的执行行为，例如是否运行、是否显示警告信息和是否缓存运行结果等。\n\n---\nexecute:\n      eval: false\n      warning: false\n      cache: true\n---\n\n\neval：设置为false时只显示代码，不运行。默认为true。\necho：设置为false时在输出文件中不显示代码，仅显示代码的运行结果。设置为fenced，会将代码块的设置，即”#|“符号后的内容，也展示出来。Figure 22.1 这个代码块就用了echo: fenced这个设定，可以看一下效果。默认为true。\noutput：设置为false时，只运行代码不显示运行结果。默认为true。\nwarning：是否显示代码运行的警告信息。默认为true。\ncache：是否开启运算结果缓存。默认为false。如果设置为true，就会在编译时将源代码的运算结果保存到文件目录中后缀为”_cache”的文件夹中。这样在重新编译同一个文档时会加快编译速度。\n\n除了对代码执行行为的全局设置，我们也可以针对每个代码块设置其执行行为。许多参数和YAML中的语法相似，只不过需要在每个参数前加上”#|”符号。如：\n\n```{r}\n#| eval: true\n#| warning: false\n#| output: true\n#| label: fig-箱型图\n#| fig-cap: 箱型图\nboxplot(1:100)\n```\n\n\n\nFigure 22.1: 箱型图"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#crossref交叉引用设置",
    "href": "quarto_foundation/yaml_settings.html#crossref交叉引用设置",
    "title": "22  YAML设置",
    "section": "\n22.8 crossref交叉引用设置",
    "text": "22.8 crossref交叉引用设置\ncrossref定义了图/表的标签、默认引用样式、编号类型等。\n\n---\ncrossref:\n  fig-title: 图     \n  tbl-title: 表     \n  title-delim: \"：\"  \n  fig-prefix: 图   \n  tbl-prefix: 表    \n  sec-prefix: 章节 \n  ref-hyperlink: true \n  fig-labels: arabic    \n  tbl-labels: arabic   \n  subref-labels: alpha A \n---\n\n\nfig-title: 图的默认标签文字（默认是”Figure”）\ntbl-title: 表的默认标签文字（默认是”Table”）\ntitle-delim: 图、表标签文字和后面的图、表标题之间的连接符（默认是”:“）\nfig-prefix: 图的默认引用样式（默认是”Figure”）\ntbl-prefix: 表的默认引用样式（默认是”Table”）\nsec-prefix: 章节的默认引用样式（默认是”Section”）\nref-hyperlink: 是否为交叉引用加上内部链接（默认是”true”）\nfig-labels: 图片的编号类型（默认是阿拉伯数字：arabic)\ntbl-labels: 表格的编号类型（默认是阿拉伯数字：arabic）\nsubref-labels: 次级引用编号类型，如组图中的小图（默认是小写字母：alpha a）\n\n可用的编号类型包括：\n\narabic (1, 2, 3)\nroman (I, II, III, IV)\nroman i (i, ii, iii, iv)\nalpha x (start from letter ‘x’)\nalpha X (start from letter ‘X’)"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-参考文献设置",
    "href": "quarto_foundation/yaml_settings.html#sec-参考文献设置",
    "title": "19  YAML设置",
    "section": "\n19.9 参考文献设置",
    "text": "19.9 参考文献设置\n只要在编辑qmd文档时插入了参考文献，YAML中会新增参考文献的配置选项：bibliography: references.bib。同时根目录下会生成一个名为”references.bib”的参考文献配置文件。该配置文件包括了qmd文档中所插入的所有参考文献的列表。以BibTeX/Citation风格语言编写。bibliography指定了这个参考文献配置文件所在的路径。\n\n---\nbibliography: references.bib\n---"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#format编译设置",
    "href": "quarto_foundation/yaml_settings.html#format编译设置",
    "title": "22  YAML设置",
    "section": "\n22.10 format编译设置",
    "text": "22.10 format编译设置\nformat定义了qmd文档编译后的文件类型，例如：“html”, “pdf”, “docx”, “odt”, “pptx”, “revealjs”, “beamer”, “gfm”（GitHub风格的Markdown文档）, “commonmark”, “mediawiki”, “epub”, “ipynb”。不同的编译格式对应的子项设置各不相同，有些参数适用于某些格式但是在另一些格式中则无法兼容。所有支持的编译格式详见Quarto官方文档。下面的案例为编译HTML和GFM的常用设置。\n\n---\nformat: \n  html:\n    theme: \n      light: flatly \n      dark: darkly \n  gfm:\n    toc: true\n    toc-depth: 1\n    number-sections: true\n    citation-location: document\n    output-file: \"README.md\" \n---\n\n编译Quarto文档时，首先knitr将运行所有代码块，并创建一个新的markdown（.md）文档，其中包括源代码及其输出结果。接下来，生成的markdown文件经过pandoc（RStudio内置了pandoc）处理后，被转换成HTML、PDF或者Word等我们需要的文档格式。RStudio封装了这些操作，当我们完成Quarto编辑，点击渲染时，就会完成上述过程。\nQuarto的渲染工作流\n\n编译HTML\n\n---\nformat: \n  html:\n    theme: \n      light: flatly \n      dark: darkly \n    embed-resources: false\n    code-tools: true\n    title-block-banner: images/banner.jpg \n    title-block-banner-color: \"black\"\n    toc: true\n    toc-title: 目录\n    toc-location: left\n    toc-depth: 2\n    toc-expand: 1\n    number-sections: true\n    number-depth: 3\n    anchor-sections: true\n    link-external-icon: true\n    link-external-newwindow: true\n    df-print: kable \n    code-link: true\n---\n\n\ntheme：主题。同 Section 22.3 。\nembed-resources：是否将所有源文件嵌入HTML文件以方便分享。默认为”false”。\ncode-tools：是否在网页右上角显示”&lt;code&gt;“按钮。点击该按钮可以看到Quarto文档的原始markdown代码。\n\ntitle-block-banner：标题横幅设置。title-block-banner有以下选项：\n\ntrue：将标题以网页横幅的形式展示，样式为them中所选样式的默认样式。\n具体颜色：如title-block-banner: \"#003262\"。\n图片路径：如title-block-banner: images/banner.jpeg。\n\n\ntoc相关设置：同 Section 22.4 。\nnumber-sections、number-depth：同 Section 26.5 。\nanchor-sections: 设置为true时，当鼠标移到各级标题上时会显示anchor link，方便我们复制直接定位到该标题的超链接。\nlink-external-icon：设置为true时会在外部链接上显示一个小图标。\nlink-external-newwindow：是否在新标签页打开外部链接。\ndf-print：表格输出样式\n\ncode-copy：设置代码复制按钮：\n\ntrue: 总是在代码块右上角显示代码复制按钮。\nfalse: 隐藏代码复制按钮。\nhover：（默认）当鼠标移过时显示代码复制按钮。\n\n\ncode-fold: 是否折叠代码。\ncode-link: 是否自动为函数加上超链接。该功能基于downlit包，可以自动为识别到的函数加上一个链接到官方文档的超链接。\n编译GitHub Flavored Markdown（GFM）\n我们可以将Quarto文档转换为GitHub风格的Markdown文档（GitHub Flavored Markdown，GFM）。这可以用来生成GitHub项目的README.md文档。\n\n---\ntitle: \"My Project\"\nformat: \n  gfm:\n    identifier-prefix: readme # 标识符\n    # preview-mode: raw # 预览原始markdown\n    keep-yaml: true\n    toc: true\n    toc-depth: 1\n    number-sections: true\n    citation-location: document\n    output-file: \"README.md\" # 输出文档的文件名\n---\n\n编译PDF\n如果要在rmarkdown、bookdown中使用PDF输出功能， 可以在在R中安装tinytex扩展包并安装TinyTeX编译软件：\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n\n其中上面第一行命令安装R的tinytex扩展包， 第二行将下载LaTeX编译程序的服务器设置为清华大学tuna镜像站， 第三行安装LaTeX编译程序。\n如果安装成功， TinyTeX软件包在MS Windows系统中一般会安装在 C:\\Users\\用户名\\AppData\\Roaming\\TinyTeX目录中， 其中”用户名”应替换成系统当前用户名。 如果需要删除TinyTeX软件包， 只要直接删除那个子目录就可以。\n为了判断TinyTeX是否安装成功， 在RStudio中运行：\n\ntinytex::is_tinytex()\n\n结果应为TRUE, 出错或者结果为FALSE都说明安装不成功。\n当用户使用RMarkdown和tinytex包转换latex并编译为PDF时， 如果缺少某些latex宏包， tinytex会自动安装缺少的宏包。"
  },
  {
    "objectID": "quarto_foundation/images_settings.html#sec-插入图片的设置",
    "href": "quarto_foundation/images_settings.html#sec-插入图片的设置",
    "title": "20  图片设置",
    "section": "\n20.1 插入图片的设置",
    "text": "20.1 插入图片的设置\n图片可以通过复制粘贴直接插入，Quarto定义图像的基本语法是：\n![图片标题](images/crossref-figure.png){#fig-elephant width=\"290\"}。\n其中，方括号内的是对象的caption（可选），小括号内是图像所在目录，“{}”内的内容是图像的label以及其他可选设置，各参数间用空格进行分割。常用的图像设置如下：\n\nwidth和height：图像的宽、高。默认单位为像素。\nfig-align：图片的对齐方式，如”left”，“right”。\n可以在小括号内添加超链接，如[![](``images/crossref-figure.png``)](https://en.wikipedia.org/wiki/Elephant)，当点击该图像时会跳转该网站。\ncaption和label的设置会使该图像能够被交叉引用（详见 Chapter 21 ）。\n\n.column-page：让图片以整个文档的宽度展示。需要首先建立一个Pandoc Div块（Figure 20.1）。然后在Pandoc Div块的参数项内填上{.column-page}。如下所示：\n\n:::{.column-page}\n![](images/elephant.jpg)\n:::\n\n这样这张图片就会以文档最大宽度显示：\n\n\n\n\n\n\n\n\n\n\n\n应用于代码块时为：#| column: page\n\n\n\n\n\n.column-screen：让图片占满整个网页的宽度。应用于代码块时为：#| column: screen。\n\n\n\n\n\n\ncolumn-screen-inset-shaded：让图片以整个文档的宽度展示，但是在后方加上一个网页宽度的阴影。应用于代码块时为：#| column: screen-inset-shaded。\n\n\n\n\n组图的设置\n要容纳和排版组图，需要首先建立一个Pandoc Div块（Figure 20.1）。\n\n\nFigure 20.1: 建立Div块\n\nDiv块的图像排版基本语法如下：\n\n\nFigure 20.2: Div块的基本语法\n\n\n“{}”内为组图的label、排版设置。\n在所有图片最后可输入组图的总标题，如上图中的”交叉引用的设置”。\n\n设置图片的排版方式。\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如::: {layout-ncol=\"2\"}。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayout复杂排版\n其基本语法和 Section 20.2.1 一致。不同点在于需要在Div块开头的”{}“内设置，同时layout后要接”=“，并且注意加引号，例如：layout=\"[[1，1]，[1]]\"。通过设置layout可以完成对多图的复杂排版。layout属性是一个二维数组，其中第一维定义行，第二维定义列。layout=\"[[1，1]，[1]]\"表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组图复杂排版设置\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n关于图片设置的详细指南，参考：https://quarto.org/docs/authoring/figures.html。"
  },
  {
    "objectID": "quarto_foundation/images_settings.html#代码块图片输出设置",
    "href": "quarto_foundation/images_settings.html#代码块图片输出设置",
    "title": "20  图片设置",
    "section": "\n20.2 代码块图片输出设置",
    "text": "20.2 代码块图片输出设置\n对于代码块运行后生成的图片，我们也可以对其进行各种设置以使其在编译后的文档中符合理想的展示要求。基本语法和 Section 20.1 中类似，只不过需要在前面加上”#|”符号，然后将其放置在代码块开头。常用的参数有：\n\n#| lable：图片标签。\n#| fig-cap：图片标题（caption）。fig-cap和lable共同用于图片的交叉引用，详见 Chapter 21。\n#| fig-width：图片的宽度。\n#| fig-height：图片的高度。\n\n其他设置包括#| fig-align、#| fig-cap-location等，见 Chapter 20 。\n\n```{r}\n#| eval: true\n#| label: fig-散点图\n#| fig-cap: \"38种流行车型的城市和高速公路里程\"\n#| fig-width: 6\n#| fig-height: 3.5\nlibrary(ggplot2)\nggplot(mpg, aes(x = hwy, y = cty, color = cyl)) +\n  geom_point(alpha = 0.5, size = 2) +\n  scale_color_viridis_c() +\n  theme_minimal()\n```\n\n\n\nFigure 20.3: 38种流行车型的城市和高速公路里程\n\n\n\n代码块组图输出设置\n如果一个代码块运行后可以生成多张图像，那么我们也可以和 Section 20.1.1 中一样，对这些图片进行组图排版。常用的参数包括：\n\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如layout-ncol: \"2\"。\nlabel：组图的标签。\nfig-cap：每张图的标题。通过”-“符号分别设置。效果如下所示：\n\n\n```{r}\n#| eval: true\n#| layout-ncol: 2\n#| label: fig-组图输出\n#| fig-cap:\n#|   - \"车辆的速度和停车距离\"\n#|   - \"汽压与温度的关系\"\n\nplot(cars)\nplot(pressure)\n```\n\n\n\n\n\nFigure 20.4: 车辆的速度和停车距离\n\n\n\n\n\nFigure 20.5: 汽压与温度的关系\n\n\n\n\n\n\n\nfig-subcap：每张图以小标题进行标注，如”(a) sub caption”、“(b) sub caption”。效果如下所示：\n\n\n```{r}\n#| eval: true\n#| label: fig-小标题组图输出\n#| fig-cap: \"小标题组图输出\"\n#| fig-subcap:\n#|   - \"汽车\"\n#|   - \"压力\"\n#| layout-ncol: 2\n\nplot(cars)\nplot(pressure)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n(B) 压力\n\n\n\nFigure 20.6: 小标题组图输出\n\n\n\n用layout进行复杂排版\nlayout属性是一个二维数组，其中第一维定义行，第二维定义列。如layout: \"[[1，1]，[1]]表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片\n#| fig-cap: 复杂排版组图输出\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[1], [1, 1]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n(C) mtcars\n\n\n\nFigure 20.7: 复杂排版组图输出\n\n\n\nlayout后的”[]“中的数字大小表示各个图像的相对大小。所以可以用任何值来自定义：\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片2\n#| fig-cap: 复杂排版组图输出2\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[100], [30, 70]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n(C) mtcars\n\n\n\nFigure 20.8: 复杂排版组图输出2\n\n\n\n如果我们输入负数，如下面的”-10”，则会在两个图之间加上相应的间距：\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片3\n#| fig-cap: 复杂排版组图输出3\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[45,-10, 45], [100]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n \n\n\n\n\n(B) 压力\n\n\n\n\n\n\n\n(C) mtcars\n\n\n\nFigure 20.9: 复杂排版组图输出3"
  },
  {
    "objectID": "quarto_foundation/cross_references.html#标题节的交叉引用",
    "href": "quarto_foundation/cross_references.html#标题节的交叉引用",
    "title": "24  交叉引用",
    "section": "\n24.1 标题/节的交叉引用",
    "text": "24.1 标题/节的交叉引用\n只需通过sec-定义label，基本语法：Introduction {#sec-introduction}。注意：要使用节的引用，需要在YAML开启标题编号（number-sections: true），以便读者能够看到这些编号。"
  },
  {
    "objectID": "quarto_foundation/cross_references.html#图片的交叉引用",
    "href": "quarto_foundation/cross_references.html#图片的交叉引用",
    "title": "21  交叉引用",
    "section": "\n21.2 图片的交叉引用",
    "text": "21.2 图片的交叉引用\n实现的方法：\n\n方法一：在源代码模式下修改被引用对象的属性，如：![Example for cross reference](images/crossref-figure.png){#fig-elephant width=\"290\"}。其中，方括号内的是对象的caption，小括号内是图片所在的目录，“{}”内的内容是图像的label以及其他可选设置。\n方法二：点击待引用对象右上角的三个点，进入对象设置。分别输入caption和ID（即label）（Figure 21.1 )。\n\n\n\n\n\n\n\n\n\n\nFigure 21.1: 交叉引用的设置\n\n\n例如下面的图片，可以被引用：Figure 21.2 。\n\n\nFigure 21.2: Example for cross reference\n\n组图的交叉引用\n基本语法：\n\n案例：\n\n\n\n\n\n(A) 素描大象\n\n\n\n\n\n(B) 油画大象\n\n\n\nFigure 21.3: 组图的交叉引用\n\n\n现在，我们就可以将组图一起引用（Figure 21.3 ），或是单独引用组图内的某一张图（Figure 21.3 (B) ，Figure 21.3 (A) ）。"
  },
  {
    "objectID": "quarto_foundation/cross_references.html#表格的交叉引用",
    "href": "quarto_foundation/cross_references.html#表格的交叉引用",
    "title": "24  交叉引用",
    "section": "\n24.3 表格的交叉引用",
    "text": "24.3 表格的交叉引用\nMarkdown表格的引用\n只需在表格后加上: My Caption {#tbl-letters}即可使该表格能够被引用。如下面的表格 Table 24.1 。\n\n\nTable 24.1: 表格的交叉引用示例\n\nCol1\nCol2\nCol3\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n代码输出表格的引用\n\nlabel：tbl-：表格的标签。\ntbl-cap：表格的标题。\nknitr包提供了一个 kable() 函数可以用来把数据框或矩阵转化成有格式的表格，支持HTML、docx、LaTeX等格式。\n\n\n```{r}\n#| eval: true\n#| label: tbl-iris\n#| tbl-cap: \"Iris数据\"\n\nlibrary(knitr)\nkable(head(iris))\n```\n\n\n\nTable 24.2: Iris数据\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\n\n现在，就可以通过 Table 24.2 来引用该表格了。\n\n\n\n\n\n\nNote\n\n\n\n关于表格的详细指南，参考：https://quarto.org/docs/authoring/tables.html。"
  },
  {
    "objectID": "quarto_foundation/insert_other_content.html#插入参考文献",
    "href": "quarto_foundation/insert_other_content.html#插入参考文献",
    "title": "25  插入其他内容",
    "section": "\n25.1 插入参考文献",
    "text": "25.1 插入参考文献\n在插入菜单中选择”Citation”：\n\n\nFigure 25.1: 参考文献的引用\n\n然后通过DOI或标题检索参考文献，选择目标文献：\n\n\nFigure 25.2: 参考文献的选择\n\n现在就会出现参考文献的交叉引用，如： (Fujii et al. 2023) 、(Sprumont et al. 2023)。并且会在文档最后生成参考文献列表，同时YAML中会新增参考文献的配置选项：bibliography: references.bib。同时根目录下会生成一个名为”references.bib”的参考文献配置文件。\n如果想改变参考文献展示的位置，可以在YAML中设置，如：\n\n---\ncitation-location: margin\n---\n\n可用的值参见 Table 22.1 。这份文档的参考文献就设置为了在页面最后展示（citation-location: document）。\n\n\n\n\n\n\nNote\n\n\n\n关于参考文献和脚注的详细指南，参考：https://quarto.org/docs/authoring/footnotes-and-citations.html。"
  },
  {
    "objectID": "quarto_foundation/insert_other_content.html#插入callouts",
    "href": "quarto_foundation/insert_other_content.html#插入callouts",
    "title": "25  插入其他内容",
    "section": "\n25.2 插入Callouts",
    "text": "25.2 插入Callouts\nCallouts会生成一个标注框，可以用来标注重要内容：\n\n例如：\n\n\n\n\n\n\nTip\n\n\n\n这是一个Callouts示例。\n\n\n其样式包括：\n\n\ncallout-note\n\n\n\ncallout-tip\n\n\n\ncallout-important\n\n\n\ncallout-caution\n\n\n\ncallout-warning"
  },
  {
    "objectID": "quarto_foundation/insert_other_content.html#插入在线视频",
    "href": "quarto_foundation/insert_other_content.html#插入在线视频",
    "title": "25  插入其他内容",
    "section": "\n25.3 插入在线视频",
    "text": "25.3 插入在线视频\n通过以下语法可以在输出文档中插入可直接播放的在线视频：\n\n{{&lt; video https://www.youtube.com/embed/wo9vZccmqwc &gt;}}\n\n\n\n\n\n\n\nFujii, Kouichi, Jin Kikuchi, Masatoshi Uchida, Masanari Machida, Midori Tsuchiya, Kentaro Hayashi, Nana Maekawa, Hajime Houzumi, Arata Honda, and Koji Wake. 2023. “Tiger Attack at a Japanese Safari Park: A Case Report.” International Journal of Emergency Medicine 16 (1). https://doi.org/10.1186/s12245-023-00556-3.\n\n\nSprumont, Adrien, Ana Rodrigues, Simon J. McGowan, Colin Bannard, and Oliver Bannard. 2023. “Germinal Centers Output Clonally Diverse Plasma Cell Populations Expressing High- and Low-Affinity Antibodies.” Cell, November. https://doi.org/10.1016/j.cell.2023.10.022."
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#项目设置",
    "href": "quarto_foundation/quarto_books.html#项目设置",
    "title": "26  Quarto Books",
    "section": "\n26.1 项目设置",
    "text": "26.1 项目设置\n\n---\nproject:\n  type: book\n  output-dir: \"docs\" \n  execute-dir: project \n---\n\n\nproject：项目类型。定义了项目编译后的文档类型，包括default, website（Quarto Websites）和book（Quarto Book）。这里我们在新建项目时选择了Quarto Books，所以这里自动填写了book。\noutput-dir：输出文件夹。编译后的HTML文件、PDF文件以及运行code chunk后产生的图像、数据等的输出文件夹。上面的例子中将输出文件夹指定为”docs”文件夹可以方便将输出的HTML文件通过GitHub Pages发布（详见 Chapter 27 ）。\nexecute-dir：在编译时，各个qmd文件内的code chunk脚本运行的根目录，默认是file，即当前qmd文档所在目录，可设置为 “project”，这样在编译过程中执行代码块时会将脚本运行根目录设置为项目根目录。"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#书结构设置",
    "href": "quarto_foundation/quarto_books.html#书结构设置",
    "title": "26  Quarto Books",
    "section": "\n26.2 书结构设置",
    "text": "26.2 书结构设置\nbook参数定义了Quarto Book的章节结构以及顶栏、导航栏等内容。是Quarto Books的YAML配置的核心。\n标题/作者/日期信息\n\n---\nbook:\n  title: \"R语言数据科学\"\n  subtitle: \"从数据清洗到高级统计学和生物信息学\"\n  author: \"杜俊宏\"\n  date: 2023/11/10\n  date-format: \"YYYY[年]M[月]D[日]\"\n  cover-image: images/book_cover.png\n---\n\n\ntitle：标题。\nsubtitle：副标题。在标题下方以较小字号展示。\nauthor：作者姓名。\ndate：文档发行日期。日期既可以手动添加，如”2023/11/10”，也可以通过now（输出样式：2023年11月11日 19:01）或today（输出样式：2023年11月11日）自动生成日期。\ndate-format：日期格式（详见： Section 22.2.1 ）。\ncover-image：封面图片。\n\n\n\n\n\n\n\nTip\n\n\n\n上面列出的信息也可以在index.qmd文件中定义。\n\n\n\nchapter章节\n章节的定义是Quarto Books的YAML配置的核心。通过chapter函数将多个不同的qmd文件（章节）按照指定的顺序结合起来就形成了一本书或者网站。\n\n---\nbook:\n  chapters:\n    - text: 主页\n      file: index.qmd\n    - intro.qmd\n    - text: \"---\" \n    - part: r_basic/r_basics.qmd\n      chapters:\n        - r_basic/environment_configuration.qmd\n        - r_basic/data_input_output.qmd\n    - part: bioinformatics/single_cell/r_single_cell.qmd\n      chapters:\n        - bioinformatics/single_cell/seurat_command_list.qmd\n        - bioinformatics/single_cell/seurat_tutorial.qmd\n        - bioinformatics/single_cell/data_visualization_methods_in_seurat.qmd\n        - bioinformatics/single_cell/sctransform.qmd\n        - bioinformatics/single_cell/integration.qmd\n    - part: quarto_foundation/quarto_foundation.qmd\n      chapters:\n        - quarto_foundation/yaml_settings.qmd\n        - quarto_foundation/images_settings.qmd\n        - quarto_foundation/cross_references.qmd\n        - quarto_foundation/insert_other_content.qmd\n        - quarto_foundation/quarto_books.qmd\n        - quarto_foundation/github_pages.qmd\n    - text: \"---\"\n    - part: \"参考文献\"\n      chapters:\n        - references.qmd\n---\n\n\n\npart：如果一本书有大量的qmd文件（章节），那么我们可以按照不同的主题将这些qmd文件分成不同的篇章。part可以用qmd文件或者字符定义。如果提供的是qmd文件，那么该qmd文件在编译后会是该篇章的首页，并以单独的一个页面显示。每个篇章可由多个不同的qmd文件（章节）组成。篇章的首页内容会以单独的一个页面显示，一般写该篇章的内容概要。如果提供的是字符，那么这个篇章只会反映在左侧导航栏上，而不会有单独的篇章首页。如上面的part: \"参考文献\"。\n\nchapters：章节。在其下方列出需要包含的所有qmd文件。part和chapters共同完成对章节的组织。\n\ntext： “---”：分隔符。会在导航栏对应位置上显示一条横线。\n\n上面的配置在编译后的效果：\n\n侧边栏\n侧边栏是传统意义上的总目录，默认在网页的左侧显示，其内容反映了上面chapter中定义的章节编排。通过sidebar对侧边栏的样式、内容等进行进一步的设定。\n\n---\nbook:\n  sidebar:\n    style: \"docked\" \n    collapse-level: 1 \n    search: true \n    logo: images/logo.png \n    tools:\n      - icon: twitter \n        href: https://twitter.com \n      - icon: youtube\n        href: https://youtube.com\n---\n\n\nstyle：侧边导航栏的风格。默认为docked，固定导航栏。也可以选择浮动导航栏，floating。\ncollapse-level：侧边导航栏初始显示到多少级标题，默认显示到一级标题，只有当浏览到某一篇章时才会展开该篇章下的2级标题。\nsearch：是否打开侧边栏上的搜索框。注意如果开启了顶栏（见下一节顶部导航栏），那么搜索按钮会默认在顶栏显示。\nlogo：在侧边导航栏上方显示图像。\ntools：定制侧边栏工具。语法同下一节顶部导航栏中的left和right内的定义类似。\n\n采用上述配置后的侧边栏样式：\n\n顶部导航栏\n除了添加侧边导航栏之外，还可以通过navbar参数添加顶部导航栏。\n\n---\nbook:\n  navbar:\n    logo: images/logo.jpg\n    background: \"#f1f1f3\" \n    foreground: \"black\" \n    search: true\n    left:\n      - text: \"Home\"\n        file: index.qmd\n      - file: intro.qmd\n      - text: \"Parts\"\n        menu:\n          - r_basic/r_basics.qmd\n          - bioinformatics/single_cell/r_single_cell.qmd\n          - quarto_foundation/quarto_foundation.qmd\n      - file: references.qmd\n    right:\n      - icon: book-fill\n        text: Bookdown\n        href: https://bookdown.org\n      - icon: github\n        text: GitHub\n        menu:\n          - text: Source Code\n            url: https://github.com/djhcod/r-notes\n          - text: Report a Bug\n            url: https://github.com/djhcod/r-notes/issues\n          - text: Pull Request\n            url: https://github.com/djhcod/r-notes/pulls\n---\n\n\nlogo：顶栏左侧的logo。\nbackground：顶栏背景色（默认为primary，网页主色）。\nforeground：顶栏字体颜色。\nsearch：是否在顶栏右侧显示搜索按钮。\n\nleft和right：分别定义顶栏左侧和右侧显示的内容：\n\nfile：qmd文件。qmd文件内的一级标题就是编译后显示在导航栏上的文字。\ntext：显示文字。在其下方添加qmd文件即可将文字链接到对应的qmd文件编译后的页面。这可以用于自定义某个qmd文件在导航栏上显示的文字。例如这里的index.qmd的标题是”主页”（title：主页），如果我们直接用file把它列出来，那么在导航栏上就会显示index.qmd的标题，即”主页”。但是我们通过text: \"Home\"，并在其下方接file: index.qmd，那么在编译后的HTML中顶栏上会显示”Home”文字，点击后还是链接到index.qmd编译后的首页。如果text下方提供的是url，那么点击该文字后就会跳转到指定网站。\nicon：图标，和text的作用类似。Quarto可以调用Bootstrap Icons图标库，只需指定图标在Bootstrap Icons网站中的的官方名字，如”github”、“twitter”，就可以直接调用该图标。\n\n\n\nFigure 26.1: Bootstrap Icons图标库\n\n\nmenu：下拉菜单。效果如 Figure 26.2 所示。\nurl和herf：效果类似，都是添加外部网址。\n\n\n\n\n\nFigure 26.2: 顶栏示例\n\n\n\n\n\n\n\nTip\n\n\n\n顶栏和侧边导航栏的更多设置，参考Quarto官方指南。\n\n\n右侧页内导航\n右侧页内导航显示的是当前页面的目录。可在book内的page-navigation和format-html内的toc相关函数中共同配置。\n\n\n---\nbook:\n  page-navigation: true\n  repo-url: https://github.com/djhcod/r-notes \n  repo-actions: [source, issue, edit] \n---\n\n\npage-navigation：是否打开右侧的页内导航。\nrepo-url：（可选）GitHub仓库的链接。\nrepo-actions：（可选）在右侧页内导航的下方显示导航到GitHub仓库各板块的链接。可选的值有source、issue、edit。如果是source，repo-actions会首先根据当前所浏览的页面，在repo-url定义的URL后加上当前页面源码的后缀（如”/blob/main/quarto_foundation/quarto_books.qmd”），这样就会得到一个指向GitHub项目中编译该页面的源码的链接。如果是edit则会在此链接的基础上再加上编辑该页面源码的后缀（“/edit/main/quarto_foundation/quarto_books.qmd”）。如果是issue则会在GitHub仓库链接的基础上加上定位到问题报告的后缀（“/issues/new”）。\n搜索框设置\nsearch可以用来指定搜索按钮的样式。同时，对于既有顶栏又有左侧导航栏的book，可以通过search来指定搜索按钮出现的位置。\n\n---\nbook:\n  search:\n    location: sidebar\n    type: textbox\n---\n\n\nlocation：搜索按钮的位置。默认为出现在顶栏（ ）最右侧（navbar）；也可以定义为sidebar，让其在侧边栏（ Section 26.2.3 ）的上方显示。\ntype：搜索按钮的样式。可以仅搜索图标（overlay），也可以展示搜索框（textbox）。\n页脚设置\n页脚出现在每个页面的最下面，通过page-footer统一配置。\n\n\nFigure 26.3: 页脚示例\n\n\n---\nbook:\n  page-footer:\n    left:\n      - text: \"This book was built with Quarto\"\n    center: \"Copyright 2023, Du Junhong\"\n    right:\n      - icon: github\n        href: https://github.com/djhcod\n    border: true  \n---\n\n页脚的配置和 Section 26.2.4 的语法基本一致，此处不再赘述。\n网站分享设置\n\n---\nbook:\n  favicon: images/logo.png # \n  sharing: [twitter, facebook] # \n  twitter-card: true\n  site-url: https://example.com\n---\n\n\n\nfavicon：网页的图标。会在标签页上显示。\n\n\n\n\nsharing：显示分享到社交网络图标。调用的是Bootstrap Icons图标库。效果如下：\n\n\n\n用户批注功能\nQuarto Books编译后的HTML网页支持配置Hypothesis标注功能。配置后不同的读者在登录Hypothesis账号后可以在页面上进行标注和评论。效果如下：\n\n\n---\nbook:\n  comments:\n    hypothesis:\n      theme: classic\n      openSidebar: false\n      showHighlights: always\n      enableExperimentalNewNoteButton: true\n---"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#format编译设置",
    "href": "quarto_foundation/quarto_books.html#format编译设置",
    "title": "26  Quarto Books",
    "section": "\n26.3 format编译设置",
    "text": "26.3 format编译设置\nformat定义了Quarto Books最终编译成的格式。Quarto Books可以编译成各种格式，如HTML、PDF、MS Word、EPub，或AsciiDoc。最常用和最好的编译格式是HTML。HTML books实际上是一种特殊类型的Quarto Website，因此支持包括全文搜索在内的网站功能。这两者最重要的一个区别是，HTML books能够使用章节编号，因此支持不同章节之间的交叉引用。因此下面只介绍编译成HTML的相关设置。\n\n---\nformat:\n  html:\n    theme:\n      light: Flatly \n      dark: darkly\n    embed-resources: false \n    code-tools: true\n    code-link: true\n    anchor-sections: true \n    link-external-newwindow: true \n    toc-depth: 3 \n    toc-expand: 1 \n---\n\n\ntheme：定义了编译文档的主题（详见： Section 22.3 ）。\nembed-resources：是否将所有源文件嵌入HTML文件以方便分享。默认为”false”。\ncode-tools：是否在网页右上角显示”&lt;code&gt;“按钮。点击该按钮可以看到Quarto文档的原始markdown代码。\ncode-link: 是否自动为函数加上超链接。该功能基于downlit包，可以自动为识别到的函数加上一个链接到官方文档的超链接。\nanchor-sections: 设置为true时，当鼠标移到各级标题上时会显示anchor link，方便我们复制直接定位到该标题的超链接。\nlink-external-icon：设置为true时会在外部链接上显示一个小图标。\nlink-external-newwindow：是否在新标签页打开外部链接。\ntoc：是否显示页内目录。对于HTML格式的Quarto Books，开启该选项后会在每个网页的右侧显示一个页面内的导航目录（ Section 26.2.5 ）。\ntoc-title：页内目录的标题。\ntoc-depth：设置页内目录显示的最低层级（默认为显示到3级标题）。\ntoc-expand：设置页内目录在一开始显示到多少级，默认显示到一级标题。当向下浏览内容时目录会自动展开到toc-depth所设置的层级。设置为true时，则在一开始就展开所有目录；设置为false则在一开始折叠所有目录。\ntoc-location：设置页内目录的位置。默认在右侧（right）,可以设置为left或body（在文稿最开头显示）。"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#代码块执行设置",
    "href": "quarto_foundation/quarto_books.html#代码块执行设置",
    "title": "26  Quarto Books",
    "section": "\n26.4 代码块执行设置",
    "text": "26.4 代码块执行设置\nexecute用来指定代码块的执行行为，例如是否运行、是否显示警告信息和是否缓存运行结果等。\n\n---\nexecute:\n  eval: true\n  warning: false\n  cache: true\n---\n\n\neval：设置为false时只显示代码，不运行。默认为true。\necho：设置为false时在输出文件中不显示代码，仅显示代码的运行结果。设置为fenced，会将代码块的设置，即”#|“符号后的内容，也展示出来。Figure 22.1 这个代码块就用了echo: fenced这个设定，可以看一下效果。默认为true。\noutput：设置为false时，只运行代码不显示运行结果。默认为true。\nwarning：是否显示代码运行的警告信息。默认为true。\ncache：是否开启运算结果缓存。默认为false。如果设置为true，就会在编译时将源代码的运算结果保存到文件目录中后缀为”_cache”的文件夹中。这样在重新编译同一个文档时会加快编译速度。"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#sec-number-sections标题编号设置",
    "href": "quarto_foundation/quarto_books.html#sec-number-sections标题编号设置",
    "title": "23  Quarto Books",
    "section": "\n23.5 标题编号设置",
    "text": "23.5 标题编号设置\n\n---\nnumber-sections: true \nnumber-depth: 2 \n---\n\n\nnumber-sections：设置为true时会给各级标题编号。默认为false。\nnumber-depth：编号的最低标题层级。默认给所有级别的标题编号。\n{.unnumbered}：如果想要某一个标题不编号，则把这行命令粘贴到该标题后面。如”第三章{.unnumbered}“。\n{.unlisted}：将某个标题设置为不在目录中列出。如”第三章{.unlisted}“。如果想要某个标题既不编号也不在目录中列出就可以这样写：”标题{.unnumbered .unlisted}“。"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#交叉引用设置",
    "href": "quarto_foundation/quarto_books.html#交叉引用设置",
    "title": "26  Quarto Books",
    "section": "\n26.6 交叉引用设置",
    "text": "26.6 交叉引用设置\n\n---\ncrossref:\n  appendix-title: \"附录\" \n  appendix-delim: \":\" \n  fig-title: 图    \n  tbl-title: 表    \n  fig-prefix: 图  \n  tbl-prefix: 表   \n  fig-labels: arabic   \n  tbl-labels: arabic   \n  subref-labels: alpha A \n---\n\n\nappendix-title: 附录的标签文字\nappendix-delim: 附录标签文字和附录标题的分隔符\nfig-title: 图的默认标签文字（默认是”Figure”）\ntbl-title: 表的默认标签文字（默认是”Table”）\ntitle-delim: 图、表标签文字和后面的图、表标题之间的连接符（默认是”:“）\nfig-prefix: 图的默认引用样式（默认是”Figure”）\ntbl-prefix: 表的默认引用样式（默认是”Table”）\nsec-prefix: 章节的默认引用样式（默认是”Section”）\nref-hyperlink: 是否为交叉引用加上内部链接（默认是”true”）\nfig-labels: 图片的编号类型（默认是阿拉伯数字：arabic)\ntbl-labels: 表格的编号类型（默认是阿拉伯数字：arabic）\nsubref-labels: 次级引用编号类型，如组图中的小图（默认是小写字母：alpha a）\n\n可用的编号类型包括：\n\narabic (1, 2, 3)\nroman (I, II, III, IV)\nroman i (i, ii, iii, iv)\nalpha x (start from letter ‘x’)\nalpha X (start from letter ‘X’)"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#排版设置",
    "href": "quarto_foundation/quarto_books.html#排版设置",
    "title": "26  Quarto Books",
    "section": "\n26.7 排版设置",
    "text": "26.7 排版设置\n\n---\nfig-cap-location: bottom\ntbl-cap-location: top\nreference-location: margin \ncitation-location: document \n---\n\n\n\nfig-cap-location：图片标题的位置。默认在图片底部（bottom）。\n\ntbl-cap-location：表格标题的位置。默认在表格上方（top）。\n\nreference-location：脚注的默认展示位置。默认为文档最后 (document)。\n\ncitation-location：参考文献的默认展示位置。默认为文档最后 (document)。\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\nreference-location\nWhere to place footnotes. Defaults to document.\n[document | section | block | margin ]\n\n\ncitation-location\nWhere to place citations. Defaults to document.\n[document | margin ]\n\n\ncap-location\nWhere to place figure and table captions. Defaults to bottom for figures and top for tables. | [top | bottom | margin]\n\n\nfig-cap-location\nWhere to place figure captions. Defaults to bottom.\n[top | bottom | margin]\n\n\ntbl-cap-location\nWhere to place table captions. Defaults to top.\n[top | bottom | margin]"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#参考文献设置",
    "href": "quarto_foundation/quarto_books.html#参考文献设置",
    "title": "26  Quarto Books",
    "section": "\n26.8 参考文献设置",
    "text": "26.8 参考文献设置\n\n---\nbibliography: references.bib # 参考文献目录\n---\n\n只要在编辑qmd文档时插入了参考文献，YAML中会新增参考文献的配置选项：bibliography: references.bib。同时根目录下会生成一个名为”references.bib”的参考文献配置文件。该配置文件包括了qmd文档中所插入的所有参考文献的列表。以BibTeX/Citation风格语言编写。bibliography指定了这个参考文献配置文件所在的路径。\n\n\n\n\n\n\nTip\n\n\n\n关于Quarto Books的详细指南，参考：https://quarto.org/docs/books/book-structure.html。"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#附制作about-pages",
    "href": "quarto_foundation/quarto_books.html#附制作about-pages",
    "title": "26  Quarto Books",
    "section": "\n26.9 附：制作About Pages",
    "text": "26.9 附：制作About Pages\nindex.qmd文件会编译形成首页/封面文件（index.html），如果我们将书籍/网页发布（详见： Chapter 27 ），这是打开网站链接后首先看到的页面。我们可以通过Quarto提供的About Pages模板来快速创建一个美观的首页，其核心是about命令。下面是一个采用了About Pages模板的index.qmd文件的示例：\n\n---\ntitle: \"关于这本笔记\"\nsidebar: false # 关闭左侧栏\ntoc: false # 关闭右侧的页面目录\nnumber-sections: false # 取消对标题的编号\ncode-tools: false # 关闭代码工具\nabout:\n  template: trestles # 模板\n  image: images/book_cover.jpg # 封面图片\n  # 添加链接\n  links:\n    - icon: book-fill # 添加图标（https://icons.getbootstrap.com）\n      text: Bookdown # 图标的文字\n      href: https://bookdown.org # 图标的链接\n    - icon: github\n      text: Github\n      href: https://github.com/djhcod/r-notes\n    - text: Email\n      href: mailto::du.jh@icloud.com\n---\n\nFinley Malloc is the Chief Data Scientist at Wengo Analytics. When not innovating on data platforms, Finley enjoys spending time unicycling and playing with her pet iguana.\n\n------------------------------------------------------------------------ # 分割线\n\n## Education\n\nUniversity of California, San Diego \\| San Diego, CA PhD in Mathematics \\| Sept 2011 - June 2015\n\nMacalester College \\| St. Paul MA B.A in Economics \\| Sept 2007 - June 2011\n\n------------------------------------------------------------------------\n\n## Experience\n\nWengo Analytics \\| Head Data Scientist \\| April 2018 - present\n\nGeoScynce \\| Chief Analyst \\| Spet 2012 - April 2018\n\n\n\n\n\n\n\nNote\n\n\n\nmailto是一种特殊的超链接，其语法是mailto::youremail.com。点击mailto::后的邮箱地址之后会打开设备的邮件应用，并且自动填写邮箱地址。\n\n\n\n\n\n\n\n\nTip\n\n\n\n更多关于About Pages的技巧，参考：Creating your personal website using Quarto。"
  },
  {
    "objectID": "quarto_foundation/github_pages.html",
    "href": "quarto_foundation/github_pages.html",
    "title": "27  发布到GitHub Pages",
    "section": "",
    "text": "28 .gitignore在 Git 中忽略文件和文件夹\n如上面的@sec-将本地静态html文件发布到github-pages 所述，我们通过git add .命令将项目中的新文件或有变动的文件信息暂存到Git库，然后用git commit -m \"my commit message\"命令提交文件。其中git add后面跟的是需要提交的文件目录，这里我们用了”.”，表示把Git文件夹内的所有文件变动信息都记录下来。当继续使用git commit命令时，每一个文件都会被添加。但是，我们有时候不想将某些特定的文件或文件夹上传，或者某些文件超出了GitHub允许的单个文件容量上限（100MB），这个时候我们就需要通过新建一个.gitignore隐藏文件来告诉Git忽略和不要追踪某些特定文件。\n.gitignore文件是一个纯文本文件，里面列出我们要求Git忽略和不追踪的的文件的列表。在.gitignore中，可以通过提及特定文件或文件夹的名称或模式来告诉Git只忽略一个文件或一个文件夹。也可以用同样的方法告诉Git忽略多个文件或文件夹。\n通常，将.gitignore文件放在仓库的根目录下。我们可以通过命令行工具来创建一个.gitignore文件。要在基于 Unix 的系统（如 macOS 或 Linux）上用命令行创建一个.gitignore文件，打开终端程序（如 macOS 上的 Terminal.app）。然后，用cd命令导航到包含项目的根文件夹（或者通过RStudio打开.Rproject项目文件，然后打开RStudio内的终端面板）。然后输入以下命令：\ntouch .gitignore\n这和 Section 27.7 一样，不会返回任何信息，但是会在项目根目录中生成一个文件名为.gitignore的隐藏文件：\n我们用文本编辑工具或者RStudio打开这个文件。会发现里面已经有一些自动帮我们填好的文件列表："
  },
  {
    "objectID": "quarto_foundation/github_pages.html#注册github账户",
    "href": "quarto_foundation/github_pages.html#注册github账户",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.1 注册GitHub账户",
    "text": "27.1 注册GitHub账户\n关于注册GitHub账户的详细指南，参考：https://happygitwithr.com/github-acct。"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#安装git",
    "href": "quarto_foundation/github_pages.html#安装git",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.2 安装Git",
    "text": "27.2 安装Git\n在终端APP或者RStudio的终端面板输入：\n\nwhich git\n\n如果返回”/usr/bin/git”，则表示Git已被安装到电脑上。如果返回”git: command not found”则表示Git未安装，则参阅《Happy Git and GitHub for the useR》进行安装。\n可以通过运行下面的命令进一步查看Git的版本：\n\ngit --version\n\n会返回”git version 2.39.3 (Apple Git-145)“这样的信息。"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#配置git",
    "href": "quarto_foundation/github_pages.html#配置git",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.3 配置Git",
    "text": "27.3 配置Git\n在终端（RStudio的终端面板或系统的终端）中逐个运行下面的命令，把其中的user.name和user.email替换成自己的用户名和GItHub账户的邮箱。这里的用户名不一定要和GitHub账户的的用户名一致，它会给本的Git仓库提供一个便于识别的标记。\n\ngit config --global user.name \"dujunhong\"\ngit config --global user.email \"du.jh@icloud.com\"\n\n或者，通过usethis包在R中进行配置：\n\nlibrary(usethis)\nuse_git_config(user.name = \"djhcod\", user.email = \"du.jh@icloud.com\")\n\n\n\n\n\n\n\nNote\n\n\n\nusethis is a package that facilitates interactive workflows for R project creation and development\n\n\n然后通过在终端中运行git config –global –list查看配好的Git信息。或者通过usethis包的git_sitrep函数查看：\n\nusethis::git_sitrep()"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#获取github个人访问令牌personal-access-tokenpat",
    "href": "quarto_foundation/github_pages.html#获取github个人访问令牌personal-access-tokenpat",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.4 获取GitHub个人访问令牌（personal access token，PAT）",
    "text": "27.4 获取GitHub个人访问令牌（personal access token，PAT）\nPAT相当于GitHub账户的密码，所以通过PAT才能让本地的Git仓库和远程的GitHub个人仓库建立连接。需要为每台想连接GitHub的电脑配置一个专属PAT。可以通过https://github.com/settings/tokens进行配置，或者运行下面的代码直接进入配置页面：\n\ncreate_github_token()\n\n在配置页面的”NOTE”中填写这个PAT的备注，建议写此PAT将要应用的设备的名称。在它的下方可以选择该PAT的到期时间：\n\n其他的设置保持默认，然后滑到页面最下方，点击”Generate token”：\n\n现在就会看到我们生成的PAT，记得把它即时复制下来，因为只要关闭了这个页面就无法再查看该密钥了：\n\n接下来，通过运行gitcreds包内的gitcreds_set函数来将PAT存储到本地：\n\ngitcreds::gitcreds_set()\n\n运行该函数后会在Console中要求我们输入token，输入刚刚获取的PAT密钥点击回车即可。\n\n如果此前已经存储了PAT，运行这个函数后会出现如下的对话框，可以选择更新已到期的PAT也可以查看已经存储的PAT。\n\n接下来我们再次运行git_sitrep函数，\n\nusethis::git_sitrep()\n\n如果看到如下红框内的信息，证明已经成功连接到了GitHub：\n\n\n\n\n\n\n\nNote\n\n\n\n更多关于PAT的获取指南，参考：https://ucsb-meds.github.io/meds-install-mac.html。"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#将r-project文件夹初始化为git存储库",
    "href": "quarto_foundation/github_pages.html#将r-project文件夹初始化为git存储库",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.5 将R Project文件夹初始化为Git存储库",
    "text": "27.5 将R Project文件夹初始化为Git存储库\n创建Quarto Books项目的内容参考 Chapter 26 。\n\n\n\n\n\n\nCaution\n\n\n\n项目文件夹的名称就是最终上传到GitHub库的名称，所以不要使用中文和空格，并起一个简单和有意义的名字。\n对于Quarto Books或者Quarto Websites项目，为了方便项目管理和GitHub Pages的转换应该在项目的YAML配置文件中将编译文件的输出文件夹设置为”docs”（ Chapter 26 ）：\nproject:\n  type: book\n  output-dir: \"book\" \n这样qmd文件编译后生成的HTML文件、脚本文件以及图片等文件都被存放在docs文件夹内。后面我们就可以指定GitHub Pages将这个docs文件夹作为构建网页的依据。\n\n\n\n通过运行use_git函数以将R Project文件夹初始化为Git存储库：\n\nusethis::use_git()\n\nConsole中会提示已经将当前项目文件夹设置为了Git存储库。当系统询问是否可以提交任何未提交的文件时，请选择是，则会将所有文件进行上传。如果要求重新启动R，请选择是。\n\n重启后，会看到RStudio的右下角窗格中出现了一个新的Git选项卡。里面列出了Git存储库，也就是我们的项目文件夹里面的所有文件，左侧用不同的颜色标注了文件的状态。\n\n这个函数的原理是在项目文件夹中生成了一个名为”.git”的隐藏文件夹，从而将其认定为Git本地存储库。在Mac上通过快捷键Command+Shift+句号可以显示/隐藏这些隐藏文件。\n\n\n\nGit存储库的结构"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#连接本地git仓库和远程github仓库",
    "href": "quarto_foundation/github_pages.html#连接本地git仓库和远程github仓库",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.6 连接本地Git仓库和远程GitHub仓库",
    "text": "27.6 连接本地Git仓库和远程GitHub仓库\n运行use_github函数后会首先创建一个项目同名的GitHub仓库，然后将所有本地Git库的文件上传到这个GitHub库中，完成后会自动打开浏览器并导航到建好的GitHub项目仓库。\n\nusethis::use_github()\n\n\n为了和GitHub统一，现在需要通过在RStusio的终端中运行下面的命令来检查一下当前项目的主分枝的名称是不是”main”。\n\ngit branch\n\n或者在RStudio中检查Git面板右上角的标签是不是”main”：\n\n同时，GitHub项目主页左上角的默认分枝也应该是”main”：\n\n如果是，则可以直接进入下一步。否则，如果当前分支的名称为”master”，需要通过运行git_default_branch_rename函数将默认分枝的名称更新为”main”。\n\nusethis::git_default_branch_rename(from = \"master\", to = \"main\")\n\n或者在终端中输入：\n\ngit config --global init.defaultBranch main\n\n然后通过git status再次检查默认分枝的名称，并回到GitHub项目主页刷新后查看默认分枝的名称是否已同步更改为”main”。"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#sec-将本地静态html文件发布到github-pages",
    "href": "quarto_foundation/github_pages.html#sec-将本地静态html文件发布到github-pages",
    "title": "24  发布到GitHub Pages",
    "section": "\n24.7 将本地静态HTML文件发布到GitHub Pages",
    "text": "24.7 将本地静态HTML文件发布到GitHub Pages\n首先，在项目根目录中创建一个名为.nojekyll的文件，该文件告诉GitHub Pages不要使用Jekyll（GitHub默认网页生成工具）对我们的文件进行额外处理。有两种方法可以做到这一点：\n\n\n在RStudio终端中运行下面的命令：\n\ntouch .nojekyll\n\n该命令运行后不会有任何提示，但是在项目的根目录中会创建一个名为.nojekyll的隐藏文件：\n\n\n在RStudio中依次点击File&gt;New File&gt;Text File，然后点击保存，文件名写成”.nojekyll”即可。\n\n\n\n然后在Git面板中选中所有的文件（Git面板中列出的都是监测到有变动的文件）。这一操作等价于在终端输入：git add .。之后点击”Commit”（等价：git commit -m \"my commit message\"）。\n\n这会打开commit说明窗口，填写右侧的commit说明后点击右下角的”Commit”就会上传所有的文件更改。\n\n上传完成后关闭窗口，这时Git面板中不会有任何文件，是因为我们已经提交了所有更改。最后点击”Push”，就会把所有文件上传到GitHub仓库（等价：git push）。\n\n完成上述操作后，我们打开浏览器进入GitHub项目主页，点击设置按钮。\n\n点击左侧导航栏的”Pages”选项，然后将GitHub Pages的创建来源选择为docs文件夹。\n\n一段时间的等待后，我们就会在这个页面的上方看到已经生成的GitHub Pages的链接。\n\n点击进去之后就可以看到我们的在线网页了。\n\n\n\n\n\n\n\nWarning\n\n\n\n不要更改docs文件夹内的任何内容。\n不要更改index.qmd文件的名称。"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Blondel, Vincent D, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne\nLefebvre. 2008. “Fast Unfolding of Communities in Large\nNetworks.” Journal of Statistical Mechanics: Theory and\nExperiment 2008 (10): P10008. https://doi.org/10.1088/1742-5468/2008/10/p10008.\n\n\nBrennecke, Philip, Simon Anders, Jong Kyoung Kim, Aleksandra A\nKołodziejczyk, Xiuwei Zhang, Valentina Proserpio, Bianka Baying, et al.\n2013. “Accounting for Technical Noise in Single-Cell RNA-Seq\nExperiments.” Nature Methods 10 (11): 1093–95. https://doi.org/10.1038/nmeth.2645.\n\n\nChoudhary, Saket, and Rahul Satija. 2022a. “Comparison and\nEvaluation of Statistical Error Models for scRNA-Seq.” Genome\nBiology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.\n\n\n———. 2022b. “Comparison and Evaluation of Statistical Error Models\nfor scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.\n\n\n———. 2022c. “Comparison and Evaluation of Statistical Error Models\nfor scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.\n\n\nCrowell, Helena L., Charlotte Soneson, Pierre-Luc Germain, Daniela\nCalini, Ludovic Collin, Catarina Raposo, Dheeraj Malhotra, and Mark D.\nRobinson. 2020. “Muscat Detects Subpopulation-Specific State\nTransitions from Multi-Sample Multi-Condition Single-Cell\nTranscriptomics Data.” Nature Communications 11 (1). https://doi.org/10.1038/s41467-020-19894-4.\n\n\nDing, Jiarui, Xian Adiconis, Sean K. Simmons, Monika S. Kowalczyk,\nCynthia C. Hession, Nemanja D. Marjanovic, Travis K. Hughes, et al.\n2020. “Systematic Comparison of Single-Cell and Single-Nucleus\nRNA-Sequencing Methods.” Nature Biotechnology 38 (6):\n737–46. https://doi.org/10.1038/s41587-020-0465-8.\n\n\nFujii, Kouichi, Jin Kikuchi, Masatoshi Uchida, Masanari Machida, Midori\nTsuchiya, Kentaro Hayashi, Nana Maekawa, Hajime Houzumi, Arata Honda,\nand Koji Wake. 2023. “Tiger Attack at a Japanese Safari Park: A\nCase Report.” International Journal of Emergency\nMedicine 16 (1). https://doi.org/10.1186/s12245-023-00556-3.\n\n\nHafemeister, Christoph, and Rahul Satija. 2019. “Normalization and\nVariance Stabilization of Single-Cell RNA-Seq Data Using Regularized\nNegative Binomial Regression.” Genome Biology 20 (1). https://doi.org/10.1186/s13059-019-1874-1.\n\n\nIlicic, Tomislav, Jong Kyoung Kim, Aleksandra A. Kolodziejczyk, Frederik\nOtzen Bagger, Davis James McCarthy, John C. Marioni, and Sarah A.\nTeichmann. 2016. “Classification of Low Quality Cells from\nSingle-Cell RNA-Seq Data.” Genome Biology 17 (1). https://doi.org/10.1186/s13059-016-0888-1.\n\n\nJunttila, Sini, Johannes Smolander, and Laura L Elo. 2022.\n“Benchmarking Methods for Detecting Differential States Between\nConditions from Multi-Subject Single-Cell RNA-Seq Data.”\nBriefings in Bioinformatics 23 (5). https://doi.org/10.1093/bib/bbac286.\n\n\nKang, Hyun Min, Meena Subramaniam, Sasha Targ, Michelle Nguyen, Lenka\nMaliskova, Elizabeth McCarthy, Eunice Wan, et al. 2017.\n“Multiplexed Droplet Single-Cell RNA-Sequencing Using Natural\nGenetic Variation.” Nature Biotechnology 36 (1): 89–94.\nhttps://doi.org/10.1038/nbt.4042.\n\n\nLause, Jan, Philipp Berens, and Dmitry Kobak. 2021. “Analytic\nPearson Residuals for Normalization of Single-Cell RNA-Seq UMI\nData.” Genome Biology 22 (1). https://doi.org/10.1186/s13059-021-02451-7.\n\n\nLevine, Jacob H., Erin F. Simonds, Sean C. Bendall, Kara L. Davis,\nEl-ad D. Amir, Michelle D. Tadmor, Oren Litvin, et al. 2015.\n“Data-Driven Phenotypic Dissection of AML Reveals Progenitor-Like\nCells That Correlate with Prognosis.” Cell 162 (1):\n184–97. https://doi.org/10.1016/j.cell.2015.05.047.\n\n\nMacosko, Evan Z., Anindita Basu, Rahul Satija, James Nemesh, Karthik\nShekhar, Melissa Goldman, Itay Tirosh, et al. 2015a. “Highly\nParallel Genome-Wide Expression Profiling of Individual Cells Using\nNanoliter Droplets.” Cell 161 (5): 1202–14. https://doi.org/10.1016/j.cell.2015.05.002.\n\n\n———, et al. 2015b. “Highly Parallel Genome-Wide Expression\nProfiling of Individual Cells Using Nanoliter Droplets.”\nCell 161 (5): 1202–14. https://doi.org/10.1016/j.cell.2015.05.002.\n\n\nNestorowa, Sonia, Fiona K. Hamey, Blanca Pijuan Sala, Evangelia\nDiamanti, Mairi Shepherd, Elisa Laurenti, Nicola K. Wilson, David G.\nKent, and Berthold Göttgens. 2016. “A Single-Cell Resolution Map\nof Mouse Hematopoietic Stem and Progenitor Cell Differentiation.”\nBlood 128 (8): e20–31. https://doi.org/10.1182/blood-2016-05-716480.\n\n\nSprumont, Adrien, Ana Rodrigues, Simon J. McGowan, Colin Bannard, and\nOliver Bannard. 2023. “Germinal Centers Output Clonally Diverse\nPlasma Cell Populations Expressing High- and Low-Affinity\nAntibodies.” Cell, November. https://doi.org/10.1016/j.cell.2023.10.022.\n\n\nSquair, Jordan W., Matthieu Gautier, Claudia Kathe, Mark A. Anderson,\nNicholas D. James, Thomas H. Hutson, Rémi Hudelle, et al. 2021.\n“Confronting False Discoveries in Single-Cell Differential\nExpression.” Nature Communications 12 (1). https://doi.org/10.1038/s41467-021-25960-2.\n\n\nStuart, Tim, Andrew Butler, Paul Hoffman, Christoph Hafemeister,\nEfthymia Papalexi, William M. Mauck, Yuhan Hao, Marlon Stoeckius, Peter\nSmibert, and Rahul Satija. 2019. “Comprehensive Integration of\nSingle-Cell Data.” Cell 177 (7): 1888–1902.e21. https://doi.org/10.1016/j.cell.2019.05.031.\n\n\nTirosh, Itay, Benjamin Izar, Sanjay M. Prakadan, Marc H. Wadsworth,\nDaniel Treacy, John J. Trombetta, Asaf Rotem, et al. 2016.\n“Dissecting the Multicellular Ecosystem of Metastatic Melanoma by\nSingle-Cell RNA-Seq.” Science 352 (6282): 189–96. https://doi.org/10.1126/science.aad0501.\n\n\nZimmerman, Kip D., Mark A. Espeland, and Carl D. Langefeld. 2021.\n“A Practical Solution to Pseudoreplication Bias in Single-Cell\nStudies.” Nature Communications 12 (1). https://doi.org/10.1038/s41467-021-21038-1."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#标准化normalization的原理和类型",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#标准化normalization的原理和类型",
    "title": "20  Normalization and regressing out unwanted variation",
    "section": "\n20.1 标准化（Normalization）的原理和类型",
    "text": "20.1 标准化（Normalization）的原理和类型\nAn essential first step in the majority of mRNA expression analyses is normalization, whereby systematic variations are adjusted for to make expression counts comparable across genes and/or samples. The counts of mapped reads for each gene is proportional to the expression of RNA (“interesting”) in addition to many other factors (“uninteresting”). Normalization is the process of adjusting raw count values to account for the “uninteresting” factors.\nThe main factors often considered during normalization are:\n\n\nSequencing depth: Accounting for sequencing depth is necessary for comparison of gene expression between cells. In the example below, each gene appears to have doubled in expression in cell 2, however this is a consequence of cell 2 having twice the sequencing depth.\n\n\n\nEach cell in scRNA-seq will have a differing number of reads associated with it. So to accurately compare expression between cells, it is necessary to normalize for sequencing depth.\n\n\n\nGene length: Accounting for gene length is necessary for comparing expression between different genes within the same cell. The number of reads mapped to a longer gene can appear to have equal count/expression as a shorter gene that is more highly expressed.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf using a 3’ or 5’ droplet-based method (10X Genomics, CEL-seq2, Drop-seq, inDrops), the length of the gene will not affect the analysis because only the 5’ or 3’ end of the transcript is sequenced. However, if using full-length sequencing (Smart-seq), the transcript length should be accounted for.\n\n\nMethods for scRNA-seq normalization\nVarious methods have been developed specifically for scRNA-seq normalization. Some simpler methods resemble what we have seen with bulk RNA-seq; the application of global scale factors adjusting for a count-depth relationship that is assumed common across all genes. However, if those assumptions are not true then this basic normalization can lead to over-correction for lowly and moderately expressed genes and, in some cases, under-normalization of highly expressed genes (Bacher et al. 2017). More complex methods will apply correction on a per-gene basis. In this lesson we will explore both approaches.\nRegardless of which method is used for normalization, it can be helpful to think of it as a two-step process (even though it is often described as a single step in most papers). The first is a scaling step and the second is a transformation.\n1. Scaling\nThe first step in normalization is to multiply each UMI count by a cell specific factor to get all cells to have the same UMI counts. Why would we want to do this? Different cells have different amounts of mRNA; this could be due to differences between cell types or variation within the same cell type depending on how well the chemistry worked in one drop versus another. In either case, we are not interested in comparing these absolute counts between cells. Instead we are interested in comparing concentrations, and scaling helps achieve this.\n2. Transformation\nThe next step is a transformation, and it is at this step where we can distinguish the simpler versus complex methods as mentioned above.\nSimple transformations are those which apply the same function to each individual measurement. Common examples include a log transform (which is applied in the original Seurat workflow), or a square root transform (less commonly used).\nIn the Hafemeister and Satija, 2019 paper the authors explored the issues with simple transformations. Specifically they evaluated the standard log normalization approach and found that genes with different abundances are affected differently and that effective normalization (using the log transform) is only observed with low/medium abundance genes (Figure 1D, below). Additionally, substantial imbalances in variance were observed with the log-normalized data (Figure 1E, below). In particular, cells with low total UMI counts exhibited disproportionately higher variance for high-abundance genes, dampening the variance contribution from other gene abundances. \n\n\nImage credit: Hafemeister C and Satija R. Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression, Genom Biology 2019 (https://doi.org/10.1186/s13059-019-1874-1)\n\nThe conclusion is, we cannot treat all genes the same.\nThe proposed solution was the use of Pearson residuals for transformation, as implemented in Seurat’s SCTransform function. With this approach:\n\nMeasurements are multiplied by a gene-specific weight\nEach gene is weighted based on how much evidence there is that it is non-uniformly expressed across cells. More evidence == more of a weight\nGenes that are expressed in only a small fraction of cells will be favored (useful for finding rare cell populations)\nNot just a consideration of the expression level is, but also the distribution of expression\n\nIn this workshop we will demonstrate the use of both transformations at different steps in the workflow."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#explore-sources-of-unwanted-variation",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#explore-sources-of-unwanted-variation",
    "title": "\n20  Normalization and regressing out unwanted variation\n",
    "section": "\n20.2 Explore sources of unwanted variation",
    "text": "20.2 Explore sources of unwanted variation\nThe most common biological data correction (or source of “uninteresting” variation) in single cell RNA-seq is the effects of the cell cycle on the transcriptome. We need to explore the data and see if we observe any effects in our data.\nSet-up\nBefore we make any comparisons across cells, we will apply a simple normalization. This is solely for the purpose of exploring the sources of variation in our data.\nThe input for this analysis is a seurat object. We will use the one that we created in Chapter 18 called filtered_seurat.\n\nlibrary(Seurat)\nfiltered_seurat &lt;- readRDS(\"output/seurat_filtered.rds\")\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts\n\nhead(filtered_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n\n# Normalize the counts\nseurat_phase &lt;- NormalizeData(filtered_seurat)\nseurat_phase\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 2 layers present: counts, data\n\n\n可以发现，运行NormalizeDataNext后的数据多出了新的layer：data, 里面即储存了标准化后的数据。Next, we take this normalized data and check to see if data correction methods are necessary.\nEvaluating effects of cell cycle\nTo assign each cell a score based on its expression of G2/M and S phase markers, we can use the Seuart function CellCycleScoring(). This function calculates cell cycle phase scores based on canonical markers that required as input.\nA list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat. We can segregate this list into markers of G2/M phase and markers of S phase. However, if you are not working with human data we have additional materials detailing how to acquire cell cycle markers for other organisms of interest.\n\n# Load cell cycle markers\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n# Score cells for cell cycle\nseurat_phase &lt;- CellCycleScoring(seurat_phase, \n                                 g2m.features = g2m.genes, \n                                 s.features = s.genes,\n                                 set.ident = TRUE)\n\n# 现在的meta.data中多出了细胞周期评分“S.Score”和“G2M.Score”，以及推断的细胞所处的周期“Phase”\nhead(seurat_phase@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n                          S.Score   G2M.Score Phase                  old.ident\nctrl_AAACATACAATGCC-1  0.02713602  0.04344302   G2M ctrl_raw_feature_bc_matrix\nctrl_AAACATACATTTCC-1  0.01519129  0.01846409   G2M ctrl_raw_feature_bc_matrix\nctrl_AAACATACCAGAAA-1 -0.05272781 -0.05038367    G1 ctrl_raw_feature_bc_matrix\nctrl_AAACATACCAGCTA-1 -0.05194312  0.04583528   G2M ctrl_raw_feature_bc_matrix\nctrl_AAACATACCATGCA-1  0.04406978 -0.03445262     S ctrl_raw_feature_bc_matrix\nctrl_AAACATACCTCGCT-1  0.03421052  0.02033139     S ctrl_raw_feature_bc_matrix\n\n# 默认的ident变成了细胞周期。查看一下细胞周期的分布情况\ntable(Idents(seurat_phase))\n\n\n  G2M    G1     S \n 9547 10387  9695 \n\n\nAfter scoring the cells for cell cycle, we would like to determine whether cell cycle is a major source of variation in our dataset using PCA.\nPCA\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for “dimensionality reduction”.\n\nNOTE: For a more detailed explanation on PCA, please look over this lesson (adapted from StatQuests/Josh Starmer’s YouTube video). We also strongly encourage you to explore the video StatQuest’s video for a more thorough understanding.\n\n\nLet’s say you are working with a single-cell RNA-seq dataset with 12,000 cells and you have quantified the expression of 20,000 genes. The schematic below demonstrates how you would go from a cell x gene matrix to principal component (PC) scores for each inividual cell.\n\nAfter the PC scores have been calculated, you are looking at a matrix of 12,000 x 12,000 that represents the information about relative gene expression in all the cells. You can select the PC1 and PC2 columns and plot that in a 2D way.\n\nYou can also use the PC scores from the first 40 PCs for downstream analysis like clustering, marker identification etc., since these represent the majority of the variation in the data. We will be talking a lot more about this later in this workshop.\n\n\n\n\n\n\n\nNote\n\n\n\nFor datasets with a larger number of cells, only the PC1 and PC2 scores for each cell are usually plotted, or used for visualization. Since these PCs explain the most variation in the dataset, the expectation is that the cells that are more similar to each other will cluster together with PC1 and PC2.\n\n\nUsing PCA to evaluate the effects of cell cycle\nTo perform PCA, we need to first choose the most variable features, then scale the data. Since highly expressed genes exhibit the highest amount of variation and we don’t want our ‘highly variable genes’ only to reflect high expression, we need to scale the data to scale variation with expression level. The Seurat ScaleData() function will scale the data by:\n\nadjusting the expression of each gene to give a mean expression across cells to be 0\n\nscaling expression of each gene to give a variance across cells to be 1\n\n\n\n# Identify the most variable genes\nseurat_phase &lt;- FindVariableFeatures(seurat_phase, \n                                     selection.method = \"vst\", # 默认值\n                                     nfeatures = 2000) # 默认值\n             \n# Scale the counts\nseurat_phase &lt;- ScaleData(seurat_phase)\nLayers(seurat_phase)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n\n可以发现，运行ScaleData后的数据多出了新的layer：scale.data, 里面即储存了归一化后的数据。Now, we can perform the PCA analysis and plot the first two principal components against each other. We also split the figure by cell cycle phase, to evaluate similarities and/or differences.\n\n# Perform PCA。如果没有指定features，RunPCA默认使用FindVariableFeatures找到的高变基因作为PCA输入.\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\",\n              split.by = \"Phase\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\nWe do not see large differences due to cell cycle phase. Based on this plot, we would not regress out the variation due to cell cycle.\n\n\n\n\n\n\nWhen should cell cycle phase be regressed out?\n\n\n\n\n\nBelow are two PCA plots taken from Chapter 13 。This first plot is similar to what we plotted above, it is a PCA prior to regression to evaluate if the cell cycle is playing a big role in driving PC1 and PC2. Clearly, the cells are separating by cell type in this case, so it suggests regressing out these effects.\n\nThis second PCA plot is post-regression, and displays how effective the regression was in removing the effect we observed.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n在需要消除细胞周期的影响时，如何通过ScaleData回归掉（regress out）细胞周期的影响，以及如何在消除细胞周期的影响同时保留增殖细胞与静止细胞的区分，参考 Chapter 13 。"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#evaluating-effects-of-mitochondrial-expression",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#evaluating-effects-of-mitochondrial-expression",
    "title": "\n20  Normalization and regressing out unwanted variation\n",
    "section": "\n20.3 Evaluating effects of mitochondrial expression\n",
    "text": "20.3 Evaluating effects of mitochondrial expression\n\nMitochondrial expression is another factor which can greatly influence clustering. Oftentimes, it is useful to regress out variation due to mitochondrial expression. However, if the differences in mitochondrial gene expression represent a biological phenomenon that may help to distinguish cell clusters, then we advise not regressing this out. In this exercise, we can perform a quick check similar to looking at cell cycle and decide whether or not we want to regress it out.\n\n\nFirst, turn the mitochondrial ratio variable into a new categorical variable based on quartiles (using the code below):\n\n# Check quartile values\nsummary(seurat_phase$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01438 0.01993 0.02139 0.02669 0.14464 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nseurat_phase$mitoFr &lt;- cut(seurat_phase@meta.data$mitoRatio, \n                           breaks=c(-Inf, 0.0144, 0.0199, 0.0267, Inf), \n                           labels=c(\"Low\", \"Medium\", \"Medium high\", \"High\"))\ntable(seurat_phase$mitoFr)\n\n\n        Low      Medium Medium high        High \n       7443        7325        7459        7402 \n\n\n\n\nNext, plot the PCA similar to how we did with cell cycle regression. Hint: use the new mitoFr variable to split cells and color them accordingly.\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\",\n              split.by = \"mitoFr\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\nEvaluate the PCA plot.\nWe do not see large differences due to mitochondrial expression. Based on this plot, we would not regress out the variation due to mitochondrial expression."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#sctransform-based-normalization-and-regressing-out-sources-of-unwanted-variation",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#sctransform-based-normalization-and-regressing-out-sources-of-unwanted-variation",
    "title": "20  Normalization and regressing out unwanted variation",
    "section": "\n20.3 SCTransform-based Normalization and regressing out sources of unwanted variation",
    "text": "20.3 SCTransform-based Normalization and regressing out sources of unwanted variation\nNow that we have established which effects are observed in our data, we can use the SCTransform method to regress out these effects. The SCTransform method was proposed as a better alternative to the log transform normalization method that we used for exploring sources of unwanted variation. The method not only normalizes data, but it also performs a variance stabilization and allows for additional covariates to be regressed out.\nAs described earlier, all genes cannot be treated the same. As such, the SCTransform method constructs a generalized linear model (GLM) for each gene with UMI counts as the response and sequencing depth as the explanatory variable. Information is pooled across genes with similar abundances, to regularize parameter estimates and obtain residuals which represent effectively normalized data values which are no longer correlated with sequencing depth.\n\n\nImage credit: Hafemeister C and Satija R. Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression, Genom Biology 2019 (https://doi.org/10.1101/576827)_\n\n\n\n\n\n\n\nNote\n\n\n\nSince the UMI counts are part of the GLM, the effects are automatically regressed out. The user can include any additional covariates (vars.to.regress) that may have an effect on expression and will be included in the model.\n\n\n数据导入\n前面的流程和此前一样\n\nrm(list = ls())\n\nlibrary(Seurat)\nfiltered_seurat &lt;- readRDS(\"output/seurat_filtered.rds\")\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts\n\nhead(filtered_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n\n\n执行SCTransform\n\n\n这里先运行一次SCTransform以便后面评估细胞周期、线粒体基因等非期望变异来源（This is solely for the purpose of exploring the sources of variation in our data）\nSCTransform替代了传统单细胞数据分析流程中的NormalizeData()、ScaleData()和FindVariableFeatures()函数的功能，因此不再需要运行这些函数。\nIn Seurat v5, SCT v2 is applied by default. You can revert to v1 by setting vst.flavor = 'v1'。\nSCTransform的运算调用了glmGamPoi包以显著提升运算速度。所以事先需要通过BiocManager安装该包。\n\n\n# SCTranform\n# BiocManager::install(\"glmGamPoi\")\nseurat_phase &lt;- SCTransform(filtered_seurat)\nseurat_phase\n\nAn object of class Seurat \n28130 features across 29629 samples within 2 assays \nActive assay: SCT (14065 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n\n# Check which assays are stored in objects\nseurat_phase@assays\n\n$RNA\nAssay (v5) data with 14065 features for 29629 cells\nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \nLayers:\n counts \n\n$SCT\nSCTAssay data with 14065 features for 29629 cells, and 1 SCTModel(s) \nTop 10 variable features:\n CCL8, IGKC, CXCL10, FTL, CCL2, CCL7, ISG15, GNLY, IGLC2, CCL4 \n\n# 查看目前默认的assay\nDefaultAssay(seurat_phase)\n\n[1] \"SCT\"\n\n# 查看默认assay的layers\nLayers(seurat_phase)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n\nNote, the last line of output specifies “Set default assay to SCT”. 表明运行SCTransform之后，会将默认的assay指定为SCTransform之后的数据。This specifies that moving forward we would like to use the data after SCT was implemented. We can view the different assays that we have stored in our seurat object.\n评估细胞周期的影响\n\n# Load cell cycle markers\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n# Score cells for cell cycle\nseurat_phase &lt;- CellCycleScoring(seurat_phase, \n                                 g2m.features = g2m.genes, \n                                 s.features = s.genes)\n\n# 现在的meta.data中多出了细胞周期评分“S.Score”和“G2M.Score”，以及推断的细胞所处的周期“Phase”\nhead(seurat_phase@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n                      nCount_SCT nFeature_SCT      S.Score    G2M.Score Phase\nctrl_AAACATACAATGCC-1       1591          863  0.010526369  0.011803814   G2M\nctrl_AAACATACATTTCC-1       1553          724  0.010251663  0.015119823   G2M\nctrl_AAACATACCAGAAA-1       1549          668 -0.019803499 -0.015779795    G1\nctrl_AAACATACCAGCTA-1       1579          777 -0.032093208  0.013380044   G2M\nctrl_AAACATACCATGCA-1       1096          371  0.008301833 -0.008402066     S\nctrl_AAACATACCTCGCT-1       1493          632  0.018235066  0.018993438   G2M\n\n# 查看一下细胞周期的分布情况\ntable(seurat_phase$Phase)\n\n\n   G1   G2M     S \n10554  9586  9489 \n\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\",\n              split.by = \"Phase\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n评估线粒体基因的影响\n\n# Check quartile values\nsummary(seurat_phase$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01438 0.01993 0.02139 0.02669 0.14464 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nseurat_phase$mitoFr &lt;- cut(seurat_phase@meta.data$mitoRatio, \n                           breaks=c(-Inf, 0.0144, 0.0199, 0.0267, Inf), \n                           labels=c(\"Low\", \"Medium\", \"Medium high\", \"High\"))\ntable(seurat_phase$mitoFr)\n\n\n        Low      Medium Medium high        High \n       7443        7325        7459        7402 \n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\",\n              split.by = \"mitoFr\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n分割layer，再次执行SCTranform\n\nSince we have two samples in our dataset (from two conditions), we want to keep them as separate layers and transform them as that is what is required for integration.\n\n# Split RNA assay by condition to perform cell cycle scoring and SCT on all samples\nseurat_phase[[\"RNA\"]] &lt;- split(seurat_phase[[\"RNA\"]], \n                               f = seurat_phase$sample) # 按照meta.data中的“sample”列进行分割\nseurat_phase\n\nAn object of class Seurat \n28130 features across 29629 samples within 2 assays \nActive assay: SCT (14065 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n 1 dimensional reduction calculated: pca\n\n\n现在可以发现RNA assay的counts和data按照”seurat_phase$sample”（ctrl vs. stim）被分别分割成了2个layer：\n\nNow we will run the SCTransform() on each sample, and regress out mitochondrial expression by specifying in the vars.to.regress argument of the SCTransform() function.\n\n\n\n\n\n\nTip\n\n\n\nThe output of SCTransform() can generate large R objects/variables in terms of memory. If we have a large dataset, then we might need to adjust the limit for allowable object sizes within R (Default is 500 1024 ^ 2 = 500 Mb*) using the following code:\n\n```{r}\n#| eval: false\noptions(future.globals.maxSize = 4000 * 1024^2)\n```\n\n\n\n执行SCTranform\n\n\n# SCTranform\nseurat_phase &lt;- SCTransform(seurat_phase, vars.to.regress = c(\"mitoRatio\"))\n\nBy default, after normalizing, adjusting the variance, and regressing out uninteresting sources of variation, SCTransform will rank the genes by residual variance and output the 3000 most variant genes. If the dataset has larger cell numbers, then it may be beneficial to adjust this parameter higher using the variable.features.n argument.\nNow we can see that in addition to the raw RNA counts, we now have a SCT component in our assays slot. The most variable features will be the only genes stored inside the SCT assay. As we move through the scRNA-seq analysis, we will choose the most appropriate assay to use for the different steps in the analysis.\nSave the object!\n\nsaveRDS(seurat_phase, \"output/split_seurat.rds\")\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] cowplot_1.1.1      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.7              magrittr_2.0.3             \n  [5] spatstat.utils_3.0-4        farver_2.1.1               \n  [7] rmarkdown_2.25              zlibbioc_1.48.0            \n  [9] vctrs_0.6.5                 ROCR_1.0-11                \n [11] DelayedMatrixStats_1.24.0   spatstat.explore_3.2-5     \n [13] RCurl_1.98-1.13             S4Arrays_1.2.0             \n [15] htmltools_0.5.7             SparseArray_1.2.2          \n [17] sctransform_0.4.1           parallelly_1.36.0          \n [19] KernSmooth_2.23-22          htmlwidgets_1.6.3          \n [21] ica_1.0-3                   plyr_1.8.9                 \n [23] plotly_4.10.3               zoo_1.8-12                 \n [25] igraph_1.5.1                mime_0.12                  \n [27] lifecycle_1.0.4             pkgconfig_2.0.3            \n [29] Matrix_1.6-4                R6_2.5.1                   \n [31] fastmap_1.1.1               GenomeInfoDbData_1.2.11    \n [33] MatrixGenerics_1.14.0       fitdistrplus_1.1-11        \n [35] future_1.33.0               shiny_1.8.0                \n [37] digest_0.6.33               colorspace_2.1-0           \n [39] patchwork_1.1.3             S4Vectors_0.40.2           \n [41] tensor_1.5                  RSpectra_0.16-1            \n [43] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [45] labeling_0.4.3              progressr_0.14.0           \n [47] fansi_1.0.5                 spatstat.sparse_3.0-3      \n [49] httr_1.4.7                  polyclip_1.10-6            \n [51] abind_1.4-5                 compiler_4.3.2             \n [53] withr_2.5.2                 fastDummies_1.7.3          \n [55] MASS_7.3-60                 DelayedArray_0.28.0        \n [57] tools_4.3.2                 lmtest_0.9-40              \n [59] httpuv_1.6.12               future.apply_1.11.0        \n [61] goftest_1.2-3               glmGamPoi_1.14.0           \n [63] glue_1.6.2                  nlme_3.1-164               \n [65] promises_1.2.1              grid_4.3.2                 \n [67] Rtsne_0.16                  cluster_2.1.6              \n [69] reshape2_1.4.4              generics_0.1.3             \n [71] gtable_0.3.4                spatstat.data_3.0-3        \n [73] tidyr_1.3.0                 data.table_1.14.8          \n [75] XVector_0.42.0              utf8_1.2.4                 \n [77] BiocGenerics_0.48.1         spatstat.geom_3.2-7        \n [79] RcppAnnoy_0.0.21            ggrepel_0.9.4              \n [81] RANN_2.6.1                  pillar_1.9.0               \n [83] stringr_1.5.1               spam_2.10-0                \n [85] RcppHNSW_0.5.0              later_1.3.1                \n [87] splines_4.3.2               dplyr_1.1.4                \n [89] lattice_0.22-5              survival_3.5-7             \n [91] deldir_2.0-2                tidyselect_1.2.0           \n [93] miniUI_0.1.1.1              pbapply_1.7-2              \n [95] knitr_1.45                  gridExtra_2.3              \n [97] IRanges_2.36.0              SummarizedExperiment_1.32.0\n [99] scattermore_1.2             stats4_4.3.2               \n[101] xfun_0.41                   Biobase_2.62.0             \n[103] matrixStats_1.1.0           stringi_1.8.2              \n[105] lazyeval_0.2.2              yaml_2.3.7                 \n[107] evaluate_0.23               codetools_0.2-19           \n[109] tibble_3.2.1                cli_3.6.1                  \n[111] uwot_0.1.16                 xtable_1.8-4               \n[113] reticulate_1.34.0           munsell_0.5.0              \n[115] Rcpp_1.0.11                 GenomeInfoDb_1.38.1        \n[117] globals_0.16.2              spatstat.random_3.2-2      \n[119] png_0.1-8                   parallel_4.3.2             \n[121] ellipsis_0.3.2              ggplot2_3.4.4              \n[123] dotCall64_1.1-1             sparseMatrixStats_1.14.0   \n[125] bitops_1.0-7                listenv_0.9.0              \n[127] viridisLite_0.4.2           scales_1.3.0               \n[129] ggridges_0.5.4              crayon_1.5.2               \n[131] leiden_0.4.3.1              purrr_1.0.2                \n[133] rlang_1.1.2                \n\n\n\n\n\n\n\n\n\n\n\nBacher, Rhonda, Li-Fang Chu, Ning Leng, Audrey P Gasch, James A Thomson, Ron M Stewart, Michael Newton, and Christina Kendziorski. 2017. “SCnorm: Robust Normalization of Single-Cell RNA-Seq Data.” Nature Methods 14 (6): 584–86. https://doi.org/10.1038/nmeth.4263."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html#clustering-workflow",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html#clustering-workflow",
    "title": "19  Single-cell RNA-seq Clustering Workflow",
    "section": "19.1 Clustering workflow",
    "text": "19.1 Clustering workflow\nFor something to be informative, it needs to exhibit variation, but not all variation is informative. The goal of our clustering analysis is to keep the major sources of variation in our dataset that should define our cell types, while restricting the variation due to uninteresting sources of variation (sequencing depth, cell cycle differences, mitochondrial expression, batch effects, etc.). Then, to determine the cell types present, we will perform a clustering analysis using the most variable genes to define the major sources of variation in the dataset.\nThe workflow for this analysis is adapted from the following sources:\n\nSatija Lab: Seurat v3 Guided Integration Tutorial\nPaul Hoffman: Cell-Cycle Scoring and Regression\n\nTo identify clusters, the following steps will be performed:\n\n1. Explore sources of unwanted variation\nThe first step in the workflow is to see if our data contains any unwanted variability. The most common biological effect that is evaluated in single-cell RNA-seq data is the effect of cell cycle on the transcriptome. Another known biological effect is mitochondrial gene expression, which is interpreted as an indication of cell stress. This step of the workflow involves exploring our data to identify which covariates we would like to regress out.\n\n\n2. Normalization and regressing out sources of unwanted variation\nSeurat recently introduced a new method called sctransform which performs multiple processing steps on scRNA-seq data. Normalization is required to scale the raw count data to obtain correct relative gene expression abundances between cells. The sctransform function implements an advanced normalization and variance stabilization of the data. The sctransform function also regresses out sources of unwanted variation in our data. In the previous step, we had identified these sources of variability, and here we specify what those covariates are.\n\n\n3. Integration\nOften with single cell RNA-seq we are working with multiple samples which correspond to different sample groups, multiple experiments or different modalities. If we want to ultimately compare celltype expression between groups it is recommended to integrate the data. Integration is a powerful method that uses these shared sources of greatest variation to identify shared sub-populations across conditions or datasets. There are several steps involved in performing intergration in Seurat. Once complete, we use visualization methods to ensure a good integration before we proceed to cluster cells.\n\n\n\n\n\n\nCaution\n\n\n\nIntegration is optional. We recommend going through the workflow without integration to decide whether or not it is necessary for your data.\n\n\n\n\n4. Clustering cells\nClusters of cells are obtained by grouping cells based on the similarity of their gene expression profiles. Expression profile similarity is determined via distance metrics, which often take dimensionality‐reduced representations as input. Seurat assigns cells to clusters based on their PCA scores derived from the expression of the integrated most variable genes.\n\n\n5. Cluster quality evaluation\nThe clusters identified in our data represent groups of cells that presumably belong to a similar cell type. Before we can confirm the celltype of a group of member cells, the following steps are taken:\n\na. Check to see that clusters are not influenced by sources of uninteresting variation.\nb. Check to see whether the major principal components are driving the different clusters.\nc. Explore the cell type identities by looking at the expression for known markers across the clusters."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#不进行整合时检验细胞分群情况",
    "href": "single_cell/scRNA-seq_online/06_integration.html#不进行整合时检验细胞分群情况",
    "title": "\n21  单细胞数据整合（Integration）\n",
    "section": "\n21.1 不进行整合时检验细胞分群情况",
    "text": "21.1 不进行整合时检验细胞分群情况\nGenerally, we always look at our clustering without integration before deciding whether we need to perform any alignment. Do not just always perform integration because you think there might be differences - explore the data. If we had performed the normalization on both conditions together in a Seurat object and visualized the similarity between cells, we would have seen condition-specific clustering.\n数据导入\nWe use the split_seurat object from the previous lesson ( Chapter 20 ).\n\nlibrary(Seurat)\nsplit_seurat &lt;- readRDS(\"output/split_seurat.rds\")\nsplit_seurat\n\nAn object of class Seurat \n28130 features across 29629 samples within 2 assays \nActive assay: SCT (14065 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n 1 dimensional reduction calculated: pca\n\n# Check which assays are stored in objects\nsplit_seurat@assays\n\n$RNA\nAssay (v5) data with 14065 features for 29629 cells\nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \nLayers:\n counts.ctrl, counts.stim \n\n$SCT\nSCTAssay data with 14065 features for 29629 cells, and 2 SCTModel(s) \nTop 10 variable features:\n FTL, IGKC, CCL2, GNLY, IGLC2, CCL3, CCL4, CXCL10, CCL7, TIMP1 \n\n# 查看目前默认的assay\nDefaultAssay(split_seurat)\n\n[1] \"SCT\"\n\n# 查看默认assay的layers\nLayers(split_seurat)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n# 查看每种样本包含多少细胞\ntable(split_seurat$sample)\n\n\n ctrl  stim \n14847 14782 \n\n# 查看降维信息\nnames(split_seurat@reductions)\n\n[1] \"pca\"\n\n\n\n降维、分群\n\n# Run PCA\nsplit_seurat &lt;- RunPCA(split_seurat)\n# Run UMAP\nsplit_seurat &lt;- RunUMAP(split_seurat, dims = 1:40, reduction = \"pca\")\n# Plot UMAP\np1 &lt;- DimPlot(split_seurat, group.by = \"sample\")\np2 &lt;- DimPlot(split_seurat, split.by = \"sample\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\nFigure 21.1: 整合前的细胞分群情况\n\n\n\n可以看到，如果不进行整合，不同样本（STIM vs. STIM）的细胞类型差异很大。Condition-specific clustering of the cells indicates that we need to integrate the cells across conditions to ensure that cells of the same cell type cluster together.\n\n\n\n\n\n\nWhy is it important the cells of the same cell type cluster together?\n\n\n\nWe want to identify cell types which are present in all samples/conditions/modalities within our dataset, and therefore would like to observe a representation of cells from both samples/conditions/modalities in every cluster. This will enable more interpretable results downstream (i.e. DE analysis, ligand-receptor analysis, differential abundance analysis…).\n\n\nIn this lesson, we will cover the integration of our samples across conditions, which is adapted from Chapter 10 .\n\n\n\n\n\n\nNote\n\n\n\n在此前的 Chapter 9 中我们学习了how to run through the workflow from normalization to clustering without integration. Other steps in the workflow remain fairly similar, but the samples would not necessarily be split in the beginning and integration would not be performed.\nIt can help to first run conditions individually if unsure what clusters to expect or expecting some different cell types between conditions (e.g. tumor and control samples), then run them together to see whether there are condition-specific clusters for cell types present in both conditions. Oftentimes, when clustering cells from multiple conditions there are condition-specific clusters and integration can help ensure the same cell types cluster together."
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#整合",
    "href": "single_cell/scRNA-seq_online/06_integration.html#整合",
    "title": "\n21  单细胞数据整合（Integration）\n",
    "section": "\n21.2 整合\n",
    "text": "21.2 整合\n\nIf cells cluster by sample, condition, batch, dataset, modality, this integration step can greatly improve the clustering and the downstream analyses.\nTo integrate, we will use the shared highly variable genes (identified using SCTransform) from each group, then, we will “integrate” or “harmonize” the groups to overlay cells that are similar or have a “common set of biological features” between groups. For example, we could integrate across:\n\n\nDifferent conditions (e.g. control and stimulated)\n\n\n\nDifferent datasets (e.g. scRNA-seq from datasets generated using different library preparation methods on the same samples)\n\n\n\nDifferent modalities (e.g. scRNA-seq and scATAC-seq)\n\n\nDifferent batches (e.g. when experimental conditions make batch processing of samples necessary)\n\nThe goal of integration is to ensure that the cell types of one condition/dataset align with the same celltypes of the other conditions/datasets (e.g. control macrophages align with stimulated macrophages).\nIntegration using CCA\nSeurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches:\nThe anchor-based CCA integration (method=CCAIntegration) utilizes the canonical correlation analysis (CCA). This method expects “correspondences” or shared biological states among at least a subset of single cells across the groups. The steps in the Seurat integration workflow are outlined in the figure below:\n\n\nImage credit: Stuart T and Butler A, et al. Comprehensive integration of single cell data, bioRxiv 2018 (https://doi.org/10.1101/460147)_\n\nThe different steps applied are as follows:\n\n\nPerform canonical correlation analysis (CCA):\nCCA identifies shared sources of variation between the conditions/groups. It is a form of PCA, in that it identifies the greatest sources of variation in the data, but only if it is shared or conserved across the conditions/groups (using the 3000 most variant genes from each sample).\nThis step roughly aligns the cells using the greatest shared sources of variation.\n\n\n\n\n\n\nNote\n\n\n\nThe shared highly variable genes are used because they are the most likely to represent those genes distinguishing the different cell types present.\n\n\n\n\nIdentify anchors or mutual nearest neighbors (MNNs) across datasets (sometimes incorrect anchors are identified):\nMNNs can be thought of as ‘best buddies’. For each cell in one condition:\n\nThe cell’s closest neighbor in the other condition is identified based on gene expression values - its ‘best buddy’.\nThe reciprocal analysis is performed, and if the two cells are ‘best buddies’ in both directions, then those cells will be marked as anchors to ‘anchor’ the two datasets together.\n\n\n“The difference in expression values between cells in an MNN pair provides an estimate of the batch effect, which is made more precise by averaging across many such pairs. A correction vector is obtained and applied to the expression values to perform batch correction.” (Stuart et al. 2019).\n\n\n\nFilter anchors to remove incorrect anchors:\nAssess the similarity between anchor pairs by the overlap in their local neighborhoods (incorrect anchors will have low scores) - do the adjacent cells have ‘best buddies’ that are adjacent to each other?\n\n\nIntegrate the conditions/datasets:\nUse anchors and corresponding scores to transform the cell expression values, allowing for the integration of the conditions/datasets (different samples, conditions, datasets, modalities)\n\n\n\n\n\n\nNote\n\n\n\nTransformation of each cell uses a weighted average of the two cells of each anchor across anchors of the datasets. Weights determined by cell similarity score (distance between cell and k nearest anchors) and anchor scores, so cells in the same neighborhood should have similar correction values.\n\n\nIf cell types are present in one dataset, but not the other, then the cells will still appear as a separate sample-specific cluster.\n\n\nNow, using our SCTransform object as input, let’s perform the integration across conditions.\n\n# 可以看到目前的降维信息包括\"pca\"和\"umap\"\nnames(split_seurat@reductions)\n\n[1] \"pca\"  \"umap\"\n\n# 整合，比较耗时间（约13min），进度条会一直显示0%直至运算完成\nseurat_integrated &lt;- IntegrateLayers(object = split_seurat,\n                                     method = CCAIntegration,\n                                     normalization.method = \"SCT\", # 指定使用的标准化方法为SCTransform\n                                     orig.reduction = \"pca\",\n                                     new.reduction = \"integrated.cca\", #  整合后新的降维数据的名称\n                                     verbose = FALSE)\n# 查看整合后的降维信息\nnames(seurat_integrated@reductions)\n\n[1] \"pca\"            \"umap\"           \"integrated.cca\"\n\n\n\n\n\n\n\n\nTip\n\n\n\n如何调用Seurat嵌入的其他整合算法进行整合，参考：Section 11.5 。"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#整合后检验细胞分群情况",
    "href": "single_cell/scRNA-seq_online/06_integration.html#整合后检验细胞分群情况",
    "title": "\n21  单细胞数据整合（Integration）\n",
    "section": "\n21.3 整合后检验细胞分群情况",
    "text": "21.3 整合后检验细胞分群情况\nAfter integration, to visualize the integrated data we can use dimensionality reduction techniques, such as PCA and Uniform Manifold Approximation and Projection (UMAP). While PCA will determine all PCs, we can only plot two at a time. In contrast, UMAP will take the information from any number of top PCs to arrange the cells in this multidimensional space. It will take those distances in multidimensional space and plot them in two dimensions working to preserve local and global structure. In this way, the distances between cells represent similarity in expression. If you wish to explore UMAP in more detail, this post is a nice introduction to UMAP theory.\nHere, we visualize with UMAP. UMAP is a stochastic algorithm – this means that it makes use of randomness both to speed up approximation steps, and to aid in solving hard optimization problems. Due to the stochastic nature, different runs of UMAP can produce different results. We can set the seed to a specific (but random) number, and this avoids the creation of a slightly different UMAP each time re-run our code.\n\n# Set seed\nset.seed(123456)\n# Run UMAP\nseurat_integrated &lt;- RunUMAP(seurat_integrated, \n                             dims = 1:40,\n                             reduction = \"integrated.cca\") # 更改降维来源为整合后的\"integrated.cca\"\nnames(seurat_integrated@reductions)\n\n[1] \"pca\"            \"umap\"           \"integrated.cca\"\n\n# Plot UMAP                             \np3 &lt;- DimPlot(seurat_integrated, reduction = \"umap\", group.by = \"sample\")\np4 &lt;- DimPlot(seurat_integrated, reduction = \"umap\", split.by = \"sample\")\nplot_grid(p1, p2, p3, p4, ncol = 2, labels = \"AUTO\")\n\n\n\nFigure 21.2: 整合前后细胞分群情况（A, B: 整合前；C, D: 整合后）\n\n\n\n\nWhen we compare the similarity between the ctrl and stim clusters in the above plot with what we see using the the unintegrated dataset, it is clear that this dataset benefitted from the integration!\n\nSave the “integrated” object!\n\n# Save integrated seurat object\nsaveRDS(seurat_integrated, \"output/integrated_seurat.rds\")"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#complex-integration-tasks",
    "href": "single_cell/scRNA-seq_online/06_integration.html#complex-integration-tasks",
    "title": "\n21  单细胞数据整合（Integration）\n",
    "section": "\n21.4 Complex Integration Tasks",
    "text": "21.4 Complex Integration Tasks\nIn the section above, we’ve presented the Seurat integration workflow, which uses canonical correlation analysis (CCA) and multiple nearest neighbors (MNN) to find “anchors” and integrate across samples, conditions, modalities, etc. While the Seurat integration approach is widely used and several benchmarking studies support its great performance in many cases, it is important to recognize that alternative integration algorithms exist and may work better for more complex integration tasks (see (Luecken et al. 2021) for a comprehensive review).\nNot all integration algorithms rely on the same methodology, and they do not always provide the same type of corrected output (embeddings, count matrix…). Their performance is also affected by preliminary data processing steps, including which normalization method was used and how highly variable genes (HVGs) were determined. All those considerations are important to keep in mind when selecting a data integration approach for your study.\nWhat do we mean by a “complex” integration task?\nIn their benchmarking study (Luecken et al. 2021) compared the performance of different scRNA-seq integration tools when confronted to different “complex” tasks. The “complexity” of integrating a dataset may relate to the number of samples (perhaps generated using different protocols) but also to the biological question the study seeks to address (e.g. comparing cell types across tissues, species…). In these contexts, you may need to integrate across multiple confounding factors before you can start exploring the biology of your system.\n\nIn these more complex scenarios, you want to select a data integration approach that successfully balances out the following challenges:\n\nCorrecting for inter-sample variability due to source samples from different donors\nCorrecting for variability across protocols/technologies (10X, SMART-Seq2, inDrop…; single-cell vs. single nucleus; variable number of input cells and sequencing depth; different sample preparation steps…)\nIdentifying consistent cell types across different tissues (peripheral blood, bone marrow, lung…) and/or different locations (e.g. areas of the brain)\nKeeping apart cell subtypes (or even cell states) that show similar transcriptomes (CD4 naive vs. memory, NK vs NKT)\nKeeping apart cell subtypes that are unique to a tissue/condition\nConserving the developmental trajectory, if applicable\n\nNot all tools may perform as well on every task, and complex datasets may require testing several data integration approaches. You might want to analyze independently each of the batches you consider to integrate across, in order to define cell identities at this level before integrating and checking that the initially annotated cell types are mixed as expected.\nHarmonizing as a method of integration\nHarmony (Korsunsky et al. 2019) was devleoped in 2019, and is an example of a tool that can work with complex integration tasks. It is available as an GitHub and CRAN, and it has functions for standalone and Seurat pipeline analyses. It has been shown to perform incredibly well from recent benchmarking studies (Tran et al. 2020).\n在Seurat工作流的基础上实现基于Harmony的单细胞数据整合，可以使用Harmony包（available on GitHub and CRAN），详见该教程。同时，Seurat V5中的IntegrateLayers函数集成了Harmony整合算法，可以直接调用，详见：Section 11.5 。Compared to other algorithms, Harmony notably presents the following advantages ((Korsunsky et al. 2019), (Tran et al. 2020)):\n\nPossibility to integrate data across several variables (for example, by experimental batch and by condition)\nSignificant gain in speed and lower memory requirements for integration of large datasets\nInteroperability with the Seurat workflow\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] cowplot_1.1.1      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.2            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.1.0      ggridges_0.5.4        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.5           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.7        \n [25] goftest_1.2-3          later_1.3.1            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.6         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.2         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-3    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.11            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.0    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.12          Matrix_1.6-4           splines_4.3.2         \n [49] igraph_1.5.1           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.7             spatstat.random_3.2-2 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             withr_2.5.2            shiny_1.8.0           \n [64] ROCR_1.0-11            evaluate_0.23          Rtsne_0.16            \n [67] future_1.33.0          fastDummies_1.7.3      survival_3.5-7        \n [70] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [73] KernSmooth_2.23-22     plotly_4.10.3          generics_0.1.3        \n [76] RcppHNSW_0.5.0         ggplot2_3.4.4          munsell_0.5.0         \n [79] scales_1.3.0           globals_0.16.2         xtable_1.8-4          \n [82] glue_1.6.2             lazyeval_0.2.2         tools_4.3.2           \n [85] data.table_1.14.8      RSpectra_0.16-1        RANN_2.6.1            \n [88] leiden_0.4.3.1         dotCall64_1.1-1        grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-164          \n [94] patchwork_1.1.3        cli_3.6.1              spatstat.sparse_3.0-3 \n [97] spam_2.10-0            fansi_1.0.5            viridisLite_0.4.2     \n[100] dplyr_1.1.4            uwot_0.1.16            gtable_0.3.4          \n[103] digest_0.6.33          progressr_0.14.0       ggrepel_0.9.4         \n[106] farver_2.1.1           htmlwidgets_1.6.3      htmltools_0.5.7       \n[109] lifecycle_1.0.4        httr_1.4.7             mime_0.12             \n[112] MASS_7.3-60           \n\n\n\n\n\n\n\n\n\n\n\nKorsunsky, Ilya, Nghia Millard, Jean Fan, Kamil Slowikowski, Fan Zhang, Kevin Wei, Yuriy Baglaenko, Michael Brenner, Po-ru Loh, and Soumya Raychaudhuri. 2019. “Fast, Sensitive and Accurate Integration of Single-Cell Data with Harmony.” Nature Methods 16 (12): 1289–96. https://doi.org/10.1038/s41592-019-0619-0.\n\n\nLuecken, Malte D., M. Büttner, K. Chaichoompu, A. Danese, M. Interlandi, M. F. Mueller, D. C. Strobl, et al. 2021. “Benchmarking Atlas-Level Data Integration in Single-Cell Genomics.” Nature Methods 19 (1): 41–50. https://doi.org/10.1038/s41592-021-01336-8.\n\n\nStuart, Tim, Andrew Butler, Paul Hoffman, Christoph Hafemeister, Efthymia Papalexi, William M. Mauck, Yuhan Hao, Marlon Stoeckius, Peter Smibert, and Rahul Satija. 2019. “Comprehensive Integration of Single-Cell Data.” Cell 177 (7): 1888–1902.e21. https://doi.org/10.1016/j.cell.2019.05.031.\n\n\nTran, Hoa Thi Nhu, Kok Siong Ang, Marion Chevrier, Xiaomeng Zhang, Nicole Yee Shin Lee, Michelle Goh, and Jinmiao Chen. 2020. “A Benchmark of Batch-Effect Correction Methods for Single-Cell RNA Sequencing Data.” Genome Biology 21 (1). https://doi.org/10.1186/s13059-019-1850-9."
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#sec-数据整合",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#sec-数据整合",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.5 数据整合",
    "text": "11.5 数据整合\nSeurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches:\n\nAnchor-based CCA integration (method=CCAIntegration)\nAnchor-based RPCA integration (method=RPCAIntegration)\nHarmony (method=HarmonyIntegration)\nFastMNN (method= FastMNNIntegration)\nscVI (method=scVIIntegration)\n\nNote that our anchor-based RPCA integration represents a faster and more conservative (less correction) method for integration. For interested users, we discuss this method in more detail in our previous RPCA vignette.\nYou can find more detail on each method, and any installation prerequisites, in Seurat’s documentation (for example, ?HarmonyIntegration). For example, harmony整合需要先安装harmony包（install.packages(\"harmony\")）；scVI integration requires reticulate which can be installed from CRAN (install.packages(\"reticulate\")) as well as scvi-tools and its dependencies installed in a conda environment. Please see scVI installation instructions here.\nEach of the following lines perform a new integration using a single line of code:\n（这里我们选择其中的CCAIntegration和HarmonyIntegration两种方式分别对数据进行整合，整合后后的降维信息分别储存在”integrated.cca”和”harmony”中）\n\nobj &lt;- IntegrateLayers(\n  object = obj,\n  method = CCAIntegration,\n  orig.reduction = \"pca\",\n  new.reduction = \"integrated.cca\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = RPCAIntegration,\n  orig.reduction = \"pca\", \n  new.reduction = \"integrated.rpca\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n```\n\n\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = HarmonyIntegration,\n  orig.reduction = \"pca\", \n  new.reduction = \"harmony\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n[4] \"harmony\"          \n\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = FastMNNIntegration,\n  new.reduction = \"integrated.mnn\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n```\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = scVIIntegration,\n  new.reduction = \"integrated.scvi\",\n  conda_env = \"../miniconda3/envs/scvi-env\", \n  verbose = FALSE\n)\nnames(obj@reductions)\n```"
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#基于传统标准化流程对非期望变异来源进行评估",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#基于传统标准化流程对非期望变异来源进行评估",
    "title": "20  Normalization and regressing out unwanted variation",
    "section": "\n20.2 基于传统标准化流程对非期望变异来源进行评估",
    "text": "20.2 基于传统标准化流程对非期望变异来源进行评估\nThe most common biological data correction (or source of “uninteresting” variation) in single cell RNA-seq is the effects of the cell cycle on the transcriptome. We need to explore the data and see if we observe any effects in our data.\nSet-up\nBefore we make any comparisons across cells, we will apply a simple normalization. This is solely for the purpose of exploring the sources of variation in our data.\nThe input for this analysis is a seurat object. We will use the one that we created in ?sec-qc called filtered_seurat.\n\nlibrary(Seurat)\nfiltered_seurat &lt;- readRDS(\"output/seurat_filtered.rds\")\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts\n\nhead(filtered_seurat@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n\n# Normalize the counts\nseurat_phase &lt;- NormalizeData(filtered_seurat)\nseurat_phase\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 2 layers present: counts, data\n\n\n可以发现，运行NormalizeDataNext后的数据多出了新的layer：data, 里面即储存了标准化后的数据。Next, we take this normalized data and check to see if data correction methods are necessary.\nEvaluating effects of cell cycle\nTo assign each cell a score based on its expression of G2/M and S phase markers, we can use the Seuart function CellCycleScoring(). This function calculates cell cycle phase scores based on canonical markers that required as input.\nA list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat. We can segregate this list into markers of G2/M phase and markers of S phase. However, if you are not working with human data we have additional materials detailing how to acquire cell cycle markers for other organisms of interest.\n\n# Load cell cycle markers\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n# Score cells for cell cycle\nseurat_phase &lt;- CellCycleScoring(seurat_phase, \n                                 g2m.features = g2m.genes, \n                                 s.features = s.genes)\n\n# 现在的meta.data中多出了细胞周期评分“S.Score”和“G2M.Score”，以及推断的细胞所处的周期“Phase”\nhead(seurat_phase@meta.data)\n\n                                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix       2344          874\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix       3125          896\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix       2578          725\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix       3261          979\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix        746          362\nctrl_AAACATACCTCGCT-1 ctrl_raw_feature_bc_matrix       3519          866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n                          S.Score   G2M.Score Phase\nctrl_AAACATACAATGCC-1  0.02713602  0.04344302   G2M\nctrl_AAACATACATTTCC-1  0.01519129  0.01846409   G2M\nctrl_AAACATACCAGAAA-1 -0.05272781 -0.05038367    G1\nctrl_AAACATACCAGCTA-1 -0.05194312  0.04583528   G2M\nctrl_AAACATACCATGCA-1  0.04406978 -0.03445262     S\nctrl_AAACATACCTCGCT-1  0.03421052  0.02033139     S\n\n# 查看一下细胞周期的分布情况\ntable(seurat_phase$Phase)\n\n\n   G1   G2M     S \n10387  9547  9695 \n\n\nAfter scoring the cells for cell cycle, we would like to determine whether cell cycle is a major source of variation in our dataset using PCA.\nPCA\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for “dimensionality reduction”.\n\nNOTE: For a more detailed explanation on PCA, please look over this lesson (adapted from StatQuests/Josh Starmer’s YouTube video). We also strongly encourage you to explore the video StatQuest’s video for a more thorough understanding.\n\n\nLet’s say you are working with a single-cell RNA-seq dataset with 12,000 cells and you have quantified the expression of 20,000 genes. The schematic below demonstrates how you would go from a cell x gene matrix to principal component (PC) scores for each inividual cell.\n\nAfter the PC scores have been calculated, you are looking at a matrix of 12,000 x 12,000 that represents the information about relative gene expression in all the cells. You can select the PC1 and PC2 columns and plot that in a 2D way.\n\nYou can also use the PC scores from the first 40 PCs for downstream analysis like clustering, marker identification etc., since these represent the majority of the variation in the data. We will be talking a lot more about this later in this workshop.\n\n\n\n\n\n\n\nNote\n\n\n\nFor datasets with a larger number of cells, only the PC1 and PC2 scores for each cell are usually plotted, or used for visualization. Since these PCs explain the most variation in the dataset, the expectation is that the cells that are more similar to each other will cluster together with PC1 and PC2.\n\n\n评估细胞周期的影响\nTo perform PCA, we need to first choose the most variable features, then scale the data. Since highly expressed genes exhibit the highest amount of variation and we don’t want our ‘highly variable genes’ only to reflect high expression, we need to scale the data to scale variation with expression level. The Seurat ScaleData() function will scale the data by:\n\nadjusting the expression of each gene to give a mean expression across cells to be 0\n\nscaling expression of each gene to give a variance across cells to be 1\n\n\n\n# Identify the most variable genes\nseurat_phase &lt;- FindVariableFeatures(seurat_phase, \n                                     selection.method = \"vst\", # 默认值\n                                     nfeatures = 2000) # 默认值\n             \n# Scale the counts\nseurat_phase &lt;- ScaleData(seurat_phase)\nLayers(seurat_phase)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n\n可以发现，运行ScaleData后的数据多出了新的layer：scale.data, 里面即储存了归一化后的数据。Now, we can perform the PCA analysis and plot the first two principal components against each other. We also split the figure by cell cycle phase, to evaluate similarities and/or differences.\n\n# Perform PCA。如果没有指定features，RunPCA默认使用FindVariableFeatures找到的高变基因作为PCA输入.\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\",\n              split.by = \"Phase\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\nWe do not see large differences due to cell cycle phase. Based on this plot, we would not regress out the variation due to cell cycle.\n\n\n\n\n\n\nWhen should cell cycle phase be regressed out?\n\n\n\n\n\nBelow are two PCA plots taken from ?sec-Elimination_of_cell_cycle_effects 。This first plot is similar to what we plotted above, it is a PCA prior to regression to evaluate if the cell cycle is playing a big role in driving PC1 and PC2. Clearly, the cells are separating by cell type in this case, so it suggests regressing out these effects.\n\nThis second PCA plot is post-regression, and displays how effective the regression was in removing the effect we observed.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n在需要消除细胞周期的影响时，如何通过ScaleData回归掉（regress out）细胞周期的影响，以及如何在消除细胞周期的影响同时保留增殖细胞与静止细胞的区分，参考 ?sec-Elimination_of_cell_cycle_effects 。\n\n\n评估线粒体基因表达的影响\nMitochondrial expression is another factor which can greatly influence clustering. Oftentimes, it is useful to regress out variation due to mitochondrial expression. However, if the differences in mitochondrial gene expression represent a biological phenomenon that may help to distinguish cell clusters, then we advise not regressing this out. In this exercise, we can perform a quick check similar to looking at cell cycle and decide whether or not we want to regress it out.\n\n\nFirst, turn the mitochondrial ratio variable into a new categorical variable based on quartiles (using the code below):\n\n# Check quartile values\nsummary(seurat_phase$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01438 0.01993 0.02139 0.02669 0.14464 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nseurat_phase$mitoFr &lt;- cut(seurat_phase@meta.data$mitoRatio, \n                           breaks=c(-Inf, 0.0144, 0.0199, 0.0267, Inf), \n                           labels=c(\"Low\", \"Medium\", \"Medium high\", \"High\"))\ntable(seurat_phase$mitoFr)\n\n\n        Low      Medium Medium high        High \n       7443        7325        7459        7402 \n\n\n\n\nNext, plot the PCA similar to how we did with cell cycle regression. Hint: use the new mitoFr variable to split cells and color them accordingly.\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\",\n              split.by = \"mitoFr\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\nEvaluate the PCA plot.\nWe do not see large differences due to mitochondrial expression. Based on this plot, we would not regress out the variation due to mitochondrial expression."
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#sec-highly_variable_features",
    "href": "single_cell/seurat/seurat_tutorial.html#sec-highly_variable_features",
    "title": "7  Seurat细胞分群官方教程",
    "section": "\n7.4 识别高变基因（highly variable features）",
    "text": "7.4 识别高变基因（highly variable features）\nWe next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). We and others (Brennecke et al. 2013) have found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.\nOur procedure in Seurat is described in detail here (Stuart et al. 2019) , and improves on previous versions by directly modeling the mean-variance relationship inherent in single-cell data, and is implemented in the FindVariableFeatures() function. By default, we return 2,000 features per dataset. These will be used in downstream analysis, like PCA.\n\npbmc &lt;- FindVariableFeatures(pbmc, \n                             selection.method = \"vst\", \n                             nfeatures = 2000)\n\n# Identify the 10 most highly variable genes\ntop10 &lt;- head(VariableFeatures(pbmc), 10)\n\n# plot variable features with and without labels\nplot1 &lt;- VariableFeaturePlot(pbmc)\nplot1\nLabelPoints(plot = plot1, points = top10, repel = TRUE)\n\n\n\n\n\n(A) 前2000个高变基因\n\n\n\n\n\n(B) 前2000个高变基因（标注了前10个高变基因）\n\n\n\nFigure 7.1: 识别高变基因"
  },
  {
    "objectID": "single_cell/seurat/integration.html#sec-Identify_differential_genes_between_sample_types",
    "href": "single_cell/seurat/integration.html#sec-Identify_differential_genes_between_sample_types",
    "title": "10  单细胞数据整合（integration）",
    "section": "\n10.5 识别不同样本类型间的差异基因",
    "text": "10.5 识别不同样本类型间的差异基因\nNow that we’ve aligned the stimulated and control cells, we can start to do comparative analyses and look at the differences induced by stimulation.\nWe can aggregate cells of a similar type and condition together to create “pseudobulk” profiles using the AggregateExpression command（通过AggregateExpression命令将同一类型的细胞按照不同的处理条件合并起来，形成一个假的组织水平的测序数据。本例中，细胞被注释为13种细胞类型，而处理条件为”STIM”和”CTRL”，因此总共会被合并成13*2=26个类别，将每一个类别看作是一个样本，这样就形成了一个所谓的假的组织水平的测序数据）.\n\naggregate_ifnb &lt;- AggregateExpression(ifnb, \n                                      group.by = c(\"seurat_annotations\", \"stim\"), \n                                      return.seurat = TRUE)\naggregate_ifnb\n\nAn object of class Seurat \n14053 features across 26 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 3 layers present: counts, data, scale.data\n\nhead(aggregate_ifnb@meta.data, 5)\n\n                         orig.ident seurat_annotations stim\nCD14 Mono_CTRL       CD14 Mono_CTRL          CD14 Mono CTRL\nCD14 Mono_STIM       CD14 Mono_STIM          CD14 Mono STIM\nCD4 Naive T_CTRL   CD4 Naive T_CTRL        CD4 Naive T CTRL\nCD4 Naive T_STIM   CD4 Naive T_STIM        CD4 Naive T STIM\nCD4 Memory T_CTRL CD4 Memory T_CTRL       CD4 Memory T CTRL\n\ncolnames(aggregate_ifnb) # 可以看到现在的表达矩阵的列（即样本）为细胞类型+处理条件\n\n [1] \"CD14 Mono_CTRL\"    \"CD14 Mono_STIM\"    \"CD4 Naive T_CTRL\" \n [4] \"CD4 Naive T_STIM\"  \"CD4 Memory T_CTRL\" \"CD4 Memory T_STIM\"\n [7] \"CD16 Mono_CTRL\"    \"CD16 Mono_STIM\"    \"B_CTRL\"           \n[10] \"B_STIM\"            \"CD8 T_CTRL\"        \"CD8 T_STIM\"       \n[13] \"T activated_CTRL\"  \"T activated_STIM\"  \"NK_CTRL\"          \n[16] \"NK_STIM\"           \"DC_CTRL\"           \"DC_STIM\"          \n[19] \"B Activated_CTRL\"  \"B Activated_STIM\"  \"Mk_CTRL\"          \n[22] \"Mk_STIM\"           \"pDC_CTRL\"          \"pDC_STIM\"         \n[25] \"Eryth_CTRL\"        \"Eryth_STIM\"       \n\n\n\nAs an initial exploratory analysis, we can compare pseudobulk profiles of two cell types (naive CD4 T cells, and CD14 monocytes), and compare their gene expression profiles before and after stimulation. We highlight genes that exhibit dramatic responses to interferon stimulation.\n\nlibrary(ggplot2)\nlibrary(cowplot)\ntheme_set(theme_cowplot())\n\n# genes that exhibit dramatic responses to interferon stimulation\ngenes.to.label = c(\"ISG15\", \"LY6E\", \"IFI6\", \"ISG20\", \"MX1\", \"IFIT2\", \"IFIT1\", \"CXCL10\",\n                   \"CCL8\")\n\np1 &lt;- CellScatter(aggregate_ifnb, \n                  \"CD14 Mono_CTRL\", \"CD14 Mono_STIM\", \n                  highlight = genes.to.label)\nLabelPoints(plot = p1, \n                  points = genes.to.label, \n                  repel = TRUE)\n\np3 &lt;- CellScatter(aggregate_ifnb, \n                  \"CD4 Naive T_CTRL\", \"CD4 Naive T_STIM\", \n                  highlight = genes.to.label)\nLabelPoints(plot = p3, \n                  points = genes.to.label, \n                  repel = TRUE)\n\n\n\n\n\n(A) CD14 Mono细胞中的基因在对照组和刺激组之间的表达量散点图\n\n\n\n\n\n(B) CD4 Naive T细胞中的基因在对照组和刺激组之间的表达量散点图\n\n\n\nFigure 10.3: CD14 Mono和CD4 Naive T细胞中的基因在对照组和刺激组之间的表达量散点图\n\n\n\n\nAs you can see, many of the same genes are upregulated (位于对角线上方) in both of these cell types and likely represent a conserved interferon response pathway, though CD14 monocytes exhibit a stronger transcriptional response.\n\n正式差异分析\nWe can now ask what genes change in different conditions for cells of the same type.\n\nFirst, we create a column in the meta.data slot to hold both the cell type and stimulation information and switch the current ident to that column.\nThen we use FindMarkers() to find the genes that are different between stimulated and control B cells. Notice that many of the top genes that show up here are the same as the ones we plotted earlier as core interferon response genes. Additionally, genes like CXCL10 which we saw were specific to monocyte and B cell interferon response show up as highly significant in this list as well.\n\n\nifnb$celltype.stim &lt;- paste(ifnb$seurat_annotations, ifnb$stim, sep = \"_\")\nIdents(ifnb) &lt;- \"celltype.stim\"\n\n# 寻找对照组和刺激组之间在B细胞中的差异基因\nb.interferon.response &lt;- FindMarkers(ifnb, \n                                     ident.1 = \"B_STIM\", \n                                     ident.2 = \"B_CTRL\", \n                                     verbose = FALSE)\nhead(b.interferon.response, n = 15)\n\n                p_val avg_log2FC pct.1 pct.2     p_val_adj\nISG15   5.387767e-159  5.0588481 0.998 0.233 7.571429e-155\nIFIT3   1.945114e-154  6.1124940 0.965 0.052 2.733468e-150\nIFI6    2.503565e-152  5.4933132 0.965 0.076 3.518260e-148\nISG20   6.492570e-150  3.0549593 1.000 0.668 9.124009e-146\nIFIT1   1.951022e-139  6.2320388 0.907 0.029 2.741772e-135\nMX1     6.897626e-123  3.9798482 0.905 0.115 9.693234e-119\nLY6E    2.825649e-120  3.7907800 0.898 0.150 3.970885e-116\nTNFSF10 4.007285e-112  6.5802175 0.786 0.020 5.631437e-108\nIFIT2   2.672552e-108  5.5525558 0.786 0.037 3.755738e-104\nB2M      5.283684e-98  0.6104044 1.000 1.000  7.425161e-94\nPLSCR1   4.634658e-96  3.8010721 0.793 0.113  6.513085e-92\nIRF7     2.411149e-94  3.1992949 0.835 0.187  3.388388e-90\nCXCL10   3.708508e-86  8.0906108 0.651 0.010  5.211566e-82\nUBE2L6   5.547472e-83  2.5167981 0.851 0.297  7.795863e-79\nPSMB9    1.716262e-77  1.7715351 0.937 0.568  2.411863e-73\n\n\nPlease note that p-values obtained from this analysis should be interpreted with caution, as these tests treat each cell as an independent replicate, and ignore inherent correlations between cells originating from the same sample. As discussed here (Crowell et al. 2020), DE tests across multiple conditions should expressly utilize multiple samples/replicates, and can be performed after aggregating (‘pseudobulking’) cells from the same sample and subpopulation together. We do not perform this analysis here, as there is a single replicate in the data, but please see our vignette comparing healthy and diabetic samples as an example for how to perform DE analysis across conditions.\nAnother useful way to visualize these changes in gene expression is with the split.by option to the FeaturePlot() or VlnPlot() function. This will display FeaturePlots of the list of given genes, split by a grouping variable (stimulation condition here).\n\nFeaturePlot(ifnb, \n            features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\"), \n            split.by = \"stim\", \n            max.cutoff = 3, \n            cols = c(\"grey\", \"red\"), \n            reduction = \"umap\")\n\n\n\n\n\nplots &lt;- VlnPlot(ifnb,\n        features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\", \"LYZ\"),\n        split.by = \"stim\",\n        group.by = \"seurat_annotations\",\n        pt.size = 0,\n        combine = FALSE) # 由于VlnPlot绘制组图时没有图例，所以这里取消绘制组图\nlibrary(patchwork)\nwrap_plots(plots = plots, ncol = 2) # 将plots列表组合成组图\n\n\n\n\n\n\nGenes such as CD3D and GNLY are canonical cell type markers (for T cells and NK/CD8 T cells) that are virtually unaffected by interferon stimulation and display similar gene expression patterns in the control and stimulated group.\nIFI6 and ISG15, on the other hand, are core interferon response genes and are upregulated accordingly in all cell types.\n\nCD14 and CXCL10 are genes that show a cell type specific interferon response.\n\nCD14 expression decreases after stimulation in CD14 monocytes, which could lead to misclassification in a supervised analysis framework, underscoring the value of integrated analysis.如果用于识别细胞类型的marker本身在不同的样本类型（处理 vs. 对照、恶性组织 vs. 正常组织）中存在表达量的差异，那么就会导致对细胞类型判断的错误。而本篇的数据整合则能够避免出现这种情况。\nCXCL10 shows a distinct upregulation in monocytes and B cells after interferon stimulation but not in other cell types."
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#sec-sc_integration",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#sec-sc_integration",
    "title": "11  Seurat v5单细胞数据整合分析",
    "section": "\n11.5 数据整合",
    "text": "11.5 数据整合\nSeurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches:\n\nAnchor-based CCA integration (method=CCAIntegration)\nAnchor-based RPCA integration (method=RPCAIntegration)\nHarmony (method=HarmonyIntegration)\nFastMNN (method= FastMNNIntegration)\nscVI (method=scVIIntegration)\n\nNote that our anchor-based RPCA integration represents a faster and more conservative (less correction) method for integration. For interested users, we discuss this method in more detail in our previous RPCA vignette.\nYou can find more detail on each method, and any installation prerequisites, in Seurat’s documentation (for example, ?HarmonyIntegration). For example, harmony整合需要先安装harmony包（install.packages(\"harmony\")）；scVI integration requires reticulate which can be installed from CRAN (install.packages(\"reticulate\")) as well as scvi-tools and its dependencies installed in a conda environment. Please see scVI installation instructions here.\nEach of the following lines perform a new integration using a single line of code:\n（这里我们选择其中的CCAIntegration和HarmonyIntegration两种方式分别对数据进行整合，整合后后的降维信息分别储存在”integrated.cca”和”harmony”中）\n\nobj &lt;- IntegrateLayers(\n  object = obj,\n  method = CCAIntegration,\n  orig.reduction = \"pca\",\n  new.reduction = \"integrated.cca\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = RPCAIntegration,\n  orig.reduction = \"pca\", \n  new.reduction = \"integrated.rpca\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n```\n\n\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = HarmonyIntegration,\n  orig.reduction = \"pca\", \n  new.reduction = \"harmony\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n[4] \"harmony\"          \n\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = FastMNNIntegration,\n  new.reduction = \"integrated.mnn\",\n  verbose = FALSE\n)\nnames(obj@reductions)\n```\n\n\n```{r}\n#| eval: false\nobj &lt;- IntegrateLayers(\n  object = obj, \n  method = scVIIntegration,\n  new.reduction = \"integrated.scvi\",\n  conda_env = \"../miniconda3/envs/scvi-env\", \n  verbose = FALSE\n)\nnames(obj@reductions)\n```"
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#sec-degs_within_the_same_cell_type_between_different_sample_types",
    "href": "single_cell/seurat/de_vignette.html#sec-degs_within_the_same_cell_type_between_different_sample_types",
    "title": "14  差异表达分析",
    "section": "\n14.3 寻找不同样本类型间同一细胞类型内的差异基因",
    "text": "14.3 寻找不同样本类型间同一细胞类型内的差异基因\nSince this dataset contains treatment information (control versus stimulated with interferon-beta), we can also ask what genes change in different conditions for cells of the same type.\n\nFirst, we create a column in the meta.data slot to hold both the cell type and treatment information and switch the current Idents to that column.\n\n\nifnb$celltype.stim &lt;- paste(ifnb$seurat_annotations, ifnb$stim, sep = \"_\")\ntable(ifnb$celltype.stim)\n\n\n B Activated_CTRL  B Activated_STIM            B_CTRL            B_STIM \n              185               203               407               571 \n   CD14 Mono_CTRL    CD14 Mono_STIM    CD16 Mono_CTRL    CD16 Mono_STIM \n             2215              2147               507               537 \nCD4 Memory T_CTRL CD4 Memory T_STIM  CD4 Naive T_CTRL  CD4 Naive T_STIM \n              859               903               978              1526 \n       CD8 T_CTRL        CD8 T_STIM           DC_CTRL           DC_STIM \n              352               462               258               214 \n       Eryth_CTRL        Eryth_STIM           Mk_CTRL           Mk_STIM \n               23                32               115               121 \n          NK_CTRL           NK_STIM          pDC_CTRL          pDC_STIM \n              298               321                51                81 \n T activated_CTRL  T activated_STIM \n              300               333 \n\nIdents(ifnb) &lt;- \"celltype.stim\"\n\n\nThen we use FindMarkers() to find the genes that are different between control and stimulated CD14 monocytes.\n\n\nmono.de &lt;- FindMarkers(ifnb, \n                       ident.1 = \"CD14 Mono_STIM\", \n                       ident.2 = \"CD14 Mono_CTRL\", \n                       verbose = FALSE)\nnrow(mono.de)\n\n[1] 6956\n\nhead(mono.de, n = 10)\n\n        p_val avg_log2FC pct.1 pct.2 p_val_adj\nIFIT1       0   7.319139 0.985 0.033         0\nCXCL10      0   8.036564 0.984 0.035         0\nRSAD2       0   6.741673 0.988 0.045         0\nTNFSF10     0   6.991279 0.989 0.047         0\nIFIT3       0   6.883785 0.992 0.056         0\nIFIT2       0   7.179929 0.961 0.039         0\nCXCL11      0   8.624208 0.932 0.012         0\nCCL8        0   9.134191 0.918 0.017         0\nIDO1        0   5.455898 0.965 0.089         0\nMX1         0   5.059052 0.960 0.093         0\n\n\nHowever, the p-values obtained from this analysis should be interpreted with caution, because these tests treat each cell as an independent replicate and ignore inherent correlations between cells originating from the same sample. Such analyses have been shown to find a large number of false positive associations, as has been demonstrated by (Squair et al. 2021), (Zimmerman, Espeland, and Langefeld 2021), (Junttila, Smolander, and Elo 2022), and others. Below, we show how pseudobulking can be used to account for such within-sample correlation."
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-theme",
    "href": "quarto_foundation/yaml_settings.html#sec-theme",
    "title": "22  YAML设置",
    "section": "\n22.3 theme主题设置",
    "text": "22.3 theme主题设置\ntheme定义了编译文档的主题。可以直接调用Quarto内置的Bootswatch主题，如”default”、“cerulean”和”cosmo”等，也可以通过Sassy Cascading Style Sheets (SCSS)文件来自定义主题。theme参数既可以在YAML中直接定义，也可以在不同的format内定义，这样可以对不同的编译格式应用不同的主题。关于Quarto主题的详细指南，参考Quarto Guide。\n\n---\nformat: \n  html:\n    theme: flatly\n---\n\nQuarto的HTML文档默认使用Bootstrap 5样式输出（theme: default）。Quarto内置了来自Bootswatch项目的25个主题。下面列出了可用的主题。关于这些主题的介绍详见：https://bootswatch.com。\n\n个人认为比较美观、清晰的主题有：Cosmo、Flatly、Lux和Darkly。可以通过light和dark分别设置一套亮色主题和一套深色主题，如：\n\n---\nformat: \n  html:\n    theme:\n      light: flatly\n      dark: darkly\n---\n\n这样，在输出的HTML网页的右上角会出现一个亮色/深色模式的切换开关。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-toc",
    "href": "quarto_foundation/yaml_settings.html#sec-toc",
    "title": "22  YAML设置",
    "section": "\n22.4 toc目录设置",
    "text": "22.4 toc目录设置\n和theme一样toc同样可以在YAML中直接定义，也可以在不同的format内定义。\n\n---\ntoc: true\ntoc-title: Contents\ntoc-depth: 2 \ntoc-expand: 2 \ntoc-location: left\n---\n\n\ntoc：是否显示目录。\ntoc-title：目录的标题。\ntoc-depth：设置目录显示的最低层级（默认为显示到3级标题）。\ntoc-expand：在一开始目录显示到多少级，默认显示到一级标题。当向下浏览内容时目录会自动展开到toc-depth所设置的层级。设置为true时，则在一开始就展开所有目录；设置为false则在一开始折叠所有目录。\ntoc-location：设置目录的位置。默认在右侧（right）,可以设置为left或body（在文稿最开头显示）。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-ref_settings",
    "href": "quarto_foundation/yaml_settings.html#sec-ref_settings",
    "title": "22  YAML设置",
    "section": "\n22.9 参考文献设置",
    "text": "22.9 参考文献设置\n只要在编辑qmd文档时插入了参考文献，YAML中会新增参考文献的配置选项：bibliography: references.bib。同时根目录下会生成一个名为”references.bib”的参考文献配置文件。该配置文件包括了qmd文档中所插入的所有参考文献的列表。以BibTeX/Citation风格语言编写。bibliography指定了这个参考文献配置文件所在的路径。\n\n---\nbibliography: references.bib\n---"
  },
  {
    "objectID": "quarto_foundation/images_settings.html#sec-Settings_for_inserting_figs",
    "href": "quarto_foundation/images_settings.html#sec-Settings_for_inserting_figs",
    "title": "23  图片设置",
    "section": "\n23.1 插入图片的设置",
    "text": "23.1 插入图片的设置\n图片可以通过复制粘贴直接插入，Quarto定义图像的基本语法是：\n![图片标题](images/crossref-figure.png){#fig-elephant width=\"290\"}。\n其中，方括号内的是对象的caption（可选），小括号内是图像所在目录，“{}”内的内容是图像的label以及其他可选设置，各参数间用空格进行分割。常用的图像设置如下：\n\nwidth和height：图像的宽、高。默认单位为像素。\nfig-align：图片的对齐方式，如”left”，“right”。\n可以在小括号内添加超链接，如[![](``images/crossref-figure.png``)](https://en.wikipedia.org/wiki/Elephant)，当点击该图像时会跳转该网站。\ncaption和label的设置会使该图像能够被交叉引用（详见 Section 24.2 ）。\n\n.column-page：让图片以整个文档的宽度展示。需要首先建立一个Pandoc Div块（Figure 23.1）。然后在Pandoc Div块的参数项内填上{.column-page}。如下所示：\n\n:::{.column-page}\n![](images/elephant.jpg)\n:::\n\n这样这张图片就会以文档最大宽度显示：\n\n\n\n\n\n\n\n\n\n\n\n应用于代码块时为：#| column: page\n\n\n\n\n\n.column-screen：让图片占满整个网页的宽度。应用于代码块时为：#| column: screen。\n\n\n\n\n\n\ncolumn-screen-inset-shaded：让图片以整个文档的宽度展示，但是在后方加上一个网页宽度的阴影。应用于代码块时为：#| column: screen-inset-shaded。\n\n\n\n\n组图的设置\n要容纳和排版组图，需要首先建立一个Pandoc Div块（Figure 23.1）。\n\n\nFigure 23.1: 建立Div块\n\nDiv块的图像排版基本语法如下：\n\n\nFigure 23.2: Div块的基本语法\n\n\n“{}”内为组图的label、排版设置。\n在所有图片最后可输入组图的总标题，如上图中的”交叉引用的设置”。\n\n设置图片的排版方式。\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如::: {layout-ncol=\"2\"}。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayout复杂排版\n其基本语法和 Section 23.2 一致。不同点在于需要在Div块开头的”{}“内设置，同时layout后要接”=“，并且注意加引号，例如：layout=\"[[1，1]，[1]]\"。通过设置layout可以完成对多图的复杂排版。layout属性是一个二维数组，其中第一维定义行，第二维定义列。layout=\"[[1，1]，[1]]\"表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组图复杂排版设置\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n关于图片设置的详细指南，参考：https://quarto.org/docs/authoring/figures.html。"
  },
  {
    "objectID": "quarto_foundation/images_settings.html#sec-Code_chunk_figs_output_settings",
    "href": "quarto_foundation/images_settings.html#sec-Code_chunk_figs_output_settings",
    "title": "23  图片设置",
    "section": "\n23.2 代码块图片输出设置",
    "text": "23.2 代码块图片输出设置\n对于代码块运行后生成的图片，我们也可以对其进行各种设置以使其在编译后的文档中符合理想的展示要求。基本语法和 中类似，只不过需要在前面加上”#|”符号，然后将其放置在代码块开头。常用的参数有：\n\n#| lable：图片标签。\n#| fig-cap：图片标题（caption）。fig-cap和lable共同用于图片的交叉引用，详见 Section 24.2 。\n#| fig-width：图片的宽度。\n#| fig-height：图片的高度。\n\n其他设置包括#| fig-align、#| fig-cap-location等，见 Section 23.1 。\n\n```{r}\n#| eval: true\n#| label: fig-散点图\n#| fig-cap: \"38种流行车型的城市和高速公路里程\"\n#| fig-width: 6\n#| fig-height: 3.5\nlibrary(ggplot2)\nggplot(mpg, aes(x = hwy, y = cty, color = cyl)) +\n  geom_point(alpha = 0.5, size = 2) +\n  scale_color_viridis_c() +\n  theme_minimal()\n```\n\n\n\nFigure 23.3: 38种流行车型的城市和高速公路里程\n\n\n\n代码块组图输出设置\n如果一个代码块运行后可以生成多张图像，那么我们也可以和 Section 23.1.1 中一样，对这些图片进行组图排版。常用的参数包括：\n\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如layout-ncol: \"2\"。\nlabel：组图的标签。\nfig-cap：每张图的标题。通过”-“符号分别设置。效果如下所示：\n\n\n```{r}\n#| eval: true\n#| layout-ncol: 2\n#| label: fig-组图输出\n#| fig-cap:\n#|   - \"车辆的速度和停车距离\"\n#|   - \"汽压与温度的关系\"\n\nplot(cars)\nplot(pressure)\n```\n\n\n\n\n\nFigure 23.4: 车辆的速度和停车距离\n\n\n\n\n\nFigure 23.5: 汽压与温度的关系\n\n\n\n\n\n\n\nfig-subcap：每张图以小标题进行标注，如”(a) sub caption”、“(b) sub caption”。效果如下所示：\n\n\n```{r}\n#| eval: true\n#| label: fig-小标题组图输出\n#| fig-cap: \"小标题组图输出\"\n#| fig-subcap:\n#|   - \"汽车\"\n#|   - \"压力\"\n#| layout-ncol: 2\n\nplot(cars)\nplot(pressure)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n(B) 压力\n\n\n\nFigure 23.6: 小标题组图输出\n\n\n\n用layout进行复杂排版\nlayout属性是一个二维数组，其中第一维定义行，第二维定义列。如layout: \"[[1，1]，[1]]表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片\n#| fig-cap: 复杂排版组图输出\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[1], [1, 1]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n(C) mtcars\n\n\n\nFigure 23.7: 复杂排版组图输出\n\n\n\nlayout后的”[]“中的数字大小表示各个图像的相对大小。所以可以用任何值来自定义：\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片2\n#| fig-cap: 复杂排版组图输出2\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[100], [30, 70]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n(C) mtcars\n\n\n\nFigure 23.8: 复杂排版组图输出2\n\n\n\n如果我们输入负数，如下面的”-10”，则会在两个图之间加上相应的间距：\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片3\n#| fig-cap: 复杂排版组图输出3\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[45,-10, 45], [100]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n(A) 汽车\n\n\n\n \n\n\n\n\n(B) 压力\n\n\n\n\n\n\n\n(C) mtcars\n\n\n\nFigure 23.9: 复杂排版组图输出3"
  },
  {
    "objectID": "quarto_foundation/cross_references.html#sec-Cross_referencing_of_figs",
    "href": "quarto_foundation/cross_references.html#sec-Cross_referencing_of_figs",
    "title": "24  交叉引用",
    "section": "\n24.2 图片的交叉引用",
    "text": "24.2 图片的交叉引用\n实现的方法：\n\n方法一：在源代码模式下修改被引用对象的属性，如：![Example for cross reference](images/crossref-figure.png){#fig-elephant width=\"290\"}。其中，方括号内的是对象的caption，小括号内是图片所在的目录，“{}”内的内容是图像的label以及其他可选设置。\n方法二：点击待引用对象右上角的三个点，进入对象设置。分别输入caption和ID（即label）（Figure 24.1 )。\n\n\n\n\n\n\n\n\n\n\nFigure 24.1: 交叉引用的设置\n\n\n例如下面的图片，可以被引用：Figure 24.2 。\n\n\nFigure 24.2: Example for cross reference\n\n组图的交叉引用\n基本语法：\n\n案例：\n\n\n\n\n\n(A) 素描大象\n\n\n\n\n\n(B) 油画大象\n\n\n\nFigure 24.3: 组图的交叉引用\n\n\n现在，我们就可以将组图一起引用（Figure 24.3 ），或是单独引用组图内的某一张图（Figure 24.3 (B) ，Figure 24.3 (A) ）。"
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#sec-number_sections",
    "href": "quarto_foundation/quarto_books.html#sec-number_sections",
    "title": "26  Quarto Books",
    "section": "\n26.5 标题编号设置",
    "text": "26.5 标题编号设置\n\n---\nnumber-sections: true \nnumber-depth: 2 \n---\n\n\nnumber-sections：设置为true时会给各级标题编号。默认为false。\nnumber-depth：编号的最低标题层级。默认给所有级别的标题编号。\n{.unnumbered}：如果想要某一个标题不编号，则把这行命令粘贴到该标题后面。如”第三章{.unnumbered}“。\n{.unlisted}：将某个标题设置为不在目录中列出。如”第三章{.unlisted}“。如果想要某个标题既不编号也不在目录中列出就可以这样写：”标题{.unnumbered .unlisted}“。"
  },
  {
    "objectID": "quarto_foundation/github_pages.html#sec-Publish_html_files_to_github_pages",
    "href": "quarto_foundation/github_pages.html#sec-Publish_html_files_to_github_pages",
    "title": "27  发布到GitHub Pages",
    "section": "\n27.7 将本地静态HTML文件发布到GitHub Pages",
    "text": "27.7 将本地静态HTML文件发布到GitHub Pages\n首先，在项目根目录中创建一个名为.nojekyll的文件，该文件告诉GitHub Pages不要使用Jekyll（GitHub默认网页生成工具）对我们的文件进行额外处理。有两种方法可以做到这一点：\n\n\n在RStudio终端中运行下面的命令：\n\ntouch .nojekyll\n\n该命令运行后不会有任何提示，但是在项目的根目录中会创建一个名为.nojekyll的隐藏文件：\n\n\n在RStudio中依次点击File&gt;New File&gt;Text File，然后点击保存，文件名写成”.nojekyll”即可。\n\n\n\n然后在Git面板中选中所有的文件（Git面板中列出的都是监测到有变动的文件）。这一操作等价于在终端输入：git add .。之后点击”Commit”（等价：git commit -m \"my commit message\"）。\n\n这会打开commit说明窗口，填写右侧的commit说明后点击右下角的”Commit”就会上传所有的文件更改。\n\n上传完成后关闭窗口，这时Git面板中不会有任何文件，是因为我们已经提交了所有更改。最后点击”Push”，就会把所有文件上传到GitHub仓库（等价：git push）。\n\n完成上述操作后，我们打开浏览器进入GitHub项目主页，点击设置按钮。\n\n点击左侧导航栏的”Pages”选项，然后将GitHub Pages的创建来源选择为docs文件夹。\n\n一段时间的等待后，我们就会在这个页面的上方看到已经生成的GitHub Pages的链接。\n\n点击进去之后就可以看到我们的在线网页了。\n\n\n\n\n\n\n\nWarning\n\n\n\n不要更改docs文件夹内的任何内容。\n不要更改index.qmd文件的名称。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#number-sections标题编号设置",
    "href": "quarto_foundation/yaml_settings.html#number-sections标题编号设置",
    "title": "22  YAML设置",
    "section": "\n22.5 number-sections标题编号设置",
    "text": "22.5 number-sections标题编号设置\n和theme一样number-sections同样可以在YAML中直接定义，也可以在不同的format内定义。\n\nnumber-sections: true\nnumber-depth: 3\n\n\nnumber-sections：设置为true时会给各级标题编号。默认为false。\nnumber-depth：编号的最低标题层级。默认给所有级别的标题编号。\n{.unnumbered}：如果想要某一个标题不编号，则把这行命令粘贴到该标题后面。如”第三章{.unnumbered}“。\n{.unlisted}：将某个标题设置为不在目录中列出。如”第三章{.unlisted}“。如果想要某个标题既不编号也不在目录中列出就可以这样写：”标题{.unnumbered .unlisted}“。"
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-number_sections",
    "href": "quarto_foundation/yaml_settings.html#sec-number_sections",
    "title": "22  YAML设置",
    "section": "\n22.5 number-sections标题编号设置",
    "text": "22.5 number-sections标题编号设置\n和theme一样number-sections同样可以在YAML中直接定义，也可以在不同的format内定义。\n\nnumber-sections: true\nnumber-depth: 3\n\n\nnumber-sections：设置为true时会给各级标题编号。默认为false。\nnumber-depth：编号的最低标题层级。默认给所有级别的标题编号。\n{.unnumbered}：如果想要某一个标题不编号，则把这行命令粘贴到该标题后面。如”第三章{.unnumbered}“。\n{.unlisted}：将某个标题设置为不在目录中列出。如”第三章{.unlisted}“。如果想要某个标题既不编号也不在目录中列出就可以这样写：”标题{.unnumbered .unlisted}“。"
  }
]