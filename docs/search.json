[
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html",
    "href": "single_cell/seurat/seurat_tutorial.html",
    "title": "Seurat细胞分群官方教程",
    "section": "",
    "text": "原文：Seurat - Guided Clustering Tutorial\n原文发布日期：2023年10月31日",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#计算线粒体基因比例",
    "href": "single_cell/seurat/seurat_tutorial.html#计算线粒体基因比例",
    "title": "Seurat细胞分群官方教程",
    "section": "\n2.1 计算线粒体基因比例",
    "text": "2.1 计算线粒体基因比例\n通过PercentageFeatureSet()函数计算每个细胞中线粒体基因的比例，并将其返回到Seurat对象的meta.data中，形成一个新列”percent.mt”。\n\npbmc[[\"percent.mt\"]] &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\")\n# Show QC metrics for the first 5 cells\nhead(pbmc@meta.data, 5)\n\n                 orig.ident nCount_RNA nFeature_RNA percent.mt\nAAACATACAACCAC-1     pbmc3k       2419          779  3.0177759\nAAACATTGAGCTAC-1     pbmc3k       4903         1352  3.7935958\nAAACATTGATCAGC-1     pbmc3k       3147         1129  0.8897363\nAAACCGTGCTTCCG-1     pbmc3k       2639          960  1.7430845\nAAACCGTGTATGCG-1     pbmc3k        980          521  1.2244898",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#可视化质控指标",
    "href": "single_cell/seurat/seurat_tutorial.html#可视化质控指标",
    "title": "Seurat细胞分群官方教程",
    "section": "\n2.2 可视化质控指标",
    "text": "2.2 可视化质控指标\n通过VlnPlot函数绘制小提琴图展示每个细胞中UMI（nCount_RNA）、基因（percent.mt）和线粒体基因（percent.mt）的数量。\n\n# Visualize QC metrics as a violin plot\nVlnPlot(pbmc, \n        features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), \n        ncol = 3)\n\n\n\n\n\n\n\n通过FeatureScatter函数展示UMI和线粒体基因数量多关系、UMI和总基因数量多关系。\n\nplot1 &lt;- FeatureScatter(pbmc, \n                        feature1 = \"nCount_RNA\", \n                        feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(pbmc, \n                        feature1 = \"nCount_RNA\", \n                        feature2 = \"nFeature_RNA\")\nplot1 + plot2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#过滤细胞",
    "href": "single_cell/seurat/seurat_tutorial.html#过滤细胞",
    "title": "Seurat细胞分群官方教程",
    "section": "\n2.3 过滤细胞",
    "text": "2.3 过滤细胞\n在本案例中使用的质控标准：\n\nfilter cells that have unique feature counts over 2,500 or less than 200\nfilter cells that have &gt;5% mitochondrial counts\n\n\npbmc &lt;- subset(pbmc, \n               subset = nFeature_RNA &gt; 200 & nFeature_RNA &lt; 2500 & percent.mt &lt; 5)\npbmc\n\nAn object of class Seurat \n13714 features across 2638 samples within 1 assay \nActive assay: RNA (13714 features, 0 variable features)\n 1 layer present: counts",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#降维可视化",
    "href": "single_cell/seurat/seurat_tutorial.html#降维可视化",
    "title": "Seurat细胞分群官方教程",
    "section": "\n6.1 降维可视化",
    "text": "6.1 降维可视化\nSeurat provides several useful ways of visualizing both cells and features that define the PCA, including VizDimReduction(), DimPlot(), and DimHeatmap() .\n\nVizDimLoadings(pbmc, dims = 1:2, reduction = \"pca\")\n\n\n\n\n\n\n\n\nDimPlot(pbmc, reduction = \"pca\") + NoLegend()\n\n\n\n\n\n\n\nIn particular DimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores.\nSetting cells to a number, will plot the ‘extreme’ cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets.\n\nDimHeatmap(pbmc, dims = 1, cells = 1000, balanced = TRUE)\n\n\n\n\n\n\n\n通过dims参数指定一个范围内的主成分，可以用来决定在后续的分析中应该包括哪些主成分。\n\nDimHeatmap(pbmc, dims = 1:15, cells = 1000, balanced = TRUE)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#非线性降维可视化",
    "href": "single_cell/seurat/seurat_tutorial.html#非线性降维可视化",
    "title": "Seurat细胞分群官方教程",
    "section": "\n9.1 非线性降维可视化",
    "text": "9.1 非线性降维可视化\n\nDimPlot(pbmc, reduction = \"umap\")\n\n\n\n\n\n\n\nYou can save the object at this point so that it can easily be loaded back in without having to rerun the computationally intensive steps performed above, or easily shared with collaborators.\n\nsaveRDS(pbmc, file = \"output/seurat_official/pbmc_tutorial.rds\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#小提琴图",
    "href": "single_cell/seurat/seurat_tutorial.html#小提琴图",
    "title": "Seurat细胞分群官方教程",
    "section": "\n11.1 小提琴图：",
    "text": "11.1 小提琴图：\n\nVlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\"))\n\n\n\n\n\n\n\nYou can plot raw counts as well（layer = \"counts\"）：\n\nVlnPlot(pbmc, \n        features = c(\"NKG7\", \"PF4\"), \n        layer = \"counts\", # Layer to pull expression data from (e.g. \"counts\" or \"data\")\n        log = TRUE)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#umap图",
    "href": "single_cell/seurat/seurat_tutorial.html#umap图",
    "title": "Seurat细胞分群官方教程",
    "section": "\n11.2 UMAP图：",
    "text": "11.2 UMAP图：\n\nFeaturePlot(pbmc,\n            features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\",\n                         \"PPBP\", \"CD8A\"))",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_tutorial.html#热图",
    "href": "single_cell/seurat/seurat_tutorial.html#热图",
    "title": "Seurat细胞分群官方教程",
    "section": "\n11.3 热图：",
    "text": "11.3 热图：\nDoHeatmap() generates an expression heatmap for given cells and features. In this case, we are plotting the top 20 markers (or all markers if less than 20) for each cluster.\n\npbmc.markers %&gt;%\n  group_by(cluster) %&gt;%\n  filter(avg_log2FC &gt; 1) %&gt;%\n  slice_head(n = 10) %&gt;% # 选取开头的10行\n  ungroup() -&gt; top10\nDoHeatmap(pbmc, features = top10$gene) + NoLegend()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat细胞分群官方教程"
    ]
  },
  {
    "objectID": "single_cell/seurat/mapping_and_annotating_query_datasets.html",
    "href": "single_cell/seurat/mapping_and_annotating_query_datasets.html",
    "title": "基于参考集的细胞注释",
    "section": "",
    "text": "原文：Mapping and annotating query datasets\n原文发布日期：2023年10月31日\nIn this vignette, we first build an integrated reference and then demonstrate how to leverage this reference to annotate new query datasets. Generating an integrated reference follows the same workflow described in more detail in the integration introduction. Once generated, this reference can be used to analyze additional query datasets through tasks like cell type label transfer and projecting query cells onto reference UMAPs. Notably, this does not require correction of the underlying raw query data and can therefore be an efficient strategy if a high quality reference is available.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于参考集的细胞注释"
    ]
  },
  {
    "objectID": "single_cell/seurat/mapping_and_annotating_query_datasets.html#数据读取",
    "href": "single_cell/seurat/mapping_and_annotating_query_datasets.html#数据读取",
    "title": "基于参考集的细胞注释",
    "section": "\n1.1 数据读取",
    "text": "1.1 数据读取\n\n\n\n\n\n\n在线读取（可能需要全局代理）\n\n\n\n\n\n\n```{r}\n#| eval: false\nlibrary(SeuratData)\nInstallData(\"panc8\")\nlibrary(Seurat)\npanc8 &lt;- LoadData(\"panc8\")\n```\n\n\n\n\n从本地下载好的数据读取：\n\npanc8 &lt;- readRDS(\"data/seurat_official/panc8.rds\")\npanc8\n\nAn object of class Seurat \n34363 features across 14890 samples within 1 assay \nActive assay: RNA (34363 features, 0 variable features)\n 2 layers present: counts, data\n\ncolnames(panc8)[1:5]\n\n[1] \"D101_5\"  \"D101_7\"  \"D101_10\" \"D101_13\" \"D101_14\"\n\nrownames(panc8)[1:5]\n\n[1] \"A1BG-AS1\" \"A1BG\"     \"A1CF\"     \"A2M-AS1\"  \"A2ML1\"   \n\nhead(panc8@meta.data, 5)\n\n        orig.ident nCount_RNA nFeature_RNA   tech replicate assigned_cluster\nD101_5        D101   4615.810         1986 celseq    celseq             &lt;NA&gt;\nD101_7        D101  29001.563         4209 celseq    celseq             &lt;NA&gt;\nD101_10       D101   6707.857         2408 celseq    celseq             &lt;NA&gt;\nD101_13       D101   8797.224         2964 celseq    celseq             &lt;NA&gt;\nD101_14       D101   5032.558         2264 celseq    celseq             &lt;NA&gt;\n        celltype dataset\nD101_5     gamma  celseq\nD101_7    acinar  celseq\nD101_10    alpha  celseq\nD101_13    delta  celseq\nD101_14     beta  celseq\n\ntable(panc8$tech)\n\n\n    celseq    celseq2 fluidigmc1     indrop  smartseq2 \n      1004       2285        638       8569       2394 \n\n\n可以看到，该数据包含了5种单细胞转录组测序技术获得的单细胞数据。\nAs a demonstration, we will use a subset of technologies to construct a reference. We will then map the remaining datasets onto this reference. we will use data from 2 technologies (celseq2和smartseq2) for the reference。\n\nlibrary(Seurat)\npancreas.ref &lt;- subset(panc8, tech %in% c(\"celseq2\", \"smartseq2\"))\n# 按照不同的测序技术将表达矩阵分为不同的layer\npancreas.ref[[\"RNA\"]] &lt;- split(pancreas.ref[[\"RNA\"]], \n                               f = pancreas.ref$tech)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于参考集的细胞注释"
    ]
  },
  {
    "objectID": "single_cell/seurat/mapping_and_annotating_query_datasets.html#数据预处理",
    "href": "single_cell/seurat/mapping_and_annotating_query_datasets.html#数据预处理",
    "title": "基于参考集的细胞注释",
    "section": "\n1.2 数据预处理",
    "text": "1.2 数据预处理\n标准化、找高变基因、归一化、降维、聚类、可视化：\n\npancreas.ref &lt;- NormalizeData(pancreas.ref)\npancreas.ref &lt;- FindVariableFeatures(pancreas.ref)\npancreas.ref &lt;- ScaleData(pancreas.ref)\npancreas.ref &lt;- RunPCA(pancreas.ref)\npancreas.ref &lt;- FindNeighbors(pancreas.ref, dims = 1:30)\npancreas.ref &lt;- FindClusters(pancreas.ref)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 4679\nNumber of edges: 174953\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9180\nNumber of communities: 19\nElapsed time: 0 seconds\n\npancreas.ref &lt;- RunUMAP(pancreas.ref, dims = 1:30)\nDimPlot(pancreas.ref, group.by = c(\"celltytpe\", \"tech\"))\n\n\n\n\n\n\n\n\nDimPlot(pancreas.ref, split.by = \"tech\")\n\n\n\n\n\n\n\n可以看到，不同的测序技术间的细胞类型差异较大。因此需要对数据进行整合，方法同此前的章节一致。\n\npancreas.ref &lt;- IntegrateLayers(object = pancreas.ref, \n                                method = CCAIntegration, \n                                orig.reduction = \"pca\",\n                                new.reduction = \"integrated.cca\", \n                                verbose = FALSE)\n# 重新聚类\npancreas.ref &lt;- FindNeighbors(pancreas.ref, \n                              reduction = \"integrated.cca\",#更改降维来源为\"integrated.cca\"\n                              dims = 1:30)\npancreas.ref &lt;- FindClusters(pancreas.ref)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 4679\nNumber of edges: 190152\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8680\nNumber of communities: 15\nElapsed time: 0 seconds\n\n# 重新降维\npancreas.ref &lt;- RunUMAP(pancreas.ref, \n                        reduction = \"integrated.cca\", #更改降维来源为\"integrated.cca\"\n                        dims = 1:30)\nDimPlot(pancreas.ref, group.by = c(\"tech\", \"celltype\"))\n\n\n\n\n\n\nDimPlot(pancreas.ref, split.by = \"tech\")\n\n\n\n\n\n\n\n可以看到，和此前相比，整合后不再有不同测序技术间细胞类型的差异。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于参考集的细胞注释"
    ]
  },
  {
    "objectID": "single_cell/seurat/mapping_and_annotating_query_datasets.html#umap映射",
    "href": "single_cell/seurat/mapping_and_annotating_query_datasets.html#umap映射",
    "title": "基于参考集的细胞注释",
    "section": "\n2.1 UMAP映射",
    "text": "2.1 UMAP映射\nWe also enable projection of a query onto the reference UMAP structure. This can be achieved by computing the reference UMAP model and then calling MapQuery() instead of TransferData().\n\npancreas.ref &lt;- RunUMAP(pancreas.ref, \n                        dims = 1:30, \n                        reduction = \"integrated.cca\", \n                        return.model = TRUE)\npancreas.query &lt;- MapQuery(anchorset = pancreas.anchors, \n                           query = pancreas.query, \n                           reference = pancreas.ref, \n                           refdata = list(celltype = \"celltype\"), #需要transfer的参考数据集的列\n                           reference.reduction = \"pca\", \n                           reduction.model = \"umap\")\n\n可以看到现在的查询数据集pancreas.query中有了降维信息（reduction）。这些信息实际上是映射的参考数据集pancreas.ref的降维信息：\n\n\n\n\n\n\n\nWhat is MapQuery doing?\n\n\n\n\n\nMapQuery()打包了三个函数的功能: TransferData(), IntegrateEmbeddings(), and ProjectUMAP(). TransferData() is used to transfer cell type labels and impute the ADT values; IntegrateEmbeddings() is used to integrate reference with query by correcting the query’s projected low-dimensional embeddings; and finally ProjectUMAP() is used to project the query data onto the UMAP structure of the reference. 所以，运行MapQuery()的效果和运行下面的脚本一样:\n\npancreas.query &lt;- TransferData(anchorset = pancreas.anchors, \n                               reference = pancreas.ref, \n                               query = pancreas.query,\n                               refdata = list(celltype = \"celltype\"))\npancreas.query &lt;- IntegrateEmbeddings(anchorset = pancreas.anchors, \n                                      reference = pancreas.ref, \n                                      query = pancreas.query,\n                                      new.reduction.name = \"ref.pca\")\npancreas.query &lt;- ProjectUMAP(query = pancreas.query, \n                              query.reduction = \"ref.pca\", \n                              reference = pancreas.ref,\n                              reference.reduction = \"pca\", \n                              reduction.model = \"umap\")\n\n\n\n\nWe can now visualize the query cells alongside our reference.\nlibrary(ggplot2)\nDimPlot(pancreas.ref, \n        reduction = \"umap\", \n        group.by = \"celltype\", \n        label = TRUE, \n        label.size = 6,\n        repel = TRUE) + \n  NoLegend() + \n  ggtitle(\"Reference annotations\")\nDimPlot(pancreas.query, \n        reduction = \"ref.umap\", \n        group.by = \"predicted.celltype\", \n        label = TRUE,\n        label.size = 6, \n        repel = TRUE) + \n  NoLegend() + \n  ggtitle(\"Query transferred labels\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n本篇主要介绍了基于单细胞转录组测序（scRNA-seq）数据的参考数据集的制作和映射。Seurat现在还提供了一种’bridge integration’的方法，可以将其他单细胞组学数据（如scATAC-seq、scDNAme、CyTOF）映射到scRNA-seq参考数据集上。详见：Dictionary Learning for cross-modality integration。\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.3            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.2.0      ggridges_0.5.5        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.5           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] ggbeeswarm_0.7.2       purrr_1.0.2            xfun_0.41             \n [25] jsonlite_1.8.8         goftest_1.2-3          later_1.3.2           \n [28] spatstat.utils_3.0-4   irlba_2.3.5.1          parallel_4.3.2        \n [31] cluster_2.1.6          R6_2.5.1               ica_1.0-3             \n [34] stringi_1.8.3          RColorBrewer_1.1-3     spatstat.data_3.0-4   \n [37] reticulate_1.34.0      parallelly_1.36.0      lmtest_0.9-40         \n [40] scattermore_1.2        Rcpp_1.0.12            knitr_1.45            \n [43] tensor_1.5             future.apply_1.11.1    zoo_1.8-12            \n [46] sctransform_0.4.1      httpuv_1.6.13          Matrix_1.6-5          \n [49] splines_4.3.2          igraph_1.6.0           tidyselect_1.2.0      \n [52] abind_1.4-5            rstudioapi_0.15.0      yaml_2.3.8            \n [55] spatstat.random_3.2-2  codetools_0.2-19       miniUI_0.1.1.1        \n [58] spatstat.explore_3.2-5 listenv_0.9.0          lattice_0.22-5        \n [61] tibble_3.2.1           plyr_1.8.9             withr_3.0.0           \n [64] shiny_1.8.0            ROCR_1.0-11            ggrastr_1.0.2         \n [67] evaluate_0.23          Rtsne_0.17             future_1.33.1         \n [70] fastDummies_1.7.3      survival_3.5-7         polyclip_1.10-6       \n [73] fitdistrplus_1.1-11    pillar_1.9.0           KernSmooth_2.23-22    \n [76] plotly_4.10.4          generics_0.1.3         RcppHNSW_0.5.0        \n [79] munsell_0.5.0          scales_1.3.0           globals_0.16.2        \n [82] xtable_1.8-4           glue_1.7.0             lazyeval_0.2.2        \n [85] tools_4.3.2            data.table_1.14.10     RSpectra_0.16-1       \n [88] RANN_2.6.1             leiden_0.4.3.1         dotCall64_1.1-1       \n [91] cowplot_1.1.2          grid_4.3.2             tidyr_1.3.0           \n [94] colorspace_2.1-0       nlme_3.1-164           patchwork_1.2.0       \n [97] beeswarm_0.4.0         vipor_0.4.7            cli_3.6.2             \n[100] spatstat.sparse_3.0-3  spam_2.10-0            fansi_1.0.6           \n[103] viridisLite_0.4.2      dplyr_1.1.4            uwot_0.1.16           \n[106] gtable_0.3.4           digest_0.6.34          progressr_0.14.0      \n[109] ggrepel_0.9.5          farver_2.1.1           htmlwidgets_1.6.4     \n[112] htmltools_0.5.7        lifecycle_1.0.4        httr_1.4.7            \n[115] mime_0.12              MASS_7.3-60.0.1",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于参考集的细胞注释"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html",
    "href": "single_cell/seurat/cell_cycle_regression.html",
    "title": "消除细胞周期的影响",
    "section": "",
    "text": "原文：Cell-Cycle Scoring and Regression\n原文发布日期：2023年10月31日\nWe demonstrate how to mitigate the effects of cell cycle heterogeneity in scRNA-seq data by calculating cell cycle phase scores based on canonical markers, and regressing these out of the data during pre-processing. We demonstrate this on a dataset of murine hematopoietic progenitors (Nestorowa et al. 2016).You can download the files needed to run this vignette here.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#创建seurat对象",
    "href": "single_cell/seurat/cell_cycle_regression.html#创建seurat对象",
    "title": "消除细胞周期的影响",
    "section": "\n1.1 创建Seurat对象",
    "text": "1.1 创建Seurat对象\n\n# Read in the expression matrix \nexp.mat &lt;- read.table(file = \"data/seurat_official/cell_cycle_vignette_files/nestorawa_forcellcycle_expressionMatrix.txt\",\n                      header = TRUE, \n                      as.is = TRUE, #保留字符型变量\n                      row.names = 1)\n# Create our Seurat object and complete the initalization steps\nlibrary(Seurat)\nmarrow &lt;- CreateSeuratObject(counts = Matrix::Matrix(as.matrix(exp.mat), \n                                                     sparse = T))\nmarrow\n\nAn object of class Seurat \n24193 features across 774 samples within 1 assay \nActive assay: RNA (24193 features, 0 variable features)\n 1 layer present: counts\n\nhead(marrow@meta.data, 5)\n\n         orig.ident nCount_RNA nFeature_RNA\nProg_013       Prog    2563089        10211\nProg_019       Prog    3030620         9991\nProg_031       Prog    1293487        10192\nProg_037       Prog    1357987         9599\nProg_008       Prog    4079891        10540\n\nmarrow &lt;- NormalizeData(marrow)\nmarrow &lt;- FindVariableFeatures(marrow, selection.method = \"vst\")\nmarrow &lt;- ScaleData(marrow, features = rownames(marrow))",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#获取细胞周期marker基因列表",
    "href": "single_cell/seurat/cell_cycle_regression.html#获取细胞周期marker基因列表",
    "title": "消除细胞周期的影响",
    "section": "\n1.2 获取细胞周期marker基因列表",
    "text": "1.2 获取细胞周期marker基因列表\nA list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat. We can segregate this list into markers of G2/M phase and markers of S phase\n\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#降维",
    "href": "single_cell/seurat/cell_cycle_regression.html#降维",
    "title": "消除细胞周期的影响",
    "section": "\n1.3 降维",
    "text": "1.3 降维\nIf we run a PCA on our object, using the variable genes we found in FindVariableFeatures() above, we see that while most of the variance can be explained by lineage, PC8 and PC10 are split on cell-cycle genes including TOP2A and MKI67. We will attempt to regress this signal from the data, so that cell-cycle heterogeneity does not contribute to PCA or downstream analysis.\n\nmarrow &lt;- RunPCA(marrow, \n                 features = VariableFeatures(marrow), \n                 ndims.print = 6:10, \n                 nfeatures.print = 10)\nDimHeatmap(marrow, dims = c(8, 10))",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#sec-Calculating_cell_cycle_scores",
    "href": "single_cell/seurat/cell_cycle_regression.html#sec-Calculating_cell_cycle_scores",
    "title": "消除细胞周期的影响",
    "section": "\n2.1 计算细胞周期评分",
    "text": "2.1 计算细胞周期评分\nFirst, we assign each cell a score, based on its expression of G2/M and S phase markers. These marker sets should be anticorrelated in their expression levels, and cells expressing neither are likely not cycling and in G1 phase.\n\n\n\n\n\n\n细胞周期\n\n\n\n\n\n细胞周期（cell cycle），是指能持续分裂的真核细胞从一次有丝分裂结束后，再到下一次分裂结束的循环过程（准确来说只要有DNA复制，不管是不是有丝分裂它都有细胞周期。生殖细胞无细胞周期。)。\n细胞周期的划分\n总的看来，细胞周期通常可划分为分裂间期（I期）和分裂期（M期），分裂间期是物质准备和积累阶段，分裂期则是细胞增殖的实施过程。整个周期表示为 I期→M期。\n其中分裂间期（I期）又常常可以划分为DNA合成前期（G1），DNA合成期（S）和DNA合成后期（G2）。在此期间的任务主要是完成染色质中的DNA复制和相关蛋白质的合成。将I期细分之后，整个细胞周期可以表示为：G1期→S期→G2期→M期。\n细胞进入G1期可能出现三种情况，其中暂不继续增殖，如骨髓干细胞和处于不利状态下的癌细胞，但在某些刺激下，这些细胞又可以继续生长分裂，因此有人把这种非增殖状态的G1期细胞称为G0期细胞。以区别处于增殖状态的G1期细胞。 而分裂期通常分作分裂前期(Prophase)、前中期(Prometaphase)、中期(Metaphase)、后期(Anaphase)和末期(Telophase)5个阶段，在此期间进行细胞物质的平均分配并形成两个新的细胞。\n\n\n\nG0: Quiescence or resting phase. The cell is not actively dividing, which is common for cells that are fully differentiated. Some types of cells enter G0 for long periods of time (many neuronal cells), while other cell types never enter G0 by continuously dividing (epithelial cells).\n\nG1: Gap 1 phase represents the beginning of interphase. During G1 there is growth of the non-chromosomal components of the cells. From this phase, the cell may enter G0 or S phase.\n\nS: Synthesis phase for the replication of the chromosomes (also part of interphase).\n\nG2: Gap 2 phase represents the end of interphase, prior to entering the mitotic phase. During this phase th cell grows in preparation for mitosis and the spindle forms.\n\nM: M phase is the nuclear division of the cell (consisting of prophase, metaphase, anaphase and telophase).\n\n\n\n\n\n\n\n\n\n状态\n阶段\n缩写\n描述\n\n\n\n休息\nG0期\nG0\n细胞离开周期并停止分裂的阶段。\n\n\n间期\nG1期\nG1\nG1检查点控制机制确保一切准备好进行DNA合成。\n\n\n合成\nS\nS\nDNA复制发生在这个阶段。\n\n\nG2期\nG2\n\nG2\n在DNA合成和有丝分裂之间的差距期间，细胞将继续增长。 G2检查点控制机制确保一切准备好进入M（有丝分裂）阶段并分裂。\n\n\n细胞分裂\n有丝分裂\nM\n细胞生长停止，细胞能量集中在有序地分裂成两个子细胞。有丝分裂中期的检查点（Metaphase Checkpoint）确保细胞可以完成细胞分裂。\n\n\n\n\n\n\nWe assign scores in the CellCycleScoring() function, which stores S and G2/M scores in object meta data, along with the predicted classification of each cell in either G2M, S or G1 phase. CellCycleScoring() can also set the identity of the Seurat object to the cell-cycle phase by passing set.ident = TRUE (the original identities are stored as old.ident). Please note that Seurat does not use the discrete classifications (G2M/G1/S) in downstream cell cycle regression. Instead, it uses the quantitative scores for G2M and S phase. However, we provide our predicted classifications in case they are of interest.\nWe score single cells based on the scoring strategy described in (Tirosh et al. 2016). See ?AddModuleScore() in Seurat for more information, this function can be used to calculate supervised module scores for any gene list.\n\nmarrow &lt;- CellCycleScoring(marrow, \n                           s.features = s.genes, \n                           g2m.features = g2m.genes, \n                           set.ident = TRUE)\ntable(Idents(marrow))\n\n\n G1 G2M   S \n287 168 319 \n\n# view cell cycle scores and phase assignments\nhead(marrow@meta.data)\n\n         orig.ident nCount_RNA nFeature_RNA     S.Score  G2M.Score Phase\nProg_013       Prog    2563089        10211 -0.14248691 -0.4680395    G1\nProg_019       Prog    3030620         9991 -0.16915786  0.5851766   G2M\nProg_031       Prog    1293487        10192 -0.34627038 -0.3971879    G1\nProg_037       Prog    1357987         9599 -0.44270212  0.6820229   G2M\nProg_008       Prog    4079891        10540  0.55854051  0.1284359     S\nProg_014       Prog    2569783        10788  0.07116218  0.3166073   G2M\n         old.ident\nProg_013      Prog\nProg_019      Prog\nProg_031      Prog\nProg_037      Prog\nProg_008      Prog\nProg_014      Prog",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#可视化细胞周期的影响",
    "href": "single_cell/seurat/cell_cycle_regression.html#可视化细胞周期的影响",
    "title": "消除细胞周期的影响",
    "section": "\n2.2 可视化细胞周期的影响",
    "text": "2.2 可视化细胞周期的影响\n可视化细胞周期marker的表达分布：\n\nRidgePlot(marrow, \n          features = c(\"PCNA\", \"TOP2A\", \"MCM6\", \"MKI67\"), \n          ncol = 2)\n\n\n\n\n\n\n\n以细胞周期marker为计算依据运行PCA：\n\nmarrow &lt;- RunPCA(marrow, features = c(s.genes, g2m.genes))\nDimPlot(marrow)\n\n\n\n\n\n\n\n\nThe PCA running on cell cycle genes reveals, unsurprisingly, that cells separate entirely by phase.\n\n这个PCA图也可以用ggplot2的语法进一步修改：\n\nlibrary(ggplot2)\nDimPlot(marrow) + \n  theme(axis.title = element_text(size = 18), \n        legend.text = element_text(size = 18)) +\n  guides(colour = guide_legend(override.aes = list(size = 10)))",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/cell_cycle_regression.html#sec-regress-out",
    "href": "single_cell/seurat/cell_cycle_regression.html#sec-regress-out",
    "title": "消除细胞周期的影响",
    "section": "\n2.3 回归（regress out）细胞周期评分",
    "text": "2.3 回归（regress out）细胞周期评分\nWe now attempt to subtract (‘regress out’) this source of heterogeneity from the data. For users of Seurat v1.4, this was implemented in RegressOut. However, as the results of this procedure are stored in the scaled data slot (therefore overwriting the output of ScaleData()), we now merge this functionality into the ScaleData() function itself.\nFor each gene, Seurat models the relationship between gene expression and the S and G2M cell cycle scores. The scaled residuals of this model represent a ‘corrected’ expression matrix, that can be used downstream for dimensional reduction.\n\nmarrow &lt;- ScaleData(marrow, \n                    vars.to.regress = c(\"S.Score\", \"G2M.Score\"), \n                    features = rownames(marrow))\n\nNow, a PCA on the variable genes no longer returns components associated with cell cycle:\n\nmarrow &lt;- RunPCA(marrow, \n                 features = VariableFeatures(marrow), \n                 nfeatures.print = 10)\n\nWhen running a PCA on only cell cycle genes, cells no longer separate by cell-cycle phase:\n\nmarrow &lt;- RunPCA(marrow, \n                 features = c(s.genes, g2m.genes))\nDimPlot(marrow)\n\n\n\n\n\n\n\nAs the best cell cycle markers are extremely well conserved across tissues and species, we have found this procedure to work robustly and reliably on diverse datasets.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "消除细胞周期的影响"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_intro.html",
    "href": "single_cell/seurat/seurat_intro.html",
    "title": "Seurat v5官方文档",
    "section": "",
    "text": "本节学习Seurat官网提供的几个vignettes。\n\n\n\nChanges in Seurat v5\nWe are excited to release Seurat v5 on CRAN, where it is now the default version for new installs. Seurat v5 is designed to be backwards compatible with Seurat v4 so existing code will continue to run, but we have made some changes to the software that will affect user results. We note that users who aim to reproduce their previous workflows in Seurat v4 can still install this version using the instructions on our install page.\nIn particular, we have made changes to:\n\nSeurat Object and Assay class:\nSeurat v5 now includes support for additional assay and data types, including on-disk matrices. To facilitate this, we have introduced an updated Seurat v5 assay. Briefly, Seurat v5 assays store data in layers (previously referred to as ‘slots’).\nFor example, these layers can store: raw counts (layer='counts'), normalized data (layer='data'), or z-scored/variance-stabilized data (layer='scale.data').\nData can be accessed using the $ accessor (i.e. obj[[\"RNA\"]]$counts), or the `LayerData function (i.e. LayerData(obj, assay=\"RNA\", layer='counts').\nWe’ve designed these updates to minimize changes for users. Existing Seurat functions and workflows from v4 continue to work in v5. For example, the command GetAssayData(obj, assay=\"RNA\", slot='counts'), will run successfully in both Seurat v4 and Seurat v5.\nIntegration workflow:\nSeurat v5 introduces a streamlined integration (见Seurat v5单细胞数据整合分析) and data transfer (见基于参考集的细胞注释) workflows that performs integration in low-dimensional space, and improves speed and memory efficiency. The results of integration are not identical between the two workflows, but users can still run the v4 integration workflow in Seurat v5 if they wish.\nIn previous versions of Seurat, the integration workflow required a list of multiple Seurat objects as input. In Seurat v5, all the data can be kept as a single object, but prior to integration, users can simply split the layers. See 本章节 for more information.\nDifferential expression:\nSeurat v5 now uses the presto package (from the Korunsky and Raychaudhari labs), when available, to perform differential expression analysis. Using presto can dramatically speed up DE testing, and we encourage users to install it.\nIn addition, in Seurat v5 we implement a pseudocount (when calculating log-FC) at the group level instead of the cell level. As a result, users will observe higher logFC estimates in v5 - but should note that these estimates may be more unstable - particularly for genes that are very lowly expressed in one of the two groups（寻找不同样本类型间同一细胞类型内的差异基因）. We gratefully acknowledge feedback from the McCarthy and Pachter labs on this topic.\nSCTransform v2:\nIn (Choudhary and Satija 2022), we implement an updated version 2 of sctransform. This is now the default version when running SCTransform in Seurat v5 (见基于SCTransform的单细胞数据标准化). Users who wish to run the previous workflow can set the vst.flavor = \"v1\" argument in the SCTransform function.\nPseudobulk analysis:\nOnce a single-cell dataset has been analyzed to annotate cell subpopulations, pseudobulk analyses (i.e. aggregating together cells within a given subpopulation and sample) can reduce noise, improve quantification of lowly expressed genes, and reduce the size of the data matrix. In Seurat v5, we encourage the use of the AggregateExpression function to perform pseudobulk analysis.\nCheck out 寻找不同样本类型间同一细胞类型内的差异基因 as well as pancreatic/healthy PBMC comparison, for examples of how to use AggregateExpression to perform robust differential expression of scRNA-seq data from multiple different conditions.\n\n\n\n\nReferences\n\n\nChoudhary, Saket, and Rahul Satija. 2022. “Comparison and Evaluation of Statistical Error Models for scRNA-Seq.” Genome Biology 23 (1). https://doi.org/10.1186/s13059-021-02584-9.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档"
    ]
  },
  {
    "objectID": "single_cell/seurat/marker_gene_identification.html",
    "href": "single_cell/seurat/marker_gene_identification.html",
    "title": "寻找marker gene",
    "section": "",
    "text": "参考原文：Introduction to scRNA-seq integration\n原文发布日期：2023年10月31日\n\n\n1 数据导入\n这里我们导入整合（integration）中完成SCTransform和整合的单细胞数据。这里的meta.data已经提前注释好了细胞类型（储存在”seurat_annotations”列中）。\n\nlibrary(Seurat)\nifnb &lt;- readRDS(\"output/seurat_official/ifnb_integrated.rds\")\nifnb\n\nAn object of class Seurat \n27359 features across 13999 samples within 2 assays \nActive assay: SCT (13306 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n 3 dimensional reductions calculated: pca, umap, integrated.dr\n\nhead(ifnb, 3)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\n                 nCount_SCT nFeature_SCT SCT_snn_res.0.6 seurat_clusters\nAAACATACATTTCC.1       1944          852               1               1\nAAACATACCAGAAA.1       1888          699               9               9\nAAACATACCTCGCT.1       1951          804               1               1\n\ntable(ifnb$seurat_annotations)\n\n\n   CD14 Mono  CD4 Naive T CD4 Memory T    CD16 Mono            B        CD8 T \n        4362         2504         1762         1044          978          814 \n T activated           NK           DC  B Activated           Mk          pDC \n         633          619          472          388          236          132 \n       Eryth \n          55 \n\nDimPlot(ifnb, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\n\n\n\n\n\n2 FindMarkers-在特定cluster之间寻找marker基因\n\n\n\n\n\n\nCaution\n\n\n\nFor a much faster implementation of the Wilcoxon Rank Sum Test,(default method for FindMarkers) please install the presto package:\n\ndevtools::install_github('immunogenomics/presto')\n\n\n\n作为演示，下面我们通过FindMarkers寻找CD16 Mono和CD14 Mono之间的差异基因（marker gene）。\n\n\n\n\n\n\nImportant\n\n\n\n对于经过SCTransform归一化处理后的单细胞数据，在进行差异分析之前，需要先运行PrepSCTFindMarkers()，来预处理SCT assay。详细解释见此链接。\n如果是基于NormalizeData标准化的单细胞数据，需要使用”RNA” assay进行差异分析，如果不是，需要通过DefaultAssay(ifnb) &lt;- \"RNA\"进行设定。\n\n\n\n# 预处理SCT assay\nifnb &lt;- PrepSCTFindMarkers(ifnb)\n# 指定细胞idents为注释信息\nIdents(ifnb) &lt;- \"seurat_annotations\"\n# 执行FindMarkers\nmonocyte.de.markers &lt;- FindMarkers(ifnb, \n                                   ident.1 = \"CD16 Mono\", \n                                   ident.2 = \"CD14 Mono\")\n# view results\nnrow(monocyte.de.markers)\n\n[1] 6869\n\nhead(monocyte.de.markers)\n\n       p_val avg_log2FC pct.1 pct.2 p_val_adj\nVMO1       0   5.641894 0.767 0.078         0\nMS4A4A     0   3.238324 0.739 0.134         0\nFCGR3A     0   3.305623 0.976 0.382         0\nPLAC8      0   3.311271 0.620 0.107         0\nCXCL16     0   2.030972 0.918 0.439         0\nMS4A7      0   2.435979 0.973 0.519         0\n\n\nThe results data frame has the following columns :\n\np_val : p-value (unadjusted)\navg_log2FC : log fold-change of the average expression between the two groups. Positive values indicate that the feature is more highly expressed in the first group.\npct.1 : The percentage of cells where the feature is detected in the first group\npct.2 : The percentage of cells where the feature is detected in the second group\np_val_adj : Adjusted p-value, based on Bonferroni correction using all features in the dataset.\n\nIf the ident.2 parameter is omitted or set to NULL, FindMarkers() will test for differentially expressed features between the group specified by ident.1 and all other cells. Additionally, the parameter only.pos can be set to TRUE to only search for positive markers, i.e. features that are more highly expressed in the ident.1 group.\n\nmonocyte.de.markers &lt;- FindMarkers(ifnb, \n                                   ident.1 = \"CD16 Mono\", \n                                   ident.2 = NULL, \n                                   only.pos = TRUE)\nnrow(monocyte.de.markers)\n\n[1] 4259\n\nhead(monocyte.de.markers)\n\n       p_val avg_log2FC pct.1 pct.2 p_val_adj\nFCGR3A     0   4.616088 0.976 0.152         0\nMS4A7      0   3.867491 0.973 0.196         0\nCXCL16     0   3.309239 0.918 0.178         0\nVMO1       0   6.207904 0.767 0.040         0\nMS4A4A     0   4.661394 0.739 0.051         0\nLST1       0   2.988332 0.887 0.205         0\n\n\n\n3 FindConservedMarkers-鉴定在所有conditions下保守的cell marker\nTo identify canonical cell type marker genes that are conserved across conditions, we provide the FindConservedMarkers() function. This function performs differential gene expression testing for each dataset/group and combines the p-values using meta-analysis methods from the MetaDE R package.\n在实际分析中，鉴定这些保守的cell marker主要用来辅助对cluster的注释：you can perform these same analysis on the unsupervised clustering results (stored in seurat_clusters), and use these conserved markers to annotate cell types in your dataset.\nWe can calculated the genes that are conserved markers irrespective of stimulation condition in cluster 6 (NK cells).\n\n\n\n\n\n\nTip\n\n\n\nFindConservedMarkers函数会调用metap包，metap包需要multtest包，所以需要先安装这两个依赖包：\n\nBiocManager::install('multtest')\ninstall.packages('metap')\n\n\n\nFindConservedMarkers中的grouping.var参数用来指定meta.data中表示样本类型或者condition的列名，其他参数及其含义基本和FindMarkers一致。\n\nnk.markers &lt;- FindConservedMarkers(ifnb, \n                                   ident.1 = \"NK\", \n                                   grouping.var = \"stim\", \n                                   only.pos = TRUE)\nhead(nk.markers)\n\n          CTRL_p_val CTRL_avg_log2FC CTRL_pct.1 CTRL_pct.2 CTRL_p_val_adj\nGNLY    0.000000e+00       85.120959      0.943      0.046   0.000000e+00\nNKG7    0.000000e+00       14.508633      0.953      0.085   0.000000e+00\nCTSW    0.000000e+00        7.597542      0.537      0.030   0.000000e+00\nFGFBP2  0.000000e+00        2.972433      0.500      0.021   0.000000e+00\nKLRC1   0.000000e+00        8.995502      0.379      0.004   0.000000e+00\nPRF1   3.646682e-300       11.866746      0.423      0.017  5.124682e-296\n          STIM_p_val STIM_avg_log2FC STIM_pct.1 STIM_pct.2 STIM_p_val_adj\nGNLY    0.000000e+00      20.3429036      0.956      0.059   0.000000e+00\nNKG7    0.000000e+00       6.0306403      0.950      0.081   0.000000e+00\nCTSW    0.000000e+00       8.2243914      0.592      0.035   0.000000e+00\nFGFBP2 4.578442e-158       0.8925926      0.259      0.016  6.434085e-154\nKLRC1   0.000000e+00       7.0700921      0.374      0.006   0.000000e+00\nPRF1    0.000000e+00       8.0777458      0.863      0.057   0.000000e+00\n            max_pval minimump_p_val\nGNLY    0.000000e+00              0\nNKG7    0.000000e+00              0\nCTSW    0.000000e+00              0\nFGFBP2 4.578442e-158              0\nKLRC1   0.000000e+00              0\nPRF1   3.646682e-300              0\n\n\n\n4 可视化cell markers的表达\nThe DotPlot() function with the split.by parameter can be useful for viewing conserved cell type markers across conditions, showing both the expression level and the percentage of cells in a cluster expressing any given gene. Here we plot 2-3 strong marker genes for each of our 14 clusters.\n\nmarkers.to.plot &lt;- c(\"CD3D\", \"CREM\", \"HSPH1\", \"SELL\", \"GIMAP5\", \"CACYBP\", \"GNLY\", \"NKG7\",\n                     \"CCL5\", \"CD8A\", \"MS4A1\", \"CD79A\", \"MIR155HG\", \"NME1\", \"FCGR3A\", \n                     \"VMO1\", \"CCL2\", \"S100A9\", \"HLA-DQA1\", \"GPR183\", \"PPBP\", \"GNG11\",\n                     \"HBA2\", \"HBB\", \"TSPAN13\", \"IL3RA\", \"IGJ\", \"PRSS57\")\nDotPlot(ifnb, \n        features = markers.to.plot, \n        cols = c(\"blue\", \"red\"), \n        dot.scale = 8, \n        split.by = \"stim\") +\n  RotatedAxis()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] mathjaxr_1.6-0         RColorBrewer_1.1-3     rstudioapi_0.15.0     \n  [4] jsonlite_1.8.8         magrittr_2.0.3         TH.data_1.1-2         \n  [7] spatstat.utils_3.0-4   farver_2.1.1           rmarkdown_2.25        \n [10] vctrs_0.6.5            multtest_2.58.0        ROCR_1.0-11           \n [13] spatstat.explore_3.2-5 htmltools_0.5.7        plotrix_3.8-4         \n [16] sctransform_0.4.1      parallelly_1.36.0      KernSmooth_2.23-22    \n [19] htmlwidgets_1.6.4      ica_1.0-3              sandwich_3.1-0        \n [22] plyr_1.8.9             plotly_4.10.4          zoo_1.8-12            \n [25] igraph_1.6.0           mime_0.12              lifecycle_1.0.4       \n [28] pkgconfig_2.0.3        Matrix_1.6-5           R6_2.5.1              \n [31] fastmap_1.1.1          rbibutils_2.2.16       fitdistrplus_1.1-11   \n [34] future_1.33.1          shiny_1.8.0            numDeriv_2016.8-1.1   \n [37] digest_0.6.34          colorspace_2.1-0       patchwork_1.2.0       \n [40] tensor_1.5             RSpectra_0.16-1        irlba_2.3.5.1         \n [43] labeling_0.4.3         progressr_0.14.0       fansi_1.0.6           \n [46] spatstat.sparse_3.0-3  httr_1.4.7             TFisher_0.2.0         \n [49] polyclip_1.10-6        abind_1.4-5            compiler_4.3.2        \n [52] withr_3.0.0            mutoss_0.1-13          fastDummies_1.7.3     \n [55] MASS_7.3-60.0.1        tools_4.3.2            lmtest_0.9-40         \n [58] metap_1.9              httpuv_1.6.13          future.apply_1.11.1   \n [61] qqconf_1.3.2           goftest_1.2-3          glue_1.7.0            \n [64] nlme_3.1-164           promises_1.2.1         grid_4.3.2            \n [67] Rtsne_0.17             cluster_2.1.6          reshape2_1.4.4        \n [70] generics_0.1.3         gtable_0.3.4           spatstat.data_3.0-4   \n [73] tidyr_1.3.0            sn_2.1.1               data.table_1.14.10    \n [76] utf8_1.2.4             BiocGenerics_0.48.1    spatstat.geom_3.2-7   \n [79] RcppAnnoy_0.0.21       ggrepel_0.9.5          RANN_2.6.1            \n [82] pillar_1.9.0           stringr_1.5.1          spam_2.10-0           \n [85] RcppHNSW_0.5.0         limma_3.58.1           later_1.3.2           \n [88] splines_4.3.2          dplyr_1.1.4            lattice_0.22-5        \n [91] survival_3.5-7         deldir_2.0-2           tidyselect_1.2.0      \n [94] miniUI_0.1.1.1         pbapply_1.7-2          knitr_1.45            \n [97] gridExtra_2.3          scattermore_1.2        stats4_4.3.2          \n[100] xfun_0.41              Biobase_2.62.0         statmod_1.5.0         \n[103] matrixStats_1.2.0      stringi_1.8.3          lazyeval_0.2.2        \n[106] yaml_2.3.8             evaluate_0.23          codetools_0.2-19      \n[109] tibble_3.2.1           cli_3.6.2              uwot_0.1.16           \n[112] xtable_1.8-4           reticulate_1.34.0      Rdpack_2.6            \n[115] munsell_0.5.0          Rcpp_1.0.12            globals_0.16.2        \n[118] spatstat.random_3.2-2  png_0.1-8              parallel_4.3.2        \n[121] ellipsis_0.3.2         ggplot2_3.4.4          presto_1.0.0          \n[124] dotCall64_1.1-1        listenv_0.9.0          viridisLite_0.4.2     \n[127] mvtnorm_1.2-4          scales_1.3.0           ggridges_0.5.5        \n[130] leiden_0.4.3.1         purrr_1.0.2            rlang_1.1.3           \n[133] multcomp_1.4-25        mnormt_2.1.1           cowplot_1.1.2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找marker gene"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html",
    "href": "single_cell/seurat/de_vignette.html",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "",
    "text": "参考原文：Introduction to scRNA-seq integration 和 Differential expression testing\n原文发布日期：2023年10月31日",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#数据导入",
    "href": "single_cell/seurat/de_vignette.html#数据导入",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n1.1 数据导入",
    "text": "1.1 数据导入\n导入我们在整合（integration）中完成SCTransform和整合的单细胞数据。这里的meta.data已经提前注释好了细胞类型（储存在”seurat_annotations”列中）。\n\nlibrary(Seurat)\nifnb_integrated &lt;- readRDS(\"output/seurat_official/ifnb_integrated.rds\")\nifnb_integrated\n\nAn object of class Seurat \n27359 features across 13999 samples within 2 assays \nActive assay: SCT (13306 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n 3 dimensional reductions calculated: pca, umap, integrated.dr\n\nhead(ifnb_integrated, 3)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\n                 nCount_SCT nFeature_SCT SCT_snn_res.0.6 seurat_clusters\nAAACATACATTTCC.1       1944          852               1               1\nAAACATACCAGAAA.1       1888          699               9               9\nAAACATACCTCGCT.1       1951          804               1               1",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#运行prepsctfindmarkers预处理sct-assay",
    "href": "single_cell/seurat/de_vignette.html#运行prepsctfindmarkers预处理sct-assay",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n1.2 运行PrepSCTFindMarkers()，预处理SCT assay",
    "text": "1.2 运行PrepSCTFindMarkers()，预处理SCT assay\n\nifnb_integrated &lt;- PrepSCTFindMarkers(ifnb_integrated)\n\n\n\n\n\n\n\nImportant\n\n\n\n对于经过SCTransform归一化处理后的单细胞数据，在进行差异分析之前，需要先运行PrepSCTFindMarkers()，来预处理SCT assay。详细解释见此链接。\n如果是基于NormalizeData标准化的单细胞数据，需要使用”RNA” assay进行差异分析（见下面的数据读取和预处理），如果不是，需要通过DefaultAssay(ifnb) &lt;- \"RNA\"进行设定。Note that the raw and normalized counts are stored in the counts and data layers of RNA assay. By default, the functions for finding markers will use normalized data. 关于FindMarkers为什么要使用”RNA” assay，参阅：https://github.com/hbctraining/scRNA-seq_online/issues/58",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#准备差异表达分析所需变量",
    "href": "single_cell/seurat/de_vignette.html#准备差异表达分析所需变量",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n1.3 准备差异表达分析所需变量",
    "text": "1.3 准备差异表达分析所需变量\nWe create a column in the meta.data slot to hold both the cell type and treatment information and switch the current Idents to that column.\n\nifnb_integrated$celltype.stim &lt;- paste(ifnb_integrated$seurat_annotations, \n                                       ifnb_integrated$stim, \n                                       sep = \"_\")\nunique(ifnb_integrated$celltype.stim)\n\n [1] \"CD14 Mono_CTRL\"    \"pDC_CTRL\"          \"CD4 Memory T_CTRL\"\n [4] \"T activated_CTRL\"  \"CD4 Naive T_CTRL\"  \"CD8 T_CTRL\"       \n [7] \"Mk_CTRL\"           \"B Activated_CTRL\"  \"B_CTRL\"           \n[10] \"DC_CTRL\"           \"CD16 Mono_CTRL\"    \"NK_CTRL\"          \n[13] \"Eryth_CTRL\"        \"CD8 T_STIM\"        \"pDC_STIM\"         \n[16] \"CD4 Naive T_STIM\"  \"B_STIM\"            \"CD14 Mono_STIM\"   \n[19] \"T activated_STIM\"  \"CD4 Memory T_STIM\" \"B Activated_STIM\" \n[22] \"NK_STIM\"           \"DC_STIM\"           \"CD16 Mono_STIM\"   \n[25] \"Mk_STIM\"           \"Eryth_STIM\"       \n\nIdents(ifnb_integrated) &lt;- \"celltype.stim\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#执行差异表达分析",
    "href": "single_cell/seurat/de_vignette.html#执行差异表达分析",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n1.4 执行差异表达分析",
    "text": "1.4 执行差异表达分析\nThen we use FindMarkers() to find the genes that are different between control and stimulated B cells.\n\n# 寻找对照组和刺激组之间在B细胞中的差异基因\n\nb.interferon.response &lt;- FindMarkers(ifnb_integrated, \n                                     ident.1 = \"B_STIM\", \n                                     ident.2 = \"B_CTRL\", \n                                     verbose = FALSE)\nhead(b.interferon.response, n = 15)\n\n                p_val avg_log2FC pct.1 pct.2     p_val_adj\nISG15   1.505650e-159  5.1597242 0.998 0.229 2.003417e-155\nIFIT3   4.128835e-154  6.2281506 0.961 0.052 5.493827e-150\nIFI6    2.493139e-153  5.6458391 0.965 0.076 3.317371e-149\nISG20   9.385626e-152  3.1715979 1.000 0.666 1.248851e-147\nIFIT1   2.447118e-139  6.2614957 0.904 0.029 3.256136e-135\nMX1     2.111961e-124  4.1490465 0.900 0.115 2.810175e-120\nLY6E    2.930420e-122  3.9278136 0.898 0.150 3.899217e-118\nTNFSF10 1.104024e-112  6.8254288 0.785 0.020 1.469014e-108\nIFIT2   3.491368e-108  5.5668205 0.783 0.037 4.645615e-104\nB2M      3.405403e-98  0.6074989 1.000 1.000  4.531229e-94\nIRF7     1.114291e-96  3.3721350 0.834 0.187  1.482675e-92\nPLSCR1   3.364901e-96  4.0217697 0.783 0.111  4.477338e-92\nUBE2L6   1.155610e-85  2.6732717 0.849 0.295  1.537655e-81\nCXCL10   5.689834e-84  8.0923962 0.639 0.010  7.570893e-80\nPSMB9    2.304426e-81  1.8684260 0.937 0.568  3.066269e-77\n\n\n\n\n\n\n\n\nWarning\n\n\n\nPlease note that p-values obtained from this analysis should be interpreted with caution, as these tests treat each cell as an independent replicate, and ignore inherent correlations between cells originating from the same sample. Such analyses have been shown to find a large number of false positive associations, as has been demonstrated by (Squair et al. 2021), (Zimmerman, Espeland, and Langefeld 2021), (Junttila, Smolander, and Elo 2022), and others. As discussed here (Crowell et al. 2020), DE tests across multiple conditions should expressly utilize multiple samples/replicates, and can be performed after aggregating (‘pseudobulking’) cells from the same sample and subpopulation together. Below, we show how pseudobulking can be used to account for such within-sample correlation.\n\n\n\n\n\n\n\n\nWarning\n\n\n\n这里没有使用进行pseudobulking的原因是，本例中“ctrl”和“sim”组都分别只有一个重复：We do not perform this analysis here, as there is a single replicate in the data.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#可视化差异基因表达",
    "href": "single_cell/seurat/de_vignette.html#可视化差异基因表达",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n1.5 可视化差异基因表达",
    "text": "1.5 可视化差异基因表达\nAnother useful way to visualize these changes in gene expression is with the split.by option to the FeaturePlot() or VlnPlot() function. This will display FeaturePlots of the list of given genes, split by a grouping variable (stimulation condition here).\n\nFeaturePlot(ifnb_integrated, \n            features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\"), \n            split.by = \"stim\", \n            max.cutoff = 3, \n            cols = c(\"grey\", \"red\"), \n            reduction = \"umap\")\n\n\n\n\n\n\n\n\nplots &lt;- VlnPlot(ifnb_integrated,\n                 features = c(\"CD3D\", \"GNLY\", \"IFI6\", \"ISG15\", \"CD14\", \"CXCL10\", \"LYZ\"),\n                 split.by = \"stim\",\n                 group.by = \"seurat_annotations\",\n                 pt.size = 0,\n                 combine = FALSE) # 由于VlnPlot绘制组图时没有图例，所以这里取消绘制组图\nlibrary(patchwork)\nwrap_plots(plots = plots, ncol = 2) # 将plots列表组合成组图\n\n\n\n\n\n\n\n\n\n\n\n\n\n结果解读\n\n\n\n\n\n\nGenes such as CD3D and GNLY are canonical cell type markers (for T cells and NK/CD8 T cells) that are virtually unaffected by interferon stimulation and display similar gene expression patterns in the control and stimulated group.\nIFI6 and ISG15, on the other hand, are core interferon response genes and are upregulated accordingly in all cell types.\n\nCD14 and CXCL10 are genes that show a cell type specific interferon response.\n\nCD14 expression decreases after stimulation in CD14 monocytes, which could lead to misclassification in a supervised analysis framework, underscoring the value of integrated analysis.如果用于识别细胞类型的marker本身在不同的样本类型（处理 vs. 对照、恶性组织 vs. 正常组织）中存在表达量的差异，那么就会导致对细胞类型判断的错误。而本篇的数据整合则能够避免出现这种情况。\nCXCL10 shows a distinct upregulation in monocytes and B cells after interferon stimulation but not in other cell types.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#数据读取和预处理",
    "href": "single_cell/seurat/de_vignette.html#数据读取和预处理",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n2.1 数据读取和预处理",
    "text": "2.1 数据读取和预处理\nFor demonstration purposes, we will be using the interferon-beta stimulated human PBMCs dataset (Kang et al. 2017) that is available via the SeuratData package.\n\n\n\n\n\n\n在线读取（可能需要全局代理）\n\n\n\n\n\n\nrm(list = ls())\nlibrary(Seurat)\nlibrary(SeuratData)\nInstallData(\"ifnb\")\nifnb &lt;- LoadData(\"ifnb\")\n\n\n\n\n从本地下载好的数据读取：\n\nrm(list = ls())\n\nlibrary(Seurat)\nifnb &lt;- readRDS(\"data/seurat_official/pbmc_ifnb.rds\")\nifnb\n\nAn object of class Seurat \n14053 features across 13999 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 2 layers present: counts, data\n\nhead(ifnb@meta.data, 5)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\n\nunique(ifnb$seurat_annotations) # 这里的数据已经提前注释好了细胞类型\n\n [1] CD14 Mono    pDC          CD4 Memory T T activated  CD4 Naive T \n [6] CD8 T        Mk           B Activated  B            DC          \n[11] CD16 Mono    NK           Eryth       \n13 Levels: CD14 Mono CD4 Naive T CD4 Memory T CD16 Mono B CD8 T ... Eryth\n\n# 标准化\nifnb &lt;- NormalizeData(ifnb)\n# 核对目前的默认assay，保证是RNA assay\nDefaultAssay(ifnb)\n\n[1] \"RNA\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#直接通过findmarkers寻找差异基因",
    "href": "single_cell/seurat/de_vignette.html#直接通过findmarkers寻找差异基因",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n2.2 直接通过FindMarkers寻找差异基因",
    "text": "2.2 直接通过FindMarkers寻找差异基因\n为了和pseudobulking后的差异分析结果进行比价，这里仍然先进行基于FindMarkers的简单差异表达分析，寻找ctrl和stim之间在CD14单核细胞中的差异基因。基本步骤和上面的准备差异表达分析所需变量一致。\n\nifnb$celltype.stim &lt;- paste(ifnb$seurat_annotations, ifnb$stim, sep = \"_\")\nunique(ifnb$celltype.stim)\n\n [1] \"CD14 Mono_CTRL\"    \"pDC_CTRL\"          \"CD4 Memory T_CTRL\"\n [4] \"T activated_CTRL\"  \"CD4 Naive T_CTRL\"  \"CD8 T_CTRL\"       \n [7] \"Mk_CTRL\"           \"B Activated_CTRL\"  \"B_CTRL\"           \n[10] \"DC_CTRL\"           \"CD16 Mono_CTRL\"    \"NK_CTRL\"          \n[13] \"Eryth_CTRL\"        \"CD8 T_STIM\"        \"pDC_STIM\"         \n[16] \"CD4 Naive T_STIM\"  \"B_STIM\"            \"CD14 Mono_STIM\"   \n[19] \"T activated_STIM\"  \"CD4 Memory T_STIM\" \"B Activated_STIM\" \n[22] \"NK_STIM\"           \"DC_STIM\"           \"CD16 Mono_STIM\"   \n[25] \"Mk_STIM\"           \"Eryth_STIM\"       \n\nIdents(ifnb) &lt;- \"celltype.stim\"\n\nmono.de &lt;- FindMarkers(ifnb, \n                       ident.1 = \"CD14 Mono_STIM\", \n                       ident.2 = \"CD14 Mono_CTRL\", \n                       verbose = FALSE)\nnrow(mono.de)\n\n[1] 6956\n\nhead(mono.de, n = 10)\n\n        p_val avg_log2FC pct.1 pct.2 p_val_adj\nIFIT1       0   7.319139 0.985 0.033         0\nCXCL10      0   8.036564 0.984 0.035         0\nRSAD2       0   6.741673 0.988 0.045         0\nTNFSF10     0   6.991279 0.989 0.047         0\nIFIT3       0   6.883785 0.992 0.056         0\nIFIT2       0   7.179929 0.961 0.039         0\nCXCL11      0   8.624208 0.932 0.012         0\nCCL8        0   9.134191 0.918 0.017         0\nIDO1        0   5.455898 0.965 0.089         0\nMX1         0   5.059052 0.960 0.093         0",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#执行pseudobulking",
    "href": "single_cell/seurat/de_vignette.html#执行pseudobulking",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n2.3 执行pseudobulking",
    "text": "2.3 执行pseudobulking\nTo pseudobulk, we will use AggregateExpression() to sum together gene counts of all the cells from the same sample for each cell type. This results in one gene expression profile per sample and cell type. We can then perform DE analysis using DESeq2 on the sample level. This treats the samples, rather than the individual cells, as independent observations.\nFirst, we need to retrieve the sample information for each cell. This is not loaded in the metadata, so we will load it from the Github repo of the source data for the original paper.\n\n\n\n\n\n\nAdd sample information to the dataset\n\n\n\n\n\n\n```{r}\n#| eval: false\n\n# 从GitHub仓库读取（可能需要代理）\n# load the inferred sample IDs of each cell\nctrl &lt;- read.table(url(\"https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye1.ctrl.8.10.sm.best\"), head = T, stringsAsFactors = F)\nstim &lt;- read.table(url(\"https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye2.stim.8.10.sm.best\"), head = T, stringsAsFactors = F)\n```\n\n\n# 这里提前下载好了两个样本信息文件，所以直接从本地读取\nctrl &lt;- readRDS(\"data/seurat_official/inferred_sample_ids_ctrl.rds\")\nstim &lt;- readRDS(\"data/seurat_official/inferred_sample_ids_stim.rds\")\ninfo &lt;- rbind(ctrl, stim)\ninfo$BARCODE[1:5]\n\n[1] \"AAACATACAATGCC-1\" \"AAACATACATTTCC-1\" \"AAACATACCAGAAA-1\" \"AAACATACCAGCTA-1\"\n[5] \"AAACATACCATGCA-1\"\n\ncolnames(ifnb)[1:5]\n\n[1] \"AAACATACATTTCC.1\" \"AAACATACCAGAAA.1\" \"AAACATACCTCGCT.1\" \"AAACATACCTGGTA.1\"\n[5] \"AAACATACGATGAA.1\"\n\n# 可以看到两者的barcode形式不一致\n# rename the cell IDs by substituting the '-' into '.'\ninfo$BARCODE &lt;- gsub(pattern = \"\\\\-\", replacement = \"\\\\.\", info$BARCODE)\ninfo$BARCODE[1:5]\n\n[1] \"AAACATACAATGCC.1\" \"AAACATACATTTCC.1\" \"AAACATACCAGAAA.1\" \"AAACATACCAGCTA.1\"\n[5] \"AAACATACCATGCA.1\"\n\n# only keep the cells with high-confidence sample ID\ninfo &lt;- info[grep(pattern = \"SNG\", x = info$BEST), ]\n\n# remove cells with duplicated IDs in both ctrl and stim groups\ninfo &lt;- info[!duplicated(info$BARCODE) & !duplicated(info$BARCODE, fromLast = T), ]\n\n# now add the sample IDs to ifnb \nrownames(info) &lt;- info$BARCODE\ninfo &lt;- info[, c(\"BEST\"), drop = F]\nnames(info) &lt;- c(\"donor_id\")\nifnb &lt;- AddMetaData(ifnb, metadata = info)\n\n# remove cells without donor IDs\nifnb$donor_id[is.na(ifnb$donor_id)] &lt;- \"unknown\"\nifnb &lt;- subset(ifnb, subset = donor_id != \"unknown\")\n\n\n\n\n可以看到，现在的meta.dat中多了样本信息列（donor_id），记录了每个细胞来自哪个患者：\n\nhead(ifnb@meta.data, 5)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\n                     celltype.stim donor_id\nAAACATACATTTCC.1    CD14 Mono_CTRL SNG-1016\nAAACATACCAGAAA.1    CD14 Mono_CTRL SNG-1256\nAAACATACCTCGCT.1    CD14 Mono_CTRL SNG-1256\nAAACATACCTGGTA.1          pDC_CTRL SNG-1039\nAAACATACGATGAA.1 CD4 Memory T_CTRL SNG-1488\n\ntable(ifnb$donor_id, ifnb$stim)\n\n          \n           CTRL STIM\n  SNG-101   491  706\n  SNG-1015 1583 1533\n  SNG-1016  697  741\n  SNG-1039  270  393\n  SNG-107   331  321\n  SNG-1244 1023  975\n  SNG-1256 1160 1203\n  SNG-1488  865 1376\n\n\n按照治疗分组（STIM vs. CTRL）、患者IDs、细胞类型（seurat_annotations）3个条件，执行pseudobulking (AggregateExpression)。通过AggregateExpression命令将同一类型的细胞按照不同的处理条件合并起来，形成一个假的组织水平的测序数据。本例中，有2个治疗分组、13种细胞类型和8个患者，总共被合并成206个类别，将每一个类别看作是一个样本，这样就形成了一个所谓的假的组织水平的测序数据。\n\npseudo_ifnb &lt;- AggregateExpression(ifnb, \n                                   assays = \"RNA\", \n                                   return.seurat = T, \n                                   group.by = c(\"stim\", \"donor_id\", \"seurat_annotations\"))\npseudo_ifnb\n\nAn object of class Seurat \n14053 features across 206 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 3 layers present: counts, data, scale.data\n\nhead(pseudo_ifnb@meta.data) # 可以看到现在的表达矩阵的barcode变成了治疗分组+患者IDs+细胞类型\n\n                                         orig.ident stim donor_id\nCTRL_SNG-101_CD14 Mono       CTRL_SNG-101_CD14 Mono CTRL  SNG-101\nCTRL_SNG-101_CD4 Naive T   CTRL_SNG-101_CD4 Naive T CTRL  SNG-101\nCTRL_SNG-101_CD4 Memory T CTRL_SNG-101_CD4 Memory T CTRL  SNG-101\nCTRL_SNG-101_CD16 Mono       CTRL_SNG-101_CD16 Mono CTRL  SNG-101\nCTRL_SNG-101_B                       CTRL_SNG-101_B CTRL  SNG-101\nCTRL_SNG-101_CD8 T               CTRL_SNG-101_CD8 T CTRL  SNG-101\n                          seurat_annotations\nCTRL_SNG-101_CD14 Mono             CD14 Mono\nCTRL_SNG-101_CD4 Naive T         CD4 Naive T\nCTRL_SNG-101_CD4 Memory T       CD4 Memory T\nCTRL_SNG-101_CD16 Mono             CD16 Mono\nCTRL_SNG-101_B                             B\nCTRL_SNG-101_CD8 T                     CD8 T\n\n\n然后和此前一样，我们在meta.data中增加一列，记录治疗分组（STIM vs. CTRL）+ 细胞类型，这是用于差异分析的分组依据。\n\npseudo_ifnb$celltype.stim &lt;- paste(pseudo_ifnb$seurat_annotations, \n                                   pseudo_ifnb$stim, \n                                   sep = \"_\")\nunique(pseudo_ifnb$celltype.stim)\n\n [1] \"CD14 Mono_CTRL\"    \"CD4 Naive T_CTRL\"  \"CD4 Memory T_CTRL\"\n [4] \"CD16 Mono_CTRL\"    \"B_CTRL\"            \"CD8 T_CTRL\"       \n [7] \"T activated_CTRL\"  \"NK_CTRL\"           \"DC_CTRL\"          \n[10] \"B Activated_CTRL\"  \"Mk_CTRL\"           \"pDC_CTRL\"         \n[13] \"Eryth_CTRL\"        \"CD14 Mono_STIM\"    \"CD4 Naive T_STIM\" \n[16] \"CD4 Memory T_STIM\" \"CD16 Mono_STIM\"    \"B_STIM\"           \n[19] \"CD8 T_STIM\"        \"T activated_STIM\"  \"NK_STIM\"          \n[22] \"DC_STIM\"           \"B Activated_STIM\"  \"Mk_STIM\"          \n[25] \"pDC_STIM\"          \"Eryth_STIM\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#sec-perform_de_analysis",
    "href": "single_cell/seurat/de_vignette.html#sec-perform_de_analysis",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n2.4 执行差异分析",
    "text": "2.4 执行差异分析\nNext, we perform DE testing on the pseudobulk level for CD14 monocytes, and compare it against the previous single-cell-level DE results.\n\n\n\n\n\n\n安装DESeq2包\n\n\n\n由于pseudobulking后的FindMarkers差异分析需要采用DESeq2包提供的方法，所以需要提前安装DESeq2包：\n\n```{r}\n#| eval: false\nBiocManager::install(\"DESeq2\")\n```\n\n注意，如果是用FindMarkers来寻找细胞类型的marker基因，则一般采用默认的Wilcoxon Rank Sum Test方法，这时需要调用的是presto 包（见FindMarkers-在特定cluster之间寻找marker基因）。\n\n\n\nIdents(pseudo_ifnb) &lt;- \"celltype.stim\"\n\nbulk.mono.de &lt;- FindMarkers(pseudo_ifnb, \n                            ident.1 = \"CD14 Mono_STIM\", \n                            ident.2 = \"CD14 Mono_CTRL\",\n                            test.use = \"DESeq2\") # 指定差异分析方法为\"DESeq2\"\nhead(bulk.mono.de, n = 15)\n\n                 p_val avg_log2FC pct.1 pct.2     p_val_adj\nIL1RN    3.701542e-275   6.160156     1     1 5.201777e-271\nIFITM2   1.955626e-250   4.318976     1     1 2.748242e-246\nSSB      2.699554e-203   3.066647     1     1 3.793683e-199\nNT5C3A   2.239898e-198   5.412972     1     1 3.147729e-194\nRTCB     5.700554e-162   3.133362     1     1 8.010989e-158\nRABGAP1L 4.743010e-161   5.562364     1     1 6.665352e-157\nDYNLT1   9.735640e-159   2.402726     1     1 1.368150e-154\nPLSCR1   3.191691e-146   2.676047     1     1 4.485284e-142\nISG20    9.664488e-145   5.443114     1     1 1.358151e-140\nNAPA     2.858013e-144   1.977719     1     1 4.016365e-140\nDDX58    5.957026e-142   4.640111     1     1 8.371409e-138\nHERC5    6.333722e-133   5.266515     1     1 8.900780e-129\nOASL     3.892853e-130   3.946745     1     1 5.470627e-126\nEIF2AK2  6.636434e-128   3.940167     1     1 9.326180e-124\nTMEM50A  6.731955e-117   1.355947     1     1 9.460416e-113\n\n\n\n\n\n\n\n\nFindMarkers支持的差异分析方法\n\n\n\n\n\nWe also support many other DE tests using other methods. For completeness, the following tests are currently supported:\n\n“wilcox” : Wilcoxon rank sum test (default, using ‘presto’ package)\n“wilcox_limma” : Wilcoxon rank sum test (using ‘limma’ package)\n“bimod” : Likelihood-ratio test for single cell feature expression, (McDavid et al., Bioinformatics, 2013)\n“roc” : Standard AUC classifier\n“t” : Student’s t-test\n“poisson” : Likelihood ratio test assuming an underlying negative binomial distribution. Use only for UMI-based datasets\n“negbinom” : Likelihood ratio test assuming an underlying negative binomial distribution. Use only for UMI-based datasets\n“LR” : Uses a logistic regression framework to determine differentially expressed genes. Constructs a logistic regression model predicting group membership based on each feature individually and compares this to a null model with a likelihood ratio test.\n“MAST” : GLM-framework that treates cellular detection rate as a covariate (Finak et al, Genome Biology, 2015) (Installation instructions)\n“DESeq2” : DE based on a model using the negative binomial distribution (Love et al, Genome Biology, 2014) (Installation instructions) For MAST and DESeq2, please ensure that these packages are installed separately in order to use them as part of Seurat. Once installed, use the test.use parameter can be used to specify which DE test to use.\n\n\n# Test for DE features using the MAST package\n# BiocManager::install('limma')\nIdents(ifnb) &lt;- \"seurat_annotations\"\nhead(FindMarkers(ifnb, \n                 ident.1 = \"CD14 Mono\", \n                 ident.2 = \"CD16 Mono\", \n                 test.use = \"wilcox_limma\"))\n\n               p_val avg_log2FC pct.1 pct.2     p_val_adj\nVMO1    0.000000e+00  -5.689802 0.084 0.777  0.000000e+00\nMS4A4A  0.000000e+00  -3.356037 0.141 0.747  0.000000e+00\nFCGR3A  0.000000e+00  -3.279465 0.418 0.982  0.000000e+00\nMS4A7   0.000000e+00  -2.390652 0.557 0.978  0.000000e+00\nRPS19   0.000000e+00  -1.321132 0.965 0.999  0.000000e+00\nFTL    1.636254e-307   1.318127 1.000 1.000 2.299427e-303",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/seurat/de_vignette.html#比较单细胞水平和pseudobulk水平的差异表达分析",
    "href": "single_cell/seurat/de_vignette.html#比较单细胞水平和pseudobulk水平的差异表达分析",
    "title": "寻找不同样本类型间同一细胞类型内的差异基因",
    "section": "\n2.5 比较单细胞水平和pseudobulk水平的差异表达分析",
    "text": "2.5 比较单细胞水平和pseudobulk水平的差异表达分析\n接下来，我们可以比较一下单细胞水平的差异表达分析的P值和pseudobulk水平的P值：\n\nnames(bulk.mono.de) &lt;- paste0(names(bulk.mono.de), \".bulk\") # 重命名列\nbulk.mono.de$gene &lt;- rownames(bulk.mono.de)\n\nnames(mono.de) &lt;- paste0(names(mono.de), \".sc\")\nmono.de$gene &lt;- rownames(mono.de)\n\nmerge_dat &lt;- merge(mono.de, bulk.mono.de, by = \"gene\")\nmerge_dat &lt;- merge_dat[order(merge_dat$p_val.bulk), ]\n\n# 查看在两种差异分析方法中P值都有意义的基因名\ncommon &lt;- merge_dat$gene[which(merge_dat$p_val.bulk &lt; 0.05 & \n                                merge_dat$p_val.sc &lt; 0.05)]\n# 查看在pseudobulk水平P&gt;0.05但是在单细胞水平P&lt;0.05的基因名：\nonly_sc &lt;- merge_dat$gene[which(merge_dat$p_val.bulk &gt; 0.05 & \n                                  merge_dat$p_val.sc &lt; 0.05)]\n# 查看在pseudobulk水平P&lt;0.05但是在单细胞水平P&gt;0.05的基因名：\nonly_bulk &lt;- merge_dat$gene[which(merge_dat$p_val.bulk &lt; 0.05 & \n                                    merge_dat$p_val.sc &gt; 0.05)]\nprint(paste0('# 在两种差异分析方法中P值都&lt;0.05的基因有: ',length(common), \"个\"))\n\n[1] \"# 在两种差异分析方法中P值都&lt;0.05的基因有: 3519个\"\n\nprint(paste0('# 仅在细胞水平差异分析中P值&lt;0.05的基因有: ',length(only_sc), \"个\"))\n\n[1] \"# 仅在细胞水平差异分析中P值&lt;0.05的基因有: 1649个\"\n\nprint(paste0('# 仅在pseudobulk差异分析中P值&lt;0.05的基因有: ',length(only_bulk), \"个\"))\n\n[1] \"# 仅在pseudobulk差异分析中P值&lt;0.05的基因有: 204个\"\n\n\n\nWe can see that while the p-values are correlated between the single-cell and pseudobulk data, the single-cell p-values are often smaller and suggest higher levels of significance. In particular, there are 3,519 genes with evidence of differential expression (prior to multiple hypothesis testing) in both analyses, 1,649 genes that only appear to be differentially expressed in the single-cell analysis, and just 204 genes that only appear to be differentially expressed in the bulk analysis.\n\n接下来，我们通过小提琴图来检查两种方法中的Top共同差异基因在在刺激组和对照组的表达水平：\n\n# create a new column to annotate sample-condition-celltype in the single-cell dataset\nifnb$donor_id.stim &lt;- paste0(ifnb$stim, \"-\", ifnb$donor_id)\nhead(ifnb@meta.data)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\nAAACATACGGCATT.1 IMMUNE_CTRL       1581          557 CTRL          CD14 Mono\n                     celltype.stim donor_id donor_id.stim\nAAACATACATTTCC.1    CD14 Mono_CTRL SNG-1016 CTRL-SNG-1016\nAAACATACCAGAAA.1    CD14 Mono_CTRL SNG-1256 CTRL-SNG-1256\nAAACATACCTCGCT.1    CD14 Mono_CTRL SNG-1256 CTRL-SNG-1256\nAAACATACCTGGTA.1          pDC_CTRL SNG-1039 CTRL-SNG-1039\nAAACATACGATGAA.1 CD4 Memory T_CTRL SNG-1488 CTRL-SNG-1488\nAAACATACGGCATT.1    CD14 Mono_CTRL SNG-1015 CTRL-SNG-1015\n\nunique(ifnb$celltype.stim)\n\n [1] \"CD14 Mono_CTRL\"    \"pDC_CTRL\"          \"CD4 Memory T_CTRL\"\n [4] \"T activated_CTRL\"  \"CD4 Naive T_CTRL\"  \"CD8 T_CTRL\"       \n [7] \"Mk_CTRL\"           \"B Activated_CTRL\"  \"B_CTRL\"           \n[10] \"DC_CTRL\"           \"NK_CTRL\"           \"CD16 Mono_CTRL\"   \n[13] \"Eryth_CTRL\"        \"CD8 T_STIM\"        \"pDC_STIM\"         \n[16] \"CD4 Naive T_STIM\"  \"B_STIM\"            \"CD14 Mono_STIM\"   \n[19] \"T activated_STIM\"  \"CD4 Memory T_STIM\" \"B Activated_STIM\" \n[22] \"NK_STIM\"           \"DC_STIM\"           \"CD16 Mono_STIM\"   \n[25] \"Mk_STIM\"           \"Eryth_STIM\"       \n\nIdents(ifnb) &lt;- \"celltype.stim\"\n\n# 这里我们检查p_val.bulk最小的前两个Top差异基因\nprint(merge_dat[merge_dat$gene %in% common[1:2], c('gene','p_val.sc','p_val.bulk')])\n\n       gene p_val.sc    p_val.bulk\n2785  IL1RN        0 3.701542e-275\n2739 IFITM2        0 1.955626e-250\n\n# 在细胞类型水平（CD14 Mono）查看这两个Top差异基因在刺激组和对照组的表达水平\nVlnPlot(ifnb, \n        features = common[1:2], \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"stim\") \n\n\n\n\n\n\n\n\n# 在样本（患者）水平查看这两个Top差异基因在刺激组和对照组的表达水平\nVlnPlot(ifnb, \n        features = common[1:2], \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"donor_id.stim\", \n        ncol = 1) \n\n\n\n\n\n\n\n\nIn both the pseudobulk and single-cell analyses, the p-values for these two genes are astronomically small. For both of these genes, when just comparing all stimulated CD4 monocytes to all control CD4 monocytes across samples, we see much higher expression in the stimulated cells.\nWhen breaking down these cells by sample, we continue to see consistently higher expression levels in the stimulated samples compared to the control samples; in other words, this finding is not driven by just one or two samples. Because of this consistency, we find this signal in both analyses.\n\nBy contrast, we can examine examples of genes that are only DE under the single-cell analysis.\n\nprint(merge_dat[merge_dat$gene %in% c('SRGN','HLA-DRA'), \n                c('gene','p_val.sc','p_val.bulk')])\n\n        gene     p_val.sc p_val.bulk\n5710    SRGN 4.025076e-21  0.1823188\n2603 HLA-DRA 4.989863e-09  0.1851302\n\nVlnPlot(ifnb, \n        features = c('SRGN','HLA-DRA'), \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"stim\") \n\n\n\n\n\n\n\n\nVlnPlot(ifnb, \n        features = c('SRGN','HLA-DRA'), \n        idents = c(\"CD14 Mono_CTRL\", \"CD14 Mono_STIM\"), \n        group.by = \"donor_id.stim\", \n        ncol = 1) \n\n\n\n\n\n\n\n\nHere, SRGN and HLA-DRA both have very small p-values in the single-cell analysis (on the orders of 10−21 and 10−9), but much larger p-values around 0.18 in the pseudobulk analysis. While there appears to be a difference between control and simulated cells when ignoring sample information, the signal is much weaker on the sample level, and we can see notable variability from sample to sample.\n\n所以，从这个例子中可以看出pseudobulk后的差异分析的结果更加准确。\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] patchwork_1.2.0    Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.8              magrittr_2.0.3             \n  [5] spatstat.utils_3.0-4        ggbeeswarm_0.7.2           \n  [7] farver_2.1.1                rmarkdown_2.25             \n  [9] zlibbioc_1.48.0             vctrs_0.6.5                \n [11] ROCR_1.0-11                 spatstat.explore_3.2-5     \n [13] RCurl_1.98-1.14             S4Arrays_1.2.0             \n [15] htmltools_0.5.7             SparseArray_1.2.3          \n [17] sctransform_0.4.1           parallelly_1.36.0          \n [19] KernSmooth_2.23-22          htmlwidgets_1.6.4          \n [21] ica_1.0-3                   plyr_1.8.9                 \n [23] plotly_4.10.4               zoo_1.8-12                 \n [25] igraph_1.6.0                mime_0.12                  \n [27] lifecycle_1.0.4             pkgconfig_2.0.3            \n [29] Matrix_1.6-5                R6_2.5.1                   \n [31] fastmap_1.1.1               MatrixGenerics_1.14.0      \n [33] GenomeInfoDbData_1.2.11     fitdistrplus_1.1-11        \n [35] future_1.33.1               shiny_1.8.0                \n [37] digest_0.6.34               colorspace_2.1-0           \n [39] S4Vectors_0.40.2            DESeq2_1.42.0              \n [41] tensor_1.5                  RSpectra_0.16-1            \n [43] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [45] labeling_0.4.3              progressr_0.14.0           \n [47] fansi_1.0.6                 spatstat.sparse_3.0-3      \n [49] httr_1.4.7                  polyclip_1.10-6            \n [51] abind_1.4-5                 compiler_4.3.2             \n [53] withr_3.0.0                 BiocParallel_1.36.0        \n [55] fastDummies_1.7.3           MASS_7.3-60.0.1            \n [57] DelayedArray_0.28.0         tools_4.3.2                \n [59] vipor_0.4.7                 lmtest_0.9-40              \n [61] beeswarm_0.4.0              httpuv_1.6.13              \n [63] future.apply_1.11.1         goftest_1.2-3              \n [65] glue_1.7.0                  nlme_3.1-164               \n [67] promises_1.2.1              grid_4.3.2                 \n [69] Rtsne_0.17                  cluster_2.1.6              \n [71] reshape2_1.4.4              generics_0.1.3             \n [73] gtable_0.3.4                spatstat.data_3.0-4        \n [75] tidyr_1.3.0                 data.table_1.14.10         \n [77] XVector_0.42.0              utf8_1.2.4                 \n [79] BiocGenerics_0.48.1         spatstat.geom_3.2-7        \n [81] RcppAnnoy_0.0.21            ggrepel_0.9.5              \n [83] RANN_2.6.1                  pillar_1.9.0               \n [85] stringr_1.5.1               spam_2.10-0                \n [87] RcppHNSW_0.5.0              limma_3.58.1               \n [89] later_1.3.2                 splines_4.3.2              \n [91] dplyr_1.1.4                 lattice_0.22-5             \n [93] survival_3.5-7              deldir_2.0-2               \n [95] tidyselect_1.2.0            locfit_1.5-9.8             \n [97] miniUI_0.1.1.1              pbapply_1.7-2              \n [99] knitr_1.45                  gridExtra_2.3              \n[101] IRanges_2.36.0              SummarizedExperiment_1.32.0\n[103] scattermore_1.2             stats4_4.3.2               \n[105] xfun_0.41                   Biobase_2.62.0             \n[107] statmod_1.5.0               matrixStats_1.2.0          \n[109] stringi_1.8.3               lazyeval_0.2.2             \n[111] yaml_2.3.8                  evaluate_0.23              \n[113] codetools_0.2-19            tibble_3.2.1               \n[115] cli_3.6.2                   uwot_0.1.16                \n[117] xtable_1.8-4                reticulate_1.34.0          \n[119] munsell_0.5.0               GenomeInfoDb_1.38.5        \n[121] Rcpp_1.0.12                 globals_0.16.2             \n[123] spatstat.random_3.2-2       png_0.1-8                  \n[125] ggrastr_1.0.2               parallel_4.3.2             \n[127] ellipsis_0.3.2              ggplot2_3.4.4              \n[129] presto_1.0.0                dotCall64_1.1-1            \n[131] bitops_1.0-7                listenv_0.9.0              \n[133] viridisLite_0.4.2           scales_1.3.0               \n[135] ggridges_0.5.5              crayon_1.5.2               \n[137] leiden_0.4.3.1              purrr_1.0.2                \n[139] rlang_1.1.3                 cowplot_1.1.2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "寻找不同样本类型间同一细胞类型内的差异基因"
    ]
  },
  {
    "objectID": "single_cell/single_cell_intro.html",
    "href": "single_cell/single_cell_intro.html",
    "title": "单细胞数据分析",
    "section": "",
    "text": "从本章开始进入单细胞数据分析的学习。这一部分的编排如下：",
    "crumbs": [
      "Home",
      "单细胞数据分析"
    ]
  },
  {
    "objectID": "single_cell/single_cell_intro.html#resources",
    "href": "single_cell/single_cell_intro.html#resources",
    "title": "单细胞数据分析",
    "section": "Resources",
    "text": "Resources\n\n其他scRNA-seq数据分析课程:\n\nSeurat vignettes\nSeurat cheatsheet\n《Analysis of single cell RNA-seq data》\n《ANALYSIS OF SINGLE CELL RNA-SEQ DATA》\nNBIS Workshop: Single Cell RNA-seq Analysis\n《Single-cell RNA-seq YouTube视频合集》\nLigand-receptor analysis with CellphoneDB\nBest practices for single-cell analysis across modalities\n\n\n\nResources for scRNA-seq Sample Prep:\n\nResearch protocol分享平台\n“Sampling time-dependent artifacts in single-cell genomics studies.” Massoni-Badosa et al.2019\n“Dissociation of solid tumor tissues with cold active protease for single-cell RNA-seq minimizes conserved collagenase-associated stress responses.” O’Flanagan et al. 2020\n“Systematic assessment of tissue dissociation and storage biases in single-cell and single-nucleus RNA-seq workflows.” Denisenko et al. 2020\n\n\n\nHighlighted papers for single-nuclei RNA-seq:\n\nSingle-nucleus and single-cell transcriptomes compared in matched cortical cell types\nA single-cell and single-nucleus RNA-Seq toolbox for fresh and frozen human tumors",
    "crumbs": [
      "Home",
      "单细胞数据分析"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html",
    "href": "single_cell/scRNA-seq_online/06_integration.html",
    "title": "单细胞数据整合（Integration）",
    "section": "",
    "text": "Learning Objectives:\n\n\n\n\nPerform integration of cells across conditions to identify cells that are similar to each other\nDescribe complex integration tasks and alternative tools for integration\nGoals:\nChallenges:\nRecommendations:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "单细胞数据整合（Integration）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#数据导入",
    "href": "single_cell/scRNA-seq_online/06_integration.html#数据导入",
    "title": "单细胞数据整合（Integration）",
    "section": "\n1.1 数据导入",
    "text": "1.1 数据导入\nWe use the split_seurat object from the previous lesson.\n\nlibrary(Seurat)\nsplit_seurat &lt;- readRDS(\"output/scRNA-seq_online/split_seurat.rds\")\nsplit_seurat\n\nAn object of class Seurat \n28130 features across 29629 samples within 2 assays \nActive assay: SCT (14065 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n 1 dimensional reduction calculated: pca\n\n# Check which assays are stored in objects\nsplit_seurat@assays\n\n$RNA\nAssay (v5) data with 14065 features for 29629 cells\nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \nLayers:\n counts.ctrl, counts.stim \n\n$SCT\nSCTAssay data with 14065 features for 29629 cells, and 2 SCTModel(s) \nTop 10 variable features:\n FTL, IGKC, CCL2, GNLY, IGLC2, CCL3, CCL4, CXCL10, CCL7, TIMP1 \n\n# 查看目前默认的assay\nDefaultAssay(split_seurat)\n\n[1] \"SCT\"\n\n# 查看默认assay的layers\nLayers(split_seurat)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n# 查看每种样本包含多少细胞\ntable(split_seurat$sample)\n\n\n ctrl  stim \n14847 14782 \n\n# 查看降维信息\nnames(split_seurat@reductions)\n\n[1] \"pca\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "单细胞数据整合（Integration）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#降维分群",
    "href": "single_cell/scRNA-seq_online/06_integration.html#降维分群",
    "title": "单细胞数据整合（Integration）",
    "section": "\n1.2 降维、分群",
    "text": "1.2 降维、分群\n\n# Run PCA\nsplit_seurat &lt;- RunPCA(split_seurat)\n# Run UMAP\nsplit_seurat &lt;- RunUMAP(split_seurat, \n                        dims = 1:40, \n                        reduction = \"pca\", \n                        reduction.name = \"umap.unintegrated\")\n\n# 分群\nsplit_seurat &lt;- FindNeighbors(split_seurat, \n                              dims = 1:40, \n                              reduction = \"pca\")\nsplit_seurat &lt;- FindClusters(split_seurat, \n                             cluster.name = \"unintegrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1104454\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8974\nNumber of communities: 22\nElapsed time: 4 seconds\n\n# Plot UMAP\np1 &lt;- DimPlot(split_seurat, reduction = \"umap.unintegrated\", group.by = \"sample\")\np2 &lt;- DimPlot(split_seurat, reduction = \"umap.unintegrated\", split.by = \"sample\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\nFigure 1: 整合前的细胞分群情况\n\n\n\n\n可以看到，如果不进行整合，不同样本（ctrl vs. stim）间的细胞类型差异很大。The resulting clusters are defined both by cell type and stimulation condition, which creates challenges for downstream analysis. Condition-specific clustering of the cells indicates that we need to integrate the cells across conditions to ensure that cells of the same cell type cluster together.\n\n\n\n\n\n\nTip\n\n\n\n关于FindNeighbors()和FindClusters()的详细说明见下一节。\n\n\n\n\n\n\n\n\nWhy is it important the cells of the same cell type cluster together?\n\n\n\nWe want to identify cell types which are present in all samples/conditions/modalities within our dataset, and therefore would like to observe a representation of cells from both samples/conditions/modalities in every cluster. This will enable more interpretable results downstream (i.e. DE analysis, ligand-receptor analysis, differential abundance analysis…).\n\n\nIn this lesson, we will cover the integration of our samples across conditions, which is adapted from Seurat-整合.\n\n\n\n\n\n\nNote\n\n\n\n在此前的Seurat-基于SCTransform中我们学习了how to run through the workflow from normalization to clustering without integration. Other steps in the workflow remain fairly similar, but the samples would not necessarily be split in the beginning and integration would not be performed.\nIt can help to first run conditions individually if unsure what clusters to expect or expecting some different cell types between conditions (e.g. tumor and control samples), then run them together to see whether there are condition-specific clusters for cell types present in both conditions. Oftentimes, when clustering cells from multiple conditions there are condition-specific clusters and integration can help ensure the same cell types cluster together.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "单细胞数据整合（Integration）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#integration-using-cca",
    "href": "single_cell/scRNA-seq_online/06_integration.html#integration-using-cca",
    "title": "单细胞数据整合（Integration）",
    "section": "\n2.1 Integration using CCA",
    "text": "2.1 Integration using CCA\nSeurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches:\nThe anchor-based CCA integration (method=CCAIntegration) utilizes the canonical correlation analysis (CCA). This method expects “correspondences” or shared biological states among at least a subset of single cells across the groups. The steps in the Seurat integration workflow are outlined in the figure below:\n\n\nImage credit: (Stuart et al. 2019)\n\nThe different steps applied are as follows:\n\n\nPerform canonical correlation analysis (CCA):\nCCA identifies shared sources of variation between the conditions/groups. It is a form of PCA, in that it identifies the greatest sources of variation in the data, but only if it is shared or conserved across the conditions/groups (using the 3000 most variant genes from each sample).\nThis step roughly aligns the cells using the greatest shared sources of variation.\n\n\n\n\n\n\nNote\n\n\n\nThe shared highly variable genes are used because they are the most likely to represent those genes distinguishing the different cell types present.\n\n\n\n\nIdentify anchors or mutual nearest neighbors (MNNs) across datasets (sometimes incorrect anchors are identified):\nMNNs can be thought of as ‘best buddies’. For each cell in one condition:\n\nThe cell’s closest neighbor in the other condition is identified based on gene expression values - its ‘best buddy’.\nThe reciprocal analysis is performed, and if the two cells are ‘best buddies’ in both directions, then those cells will be marked as anchors to ‘anchor’ the two datasets together.\n\n\n“The difference in expression values between cells in an MNN pair provides an estimate of the batch effect, which is made more precise by averaging across many such pairs. A correction vector is obtained and applied to the expression values to perform batch correction.” (Stuart et al. 2019)\n\n\n\nFilter anchors to remove incorrect anchors:\nAssess the similarity between anchor pairs by the overlap in their local neighborhoods (incorrect anchors will have low scores) - do the adjacent cells have ‘best buddies’ that are adjacent to each other?\n\n\nIntegrate the conditions/datasets:\nUse anchors and corresponding scores to transform the cell expression values, allowing for the integration of the conditions/datasets (different samples, conditions, datasets, modalities)\n\n\n\n\n\n\nNote\n\n\n\nTransformation of each cell uses a weighted average of the two cells of each anchor across anchors of the datasets. Weights determined by cell similarity score (distance between cell and k nearest anchors) and anchor scores, so cells in the same neighborhood should have similar correction values.\n\n\nIf cell types are present in one dataset, but not the other, then the cells will still appear as a separate sample-specific cluster.\n\n\nNow, using our SCTransform object as input, let’s perform the integration across conditions.\n\n# 可以看到目前的降维信息包括\"pca\"和\"umap.unintegrated\"\nnames(split_seurat@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\"\n\n# 整合，比较耗时间（约13min），进度条会一直显示0%直至运算完成\nlibrary(beepr)\nseurat_integrated &lt;- IntegrateLayers(object = split_seurat,\n                                     method = CCAIntegration,\n                                     normalization.method = \"SCT\", # 指定使用的标准化方法为SCTransform\n                                     orig.reduction = \"pca\",\n                                     new.reduction = \"integrated.cca\", #  整合后新的降维数据的名称\n                                     verbose = FALSE); beep()\n\n# 整合后重新合并RNA layer\nseurat_integrated[[\"RNA\"]] &lt;- JoinLayers(seurat_integrated[[\"RNA\"]])\n\n# 查看整合后的降维信息\nnames(seurat_integrated@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"integrated.cca\"   \n\n\n\n\n\n\n\n\nTip\n\n\n\n如何调用Seurat嵌入的其他整合算法进行整合，参考：Seurat v5单细胞数据整合分析。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "单细胞数据整合（Integration）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#save-the-integrated-object",
    "href": "single_cell/scRNA-seq_online/06_integration.html#save-the-integrated-object",
    "title": "单细胞数据整合（Integration）",
    "section": "\n3.1 Save the “integrated” object!",
    "text": "3.1 Save the “integrated” object!\n\n# Save integrated seurat object\nsaveRDS(seurat_integrated, \"output/scRNA-seq_online/integrated_seurat.rds\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "单细胞数据整合（Integration）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_integration.html#harmonizing-as-a-method-of-integration",
    "href": "single_cell/scRNA-seq_online/06_integration.html#harmonizing-as-a-method-of-integration",
    "title": "单细胞数据整合（Integration）",
    "section": "\n4.1 Harmonizing as a method of integration",
    "text": "4.1 Harmonizing as a method of integration\nHarmony (Korsunsky et al. 2019) was devleoped in 2019, and is an example of a tool that can work with complex integration tasks. It is available as an GitHub and CRAN, and it has functions for standalone and Seurat pipeline analyses. It has been shown to perform incredibly well from recent benchmarking studies (Tran et al. 2020).\n在Seurat工作流的基础上实现基于Harmony的单细胞数据整合，可以使用Harmony包（available on GitHub and CRAN），详见该教程。同时，Seurat V5中的IntegrateLayers函数集成了Harmony整合算法，可以直接调用，详见：Seurat v5单细胞数据整合分析。Compared to other algorithms, Harmony notably presents the following advantages (Korsunsky et al. 2019) (Tran et al. 2020):\n\nPossibility to integrate data across several variables (for example, by experimental batch and by condition)\nSignificant gain in speed and lower memory requirements for integration of large datasets\nInteroperability with the Seurat workflow\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] beepr_1.3          cowplot_1.1.2      Seurat_5.0.1       SeuratObject_5.0.1\n[5] sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.3            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.2.0      ggridges_0.5.5        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.5           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.8        \n [25] goftest_1.2-3          later_1.3.2            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.6         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.3         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-4    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.12            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.1    audio_0.1-11           zoo_1.8-12            \n [46] sctransform_0.4.1      httpuv_1.6.13          Matrix_1.6-5          \n [49] splines_4.3.2          igraph_1.6.0           tidyselect_1.2.0      \n [52] abind_1.4-5            rstudioapi_0.15.0      yaml_2.3.8            \n [55] spatstat.random_3.2-2  codetools_0.2-19       miniUI_0.1.1.1        \n [58] spatstat.explore_3.2-5 listenv_0.9.0          lattice_0.22-5        \n [61] tibble_3.2.1           plyr_1.8.9             withr_3.0.0           \n [64] shiny_1.8.0            ROCR_1.0-11            evaluate_0.23         \n [67] Rtsne_0.17             future_1.33.1          fastDummies_1.7.3     \n [70] survival_3.5-7         polyclip_1.10-6        fitdistrplus_1.1-11   \n [73] pillar_1.9.0           KernSmooth_2.23-22     plotly_4.10.4         \n [76] generics_0.1.3         RcppHNSW_0.5.0         ggplot2_3.4.4         \n [79] munsell_0.5.0          scales_1.3.0           globals_0.16.2        \n [82] xtable_1.8-4           glue_1.7.0             lazyeval_0.2.2        \n [85] tools_4.3.2            data.table_1.14.10     RSpectra_0.16-1       \n [88] RANN_2.6.1             leiden_0.4.3.1         dotCall64_1.1-1       \n [91] grid_4.3.2             tidyr_1.3.0            colorspace_2.1-0      \n [94] nlme_3.1-164           patchwork_1.2.0        cli_3.6.2             \n [97] spatstat.sparse_3.0-3  spam_2.10-0            fansi_1.0.6           \n[100] viridisLite_0.4.2      dplyr_1.1.4            uwot_0.1.16           \n[103] gtable_0.3.4           digest_0.6.34          progressr_0.14.0      \n[106] ggrepel_0.9.5          farver_2.1.1           htmlwidgets_1.6.4     \n[109] htmltools_0.5.7        lifecycle_1.0.4        httr_1.4.7            \n[112] mime_0.12              MASS_7.3-60.0.1",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "单细胞数据整合（Integration）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html",
    "title": "细胞分群质量评估",
    "section": "",
    "text": "Learning Objectives:\n\n\n\n\nEvaluate whether clustering artifacts are present\nDetermine the quality of clustering with PCA and UMAP plots, and decide when to re-cluster\nAssess known cell type markers to hypothesize cell type identities of clusters\nAfter separating cells into clusters, it is crtical to evaluate whether they are biologically meaningful or not. At this point we can also decide if we need to re-cluster and/or potentialy go back to a previous QC step.\nIn this lesson you will:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#cd14-monocyte-markers",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#cd14-monocyte-markers",
    "title": "细胞分群质量评估",
    "section": "\n7.1 CD14+ monocyte markers",
    "text": "7.1 CD14+ monocyte markers\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"CD14\", \"LYZ\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nCD14+ monocytes appear to correspond to clusters 1, and 3. We wouldn’t include clusters 14 and 10 because they do not highly express both of these markers.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#sec-fcgr3a_monocyte_markers",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#sec-fcgr3a_monocyte_markers",
    "title": "细胞分群质量评估",
    "section": "\n7.2 FCGR3A+ monocyte markers",
    "text": "7.2 FCGR3A+ monocyte markers\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"FCGR3A\", \"MS4A7\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nFCGR3A+ monocytes markers distinctly highlight cluster 10, although we do see some decent expression in clusters 1 and 3. We would like to see additional markers for FCGR3A+ cells show up when we perform the marker identification.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#conventional-dendritic-cell-markers",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#conventional-dendritic-cell-markers",
    "title": "细胞分群质量评估",
    "section": "\n7.3 Conventional dendritic cell markers",
    "text": "7.3 Conventional dendritic cell markers\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"FCER1A\", \"CST3\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nThe markers corresponding to conventional dendritic cells identify cluster 14 (both markers consistently show expression).",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#plasmacytoid-dendritic-cell-markers",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#plasmacytoid-dendritic-cell-markers",
    "title": "细胞分群质量评估",
    "section": "\n7.4 Plasmacytoid dendritic cell markers",
    "text": "7.4 Plasmacytoid dendritic cell markers\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"IL3RA\", \"GZMB\", \"SERPINF1\", \"ITM2C\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nPlasmacytoid dendritic cells represent cluster 16. While there are a lot of differences in the expression of these markers, we see cluster 16 (though small) is consistently strongly expressed.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#macrophages",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#macrophages",
    "title": "细胞分群质量评估",
    "section": "\n7.5 Macrophages",
    "text": "7.5 Macrophages\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"MARCO\", \"ITGAM\", \"ADGRE1\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nWe don’t see much overlap of our markers, so no clusters appear to correspond to macrophages; perhaps cell culture conditions negatively selected for macrophages (more highly adherent).",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#b-cells",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#b-cells",
    "title": "细胞分群质量评估",
    "section": "\n7.6 B cells",
    "text": "7.6 B cells\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"CD79A\", \"MS4A1\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\n可以看出，cluster 11, 7, 13属于B细胞。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#t-cells",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#t-cells",
    "title": "细胞分群质量评估",
    "section": "\n7.7 T cells",
    "text": "7.7 T cells\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"CD3D\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nT细胞的标志物在大量的cluster中均表达，包括cluster 0, 2, 6, 4, 5, 9。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#sec-cd4_t_cells",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#sec-cd4_t_cells",
    "title": "细胞分群质量评估",
    "section": "\n7.8 CD4+ T cells",
    "text": "7.8 CD4+ T cells\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"CD3D\", \"IL7R\", \"CCR7\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\n大致看出cluster 4, 0, 6, 2属于CD4+ T 细胞。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#cd8-t-cells",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#cd8-t-cells",
    "title": "细胞分群质量评估",
    "section": "\n7.9 CD8+ T cells",
    "text": "7.9 CD8+ T cells\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"CD3D\", \"CD8A\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\ncluster 5和 cluster 9属于CD8+ T细胞。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#nk-cells",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#nk-cells",
    "title": "细胞分群质量评估",
    "section": "\n7.10 NK cells",
    "text": "7.10 NK cells\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"GNLY\", \"NKG7\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\ncluster 8, 12属于NK细胞。这和我们在前面的 Section 6 中的结论（第二主成分的top基因GNLY和NKG7在cluster 8和cluster 12中高表达）一致。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#megakaryocytes巨核细胞",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#megakaryocytes巨核细胞",
    "title": "细胞分群质量评估",
    "section": "\n7.11 Megakaryocytes（巨核细胞）",
    "text": "7.11 Megakaryocytes（巨核细胞）\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"PPBP\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\ncluster 15属于巨核细胞。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#erythrocytes红细胞",
    "href": "single_cell/scRNA-seq_online/08_SC_clustering_quality_control.html#erythrocytes红细胞",
    "title": "细胞分群质量评估",
    "section": "\n7.12 Erythrocytes（红细胞）",
    "text": "7.12 Erythrocytes（红细胞）\n\nFeaturePlot(seurat_clustered, \n            reduction = \"umap\", \n            features = c(\"HBB\", \"HBA2\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\n可以看到，红细胞的marker gene基本没有明显的表达。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞分群质量评估"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html",
    "title": "Normalization and regressing out unwanted variation",
    "section": "",
    "text": "Learning Objectives:\n\n\n\n\nDiscuss why normalizing counts is necessary for accurate comparison between cells\nDescribe different normalization approaches\nEvaluate the effects from any unwanted sources of variation and correct for them\nNow that we have our high quality cells, we can explore our data and see if we are able to identify any sources of unwanted variation. Depending on what we observe, we will utilize that information when performing variance stabilization using SCTransform but also to regress out the effects of any covariates that have an effect on our data.\nGoals:\nChallenges:\nRecommendations:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#methods-for-scrna-seq-normalization",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#methods-for-scrna-seq-normalization",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n1.1 Methods for scRNA-seq normalization",
    "text": "1.1 Methods for scRNA-seq normalization\nVarious methods have been developed specifically for scRNA-seq normalization. Some simpler methods resemble what we have seen with bulk RNA-seq; the application of global scale factors adjusting for a count-depth relationship that is assumed common across all genes. However, if those assumptions are not true then this basic normalization can lead to over-correction for lowly and moderately expressed genes and, in some cases, under-normalization of highly expressed genes (Bacher et al. 2017). More complex methods will apply correction on a per-gene basis. In this lesson we will explore both approaches.\nRegardless of which method is used for normalization, it can be helpful to think of it as a two-step process (even though it is often described as a single step in most papers). The first is a scaling step and the second is a transformation.\n1. Scaling\nThe first step in normalization is to multiply each UMI count by a cell specific factor to get all cells to have the same UMI counts. Why would we want to do this? Different cells have different amounts of mRNA; this could be due to differences between cell types or variation within the same cell type depending on how well the chemistry worked in one drop versus another. In either case, we are not interested in comparing these absolute counts between cells. Instead we are interested in comparing concentrations, and scaling helps achieve this.\n2. Transformation\nThe next step is a transformation, and it is at this step where we can distinguish the simpler versus complex methods as mentioned above.\nSimple transformations are those which apply the same function to each individual measurement. Common examples include a log transform (which is applied in the original Seurat workflow), or a square root transform (less commonly used).\nIn the (Hafemeister and Satija 2019) the authors explored the issues with simple transformations. Specifically they evaluated the standard log normalization approach and found that genes with different abundances are affected differently and that effective normalization (using the log transform) is only observed with low/medium abundance genes (Figure 1D, below). Additionally, substantial imbalances in variance were observed with the log-normalized data (Figure 1E, below). In particular, cells with low total UMI counts exhibited disproportionately higher variance for high-abundance genes, dampening the variance contribution from other gene abundances. \n\n\nImage credit: (Hafemeister and Satija 2019)\n\nThe conclusion is, we cannot treat all genes the same.\nThe proposed solution was the use of Pearson residuals for transformation, as implemented in Seurat’s SCTransform function. With this approach:\n\nMeasurements are multiplied by a gene-specific weight\nEach gene is weighted based on how much evidence there is that it is non-uniformly expressed across cells. More evidence == more of a weight\nGenes that are expressed in only a small fraction of cells will be favored (useful for finding rare cell populations)\nNot just a consideration of the expression level is, but also the distribution of expression\n\nIn this workshop we will demonstrate the use of both transformations at different steps in the workflow.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#set-up",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#set-up",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n2.1 Set-up",
    "text": "2.1 Set-up\nBefore we make any comparisons across cells, we will apply a simple normalization. This is solely for the purpose of exploring the sources of variation in our data.\nThe input for this analysis is a seurat object. We will use the one that we created in 质控 called filtered_seurat.\n\nlibrary(Seurat)\nfiltered_seurat &lt;- readRDS(\"output/scRNA-seq_online/seurat_filtered.rds\")\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts\n\nhead(filtered_seurat@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1\n\n# Normalize the counts\nseurat_phase &lt;- NormalizeData(filtered_seurat)\nseurat_phase\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 2 layers present: counts, data\n\n\n可以发现，运行NormalizeDataNext后的数据多出了新的layer：data, 里面即储存了标准化后的数据。Next, we take this normalized data and check to see if data correction methods are necessary.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#sec-evaluating_effects_of_cell_cycle",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#sec-evaluating_effects_of_cell_cycle",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n2.2 评估细胞周期的影响（Evaluating effects of cell cycle）",
    "text": "2.2 评估细胞周期的影响（Evaluating effects of cell cycle）\n计算细胞周期评分\n\n\n\n\n\n\nTip\n\n\n\n关于细胞周期的详细说明，见Seurat-消除细胞周期的影响。\n\n\nTo assign each cell a score based on its expression of G2/M and S phase markers, we can use the Seuart function CellCycleScoring(). This function calculates cell cycle phase scores based on canonical markers that required as input.\nA list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat. We can segregate this list into markers of G2/M phase and markers of S phase. However, if you are not working with human data we have additional materials detailing how to acquire cell cycle markers for other organisms of interest.\n\n# Load cell cycle markers\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n# Score cells for cell cycle\nseurat_phase &lt;- CellCycleScoring(seurat_phase, \n                                 g2m.features = g2m.genes, \n                                 s.features = s.genes)\n\n# 现在的meta.data中多出了细胞周期评分“S.Score”和“G2M.Score”，以及推断的细胞所处的周期“Phase”\nhead(seurat_phase@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1\n                          S.Score   G2M.Score Phase\nctrl_AAACATACAATGCC-1  0.02713602  0.04344302   G2M\nctrl_AAACATACATTTCC-1  0.01519129  0.01846409   G2M\nctrl_AAACATACCAGAAA-1 -0.05272781 -0.05038367    G1\nctrl_AAACATACCAGCTA-1 -0.05194312  0.04583528   G2M\nctrl_AAACATACCATGCA-1  0.04406978 -0.03445262     S\nctrl_AAACATACCTCGCT-1  0.03421052  0.02033139     S\n\n# 查看一下细胞周期的分布情况\ntable(seurat_phase$Phase)\n\n\n   G1   G2M     S \n10387  9547  9695 \n\n\n使用PCA确定细胞周期是否是我们数据集中的主要变异来源\nAfter scoring the cells for cell cycle, we would like to determine whether cell cycle is a major source of variation in our dataset using PCA（见PCA原理）.\nTo perform PCA, we need to first choose the most variable features, then scale the data. Since highly expressed genes exhibit the highest amount of variation and we don’t want our ‘highly variable genes’ only to reflect high expression, we need to scale the data to scale variation with expression level. The Seurat ScaleData() function will scale the data by:\n\nadjusting the expression of each gene to give a mean expression across cells to be 0\n\nscaling expression of each gene to give a variance across cells to be 1\n\n\n\n# Identify the most variable genes\nseurat_phase &lt;- FindVariableFeatures(seurat_phase, \n                                     selection.method = \"vst\", # 默认值\n                                     nfeatures = 2000) # 默认值\n             \n# Scale the counts\nseurat_phase &lt;- ScaleData(seurat_phase)\nLayers(seurat_phase)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n\n可以发现，运行ScaleData后的数据多出了新的layer：scale.data, 里面即储存了归一化后的数据。Now, we can perform the PCA analysis and plot the first two principal components against each other. We also split the figure by cell cycle phase, to evaluate similarities and/or differences.\n\n# Perform PCA。如果没有指定features，RunPCA默认使用FindVariableFeatures找到的高变基因作为PCA输入.\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\",\n              split.by = \"Phase\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\n\nWe do not see large differences due to cell cycle phase. Based on this plot, we would not regress out the variation due to cell cycle.\n\n\n\n\n\n\nWhen should cell cycle phase be regressed out?\n\n\n\n\n\nBelow are two PCA plots taken from Seurat-消除细胞周期的影响。This first plot is similar to what we plotted above, it is a PCA prior to regression to evaluate if the cell cycle is playing a big role in driving PC1 and PC2. Clearly, the cells are separating by cell type in this case, so it suggests regressing out these effects.\n\nThis second PCA plot is post-regression, and displays how effective the regression was in removing the effect we observed.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n在需要消除细胞周期的影响时，如何通过ScaleData回归掉（regress out）细胞周期的影响，以及如何在消除细胞周期的影响同时保留增殖细胞与静止细胞的区分，参考 Seurat-消除细胞周期的影响。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#评估线粒体基因表达的影响",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#评估线粒体基因表达的影响",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n2.3 评估线粒体基因表达的影响",
    "text": "2.3 评估线粒体基因表达的影响\nMitochondrial expression is another factor which can greatly influence clustering. Oftentimes, it is useful to regress out variation due to mitochondrial expression. However, if the differences in mitochondrial gene expression represent a biological phenomenon that may help to distinguish cell clusters, then we advise not regressing this out. In this exercise, we can perform a quick check similar to looking at cell cycle and decide whether or not we want to regress it out.\n\n\nFirst, turn the mitochondrial ratio variable into a new categorical variable based on quartiles. 根据各细胞线粒体基因的比例的四分位数将所有细胞分为低线粒体基因比例细胞、中线粒体基因比例细胞···\n\n# Check quartile values\nsummary(seurat_phase$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01438 0.01993 0.02139 0.02669 0.14464 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nseurat_phase$mitoFr &lt;- cut(seurat_phase@meta.data$mitoRatio, \n                           breaks=c(-Inf, 0.0144, 0.0199, 0.0267, Inf), \n                           labels=c(\"Low\", \"Medium\", \"Medium high\", \"High\"))\ntable(seurat_phase$mitoFr)\n\n\n        Low      Medium Medium high        High \n       7443        7325        7459        7402 \n\n\n\n\nNext, plot the PCA similar to how we did with cell cycle regression. Hint: use the new mitoFr variable to split cells and color them accordingly.\n\n# 根据各细胞线粒体基因的比例信息绘制PCA\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\",\n              split.by = \"mitoFr\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\n\n\n\nEvaluate the PCA plot.\nWe do not see large differences due to mitochondrial expression. Based on this plot, we would not regress out the variation due to mitochondrial expression.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#数据导入",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#数据导入",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n3.1 数据导入",
    "text": "3.1 数据导入\n前面的流程和此前一样\n\nrm(list = ls())\n\nlibrary(Seurat)\nfiltered_seurat &lt;- readRDS(\"output/scRNA-seq_online/seurat_filtered.rds\")\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts\n\nhead(filtered_seurat@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#执行sctransform",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#执行sctransform",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n3.2 执行SCTransform\n",
    "text": "3.2 执行SCTransform\n\n\n这里先运行一次SCTransform以便后面评估细胞周期、线粒体基因等非期望变异来源（This is solely for the purpose of exploring the sources of variation in our data）\nSCTransform替代了传统单细胞数据分析流程中的NormalizeData()、ScaleData()和FindVariableFeatures()函数的功能，因此不再需要运行这些函数。\nIn Seurat v5, SCT v2 is applied by default. You can revert to v1 by setting vst.flavor = 'v1'。\nSCTransform的运算调用了glmGamPoi包以显著提升运算速度。所以事先需要通过BiocManager安装该包。\n\n\n# SCTranform\n# BiocManager::install(\"glmGamPoi\")\nseurat_phase &lt;- SCTransform(filtered_seurat, verbose = FALSE)\nseurat_phase\n\nAn object of class Seurat \n28130 features across 29629 samples within 2 assays \nActive assay: SCT (14065 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n\n# Check which assays are stored in objects\nseurat_phase@assays\n\n$RNA\nAssay (v5) data with 14065 features for 29629 cells\nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \nLayers:\n counts \n\n$SCT\nSCTAssay data with 14065 features for 29629 cells, and 1 SCTModel(s) \nTop 10 variable features:\n CCL8, IGKC, CXCL10, FTL, CCL2, CCL7, ISG15, GNLY, IGLC2, CCL4 \n\n# 查看目前默认的assay\nDefaultAssay(seurat_phase)\n\n[1] \"SCT\"\n\n# 查看默认assay的layers\nLayers(seurat_phase)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n\nNote, the last line of output specifies “Set default assay to SCT”. 表明运行SCTransform之后，会将默认的assay指定为SCTransform之后的数据。This specifies that moving forward we would like to use the data after SCT was implemented. We can view the different assays that we have stored in our seurat object.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#评估细胞周期的影响",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#评估细胞周期的影响",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n3.3 评估细胞周期的影响",
    "text": "3.3 评估细胞周期的影响\n\n# Load cell cycle markers\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n# Score cells for cell cycle\nseurat_phase &lt;- CellCycleScoring(seurat_phase, \n                                 g2m.features = g2m.genes, \n                                 s.features = s.genes)\n\n# 现在的meta.data中多出了细胞周期评分“S.Score”和“G2M.Score”，以及推断的细胞所处的周期“Phase”\nhead(seurat_phase@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1\n                      nCount_SCT nFeature_SCT      S.Score    G2M.Score Phase\nctrl_AAACATACAATGCC-1       1591          863  0.010526369  0.011803814   G2M\nctrl_AAACATACATTTCC-1       1553          724  0.010251663  0.015119823   G2M\nctrl_AAACATACCAGAAA-1       1549          668 -0.019803499 -0.015779795    G1\nctrl_AAACATACCAGCTA-1       1579          777 -0.032093208  0.013380044   G2M\nctrl_AAACATACCATGCA-1       1096          371  0.008301833 -0.008402066     S\nctrl_AAACATACCTCGCT-1       1493          632  0.018235066  0.018993438   G2M\n\n# 查看一下细胞周期的分布情况\ntable(seurat_phase$Phase)\n\n\n   G1   G2M     S \n10554  9586  9489 \n\n# 执行PCA\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"Phase\",\n              split.by = \"Phase\")\nlibrary(cowplot)\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#评估线粒体基因的影响",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#评估线粒体基因的影响",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n3.4 评估线粒体基因的影响",
    "text": "3.4 评估线粒体基因的影响\n\n# Check quartile values\nsummary(seurat_phase$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01438 0.01993 0.02139 0.02669 0.14464 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nseurat_phase$mitoFr &lt;- cut(seurat_phase@meta.data$mitoRatio, \n                           breaks=c(-Inf, 0.0144, 0.0199, 0.0267, Inf), \n                           labels=c(\"Low\", \"Medium\", \"Medium high\", \"High\"))\ntable(seurat_phase$mitoFr)\n\n\n        Low      Medium Medium high        High \n       7443        7325        7459        7402 \n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\")\np2 &lt;- DimPlot(seurat_phase,\n              reduction = \"pca\",\n              group.by= \"mitoFr\",\n              split.by = \"mitoFr\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#re_sctransform",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#re_sctransform",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n3.5 分割layer，再次执行SCTranform",
    "text": "3.5 分割layer，再次执行SCTranform\nSince we have two samples in our dataset (from two conditions), we want to keep them as separate layers and transform them as that is what is required for integration.\n\n# Split RNA assay by condition to perform cell cycle scoring and SCT on all samples\nseurat_phase[[\"RNA\"]] &lt;- split(seurat_phase[[\"RNA\"]], \n                               f = seurat_phase$sample) # 按照meta.data中的“sample”列进行分割\nseurat_phase\n\nAn object of class Seurat \n28130 features across 29629 samples within 2 assays \nActive assay: SCT (14065 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n 1 dimensional reduction calculated: pca\n\n\n现在可以发现RNA assay的counts和data按照”seurat_phase$sample”（ctrl vs. stim）被分别分割成了2个layer：\n\nNow we will run the SCTransform() on each sample, and regress out mitochondrial expression by specifying in the vars.to.regress argument of the SCTransform() function.\n\n\n\n\n\n\nTip\n\n\n\nThe output of SCTransform() can generate large R objects/variables in terms of memory. If we have a large dataset, then we might need to adjust the limit for allowable object sizes within R (Default is 500 1024 ^ 2 = 500 Mb*) using the following code:\n\n```{r}\n#| eval: false\noptions(future.globals.maxSize = 4000 * 1024^2)\n```\n\n如果出现如下报错：\nError: vector memory exhausted (limit reached?)\n说明所处理的数据量超出了R内存分配上限，请参阅提高R内存分配上限（macOS）进行处理。\n\n\n执行SCTranform\n\n# SCTranform\nseurat_phase &lt;- SCTransform(seurat_phase, \n                            vars.to.regress = c(\"mitoRatio\"),\n                            verbose = FALSE)\n\nBy default, after normalizing, adjusting the variance, and regressing out uninteresting sources of variation, SCTransform will rank the genes by residual variance and output the 3000 most variant genes. If the dataset has larger cell numbers, then it may be beneficial to adjust this parameter higher using the variable.features.n argument.\nNow we can see that in addition to the raw RNA counts, we now have a SCT component in our assays slot. The most variable features will be the only genes stored inside the SCT assay. As we move through the scRNA-seq analysis, we will choose the most appropriate assay to use for the different steps in the analysis.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#save-the-object",
    "href": "single_cell/scRNA-seq_online/06_SC_SCT_normalization.html#save-the-object",
    "title": "Normalization and regressing out unwanted variation",
    "section": "\n3.6 Save the object!",
    "text": "3.6 Save the object!\n\nsaveRDS(seurat_phase, \"output/scRNA-seq_online/split_seurat.rds\")\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] cowplot_1.1.2      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.8              magrittr_2.0.3             \n  [5] spatstat.utils_3.0-4        farver_2.1.1               \n  [7] rmarkdown_2.25              zlibbioc_1.48.0            \n  [9] vctrs_0.6.5                 ROCR_1.0-11                \n [11] DelayedMatrixStats_1.24.0   spatstat.explore_3.2-5     \n [13] RCurl_1.98-1.14             S4Arrays_1.2.0             \n [15] htmltools_0.5.7             SparseArray_1.2.3          \n [17] sctransform_0.4.1           parallelly_1.36.0          \n [19] KernSmooth_2.23-22          htmlwidgets_1.6.4          \n [21] ica_1.0-3                   plyr_1.8.9                 \n [23] plotly_4.10.4               zoo_1.8-12                 \n [25] igraph_1.6.0                mime_0.12                  \n [27] lifecycle_1.0.4             pkgconfig_2.0.3            \n [29] Matrix_1.6-5                R6_2.5.1                   \n [31] fastmap_1.1.1               GenomeInfoDbData_1.2.11    \n [33] MatrixGenerics_1.14.0       fitdistrplus_1.1-11        \n [35] future_1.33.1               shiny_1.8.0                \n [37] digest_0.6.34               colorspace_2.1-0           \n [39] patchwork_1.2.0             S4Vectors_0.40.2           \n [41] tensor_1.5                  RSpectra_0.16-1            \n [43] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [45] labeling_0.4.3              progressr_0.14.0           \n [47] fansi_1.0.6                 spatstat.sparse_3.0-3      \n [49] httr_1.4.7                  polyclip_1.10-6            \n [51] abind_1.4-5                 compiler_4.3.2             \n [53] withr_3.0.0                 fastDummies_1.7.3          \n [55] MASS_7.3-60.0.1             DelayedArray_0.28.0        \n [57] tools_4.3.2                 lmtest_0.9-40              \n [59] httpuv_1.6.13               future.apply_1.11.1        \n [61] goftest_1.2-3               glmGamPoi_1.14.0           \n [63] glue_1.7.0                  nlme_3.1-164               \n [65] promises_1.2.1              grid_4.3.2                 \n [67] Rtsne_0.17                  cluster_2.1.6              \n [69] reshape2_1.4.4              generics_0.1.3             \n [71] gtable_0.3.4                spatstat.data_3.0-4        \n [73] tidyr_1.3.0                 data.table_1.14.10         \n [75] XVector_0.42.0              utf8_1.2.4                 \n [77] BiocGenerics_0.48.1         spatstat.geom_3.2-7        \n [79] RcppAnnoy_0.0.21            ggrepel_0.9.5              \n [81] RANN_2.6.1                  pillar_1.9.0               \n [83] stringr_1.5.1               spam_2.10-0                \n [85] RcppHNSW_0.5.0              later_1.3.2                \n [87] splines_4.3.2               dplyr_1.1.4                \n [89] lattice_0.22-5              survival_3.5-7             \n [91] deldir_2.0-2                tidyselect_1.2.0           \n [93] miniUI_0.1.1.1              pbapply_1.7-2              \n [95] knitr_1.45                  gridExtra_2.3              \n [97] IRanges_2.36.0              SummarizedExperiment_1.32.0\n [99] scattermore_1.2             stats4_4.3.2               \n[101] xfun_0.41                   Biobase_2.62.0             \n[103] matrixStats_1.2.0           stringi_1.8.3              \n[105] lazyeval_0.2.2              yaml_2.3.8                 \n[107] evaluate_0.23               codetools_0.2-19           \n[109] tibble_3.2.1                cli_3.6.2                  \n[111] uwot_0.1.16                 xtable_1.8-4               \n[113] reticulate_1.34.0           munsell_0.5.0              \n[115] Rcpp_1.0.12                 GenomeInfoDb_1.38.5        \n[117] globals_0.16.2              spatstat.random_3.2-2      \n[119] png_0.1-8                   parallel_4.3.2             \n[121] ellipsis_0.3.2              ggplot2_3.4.4              \n[123] dotCall64_1.1-1             sparseMatrixStats_1.14.0   \n[125] bitops_1.0-7                listenv_0.9.0              \n[127] viridisLite_0.4.2           scales_1.3.0               \n[129] ggridges_0.5.5              crayon_1.5.2               \n[131] leiden_0.4.3.1              purrr_1.0.2                \n[133] rlang_1.1.3",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Normalization and regressing out unwanted variation"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html",
    "title": "质控",
    "section": "",
    "text": "Learning Objectives:\nEach step of this workflow has its own goals and challenges. For QC of our raw count data, they include:\nGoals:\nChallenges:\nRecommendations:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#novelty-score",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#novelty-score",
    "title": "质控",
    "section": "\n1.1 Novelty score",
    "text": "1.1 Novelty score\nThis value is quite easy to calculate, as we take the log10 of the number of genes detected per cell and the log10 of the number of UMIs per cell, then divide the log10 number of genes by the log10 number of UMIs. The novelty score and how it relates to complexity of the RNA species, is described in more detail later in this lesson.\n\n# Add number of genes per UMI for each cell to metadata\nmerged_seurat$log10GenesPerUMI &lt;- log10(merged_seurat$nFeature_RNA) / log10(merged_seurat$nCount_RNA)\nhead(merged_seurat@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\n                      log10GenesPerUMI\nctrl_AAACATACAATGCC-1        0.8728630\nctrl_AAACATACATTTCC-1        0.8447596\nctrl_AAACATACCAGAAA-1        0.8384933\nctrl_AAACATACCAGCTA-1        0.8512622\nctrl_AAACATACCATGCA-1        0.8906861\nctrl_AAACATACCTCGCT-1        0.8283053\n\nsummary(merged_seurat$log10GenesPerUMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.5490  0.8565  0.8739  0.8734  0.8907  0.9785",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#mitochondrial-ratio",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#mitochondrial-ratio",
    "title": "质控",
    "section": "\n1.2 Mitochondrial Ratio",
    "text": "1.2 Mitochondrial Ratio\nSeurat has a convenient function that allows us to calculate the proportion of transcripts mapping to mitochondrial genes. The PercentageFeatureSet() function takes in a pattern argument and searches through all gene identifiers in the dataset for that pattern. Since we are looking for mitochondrial genes, we are searching any gene identifiers that begin with the pattern “MT-”. For each cell, the function takes the sum of counts across all genes (features) belonging to the “Mt-” set, and then divides by the count sum for all genes (features). This value is multiplied by 100 to obtain a percentage value.\n\n\n\n\n\n\nNote\n\n\n\nFor our analysis, rather than using a percentage value we would prefer to work with the ratio value. As such, we will reverse that last step performed by the function by taking the output value and dividing by 100.\n\n\n\n# Compute percent mito ratio\nmerged_seurat$mitoRatio &lt;- PercentageFeatureSet(object = merged_seurat, pattern = \"^MT-\")\nmerged_seurat$mitoRatio &lt;- merged_seurat@meta.data$mitoRatio / 100\nsummary(merged_seurat$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01422 0.01993 0.02174 0.02696 0.39940 \n\nboxplot(merged_seurat$mitoRatio)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pattern provided (“^MT-”) works for human gene names. You may need to adjust the pattern argument depending on your organism of interest. Additionally, if you weren’t using gene names as the gene ID then this function wouldn’t work as we have used it above as the pattern will not suffice. Since there are caveats to using this function, it is advisable to manually compute this metric. If you are interested, we have code available to compute this metric on your own.\n\n\n\n\n\n\n\n\n识别核糖体基因\n\n\n\n这里我们没有对核糖体基因进行评估和过滤。在实际操作中应该根据细胞类型和条件决定是否过滤核糖体基因及过滤的阈值。\n如下表所示，人类核糖体基因的基因名以“RPS”或“RPL”开头，因此可以通过”^RP[SL]“正则表达式来识别这些核糖体基因。\n\n\n人类核糖体基因（来自gencode.v32.annotation.gtf文件）\n\n\nmerged_seurat$riboRatio &lt;- PercentageFeatureSet(\n  object = merged_seurat, \n  pattern = \"^RP[SL]\"\n  )",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#additional-metadata-columns",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#additional-metadata-columns",
    "title": "质控",
    "section": "\n1.3 Additional metadata columns",
    "text": "1.3 Additional metadata columns\nWe are a now all set with quality metrics required for assessing our data. However, we would like to include some additional information that would be useful to have in our metadata including cell IDs and condition information.\nWhen we added columns of information to our metadata file above, we simply added it directly to the metadata slot in the Seurat object using the $ operator.\nWe’ll add a new column for cell identifiers. This information is currently located in the row names of our metadata dataframe. We will keep the rownames as is and duplicate it into a new column called cells:\n\n# Add cell IDs to metadata\nmerged_seurat$cells &lt;- rownames(merged_seurat@meta.data)\n\nNow you are all setup with the metrics you need to assess the quality of your data! Your final metadata table will have rows that correspond to each cell, and columns with information about those cells.\n\n# 保存\nsaveRDS(merged_seurat, file = \"output/scRNA-seq_online/merged_seurat_with_qc_metrics.rds\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#cell-counts",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#cell-counts",
    "title": "质控",
    "section": "\n2.1 Cell counts",
    "text": "2.1 Cell counts\nThe cell counts are determined by the number of unique cellular barcodes detected. For this experiment, between 12,000 -13,000 cells are expected.\nIn an ideal world, you would expect the number of unique cellular barcodes to correpsond to the number of cells you loaded. However, this is not the case as capture rates of cells are only a proportion of what is loaded. For example, the inDrops cell capture efficiency is higher (70-80%) compared to 10X which is between 50-60%.\n\n\n\n\n\n\nNote\n\n\n\nThe capture efficiency could appear much lower if the cell concentration used for library preparation was not accurate. Cell concentration should NOT be determined by FACS machine or Bioanalyzer (these tools are not accurate for concentration determination), instead use a hemocytometer or automated cell counter for calculation of cell concentration.\n\n\nThe cell numbers can also vary by protocol, producing cell numbers that are much higher than what we loaded. For example, during the inDrops protocol, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. Similarly, with the 10X protocol there is a chance of obtaining only a barcoded bead in the emulsion droplet (GEM) and no actual cell. Both of these, in addition to the presence of dying cells can lead to a higher number of cellular barcodes than cells.\n\n# Visualize the number of cell counts per sample\nlibrary(ggplot2)\nmerged_seurat@meta.data  |&gt; \n    ggplot(aes(x = sample, fill = sample)) + \n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n    theme(plot.title = element_text(hjust = 0.5, face = \"bold\")) +\n    ggtitle(\"NCells\")\n\n\n\n\n\n\n\nWe see over 15,000 cells per sample, which is quite a bit more than the 12-13,000 expected. It is clear that we likely have some junk ‘cells’ present.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#umi-counts-transcripts-per-cell",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#umi-counts-transcripts-per-cell",
    "title": "质控",
    "section": "\n2.2 UMI counts (transcripts) per cell",
    "text": "2.2 UMI counts (transcripts) per cell\nThe UMI counts per cell should generally be above 500, that is the low end of what we expect. If UMI counts are between 500-1000 counts, it is usable but the cells probably should have been sequenced more deeply.\n\n# Visualize the number UMIs/transcripts per cell\nmerged_seurat@meta.data |&gt; \n    ggplot(aes(color = sample, x = nCount_RNA, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    ylab(\"Cell density\") +\n    geom_vline(xintercept = 500)\n\n\n\n\n\n\n\nWe can see that majority of our cells in both samples have 1000 UMIs or greater, which is great.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#genes-detected-per-cell",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#genes-detected-per-cell",
    "title": "质控",
    "section": "\n2.3 Genes detected per cell",
    "text": "2.3 Genes detected per cell\nWe have similar expectations for gene detection as for UMI detection, although it may be a bit lower than UMIs. For high quality data, the proportional histogram should contain a single large peak that represents cells that were encapsulated. If we see a small shoulder to the left of the major peak (not present in our data), or a bimodal distribution of the cells, that can indicate a couple of things:\n\nIt might be that there are a set of cells that failed for some reason.\nIt could also be that there are biologically different types of cells (i.e. quiescent cell populations, less complex cells of interest), and/or one type is much smaller than the other (i.e. cells with high counts may be cells that are larger in size).\n\nTherefore, this threshold should be assessed with other metrics that we describe in this lesson.\n\n# Visualize the distribution of genes detected per cell via histogram\nmerged_seurat@meta.data |&gt;\n    ggplot(aes(color = sample, x = nFeature_RNA, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    theme_classic() +\n    scale_x_log10() + \n    geom_vline(xintercept = 250)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#complexity",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#complexity",
    "title": "质控",
    "section": "\n2.4 Complexity",
    "text": "2.4 Complexity\nWe can evaluate each cell in terms of how complex the RNA species are by using a measure called the novelty score. The novelty score is computed by taking the ratio of nGenes over nUMI. If there are many captured transcripts (high nUMI) and a low number of genes detected in a cell, this likely means that you only captured a low number of genes and simply sequenced transcripts from those lower number of genes over and over again. These low complexity (low novelty) cells could represent a specific cell type (i.e. red blood cells which lack a typical transcriptome), or could be due to an artifact or contamination. Generally, we expect the novelty score to be above 0.80 for good quality cells.\n\n# Visualize the overall complexity of the gene expression by visualizing the genes detected per UMI (novelty score)\nmerged_seurat@meta.data |&gt;\n    ggplot(aes(x = log10GenesPerUMI, color = sample, fill=sample)) +\n    geom_density(alpha = 0.2) +\n    theme_classic() +\n    geom_vline(xintercept = 0.8)\n\n\n\n\n\n\n\n如果有较多的细胞处于较低的novelty score，表示可能样品受到了红细胞等低复杂性细胞的污染。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#mitochondrial-counts-ratio",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#mitochondrial-counts-ratio",
    "title": "质控",
    "section": "\n2.5 Mitochondrial counts ratio",
    "text": "2.5 Mitochondrial counts ratio\nThis metric can identify whether there is a large amount of mitochondrial contamination from dead or dying cells. We define poor quality samples for mitochondrial counts as cells which surpass the 0.2 mitochondrial ratio mark, unless of course you are expecting this in your sample.\n\n# Visualize the distribution of mitochondrial gene expression detected per cell\nmerged_seurat@meta.data |&gt;\n    ggplot(aes(color = sample, x = mitoRatio, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nReads per cell is another metric that can be useful to explore; however, the workflow used would need to save this information to assess. Generally, with this metric you hope to see all of the samples with peaks in relatively the same location between 10,000 and 100,000 reads per cell.\n\n\nVisualize QC metrics as a violin plot:\n\nVlnPlot(merged_seurat, \n        features = c(\"nFeature_RNA\", \"nCount_RNA\", \"log10GenesPerUMI\", \"mitoRatio\"), \n        ncol = 4,\n        pt.size = 0)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#joint-filtering-effects",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#joint-filtering-effects",
    "title": "质控",
    "section": "\n2.6 Joint filtering effects",
    "text": "2.6 Joint filtering effects\nConsidering any of these QC metrics in isolation can lead to misinterpretation of cellular signals. For example, cells with a comparatively high fraction of mitochondrial counts may be involved in respiratory processes and may be cells that you would like to keep. Likewise, other metrics can have other biological interpretations. A general rule of thumb when performing QC is to set thresholds for individual metrics to be as permissive as possible, and always consider the joint effects of these metrics. In this way, you reduce the risk of filtering out any viable cell populations.\nTwo metrics that are often evaluated together are the number of UMIs and the number of genes detected per cell. Here, we have plotted the number of genes versus the number of UMIs coloured by the fraction of mitochondrial reads. Jointly visualizing the count and gene thresholds and additionally overlaying the mitochondrial fraction, gives a summarized persepective of the quality per cell.\n\n# Visualize the correlation between genes detected and number of UMIs and determine whether strong presence of cells with low numbers of genes/UMIs\nmerged_seurat@meta.data |&gt; \n    ggplot(aes(x = nCount_RNA, y = nFeature_RNA, color = mitoRatio)) + \n    geom_point() + \n    scale_colour_gradient(low = \"gray90\", high = \"black\") +\n    stat_smooth(method = lm) +\n    scale_x_log10() + \n    scale_y_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 500) +\n    geom_hline(yintercept = 250) +\n    facet_wrap(~sample)\n\n\n\n\n\n\n\nGood cells will generally exhibit both higher number of genes per cell and higher numbers of UMIs (upper right quadrant of the plot). Cells that are poor quality are likely to have low genes and UMIs per cell, and correspond to the data points in the bottom left quadrant of the plot. With this plot we also evaluate the slope of the line, and any scatter of data points in the bottom right hand quadrant of the plot. These cells have a high number of UMIs but only a few number of genes. These could be dying cells, but also could represent a population of a low complexity celltype (i.e red blood cells).\n\n\n好的细胞通常会表现出更多的基因数量和更多的UMI(图的右上象限)。\n质量差的细胞可能具有较低的基因和UMI，对应于该图左下角象限中的数据点。\n我们还希望所有样品都有类似的线条和相似的斜率。\n该图右下角中的散在数据点表示这些细胞有大量的UMI，但只有少数几个基因。这些可能是濒临死亡的细胞，也可能代表一种低复杂性细胞类型(即红细胞)。\n\n\nMitochondrial read fractions are only high in particularly low count cells with few detected genes (darker colored data points). This could be indicative of damaged/dying cells whose cytoplasmic mRNA has leaked out through a broken membrane, and thus, only mRNA located in the mitochondria is still conserved. We can see from the plot, that these cells are filtered out by our count and gene number thresholds.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#cell-level-filtering",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#cell-level-filtering",
    "title": "质控",
    "section": "\n3.1 Cell-level filtering",
    "text": "3.1 Cell-level filtering\nNow that we have visualized the various metrics, we can decide on the thresholds to apply which will result in the removal of low quality cells. Often the recommendations mentioned earlier are a rough guideline, and the specific experiment needs to inform the exact thresholds chosen. We will use the following thresholds:\n\n在完成了细胞质量可视化评估之后就可以确定一系列质量控制的阈值来进行低质量细胞的过滤。这里选择如下阈值：\n\n\nnUMI &gt; 500\nnGene &gt; 250\nlog10GenesPerUMI &gt; 0.8\nmitoRatio &lt; 0.2\n\nTo filter, we wil go back to our Seurat object and use the subset() function:\n\n# Filter out low quality cells using selected thresholds - these will change with experiment\nfiltered_seurat &lt;- subset(x = merged_seurat, \n                          subset= (nCount_RNA &gt;= 500) & \n                                  (nFeature_RNA &gt;= 250) & \n                                  (log10GenesPerUMI &gt; 0.80) & \n                                  (mitoRatio &lt; 0.20))\npaste0(\"质控过滤掉了\", ncol(merged_seurat) - ncol(filtered_seurat), \"个细胞\")\n\n[1] \"质控过滤掉了1815个细胞\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#gene-level-filtering",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#gene-level-filtering",
    "title": "质控",
    "section": "\n3.2 Gene-level filtering",
    "text": "3.2 Gene-level filtering\nWithin our data we will have many genes with zero counts. These genes can dramatically reduce the average expression for a cell and so we will remove them from our data. We will start by identifying which genes have a zero count in each cell:\n\nLayers(filtered_seurat)\n\n[1] \"counts\"\n\n# 在seurat V5中不同样本的数据被放到不同的layer中，为了方便后面计数基因，所以先将layer合并\nfiltered_seurat &lt;- JoinLayers(filtered_seurat)\nLayers(filtered_seurat)\n\n[1] \"counts\"\n\n# Extract counts\ncounts &lt;- filtered_seurat@assays[[\"RNA\"]]@layers[[\"counts\"]]\n\nNow, we will perform some filtering by prevalence. If a gene is only expressed in a handful of cells, it is not particularly meaningful as it still brings down the averages for all other cells it is not expressed in. For our data we choose to keep only genes which are expressed in 10 or more cells. By using this filter, genes which have zero counts in all cells will effectively be removed.\n\n# Only keeping those genes expressed in more than 10 cells\nkeep_genes &lt;- rownames(filtered_seurat)[rowSums(counts &gt; 0) &gt;= 10]\n\npaste0(\"过滤掉了\", nrow(filtered_seurat) - length(keep_genes), \"个基因；剩余\", \n       length(keep_genes), \"个基因\")\n\n[1] \"过滤掉了19473个基因；剩余14065个基因\"\n\n# 过滤基因\nfiltered_seurat &lt;- subset(filtered_seurat, \n                          features = keep_genes)\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#cell-counts-1",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#cell-counts-1",
    "title": "质控",
    "section": "\n6.1 Cell counts",
    "text": "6.1 Cell counts\nThe cell counts are determined by the number of unique cellular barcodes detected. During the droplet-based protocols, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. We often see all possible combinations of cellular barcodes at a low level, leading to a higher number of cellular barcodes than cells.\nYou expect the number of unique cellular barcodes to be often greater than the number of seuqenced cells due to some hydrogels having more than one cellular barcode. The yellow sample below seems to have at least double the number of cellular barcodes as the other samples.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#umi-counts-per-cell",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#umi-counts-per-cell",
    "title": "质控",
    "section": "\n6.2 UMI counts per cell",
    "text": "6.2 UMI counts per cell\nThe number of UMIs per cell tends to be very low for the Unsorted sample (yellow). The other samples have good numbers of UMIs per cell, indicating a problem only with the Unsorted sample. Using this cutoff, we will lose the majority of the Unsorted cells.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#genes-detected-per-cell-1",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#genes-detected-per-cell-1",
    "title": "质控",
    "section": "\n6.3 Genes detected per cell",
    "text": "6.3 Genes detected per cell\nSeeing gene detection in the range of 500-5000 is normal for inDrop/10X analyses. However, expectations can vary depending on the complexity of the cells expected in the experiment. Similar expectations for gene detection as for UMI detection.\nAll samples other than the Unsorted sample have a good number of genes detected (with medians between 1,000 - 3,000 genes), which correspond to the numbers of UMIs per cell for each sample. However, the Unsorted sample has a very low median number of genes per cell, indicating a sample failure.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#umis-vs.-genes-detected",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#umis-vs.-genes-detected",
    "title": "质控",
    "section": "\n6.4 UMIs vs. genes detected",
    "text": "6.4 UMIs vs. genes detected\nPoor quality cells are likely to have low genes and UMIs per cell. Therefore, a poor sample is likely to have cells in the lower left of the graph. Good cells should exhibit both higher number of genes per cell and higher numbers of UMIs. We also expect similar lines with similar slopes for all samples.\nThe Unsorted sample has many cells with few UMIs and low number of genes per cell. The other samples look fine.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#mitochondrial-counts-ratio-1",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#mitochondrial-counts-ratio-1",
    "title": "质控",
    "section": "\n6.5 Mitochondrial counts ratio",
    "text": "6.5 Mitochondrial counts ratio\nPoor quality samples for mitochondrial counts would have larger peaks above the 0.1 mitochondrial ratio mark, unless it is expected based on sample type.\nThere was just a very low number of genes detected for the Unsorted sample, so mitochondrial expression appears higher mainly due to this fact. The poor quality of the Unsorted sample does not appear to be due to dead or dying cells. The other samples have little mitochondrial expression, although hPSC sample has a bit more than the Sorted samples. Since the hPSC sample was expected to have cell types with higher levels of mitochondrial expression, it may have been advisable to not to use a threshold for this metric.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#novelty",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#novelty",
    "title": "质控",
    "section": "\n6.6 Novelty",
    "text": "6.6 Novelty\nWe can see the samples where we sequenced each cell less have a higher overall novelty, that is because we have not started saturated the sequencing for any given gene for these samples. Outlier cells in these samples might be cells that we have a less complex RNA species than other cells. Sometimes we can detect contamination with low complexity cell types like red blood cells via this metric.\nAll of the samples look fine for complexity, except for the Unsorted sample, so it is unlikely that there is contamination with low complexity cell types in these of the samples. The Unsorted sample has a larger shoulder than desired, but is not bad by this metric.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/04_SC_quality_control.html#filtered-results",
    "href": "single_cell/scRNA-seq_online/04_SC_quality_control.html#filtered-results",
    "title": "质控",
    "section": "\n6.7 Filtered results",
    "text": "6.7 Filtered results\nOne main plot to look at to determine the success of the filtering criteria is the number of cell counts. The number of cells to expect depends on the library preparation method, but for inDrops we see ~80% or less of the total sequenced cells per sample and for 10X it is often ~50% or less.\n\nIn addition, it is a good idea to explore all of the quality plots for the filtered data. All plots should be much improved for the number of reads per cell, genes detected, UMIs per cell, mitochondrial ratio, and novelty. Since the Unsorted sample was a poor quality sample, the filter will remove a large number of the cells for this sample; in this case all cells except 1 were filtered out.\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.3            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.2.0      ggridges_0.5.5        \n [10] compiler_4.3.2         mgcv_1.9-1             png_0.1-8             \n [13] vctrs_0.6.5            reshape2_1.4.4         stringr_1.5.1         \n [16] pkgconfig_2.0.3        fastmap_1.1.1          ellipsis_0.3.2        \n [19] labeling_0.4.3         utf8_1.2.4             promises_1.2.1        \n [22] rmarkdown_2.25         ggbeeswarm_0.7.2       purrr_1.0.2           \n [25] xfun_0.41              jsonlite_1.8.8         goftest_1.2-3         \n [28] later_1.3.2            spatstat.utils_3.0-4   irlba_2.3.5.1         \n [31] parallel_4.3.2         cluster_2.1.6          R6_2.5.1              \n [34] ica_1.0-3              stringi_1.8.3          RColorBrewer_1.1-3    \n [37] spatstat.data_3.0-4    reticulate_1.34.0      parallelly_1.36.0     \n [40] lmtest_0.9-40          scattermore_1.2        Rcpp_1.0.12           \n [43] knitr_1.45             tensor_1.5             future.apply_1.11.1   \n [46] zoo_1.8-12             sctransform_0.4.1      httpuv_1.6.13         \n [49] Matrix_1.6-5           splines_4.3.2          igraph_1.6.0          \n [52] tidyselect_1.2.0       abind_1.4-5            rstudioapi_0.15.0     \n [55] yaml_2.3.8             spatstat.random_3.2-2  codetools_0.2-19      \n [58] miniUI_0.1.1.1         spatstat.explore_3.2-5 listenv_0.9.0         \n [61] lattice_0.22-5         tibble_3.2.1           plyr_1.8.9            \n [64] withr_3.0.0            shiny_1.8.0            ROCR_1.0-11           \n [67] ggrastr_1.0.2          evaluate_0.23          Rtsne_0.17            \n [70] future_1.33.1          fastDummies_1.7.3      survival_3.5-7        \n [73] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [76] KernSmooth_2.23-22     plotly_4.10.4          generics_0.1.3        \n [79] RcppHNSW_0.5.0         munsell_0.5.0          scales_1.3.0          \n [82] globals_0.16.2         xtable_1.8-4           glue_1.7.0            \n [85] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.10    \n [88] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [91] dotCall64_1.1-1        cowplot_1.1.2          grid_4.3.2            \n [94] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-164          \n [97] patchwork_1.2.0        beeswarm_0.4.0         vipor_0.4.7           \n[100] cli_3.6.2              spatstat.sparse_3.0-3  spam_2.10-0           \n[103] fansi_1.0.6            viridisLite_0.4.2      dplyr_1.1.4           \n[106] uwot_0.1.16            gtable_0.3.4           digest_0.6.34         \n[109] progressr_0.14.0       ggrepel_0.9.5          farver_2.1.1          \n[112] htmlwidgets_1.6.4      htmltools_0.5.7        lifecycle_1.0.4       \n[115] httr_1.4.7             mime_0.12              MASS_7.3-60.0.1",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "质控"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/00_intro.html",
    "href": "single_cell/scRNA-seq_online/00_intro.html",
    "title": "scRNA-seq_online学习材料",
    "section": "",
    "text": "本节内容来自Mary Piper等编写的scRNA-seq_online: scRNA-seq Lessons from HCBC (first release)\n代码文件下载自GitHub仓库：scRNA-seq_online\n在线版本：https://hbctraining.github.io/scRNA-seq_online/\nGitHub仓库更新日期：2023年12月13日\nThis repository has teaching materials for a hands-on Introduction to single-cell RNA-seq analysis workshop. This workshop will instruct participants on how to design a single-cell RNA-seq experiment, and how to efficiently manage and analyze the data starting from count matrices. This will be a hands-on workshop in which we will focus on using the Seurat package using R/RStudio. Working knowledge of R is required or completion of the Introduction to R workshop.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/00_intro.html#其他scrna-seq数据分析课程",
    "href": "single_cell/scRNA-seq_online/00_intro.html#其他scrna-seq数据分析课程",
    "title": "scRNA-seq_online学习材料",
    "section": "其他scRNA-seq数据分析课程:",
    "text": "其他scRNA-seq数据分析课程:\n\nSeurat vignettes\nSeurat cheatsheet\n《Analysis of single cell RNA-seq data》\n《ANALYSIS OF SINGLE CELL RNA-SEQ DATA》\nNBIS Workshop: Single Cell RNA-seq Analysis\n《Single-cell RNA-seq YouTube视频合集》\nLigand-receptor analysis with CellphoneDB\nBest practices for single-cell analysis across modalities",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/00_intro.html#resources-for-scrna-seq-sample-prep",
    "href": "single_cell/scRNA-seq_online/00_intro.html#resources-for-scrna-seq-sample-prep",
    "title": "scRNA-seq_online学习材料",
    "section": "Resources for scRNA-seq Sample Prep:",
    "text": "Resources for scRNA-seq Sample Prep:\n\nResearch protocol分享平台\n“Sampling time-dependent artifacts in single-cell genomics studies.” Massoni-Badosa et al.2019\n“Dissociation of solid tumor tissues with cold active protease for single-cell RNA-seq minimizes conserved collagenase-associated stress responses.” O’Flanagan et al. 2020\n“Systematic assessment of tissue dissociation and storage biases in single-cell and single-nucleus RNA-seq workflows.” Denisenko et al. 2020",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/00_intro.html#highlighted-papers-for-single-nuclei-rna-seq",
    "href": "single_cell/scRNA-seq_online/00_intro.html#highlighted-papers-for-single-nuclei-rna-seq",
    "title": "scRNA-seq_online学习材料",
    "section": "Highlighted papers for single-nuclei RNA-seq:",
    "text": "Highlighted papers for single-nuclei RNA-seq:\n\nSingle-nucleus and single-cell transcriptomes compared in matched cortical cell types\nA single-cell and single-nucleus RNA-Seq toolbox for fresh and frozen human tumors",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "",
    "text": "参考：单细胞多数据集整合示例\n上一节中我们完成了对GSE150430的分群注释，并提取了髓系细胞亚群，本节对髓系细胞进一步分群。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#sctransformpca",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#sctransformpca",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.1 SCTransform、PCA",
    "text": "2.1 SCTransform、PCA\n\nmyeloid_seurat &lt;- readRDS(\"output/sc_supplementary/GSE150430_myeloid_seurat.RDS\")\n\n# SCTranform\nmyeloid_seurat &lt;- SCTransform(myeloid_seurat, verbose = FALSE)\nmyeloid_seurat\n\nAn object of class Seurat \n39690 features across 3997 samples within 2 assays \nActive assay: SCT (14970 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n\n# Check which assays are stored in objects\nmyeloid_seurat@assays\n\n$RNA\nAssay (v5) data with 24720 features for 3997 cells\nFirst 10 features:\n RP11-34P13.7, RP11-34P13.8, AL627309.1, AP006222.2, RP4-669L17.10,\nRP4-669L17.2, RP5-857K21.4, RP11-206L10.3, RP11-206L10.5, RP11-206L10.2 \nLayers:\n counts.N01, counts.P01, counts.P02, counts.P03, counts.P04, counts.P05,\ncounts.P06, counts.P07, counts.P08, counts.P09, counts.P10, counts.P11,\ncounts.P12, counts.P13, counts.P14, counts.P15 \n\n$SCT\nSCTAssay data with 14970 features for 3997 cells, and 16 SCTModel(s) \nTop 10 variable features:\n IL1RN, CLEC10A, PKIB, HBEGF, MSR1, IER3, LGMN, CA2, CFD, GLUL \n\n# 查看目前默认的assay\nDefaultAssay(myeloid_seurat)\n\n[1] \"SCT\"\n\n# 查看默认assay的layers\nLayers(myeloid_seurat)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n# 执行PCA\nmyeloid_seurat &lt;- RunPCA(myeloid_seurat)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#不进行整合时检查细胞分群情况",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#不进行整合时检查细胞分群情况",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.2 不进行整合时检查细胞分群情况：",
    "text": "2.2 不进行整合时检查细胞分群情况：\n\n# 查看降维信息\nnames(myeloid_seurat@reductions)\n\n[1] \"pca\"\n\n# Run UMAP\nmyeloid_seurat &lt;- RunUMAP(myeloid_seurat, \n                          dims = 1:40, \n                          reduction = \"pca\",\n                          reduction.name = \"umap.unintegrated\")\n\n# 分群\n# Determine the K-nearest neighbor graph\nmyeloid_seurat &lt;- FindNeighbors(myeloid_seurat, \n                                dims = 1:40, \n                                reduction = \"pca\")\nmyeloid_seurat &lt;- FindClusters(myeloid_seurat, \n                               cluster.name = \"unintegrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 3997\nNumber of edges: 211202\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.7202\nNumber of communities: 8\nElapsed time: 0 seconds\n\n# Plot UMAP\np1 &lt;- DimPlot(myeloid_seurat, \n              reduction = \"umap.unintegrated\",\n              group.by = \"samples\")\np2 &lt;- DimPlot(myeloid_seurat, \n              reduction = \"umap.unintegrated\",\n              split.by = \"samples\")\nplot_grid(p1, p2, \n          ncol = 1, labels = \"AUTO\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#整合",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#整合",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.3 整合",
    "text": "2.3 整合\n\n# 整合\nmyeloid_integrated &lt;- IntegrateLayers(object = myeloid_seurat,\n                                      method = HarmonyIntegration,\n                                      verbose = FALSE)\n\n\n# 整合后合并RNA layer\nmyeloid_integrated[[\"RNA\"]] &lt;- JoinLayers(myeloid_integrated[[\"RNA\"]])\n\n# 查看整合后的降维信息\nnames(myeloid_integrated@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"harmony\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#整合后检验细胞分群情况",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#整合后检验细胞分群情况",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.4 整合后检验细胞分群情况\n",
    "text": "2.4 整合后检验细胞分群情况\n\n\nset.seed(123456)\n# Run UMAP\nmyeloid_integrated &lt;- RunUMAP(myeloid_integrated, \n                              dims = 1:40,\n                              reduction = \"harmony\", # 更改降维来源为整合后的\"harmony\"\n                              reduction.name = \"umap.integrated\")\nnames(myeloid_integrated@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"harmony\"          \n[4] \"umap.integrated\"  \n\n# 分群\nmyeloid_integrated &lt;- FindNeighbors(myeloid_integrated, \n                                    dims = 1:40, \n                                    reduction = \"harmony\") #更改降维来源为\"harmony\"\nmyeloid_integrated &lt;- FindClusters(myeloid_integrated, \n                                   cluster.name = \"integrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 3997\nNumber of edges: 290917\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.7795\nNumber of communities: 10\nElapsed time: 0 seconds\n\ncolnames(myeloid_integrated@meta.data)\n\n [1] \"orig.ident\"            \"nCount_RNA\"            \"nFeature_RNA\"         \n [4] \"samples\"               \"log10GenesPerUMI\"      \"mitoRatio\"            \n [7] \"cells\"                 \"S.Score\"               \"G2M.Score\"            \n[10] \"Phase\"                 \"mitoFr\"                \"groups\"               \n[13] \"old_clusters\"          \"nCount_SCT\"            \"nFeature_SCT\"         \n[16] \"unintegrated_clusters\" \"seurat_clusters\"       \"integrated_clusters\"  \n\n# Plot UMAP                             \np3 &lt;- DimPlot(myeloid_integrated, \n              reduction = \"umap.integrated\", \n              group.by = \"samples\")\np4 &lt;- DimPlot(myeloid_integrated, \n              reduction = \"umap.integrated\", \n              split.by = \"samples\")\nplot_grid(p1, p3, p2, p4, \n          ncol = 1, \n          labels = c(\"Before Harmony\", \"After Harmony\", \n                     \"Before Harmony\", \"After Harmony\"))",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#聚类",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#聚类",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.5 聚类",
    "text": "2.5 聚类\n\n# Determine the clusters for various resolutions                                \nmyeloid_integrated &lt;- FindClusters(myeloid_integrated,\n                                   resolution = c(0.01, 0.05, 0.1, 0.2, 0.3, \n                                                  0.4, 0.5, 0.8, 1),\n                                   verbose = F)\n# Explore resolutions\nhead(myeloid_integrated@meta.data, 5)\n\n                       orig.ident nCount_RNA nFeature_RNA samples\nN01_AGCGTCGAGTGAAGAG.1        N01   2691.228         2086     N01\nN01_GCAATCATCAGCCTAA.1        N01   2139.759         1566     N01\nN01_CGTGTAATCCCACTTG.1        N01   2251.166         1803     N01\nN01_AAACGGGCATTTCAGG.1        N01   1909.545         1226     N01\nN01_AAAGATGCAATGTAAG.1        N01   1796.109         1360     N01\n                       log10GenesPerUMI   mitoRatio                  cells\nN01_AGCGTCGAGTGAAGAG.1        0.9677441 0.010726702 N01_AGCGTCGAGTGAAGAG.1\nN01_GCAATCATCAGCCTAA.1        0.9592918 0.018235699 N01_GCAATCATCAGCCTAA.1\nN01_CGTGTAATCCCACTTG.1        0.9712410 0.017482940 N01_CGTGTAATCCCACTTG.1\nN01_AAACGGGCATTTCAGG.1        0.9413461 0.011039803 N01_AAACGGGCATTTCAGG.1\nN01_AAAGATGCAATGTAAG.1        0.9628822 0.006095955 N01_AAAGATGCAATGTAAG.1\n                            S.Score   G2M.Score Phase mitoFr groups\nN01_AGCGTCGAGTGAAGAG.1 -0.093324147 -0.04497299    G1 Medium Normal\nN01_GCAATCATCAGCCTAA.1  0.008569604 -0.03484456     S   High Normal\nN01_CGTGTAATCCCACTTG.1 -0.013729028 -0.05064395    G1   High Normal\nN01_AAACGGGCATTTCAGG.1 -0.005136538 -0.03723796    G1 Medium Normal\nN01_AAAGATGCAATGTAAG.1 -0.039476505 -0.04625311    G1    Low Normal\n                               old_clusters nCount_SCT nFeature_SCT\nN01_AGCGTCGAGTGAAGAG.1          Macrophages       2455         1929\nN01_GCAATCATCAGCCTAA.1          Macrophages       2252         1505\nN01_CGTGTAATCCCACTTG.1          Macrophages       2359         1712\nN01_AAACGGGCATTTCAGG.1          Macrophages       2044         1197\nN01_AAAGATGCAATGTAAG.1 Myeloid (unspecific)       2271         1322\n                       unintegrated_clusters seurat_clusters\nN01_AGCGTCGAGTGAAGAG.1                     0               5\nN01_GCAATCATCAGCCTAA.1                     0               6\nN01_CGTGTAATCCCACTTG.1                     0               5\nN01_AAACGGGCATTTCAGG.1                     6               7\nN01_AAAGATGCAATGTAAG.1                     5              10\n                       integrated_clusters SCT_snn_res.0.01 SCT_snn_res.0.05\nN01_AGCGTCGAGTGAAGAG.1                   3                0                0\nN01_GCAATCATCAGCCTAA.1                   3                0                0\nN01_CGTGTAATCCCACTTG.1                   3                0                0\nN01_AAACGGGCATTTCAGG.1                   1                0                0\nN01_AAAGATGCAATGTAAG.1                   7                0                1\n                       SCT_snn_res.0.1 SCT_snn_res.0.2 SCT_snn_res.0.3\nN01_AGCGTCGAGTGAAGAG.1               0               0               3\nN01_GCAATCATCAGCCTAA.1               0               0               3\nN01_CGTGTAATCCCACTTG.1               0               0               3\nN01_AAACGGGCATTTCAGG.1               1               1               1\nN01_AAAGATGCAATGTAAG.1               3               4               5\n                       SCT_snn_res.0.4 SCT_snn_res.0.5 SCT_snn_res.0.8\nN01_AGCGTCGAGTGAAGAG.1               3               3               3\nN01_GCAATCATCAGCCTAA.1               3               3               3\nN01_CGTGTAATCCCACTTG.1               3               3               3\nN01_AAACGGGCATTTCAGG.1               1               1               1\nN01_AAAGATGCAATGTAAG.1               6               7               7\n                       SCT_snn_res.1\nN01_AGCGTCGAGTGAAGAG.1             5\nN01_GCAATCATCAGCCTAA.1             6\nN01_CGTGTAATCCCACTTG.1             5\nN01_AAACGGGCATTTCAGG.1             7\nN01_AAAGATGCAATGTAAG.1            10\n\n# 查看各个分辨率下的细胞分群情况\nselect(myeloid_integrated@meta.data, \n       starts_with(match = \"SCT_snn_res.\")) %&gt;%  \n  lapply(levels)\n\n$SCT_snn_res.0.01\n[1] \"0\"\n\n$SCT_snn_res.0.05\n[1] \"0\" \"1\"\n\n$SCT_snn_res.0.1\n[1] \"0\" \"1\" \"2\" \"3\"\n\n$SCT_snn_res.0.2\n[1] \"0\" \"1\" \"2\" \"3\" \"4\"\n\n$SCT_snn_res.0.3\n[1] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\"\n\n$SCT_snn_res.0.4\n[1] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\"\n\n$SCT_snn_res.0.5\n[1] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"\n\n$SCT_snn_res.0.8\n [1] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\" \"9\"\n\n$SCT_snn_res.1\n [1] \"0\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n绘制聚类树展示不同分辨率下的细胞分群情况及相互关系\n\ntree &lt;- clustree(myeloid_integrated@meta.data, \n                 prefix = \"SCT_snn_res.\") # 指定包含聚类信息的列\ntree\n\n\n\n\n\n\n\n这里，选取分辨为0.8\n\nIdents(myeloid_integrated) &lt;- \"SCT_snn_res.0.8\"\n\n聚类可视化\n\n# Plot the UMAP\nDimPlot(myeloid_integrated,\n        reduction = \"umap.integrated\",\n        label = T)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#细胞分群质量评估",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#细胞分群质量评估",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.6 细胞分群质量评估\n",
    "text": "2.6 细胞分群质量评估\n\n分析样本类型是否影响细胞分群\n\n# 先简单查看不同cluster的细胞数\ntable(myeloid_integrated@active.ident)\n\n\n  0   1   2   3   4   5   6   7   8   9 \n891 737 642 419 406 280 229 191 127  75 \n\n# 查看不同样本类型中的细胞分群情况\nDimPlot(myeloid_integrated, \n        reduction = \"umap.integrated\",\n        label = TRUE, \n        split.by = \"groups\") + \n  NoLegend()\n\n\n\n\n\n\n\n分析细胞周期是否影响细胞分群\n\n# Explore whether clusters segregate by cell cycle phase\nDimPlot(myeloid_integrated,\n        reduction = \"umap.integrated\",\n        label = TRUE, \n        split.by = \"Phase\") + \n  NoLegend()\n\n\n\n\n\n\n\n分析其他非期望变异来源是否会影响细胞分群\n\n# Determine metrics to plot present in seurat_clustered@meta.data\nmetrics &lt;-  c(\"nCount_RNA\", \"nFeature_RNA\", \"S.Score\", \"G2M.Score\", \"mitoRatio\")\n\nFeaturePlot(myeloid_integrated, \n            reduction = \"umap.integrated\", \n            features = metrics,\n            pt.size = 0.4, \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\n保存\n\nsaveRDS(myeloid_integrated, \n        file = \"output/sc_supplementary/GSE150430_myeloid_clustered.RDS\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#亚群细胞注释",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_2.html#亚群细胞注释",
    "title": "多个单细胞数据集整合分析（下）",
    "section": "\n2.7 亚群细胞注释",
    "text": "2.7 亚群细胞注释\n髓系亚群进一步细分的marker如下：\n\ngenes_to_check &lt;- list(\n  Mac = c(\"CD14\", \"CD163\", \"APOE\", \"C1QA\", \"C1QB\", \"C1QC\"),\n  pDC = c(\"LILRA4\", \"IL3RA\", \"TCF4\", \"TCL1A\", \"CLEC4C\"),\n  DC1 = c(\"CLEC9A\", \"XCR1\", \"BATF3\"),\n  DC2 = c(\"CD1A\", \"FCER1A\", \"CD1C\", \"CD1E\", \"CLEC10A\"),\n  DC3 = c(\"CCR7\", \"LAMP3\", \"FSCN1\", \"CCL22\", \"BIRC3\"),\n  Mono = c(\"VCVN\", \"FCN1\", \"S100A12\", \"S100A8\", \"S100A9\", \"FCGR3A\")\n)\n\n查看marker基因的表达：\n\nDotPlot(myeloid_integrated,\n        features = genes_to_check) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n手动注释：\n\nmyeloid_clustered &lt;- RenameIdents(\n  myeloid_integrated,\n  \"0\" = \"Macrophages\",\n  \"1\" = \"DC2\",\n  \"2\" = \"Unknown\",\n  \"3\" = \"Macrophages\",\n  \"4\" = \"Monocyte\",\n  \"5\" = \"Macrophages\",\n  \"6\" = \"Unknown\",\n  \"7\" = \"DC1\",\n  \"8\" = \"DC2\",\n  \"9\" = \"Macrophages\"\n)\ntable(Idents(myeloid_clustered))\n\n\nMacrophages         DC2     Unknown    Monocyte         DC1 \n       1665         864         871         406         191 \n\n# Plot the UMAP\np1 &lt;- DimPlot(\n  myeloid_clustered,\n  reduction = \"umap.integrated\",\n  label = T\n)\np1\n\n\n\n\n\n\n\n在注释好的数据中再次检查marker基因的表达情况：\n\nDotPlot(myeloid_clustered, \n        features = genes_to_check) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n这里我们参考Seurat-对FeaturePlot的进一步修饰中的方法，可视化巨噬细胞marker基因的共表达情况：\n\np2 &lt;- Plot_Density_Joint_Only(\n  myeloid_clustered,\n  features = c(\n    \"CD14\", \"CD163\", \"APOE\",\n    \"C1QA\", \"C1QB\", \"C1QC\"\n  ),\n  reduction = \"umap.integrated\",\n  custom_palette = BlueAndRed()\n)\np2\n\n\n\n髓系细胞进一步分群及巨噬细胞marker基因共表达情况\n\n\nplot_grid(\n  p1, p2,\n  labels = \"AUTO\"\n)\n\n\n\n髓系细胞进一步分群及巨噬细胞marker基因共表达情况\n\n\n\n保存\n\nsaveRDS(myeloid_clustered, \n        file = \"output/sc_supplementary/GSE150430_myeloid_clustered.RDS\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（下）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/DecontX.html",
    "href": "single_cell/sc_supplementary/DecontX.html",
    "title": "预测和去除单细胞转录组的环境游离RNA污染",
    "section": "",
    "text": "参考：\n使用DecontX预测和去除单细胞转录组的环境游离RNA污染\nDecontamination of ambient RNA in single-cell genomic data with DecontX\nSoupX 帮助文档\n\n\n\n\n\n\n\nNote\n\n\n\n如果你的UMAP可视化时候总是出现毛毛躁躁的边缘和大量散在细胞，还有很多细胞亚群之间有连续的细胞（maybe可能时真是存在的过渡态细胞），就需要考虑这个使用DecontX预测和去除单细胞转录组的环境游离RNA污染。\n\n\n\nIn droplet based, single cell RNA-seq experiments, there is always a certain amount of background mRNAs present in the dilution that gets distributed into the droplets with cells and sequenced along with them. The net effect of this is to produce a background contamination that represents expression not from the cell contained within a droplet, but the solution that contained the cells.\n\n在单细胞测序中，由于在处理细胞样品的时候需要用到机械解离或者酶解的步骤，所以免不了会造成细胞的破裂同时产生环境游离RNA。细胞悬液中的环境 RNA 可能会与细胞的原生 mRNA 一起被异常计数，从而导致不同细胞群之间转录本的交叉污染。环境游离RNA污染对细胞测序质量的影响较大，因此，有效地计算和预测游离RNA污染，去除污染严重的低质量细胞对单细胞测序分析具有重要意义。\n\n目前，R包SoupX就可以实现这样的目的，详见：SoupX——去除RNA污染。这篇笔记我们介绍另一个R包decontX (Yang et al. 2020)。这个包的主要优点是使用方便，步骤简便，且结果容易使用。DecontX 是一种新的贝叶斯方法，用于估计和去除单细胞数据中的环境污染，可以整合到 scRNA-seq 工作流中，以改进下游分析。DecontX既可以用于去除单细胞转录组数据中的环境游离RNA污染（decontX），也可以用于单细胞蛋白表达谱中的污染（deconPro）。\n安装SoupX：\n\nBiocManager::install(\"decontX\")\n\n\n1 加载包\n\nlibrary(Seurat)\nlibrary(decontX)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(beepr)\n\n\n2 数据导入/质控\nDecontX can take either a SingleCellExperiment object or a counts matrix as input. decontX will attempt to convert any input matrix to class dgCMatrix from package Matrix before starting the analysis. 在Seurat工作流中，评估并去除环境游离RNA的污染一般在质控之后进行。这里我们用scRNA-seq_online-质控中已经完成质控的Seurat对象作为演示。最后和scRNA-seq_online-细胞聚类中没有进行环境游离RNA去除的细胞分群结果进行比较。\n\nfiltered_seurat &lt;- readRDS(\"output/scRNA-seq_online/seurat_filtered.rds\")\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts\n\nhead(filtered_seurat, 5)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1\n\n\n\n3 执行decontX\n\nIn this scenario, decontX will estimate the contamination distribution for each cell cluster based on the profiles of the other cell clusters in the filtered dataset. The estimated contamination results can be found in the colData(sce)$decontX_contamination and the decontaminated counts can be accessed with decontXcounts(sce).\n\ndecontx_result &lt;- decontX(filtered_seurat[[\"RNA\"]]$counts)\n\n# 提取环境RNA污染的预测结果\ndecontx_result$contamination[1:5]\n\n[1] 0.0005892543 0.0642801956 0.0057000246 0.1023643666 0.2893165532\n\nlength(decontx_result$contamination)\n\n[1] 29629\n\nsummary(decontx_result$contamination)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0002503 0.0120741 0.0336210 0.0833928 0.0955089 0.9974462 \n\n\n可以看到每个细胞都有一个decontx_result$contamination结果，即预测的环境游离RNA的比例。因此，接下来我们可以将其直接写入Seurat对象的meta.data中，并根据这一信息进行细胞过滤。\n\n# 将环境RNA污染的预测结果写入Seurat对象的meta.data中\nfiltered_seurat$Contamination &lt;- decontx_result$contamination\nhead(filtered_seurat, 5)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1\n                      Contamination\nctrl_AAACATACAATGCC-1  0.0005892543\nctrl_AAACATACATTTCC-1  0.0642801956\nctrl_AAACATACCAGAAA-1  0.0057000246\nctrl_AAACATACCAGCTA-1  0.1023643666\nctrl_AAACATACCATGCA-1  0.2893165532\n\n\n绘图展示污染率的分布情况\n\np1 &lt;- filtered_seurat@meta.data |&gt; \n    ggplot(aes(color = sample, x = Contamination, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    ylab(\"Cell density\") +\n    geom_vline(xintercept = 0.2) +\n    theme_bw()\n\np2 &lt;- filtered_seurat@meta.data |&gt; \n  ggplot(aes(x = sample, y = Contamination, fill = sample)) +\n    geom_violin(width = 1.4) +\n    geom_boxplot(width = 0.1, color = \"gray\") +\n    theme_bw()\n\n\n4 过滤高环境RNA污染的细胞\n对于污染率的过滤标准，DecontX官方并没有给予明确的建议，这里参考的了SoupX的官方文档，选择Contamination &lt; 0.2。\n\nlow_con_seurat &lt;- subset(filtered_seurat, Contamination &lt; 0.2)\npaste0(\"通过decontX过滤掉了\", ncol(filtered_seurat) - ncol(low_con_seurat), \"个细胞\")\n\n[1] \"通过decontX过滤掉了3574个细胞\"\n\n\n重新评估污染率的分布情况\n\np3 &lt;- low_con_seurat@meta.data |&gt; \n    ggplot(aes(color = sample, x = Contamination, fill = sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    ylab(\"Cell density\") +\n    geom_vline(xintercept = 0.2) +\n    theme_bw()\n\np4 &lt;- low_con_seurat@meta.data |&gt; \n    ggplot(aes(x = sample, y = Contamination, fill = sample)) +\n    geom_violin(width = 1.4) +\n    geom_boxplot(width = 0.1, color = \"gray\") +\n    theme_bw()\n\nplot_grid(p1, p2, p3, p4,\n          ncol = 2, \n          labels = \"AUTO\")\n\n\n\n去除高环境RNA污染的细胞前（A、B）后（C、D）的环境RNA比例分布\n\n\n\n\n5 SCTranform、整合\n这里省略细胞周期、线粒体基因等非期望变异来源的评估，省略整合前细胞分群情况的评估。\n\n# 分割layer，执行SCTranform\nlow_con_seurat[[\"RNA\"]] &lt;- split(low_con_seurat[[\"RNA\"]], \n                                 f = low_con_seurat$sample) \nlow_con_seurat\n\nAn object of class Seurat \n14065 features across 26055 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 2 layers present: counts.ctrl, counts.stim\n\n# SCTranform\nlow_con_seurat &lt;- SCTransform(\n  low_con_seurat, \n  vars.to.regress = c(\"mitoRatio\"),\n  verbose = FALSE\n  )\nlow_con_seurat\n\nAn object of class Seurat \n28044 features across 26055 samples within 2 assays \nActive assay: SCT (13979 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: RNA\n\n# Run PCA\nlow_con_seurat &lt;- RunPCA(low_con_seurat)\nnames(low_con_seurat@reductions)\n\n[1] \"pca\"\n\n# 整合\nseurat_integrated &lt;- IntegrateLayers(\n  object = low_con_seurat,\n  method = CCAIntegration,\n  normalization.method = \"SCT\",\n  orig.reduction = \"pca\",\n  verbose = FALSE\n); beep()\n\n# 整合后重新合并RNA layer\nseurat_integrated[[\"RNA\"]] &lt;- JoinLayers(seurat_integrated[[\"RNA\"]])\n# 查看整合后的降维信息\nnames(seurat_integrated@reductions)\n\n[1] \"pca\"           \"integrated.dr\"\n\n\n\n6 非线性降维、分群\n\n# Set seed\nset.seed(123456)\n\n# Run UMAP\nseurat_integrated &lt;- RunUMAP(\n  seurat_integrated,\n  dims = 1:40,\n  reduction = \"integrated.dr\", # 更改降维来源为整合后的\"integrated.dr\"\n  reduction.name = \"umap.integrated\"\n)\n\n# 分群\nseurat_integrated &lt;- FindNeighbors(\n  seurat_integrated,\n  dims = 1:40,\n  reduction = \"integrated.dr\"\n) \n\nseurat_integrated &lt;- FindClusters(\n  seurat_integrated,\n  resolution = 0.8 # 这里省略探索分辨率的步骤，为了和此前的章节一致，将分辨率设为0.8\n)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 26055\nNumber of edges: 985955\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8805\nNumber of communities: 21\nElapsed time: 4 seconds\n\nhead(seurat_integrated, 5)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\n                      log10GenesPerUMI  mitoRatio                 cells\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1\n                      Contamination nCount_SCT nFeature_SCT SCT_snn_res.0.8\nctrl_AAACATACAATGCC-1  0.0005892543       1541          856               2\nctrl_AAACATACATTTCC-1  0.0642801956       1489          697               1\nctrl_AAACATACCAGAAA-1  0.0057000246       1519          662               5\nctrl_AAACATACCAGCTA-1  0.1023643666       1497          724               5\nctrl_AAACATACCTCGCT-1  0.0036639072       1411          573               1\n                      seurat_clusters\nctrl_AAACATACAATGCC-1               2\nctrl_AAACATACATTTCC-1               1\nctrl_AAACATACCAGAAA-1               5\nctrl_AAACATACCAGCTA-1               5\nctrl_AAACATACCTCGCT-1               1\n\n# Assign identity of clusters\nIdents(seurat_integrated) &lt;- \"SCT_snn_res.0.8\"\ntable(Idents(seurat_integrated))\n\n\n   0    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15 \n3525 3062 3034 2321 2203 1888 1775 1707 1181 1076 1074  701  489  464  460  336 \n  16   17   18   19   20 \n 330  248  109   46   26 \n\n# Plot the UMAP\nDimPlot(seurat_integrated,\n        reduction = \"umap.integrated\",\n        label = FALSE,\n        label.size = 6)\n\n\n\n去除高环境游离RNA污染细胞后的分群情况\n\n\n\n可以看到和来自scRNA-seq_online-细胞聚类 （下图）的分群情况相比，去除了高环境RNA污染的细胞后，细胞群边缘的毛刺有所减少，细胞界线更加清晰。\n\n\n未去除高环境游离RNA污染细胞的分群情况\n\n\n\n\n\n\n\nTip\n\n\n\ndecontX可以整合进标准的Seurat工作流中的质控步骤中。但是，也可以在先不进行decontX的情况下，进行常规的整合、降维、分群。如果分群效果不理想，即有明显的边缘毛躁和大量散在细胞的情况，可以再提取这时候的counts，执行decontX。这时候可以通过FeaturePlot()去可视化高游离RNA污染的细胞的分布情况：\n\nFeaturePlot(\n  seurat_integrated,\n  features = \"Contamination\",\n  raster = FALSE # 细胞过多时候需要加这个参数\n) +\n  scale_color_viridis_c() +\n  theme_bw() +\n  theme(\n    panel.grid = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  ) +\n  xlab(\"scVI_UMAP_1\") +\n  ylab(\"scVI_UMAP_2\")\n\n\n\n通过FeaturePlot()可视化游离RNA分布情况的示例。可以看到，通过可视化Contamination，这些边缘的毛躁就是Contamination较高地细胞。\n\n然后选择合适的阈值过滤细胞。之后用过滤后的counts和meta.data重新构建Seurat对象：\n\nlow_con_seurat &lt;- subset(filtered_seurat, Contamination &lt; 0.2)\n\nnew_seurat &lt;- CreateSeuratObject(\n  counts = low_con_seurat[[\"RNA\"]]$counts,\n  meta.data = low_con_seurat@meta.data)\n\n然后重新执行整合、降维、分群等步骤。最后和此前的细胞分群情况进行比较。\n\n```{r}\n#| eval: false\n#| fig-width: 10\n#| fig-cap: 过滤环境RNA污染前（A）后（B）的UMAP图\np2 &lt;- DimPlot(\n  low_con_seurat, \n  reduction = \"umap\",\n  label = T\n  )\np2\n\nplot_grid(\n  p1, p2, \n  labels = \"AUTO\")\n```\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] beepr_1.3          cowplot_1.1.2      ggplot2_3.4.4      decontX_1.0.0     \n[5] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.21            splines_4.3.2              \n  [3] later_1.3.2                 bitops_1.0-7               \n  [5] tibble_3.2.1                polyclip_1.10-6            \n  [7] fastDummies_1.7.3           lifecycle_1.0.4            \n  [9] StanHeaders_2.32.5          globals_0.16.2             \n [11] lattice_0.22-5              MASS_7.3-60.0.1            \n [13] magrittr_2.0.3              plotly_4.10.4              \n [15] rmarkdown_2.25              yaml_2.3.8                 \n [17] httpuv_1.6.13               glmGamPoi_1.14.0           \n [19] sctransform_0.4.1           spam_2.10-0                \n [21] pkgbuild_1.4.3              spatstat.sparse_3.0-3      \n [23] reticulate_1.34.0           pbapply_1.7-2              \n [25] RColorBrewer_1.1-3          abind_1.4-5                \n [27] zlibbioc_1.48.0             audio_0.1-11               \n [29] Rtsne_0.17                  GenomicRanges_1.54.1       \n [31] purrr_1.0.2                 BiocGenerics_0.48.1        \n [33] RCurl_1.98-1.14             GenomeInfoDbData_1.2.11    \n [35] IRanges_2.36.0              S4Vectors_0.40.2           \n [37] ggrepel_0.9.5               inline_0.3.19              \n [39] irlba_2.3.5.1               listenv_0.9.0              \n [41] spatstat.utils_3.0-4        goftest_1.2-3              \n [43] RSpectra_0.16-1             spatstat.random_3.2-2      \n [45] fitdistrplus_1.1-11         parallelly_1.36.0          \n [47] DelayedMatrixStats_1.24.0   leiden_0.4.3.1             \n [49] codetools_0.2-19            DelayedArray_0.28.0        \n [51] scuttle_1.12.0              tidyselect_1.2.0           \n [53] farver_2.1.1                viridis_0.6.4              \n [55] ScaledMatrix_1.10.0         matrixStats_1.2.0          \n [57] stats4_4.3.2                spatstat.explore_3.2-5     \n [59] jsonlite_1.8.8              BiocNeighbors_1.20.2       \n [61] ellipsis_0.3.2              progressr_0.14.0           \n [63] ggridges_0.5.5              survival_3.5-7             \n [65] scater_1.30.1               dbscan_1.1-12              \n [67] tools_4.3.2                 ica_1.0-3                  \n [69] Rcpp_1.0.12                 glue_1.7.0                 \n [71] gridExtra_2.3               SparseArray_1.2.3          \n [73] xfun_0.41                   MatrixGenerics_1.14.0      \n [75] GenomeInfoDb_1.38.5         dplyr_1.1.4                \n [77] loo_2.6.0                   withr_3.0.0                \n [79] combinat_0.0-8              fastmap_1.1.1              \n [81] MCMCprecision_0.4.0         fansi_1.0.6                \n [83] rsvd_1.0.5                  digest_0.6.34              \n [85] R6_2.5.1                    mime_0.12                  \n [87] colorspace_2.1-0            scattermore_1.2            \n [89] tensor_1.5                  spatstat.data_3.0-4        \n [91] utf8_1.2.4                  tidyr_1.3.0                \n [93] generics_0.1.3              data.table_1.14.10         \n [95] httr_1.4.7                  htmlwidgets_1.6.4          \n [97] S4Arrays_1.2.0              uwot_0.1.16                \n [99] pkgconfig_2.0.3             gtable_0.3.4               \n[101] lmtest_0.9-40               SingleCellExperiment_1.24.0\n[103] XVector_0.42.0              htmltools_0.5.7            \n[105] dotCall64_1.1-1             scales_1.3.0               \n[107] Biobase_2.62.0              png_0.1-8                  \n[109] knitr_1.45                  rstudioapi_0.15.0          \n[111] reshape2_1.4.4              nlme_3.1-164               \n[113] curl_5.2.0                  zoo_1.8-12                 \n[115] stringr_1.5.1               KernSmooth_2.23-22         \n[117] vipor_0.4.7                 parallel_4.3.2             \n[119] miniUI_0.1.1.1              pillar_1.9.0               \n[121] grid_4.3.2                  vctrs_0.6.5                \n[123] RANN_2.6.1                  promises_1.2.1             \n[125] BiocSingular_1.18.0         beachmat_2.18.0            \n[127] xtable_1.8-4                cluster_2.1.6              \n[129] beeswarm_0.4.0              evaluate_0.23              \n[131] cli_3.6.2                   compiler_4.3.2             \n[133] rlang_1.1.3                 crayon_1.5.2               \n[135] rstantools_2.3.1.1          future.apply_1.11.1        \n[137] labeling_0.4.3              ggbeeswarm_0.7.2           \n[139] plyr_1.8.9                  stringi_1.8.3              \n[141] rstan_2.32.5                viridisLite_0.4.2          \n[143] deldir_2.0-2                QuickJSR_1.0.9             \n[145] BiocParallel_1.36.0         munsell_0.5.0              \n[147] lazyeval_0.2.2              spatstat.geom_3.2-7        \n[149] V8_4.4.1                    Matrix_1.6-5               \n[151] RcppHNSW_0.5.0              patchwork_1.2.0            \n[153] sparseMatrixStats_1.14.0    future_1.33.1              \n[155] shiny_1.8.0                 SummarizedExperiment_1.32.0\n[157] ROCR_1.0-11                 igraph_1.6.0               \n[159] RcppParallel_5.1.7         \n\n\n\n\n\nReferences\n\n\nYang, Shiyi, Sean E. Corbett, Yusuke Koga, Zhe Wang, W Evan Johnson, Masanao Yajima, and Joshua D. Campbell. 2020. “Decontamination of Ambient RNA in Single-Cell RNA-Seq with DecontX.” Genome Biology 21 (1). https://doi.org/10.1186/s13059-020-1950-6.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "预测和去除单细胞转录组的环境游离RNA污染"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/sc_supplementary_intro.html",
    "href": "single_cell/sc_supplementary/sc_supplementary_intro.html",
    "title": "单细胞补充内容",
    "section": "",
    "text": "本章对此前的单细胞分析内容进行补充，包括不同格式数据的读取、多个数据集整合分析等（更新中）。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/universal_marker.html",
    "href": "single_cell/sc_supplementary/universal_marker.html",
    "title": "细胞分群通用marker",
    "section": "",
    "text": "参考原文：\n是否是免疫细胞很容易区分那是否是肿瘤细胞呢？\nCNS图表复现03—单细胞区分免疫细胞和肿瘤细胞\n\n\n1 区分免疫细胞和非免疫细胞\n\nImmune: PTPRC (编码CD45)\nEpithelial/cancer：EPCAM\nStromal (CD10+,MME, fibo or CD31+,PECAM1,endo)\n\nCells were defined as non-immune if belonging to a cluster low for PTPRC (gene for CD45) and high for any of the following genes:\n\nMUC5A (goblet cell marker)\nKRT5 (basal epithelial cell marker)\nSFTPD (secretory cell marker)\nEPCAM (pan-epithelial cell marker)\nCDH5 (endothelial cell marker)\nCOL1A2 and ACTA2 (fibroblast markers)\n\n所以你拿到自己的单细胞测序数据后，走完基础流程，可以直接看看这些基因的表达量分布图（气泡图或者小提琴图均可）。下面是一个例子：\n\ngenes_to_check = c(\"PTPRC\",\n                   \"EPCAM\",\n                   \"CD3G\",\"CD3E\", # T cells\n                   \"CD79A\", \"BLNK\", \"MS4A1\", # B cells\n                   \"CD68\", \"CSF1R\", # Monocytes and macrophages\n                   \"MARCO\", \"CD207\", \"PMEL\", \"ALB\", \"C1QB\", \"CLDN5\", \"FCGR3B\", \"COL1A1\")\np &lt;- DotPlot(sce, features = genes_to_check) + coord_flip()\np\n\n\n接下来我们直接根据PTPRC的总表达量的中位数将所有细胞分为免疫细胞和非免疫细胞：\n\n# Annotate Immune vs Nonimmune clusters\n# At this point we dont care for a more detailed annotation as we will annotate immune and non-immune separately later\ndat &lt;- p$data \ncd45 &lt;- dat[dat$features.plot == 'PTPRC',]\nfivenum(cd45$avg.exp.scaled)\nimm &lt;- cd45[cd45$avg.exp.scaled &gt; -0.5,]$id\nimm\nsce$immune_annotation &lt;- ifelse(sce$RNA_snn_res.0.5 %in% imm ,'immune', 'non-immune')\ntable(sce$immune_annotation)\n\n接下来可以进行 TSNE plot  可视化，看到免疫细胞和非免疫细胞是泾渭分明：\n\np &lt;- TSNEPlot(object = sce, group.by = 'immune_annotation')\np\n\n\n\n2 区分出恶性细胞\n很多情况下是靠inferCNV算法的结果，比如发表于2017年12月，在CELL杂志：Single-Cell Transcriptomic Analysis of Primary and Metastatic Tumor Ecosystems in Head and Neck Cancer 的文献，就是使用inferCNV算法对来自18名患者的5,902个细胞，分成2215个恶性细胞和3363个非恶性细胞如下所示：\n\n可以看到，通过inferCNV算法，能发现非恶性细胞的CNV是几乎没有的，而恶性细胞呢，或多或少有一些染色体片段的拷贝数扩增或者缺失。\n\n3 细胞初步分群通用marker\n\n一般来说肿瘤样品的单细胞首先是按照如下所示的标记基因进行第一次分群 ：\n\n免疫细胞共同标记：PTPRC\n髓系细胞（myeloid）：CD163、AIF1\nT cells：CD3D、CD3E、CD4、CD8A\nB cells：CD19、CD79A、MS4A1（编码CD20）、SDC1、CD27、CD38\nPlasma cells：IGHG1、MZB1、SDC1（编码CD138）、JCHAIN\nMonocytes and macrophages：CD68、CD163、CD14\nMonocyte：S100A9、S100A8、MMP19\nMacrophages：C1QA、C1QB\nMast cells：TPSAB1、TPSB2\nNK cells：KLRB1、KLRD1、NCR1、GNLY、NKG7\n【NK Cells：FGFBP2, FCG3RA, CX3CR1】\nEpithelial/cancer：EPCAM、KRT19、PROM1、ALDH1A1、CD24\nEndothelial cells：PECAM1、VWF\nFibroblasts：FGF7、MME、ACTA2、COL3A1\n\n\ngenes_to_check = c('PTPRC', \n                   \"CD163\",\"AIF1\", \n                   'CD3D', 'CD3E', 'CD4', 'CD8A', \n                   'CD19', 'CD79A', 'MS4A1', \"SDC1\", \"CD27\", \"CD38\",\n                   'IGHG1', 'MZB1', 'SDC1', \"JCHAIN\", \n                   'CD68', 'CD163', 'CD14', \n                   'S100A9', 'S100A8', 'MMP19',\n                   'C1QA',  'C1QB', \n                   'TPSAB1', 'TPSB2', \n                   'KLRB1', \"KLRD1\", 'NCR1', \"GNLY\", \"NKG7\", \n                   'FGF7', 'MME', 'ACTA2', \"COL3A1\", \n                   'PECAM1', 'VWF', \n                   'EPCAM', 'KRT19', 'PROM1', 'ALDH1A1') \n\n\n\n\n\n\n\n案例\n\n\n\n\n\n来源：巨噬细胞新分类体系（一篇Science文献复现）\n\ngenes_to_check = c('PTPRC', 'CD3D', 'CD3E', 'CD4','CD8A',\n                   'CD19', 'CD79A', 'MS4A1' ,\n                   'IGHG1', 'MZB1', 'SDC1',\n                   'CD68', 'CD163', 'CD14', \n                   'TPSAB1' , 'TPSB2', \n                   'RCVRN','FPR1' , 'ITGAM' ,\n                   'C1QA',  'C1QB',  \n                   'S100A9', 'S100A8', 'MMP19',\n                   'FCGR3A','LAMP3', 'IDO1','IDO2',## DC3 \n                   'CD1E','CD1C', # DC2\n                   'KLRB1','NCR1', \n                   'FGF7','MME', 'ACTA2', \n                   'DCN', 'LUM',  'GSN' , # mouse PDAC fibo \n                   'PECAM1', 'VWF',  \n                   'EPCAM' , 'KRT19','KRT7', \n                   'FYXD2', 'TM4SF4', 'ANXA4',# 胆管上皮细胞\n                   'APOC3', 'FABP1',  'APOA1',  # 肝细胞\n                   'Serpina1c','PROM1', 'ALDH1A1' )\nDotPlot(sce.all, \n        features = genes_to_check,\n        assay='RNA',\n        group.by = 'celltype' ) + \n  coord_flip()\n\n\n根据气泡图所示的marker基因表达情况，确定细胞分群如下\n\n\nCluster ID\n细胞类型\n\n\n\n0, 7\nT cells\n\n\n2\nMacrophages\n\n\n8\nMast cells\n\n\n1, 9, 10\nEpithelial/cancer cells\n\n\n6\nFibroblasts\n\n\n5\nEndothelial cells\n\n\n4\nCycling\n\n\n3\nB cells\n\n\n\n\n\n\n\n髓系免疫细胞亚群:\n\nth=theme(axis.text.x = element_text(angle = 45,\n                                    vjust = 0.5, hjust=0.5))\nmyeloids = list(\n  Mac=c(\"C1QA\",\"C1QB\",\"C1QC\",\"SELENOP\",\"RNASE1\",\"DAB2\",\"LGMN\",\"PLTP\",\"MAF\",\"SLCO2B1\"),\n  mono=c(\"VCAN\",\"FCN1\",\"CD300E\",\"S100A12\",\"EREG\",\"APOBEC3A\",\"STXBP2\",\"ASGR1\",\"CCR2\",\"NRG1\"),\n  neutrophils = c(\"FCGR3B\",\"CXCR2\",\"SLC25A37\",\"G0S2\",\"CXCR1\",\"ADGRG3\",\"PROK2\",\"STEAP4\",\"CMTM2\" ),\n  pDC = c(\"GZMB\",\"SCT\",\"CLIC3\",\"LRRC26\",\"LILRA4\",\"PACSIN1\",\"CLEC4C\",\"MAP1A\",\"PTCRA\",\"C12orf75\"),\n  DC1 = c(\"CLEC9A\",\"XCR1\",\"CLNK\",\"CADM1\",\"ENPP1\",\"SNX22\",\"NCALD\",\"DBN1\",\"HLA-DOB\",\"PPY\"),\n  DC2 = c( \"CD1C\",\"FCER1A\",\"CD1E\",\"AL138899.1\",\"CD2\",\"GPAT3\",\"CCND2\",\"ENHO\",\"PKIB\",\"CD1B\"),\n  DC3 =  c(\"HMSD\",\"ANKRD33B\",\"LAD1\",\"CCR7\",\"LAMP3\",\"CCL19\",\"CCL22\",\"INSM1\",\"TNNT2\",\"TUBB2B\")\n)\np &lt;- DotPlot(sce.all, features = myeloids,\n             assay='RNA' ,group.by = 'celltype' )  +th\n\np",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "细胞分群通用marker"
    ]
  },
  {
    "objectID": "r_basic/character.html",
    "href": "r_basic/character.html",
    "title": "字符的处理",
    "section": "",
    "text": "substr(\" A BC\",\n       1,#从第几个字符开始截取\n       3)#截取多少个字符\n\n[1] \" A \"\n\nsubstring(\" A BC\", 1, 3)\n\n[1] \" A \"\n\n\nsubstr()对含有空格和特殊字符如下划线的支持不好，这种情况可采用stringr包内的字符分割函数str_split()来实现。下面实现从”A_B_C”中截取”B”：\n\nlibrary(stringr)\nstr_split(\"A_B_C\",\n          \"_\",#按照什么标志切割字符\n          simplify = T)[,2] #这里把\"A_B_C\"切开后，“B\"应该位于第二个，所以通过[,2]取第二个元素\n\n[1] \"B\"\n\nstr_sub(\"A_B_C\",\n        1,\n        2)\n\n[1] \"A_\"",
    "crumbs": [
      "Home",
      "R语言基础",
      "字符的处理"
    ]
  },
  {
    "objectID": "r_basic/character.html#unite函数的使用",
    "href": "r_basic/character.html#unite函数的使用",
    "title": "字符的处理",
    "section": "\n3.1 unite()函数的使用",
    "text": "3.1 unite()函数的使用\n构建案例数据\n\na1 &lt;- rep(1,5) # 重复“1” 5次\na2 &lt;- rep(2,5)\na3 &lt;- rep(3,5)\nA &lt;- data.frame(a1,a2,a3)\nA\n\n  a1 a2 a3\n1  1  2  3\n2  1  2  3\n3  1  2  3\n4  1  2  3\n5  1  2  3\n\n\n现在想对生成的数据框A里面的a1,a2和a3列进行合并，形成新”a123”列，其中a1与a2用”~“连接，a2与a3列用”/“连接。\n首先对数据A的列a1,a2合并为新列a12，用”~“连接。\n\nlibrary(tidyr)\nA1 &lt;- unite(A,#目标数据集\n            \"a12\",#新列的名称\n            a1,a2,#需要合并的列名(若用“:”连接则表示合并两列及之间的所有列)\n            sep = '~',#指定连接符\n            remove=F)#是否移除原始列\n\n#或者\nA1 &lt;- A %&gt;% unite(\"a12\",a1,a2,sep = '~',remove=F)\nA1\n\n  a12 a1 a2 a3\n1 1~2  1  2  3\n2 1~2  1  2  3\n3 1~2  1  2  3\n4 1~2  1  2  3\n5 1~2  1  2  3\n\n\n然后对A1里面的a12列与a3列用”/“连接，形成新列”a123”\n\nA2 &lt;- unite(A1,\"a123\",a12,a3,sep = '/',remove=F)\nA2\n\n   a123 a12 a1 a2 a3\n1 1~2/3 1~2  1  2  3\n2 1~2/3 1~2  1  2  3\n3 1~2/3 1~2  1  2  3\n4 1~2/3 1~2  1  2  3\n5 1~2/3 1~2  1  2  3\n\n#也可以用管道传参一步搞定\nA2 &lt;- A %&gt;% \n  unite(a12,a1,a2,sep = '~',remove=F) %&gt;% \n  unite(a123,a12,a3,sep = '/',remove=F)\nA2\n\n   a123 a12 a1 a2 a3\n1 1~2/3 1~2  1  2  3\n2 1~2/3 1~2  1  2  3\n3 1~2/3 1~2  1  2  3\n4 1~2/3 1~2  1  2  3\n5 1~2/3 1~2  1  2  3",
    "crumbs": [
      "Home",
      "R语言基础",
      "字符的处理"
    ]
  },
  {
    "objectID": "r_basic/character.html#in指令",
    "href": "r_basic/character.html#in指令",
    "title": "字符的处理",
    "section": "\n4.1 %in%指令\n",
    "text": "4.1 %in%指令\n\n它会把每个字符串当成判断的最小单位，所以不能用来判断/查找”长字符串中是否含有特定的短字符串”\n\nplaces &lt;- c(\"中国四川\",\"中国北京\",\"中国安徽\",\"北京天安门\")\nplaces\n\n[1] \"中国四川\"   \"中国北京\"   \"中国安徽\"   \"北京天安门\"\n\n\"中国四川\" %in% places\n\n[1] TRUE\n\n\"中国\" %in% places\n\n[1] FALSE",
    "crumbs": [
      "Home",
      "R语言基础",
      "字符的处理"
    ]
  },
  {
    "objectID": "r_basic/character.html#grep函数",
    "href": "r_basic/character.html#grep函数",
    "title": "字符的处理",
    "section": "\n4.2 grep()函数\n",
    "text": "4.2 grep()函数\n\ngrep的全称是global search regular expression and print out the line,可以通过正则表达式搜索文本，并把匹配的行打印出来。所谓正则表达式，就是用某种模式去匹配一类字符串的一个公式，很多文本编辑器或者程序语言都支持该方式进行字符串的操作。下面我们用该函数首先查找y中是否有包含”北京”字样的条目，并返回其所在位置：\n\ngrep(\n  pattern = \"北京\", # 需要找找的字符\n  x = places, # 从哪里查找\n  ignore.case = F, # 是否忽略大小写，默认为FALSE\n  value = F, # 默认为FALSE，表示返回匹配到的字符所在的位置；TRUE则返回查找到的值\n  invert = F # 如果为TRUE，则返回未匹配到的字符的值或位置\n) \n\n[1] 2 4\n\n\n查找y中包含”北京”的条目有哪些：\n\ngrep(\"北京\", places, ignore.case = F, value = T, invert = F)\n\n[1] \"中国北京\"   \"北京天安门\"\n\n\n从framdata数据集中，提取NAME包含了”TR”的个案，形成新的TR_data数据集。\n生成演示数据\n\nframdata &lt;- data.frame(ID = c(6, 8, 12, 14, 14, 15, 17, 22, 24, 23),\n                       NAME = c(\"A_CT\", \"B_CT\", \"C_CT\", \"D_CT\", \"E_TR\", \"F_TR\",\n                                \"G_TR\", \"H_TR\", \"I_TR\", \"J_TR\"),\n                       VALUE = c(14, 12, 12, 13, 7, 8, 7, 4, 6, 5))\nframdata\n\n   ID NAME VALUE\n1   6 A_CT    14\n2   8 B_CT    12\n3  12 C_CT    12\n4  14 D_CT    13\n5  14 E_TR     7\n6  15 F_TR     8\n7  17 G_TR     7\n8  22 H_TR     4\n9  24 I_TR     6\n10 23 J_TR     5\n\n\n利用该函数返回framdata中NAME列中包含了”TR”的行号\n\ngrep(\"TR\", framdata$NAME, ignore.case = F, value = F, invert = F)\n\n[1]  5  6  7  8  9 10\n\n\n下面最终实现上述目的\n\nTR_data &lt;- framdata[grep(\"TR\", framdata$NAME),]\nTR_data\n\n   ID NAME VALUE\n5  14 E_TR     7\n6  15 F_TR     8\n7  17 G_TR     7\n8  22 H_TR     4\n9  24 I_TR     6\n10 23 J_TR     5",
    "crumbs": [
      "Home",
      "R语言基础",
      "字符的处理"
    ]
  },
  {
    "objectID": "r_basic/character.html#grepl函数",
    "href": "r_basic/character.html#grepl函数",
    "title": "字符的处理",
    "section": "\n4.3 grepl()函数\n",
    "text": "4.3 grepl()函数\n\ngrep()和grepl()这两个函数最大的区别在于grep()返回找到的位置，grepl返回【是否】包含查找内容的逻辑向量。\n\ngrepl(\"北京\", places)\n\n[1] FALSE  TRUE FALSE  TRUE\n\nany(grepl(\"北京\", places))#只要places中有包含了“北京”的项目就返回一个\"TRUE\"\n\n[1] TRUE",
    "crumbs": [
      "Home",
      "R语言基础",
      "字符的处理"
    ]
  },
  {
    "objectID": "r_basic/character.html#startswith和endswith",
    "href": "r_basic/character.html#startswith和endswith",
    "title": "字符的处理",
    "section": "\n4.4 startsWith()和endsWith()\n",
    "text": "4.4 startsWith()和endsWith()\n\n用于查找开头或结尾的字符\n\n# 从“places”中查找以“中国”开头的对象\nstartsWith(\n  x = places, # 从哪里查找\n  prefix = \"中国\" # 查找内容\n  )\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n# 用grepl()的方式：\ngrepl(pattern = \"^中国\", places)\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n# 从“places”中查找以“北京”结尾的对象\nendsWith(x = places, \"北京\")\n\n[1] FALSE  TRUE FALSE FALSE\n\n# 用grepl()的方式：\ngrepl(pattern = \"北京$\", places)\n\n[1] FALSE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tidyr_1.3.0   stringr_1.5.1\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       cli_3.6.2         knitr_1.45        rlang_1.1.3      \n [5] xfun_0.41         stringi_1.8.3     purrr_1.0.2       generics_0.1.3   \n [9] jsonlite_1.8.8    glue_1.7.0        htmltools_0.5.7   fansi_1.0.6      \n[13] rmarkdown_2.25    tibble_3.2.1      evaluate_0.23     fastmap_1.1.1    \n[17] yaml_2.3.8        lifecycle_1.0.4   compiler_4.3.2    dplyr_1.1.4      \n[21] codetools_0.2-19  pkgconfig_2.0.3   htmlwidgets_1.6.4 rstudioapi_0.15.0\n[25] digest_0.6.34     R6_2.5.1          tidyselect_1.2.0  utf8_1.2.4       \n[29] pillar_1.9.0      magrittr_2.0.3    withr_3.0.0       tools_4.3.2",
    "crumbs": [
      "Home",
      "R语言基础",
      "字符的处理"
    ]
  },
  {
    "objectID": "r_basic/loop.html",
    "href": "r_basic/loop.html",
    "title": "循环",
    "section": "",
    "text": "参考：\n【R语言】优雅的循环迭代：purrr包\nhttps://purrr.tidyverse.org\n循环迭代，就是将一个函数依次应用（映射）到序列的每一个元素上。用R写循环从低到高有三种境界：基础的显式for循环，到apply()函数家族，最后到purrr包map()函数家族泛函式编程。在R语言中应该尽量避免显式循环的应用。而apply()函数家族和map()函数家族都能够用于避免显式使用循环结构。map()系列函数提供了更多的一致性、规范性和便利性，更容易记住和使用。速度来说，apply()家族稍快，但可以忽略不计。",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#sec-map_function",
    "href": "r_basic/loop.html#sec-map_function",
    "title": "循环",
    "section": "\n2.1 map()\n",
    "text": "2.1 map()\n\n依次应用一元函数到一个序列的每个元素上，基本等同 lapply()：\n\n\n\n\n\n\nTip\n\n\n\n序列包括以下的类型：\n\n原子向量（各个元素都是同类型的），包括 6 种类型：logical、integer、double、character、complex、raw，其中 integer 和 double 也统称为numeric\n列表（包含的元素可以是不同类型的）\n\n\n\n\n\nlibrary(purrr)\nchr &lt;- list(x = c(\"a\", \"b\"), y = c(\"c\", \"d\"))\nchr\n\n$x\n[1] \"a\" \"b\"\n\n$y\n[1] \"c\" \"d\"\n\n# 让chr中的字符降序排列\nmap(chr, sort, decreasing = TRUE)\n\n$x\n[1] \"b\" \"a\"\n\n$y\n[1] \"d\" \"c\"\n\n\n如过map()应用对象是数据框，那么会将函数应用于数据框的每一列（可以把数据框的每一列看作一个元素）:\n\nx_df &lt;- data.frame(a = 1:10, b = 11:20, c = 21:30)\nx_df\n\n    a  b  c\n1   1 11 21\n2   2 12 22\n3   3 13 23\n4   4 14 24\n5   5 15 25\n6   6 16 26\n7   7 17 27\n8   8 18 28\n9   9 19 29\n10 10 20 30\n\n# 计算x_tab每一列的均值\nmap(x_df, mean)\n\n$a\n[1] 5.5\n\n$b\n[1] 15.5\n\n$c\n[1] 25.5\n\n\nmean()函数还有其它参数，如 na.rm，这些需要特别指定的目标函数参数可以放到函数的后面：\n\nmap(x_df, mean, na.rm = TRUE)  # 因为数据不含NA, 故结果同上\n\n$a\n[1] 5.5\n\n$b\n[1] 15.5\n\n$c\n[1] 25.5",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#map2",
    "href": "r_basic/loop.html#map2",
    "title": "循环",
    "section": "\n2.2 map2()\n",
    "text": "2.2 map2()\n\n依次应用二元函数到两个序列的每对元素上（要求两个序列有相同的长度）：\n\n\nx &lt;- list(a = 1:10, b = 11:20, c = 21:30)\nx\n\n$a\n [1]  1  2  3  4  5  6  7  8  9 10\n\n$b\n [1] 11 12 13 14 15 16 17 18 19 20\n\n$c\n [1] 21 22 23 24 25 26 27 28 29 30\n\ny &lt;- list(1, 2, 3)\ny\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\nmap2(x, y,\\(x, y) x*y)\n\n$a\n [1]  1  2  3  4  5  6  7  8  9 10\n\n$b\n [1] 22 24 26 28 30 32 34 36 38 40\n\n$c\n [1] 63 66 69 72 75 78 81 84 87 90\n\n\nmap2()应用对象也可以是数据框和向量：\n\ny_vec &lt;- c(1:3)\ny_vec\n\n[1] 1 2 3\n\n# 将y_vec中的每一个元素逐一与x_df中对应的列中的每个值相乘\nmap2(x_df, y_vec, \\(x, y) x*y)\n\n$a\n [1]  1  2  3  4  5  6  7  8  9 10\n\n$b\n [1] 22 24 26 28 30 32 34 36 38 40\n\n$c\n [1] 63 66 69 72 75 78 81 84 87 90\n\n\n\ny_df &lt;- data.frame(d = 21:30, e = 11:20, f = 1:10)\ny_df\n\n    d  e  f\n1  21 11  1\n2  22 12  2\n3  23 13  3\n4  24 14  4\n5  25 15  5\n6  26 16  6\n7  27 17  7\n8  28 18  8\n9  29 19  9\n10 30 20 10\n\n# 将y_df中的每列逐一与x_df中对应的列中的每个值相乘\nmap2(x_df, y_df, \\(x, y) x*y)\n\n$a\n [1]  21  44  69  96 125 156 189 224 261 300\n\n$b\n [1] 121 144 169 196 225 256 289 324 361 400\n\n$c\n [1]  21  44  69  96 125 156 189 224 261 300\n\n# 输出数据框\nmap2_df(x_df, y_df, \\(x, y) x*y)\n\n# A tibble: 10 × 3\n       a     b     c\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1    21   121    21\n 2    44   144    44\n 3    69   169    69\n 4    96   196    96\n 5   125   225   125\n 6   156   256   156\n 7   189   289   189\n 8   224   324   224\n 9   261   361   261\n10   300   400   300",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#pmap",
    "href": "r_basic/loop.html#pmap",
    "title": "循环",
    "section": "\n2.3 pmap()\n",
    "text": "2.3 pmap()\n\n应用多元函数到多个序列的每组元素上，可以实现对数据框逐行迭代\n\n\nz &lt;- list(4, 5, 6)\npmap(\n  list(x, y, z),\n  function(first, second, third) first * (second + third)\n)\n\n$a\n [1]  5 10 15 20 25 30 35 40 45 50\n\n$b\n [1]  77  84  91  98 105 112 119 126 133 140\n\n$c\n [1] 189 198 207 216 225 234 243 252 261 270\n\n\n也可以应用于数据框，实现对数据框逐行迭代：\n\nx_df\n\n    a  b  c\n1   1 11 21\n2   2 12 22\n3   3 13 23\n4   4 14 24\n5   5 15 25\n6   6 16 26\n7   7 17 27\n8   8 18 28\n9   9 19 29\n10 10 20 30\n\npmap_dbl(\n  x_df,\n  ~ ..1 * (..2 + ..3)\n) # 这里用带后缀的形式（pmap_dbl）返回数值型向量（见下文）\n\n [1]  32  68 108 152 200 252 308 368 432 500",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#给map函数添加后缀",
    "href": "r_basic/loop.html#给map函数添加后缀",
    "title": "循环",
    "section": "\n2.4 给map函数添加后缀",
    "text": "2.4 给map函数添加后缀\nmap系列函数的运算结果默认是列表型的，但是map系列函数都有后缀形式，以决定循环迭代之后返回的数据类型，这是 purrr 比 apply函数族更先进和便利的一大优势。常用后缀如下（这里以map()为例，map2()和pmap()也有与之对应的后缀）：\n\n\nmap_dbl(.x, .f): 返回数值型向量\n\n【案例】在上面的map()案例中，求均值返回的结果是数值型，所以更好的做法是将返回结果指定为数值型向量，只需在map后加上_dbl的后缀：\n\nmap_dbl(x_df, mean)\n\n   a    b    c \n 5.5 15.5 25.5 \n\n\n\n\nmap_int(.x, .f): 返回整数型向量\n\n\n\nmap_lgl(.x, .f): 返回逻辑型向量\n\n\n\nmap_chr(.x, .f): 返回字符型向量\n\n\n\nmap_dfr(.x, .f): 返回数据框列表，再 bind_rows 按行合并为一个数据框\n【案例】批量读取具有相同列名的数据文件并合并成一个数据框\n\nfiles = list.files(\"datas/\", pattern = \"xlsx\", full.names = TRUE)\ndf = map_dfr(files, read_xlsx)    # 批量读取+按行堆叠合并\n\nmap_dfr(files, read_xlsx) 依次将 read_xlsx() 函数应用到各个文件路径上，即依次读取数据，返回结果是数据框，同时“dfr”表示再做按行合并，一步到位。若需要设置 read_xlsx() 的其它参数，只需在后面设置即可。\n\nmap_dfc(.x, .f): 返回数据框列表，再 bind_cols 按列合并为一个数据框",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#walk系列",
    "href": "r_basic/loop.html#walk系列",
    "title": "循环",
    "section": "\n2.5 walk()系列\n",
    "text": "2.5 walk()系列\n\n将函数依次作用到序列上，不返回结果。有些批量操作是没有或不关心返回结果的，例如批量保存到文件：save(), write_csv() 、saveRDS()等。walk()系列同样包括了walk()、walk2和pwalk()。\n\n【例一】将mpg数据按“manufacturer”分组，每个“manufacturer”的数据分别保存为单独数据文件。\n\n# 读取ggplot2包自带mpg数据集（该数据为tibble型）\ndf &lt;- ggplot2::mpg\nhead(df)\n\n# A tibble: 6 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…\n6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…\n\n# 通过group_nest将mpg数据按“manufacturer”分组，每个“manufacturer”的数据分别保存为单独数据\nlibrary(dplyr)\ndf &lt;- group_nest(df, manufacturer) \ndf\n\n# A tibble: 15 × 2\n   manufacturer                data\n   &lt;chr&gt;        &lt;list&lt;tibble[,10]&gt;&gt;\n 1 audi                   [18 × 10]\n 2 chevrolet              [19 × 10]\n 3 dodge                  [37 × 10]\n 4 ford                   [25 × 10]\n 5 honda                   [9 × 10]\n 6 hyundai                [14 × 10]\n 7 jeep                    [8 × 10]\n 8 land rover              [4 × 10]\n 9 lincoln                 [3 × 10]\n10 mercury                 [4 × 10]\n11 nissan                 [13 × 10]\n12 pontiac                 [5 × 10]\n13 subaru                 [14 × 10]\n14 toyota                 [34 × 10]\n15 volkswagen             [27 × 10]\n\n# 批量输出这些数据\npwalk(df, ~ write.csv(..2, paste0(\"output/r_basic/\", ..1, \".csv\")))\n\n\n【例二】这个例子来自读取非标准10X格式文件，要实现在”output/r_basic/GSE184880_RAW”中批量建立文件夹的目的。\n首先是构建文件夹的目录和名字，这一部分的目的参照读取非标准10X格式文件。\n\n# 列出\nfiles &lt;- list.files(\"data/sc_supplementary/GSE184880_RAW\")\nfiles[1:10]\n\n [1] \"GSM5599220_Norm1\"                 \"GSM5599220_Norm1.barcodes.tsv.gz\"\n [3] \"GSM5599220_Norm1.genes.tsv.gz\"    \"GSM5599220_Norm1.matrix.mtx.gz\"  \n [5] \"GSM5599221_Norm2\"                 \"GSM5599221_Norm2.barcodes.tsv.gz\"\n [7] \"GSM5599221_Norm2.genes.tsv.gz\"    \"GSM5599221_Norm2.matrix.mtx.gz\"  \n [9] \"GSM5599222_Norm3\"                 \"GSM5599222_Norm3.barcodes.tsv.gz\"\n\ndirnames &lt;- gsub(pattern = \".barcodes.tsv.gz|.genes.tsv.gz|.matrix.mtx.gz\", \n                 replacement = \"\", \n                 x = files) %&gt;%  \n  unique() %&gt;% \n  paste0(\"output/r_basic/GSE184880_RAW/\", .) \ndirnames\n\n [1] \"output/r_basic/GSE184880_RAW/GSM5599220_Norm1\"  \n [2] \"output/r_basic/GSE184880_RAW/GSM5599221_Norm2\"  \n [3] \"output/r_basic/GSE184880_RAW/GSM5599222_Norm3\"  \n [4] \"output/r_basic/GSE184880_RAW/GSM5599223_Norm4\"  \n [5] \"output/r_basic/GSE184880_RAW/GSM5599224_Norm5\"  \n [6] \"output/r_basic/GSE184880_RAW/GSM5599225_Cancer1\"\n [7] \"output/r_basic/GSE184880_RAW/GSM5599226_Cancer2\"\n [8] \"output/r_basic/GSE184880_RAW/GSM5599227_Cancer3\"\n [9] \"output/r_basic/GSE184880_RAW/GSM5599228_Cancer4\"\n[10] \"output/r_basic/GSE184880_RAW/GSM5599229_Cancer5\"\n[11] \"output/r_basic/GSE184880_RAW/GSM5599230_Cancer6\"\n[12] \"output/r_basic/GSE184880_RAW/GSM5599231_Cancer7\"\n\n# 在“output/r_basic”目标位置先建立一个“GSE184880_RAW”用于存放一会儿构建的文件夹\ndir.create(\"output/r_basic/GSE184880_RAW\")\n\n通过pwalk()根据文件夹的名称“dirnames”建立文件夹。⚠️注意pwalk()只能应用于列表对象，所以这里通过list()进行了转化：\n\npwalk(list(dirnames), dir.create)\n\n\n\n建立好的文件夹\n\n\n\n\n\n\n\nTip\n\n\n\n更多关于purr包的应用，参考：【R语言】优雅的循环迭代：purrr包、https://purrr.tidyverse.org。\n\n\n\n\n\n\n\n\napply家族 vs. map家族函数\n\n\n\n\n\nThere are two primary differences between the base apply family and the purrr map family: purrr functions are named more consistently, and more fully explore the space of input and output variants.\n\npurrr functions consistently use . as prefix to avoid inadvertently matching arguments of the purrr function, instead of the function that you’re trying to call. Base functions use a variety of techniques including upper case (e.g. lapply(X, FUN, ...)) or require anonymous functions (e.g. Map()).\nAll map functions are type stable: you can predict the type of the output using little information about the inputs. In contrast, the base functions sapply() and mapply() automatically simplify making the return value hard to predict.\nThe map functions all start with the data, followed by the function, then any additional constant argument. Most base apply functions also follow this pattern, but mapply() starts with the function, and Map() has no way to supply additional constant arguments.\npurrr functions provide all combinations of input and output variants, and include variants specifically for the common two argument case.\n\napply家族和map家族函数对照表：\n\n\n\n\n\n\n\n\nOutput\nInput\nBase R\npurrr\n\n\n\nList\n1 vector\nlapply()\nmap()\n\n\nList\n2 vectors\n\nmapply(), Map()\n\nmap2()\n\n\nList\n&gt;2 vectors\n\nmapply(), Map()\n\npmap()\n\n\nAtomic vector of desired type\n1 vector\nvapply()\n\nmap_lgl() (logical)\nmap_int() (integer)\nmap_dbl() (double)\nmap_chr() (character)\nmap_raw() (raw)\n\n\n\nAtomic vector of desired type\n2 vectors\n\nmapply(), Map(), then is.*() to check type\n\nmap2_lgl() (logical)\nmap2_int() (integer)\nmap2_dbl() (double)\nmap2_chr() (character)\nmap2_raw() (raw)\n\n\n\nAtomic vector of desired type\n&gt;2 vectors\n\nmapply(), Map(), then is.*() to check type\n\nmap2_lgl() (logical)\nmap2_int() (integer)\nmap2_dbl() (double)\nmap2_chr() (character)\nmap2_raw() (raw)\n\n\n\nSide effect only\n1 vector\nloops\nwalk()\n\n\nSide effect only\n2 vectors\nloops\nwalk2()\n\n\nSide effect only\n&gt;2 vectors\nloops\npwalk()\n\n\nData frame (rbindoutputs)\n1 vector\n\nlapply() then rbind()\n\nmap_dfr()\n\n\nData frame (rbindoutputs)\n2 vectors\n\nmapply()/Map() thenrbind()\n\nmap2_dfr()\n\n\nData frame (rbindoutputs)\n&gt;2 vectors\n\nmapply()/Map() thenrbind()\n\npmap_dfr()\n\n\nData frame (cbindoutputs)\n1 vector\n\nlapply() then cbind()\n\nmap_dfc()\n\n\nData frame (cbindoutputs)\n2 vectors\n\nmapply()/Map() thencbind()\n\nmap2_dfc()\n\n\nData frame (cbindoutputs)\n&gt;2 vectors\n\nmapply()/Map() thencbind()\n\npmap_dfc()\n\n\nAny\nVector and its names\n\nl/s/vapply(X, function(x) f(x, names(x))) ormapply/Map(f, x, names(x))\n\n\nimap(), imap_*() (lgl, dbl, dfr, and etc. just like formap(), map2(), and pmap())\n\n\nAny\nSelected elements of the vector\nl/s/vapply(X[index], FUN, ...)\n\nmap_if(), map_at()\n\n\n\nList\nRecursively apply to list within list\nrapply()\nmap_depth()\n\n\nList\nList only\nlapply()\n\nlmap(), lmap_at(),lmap_if()\n\n\n\n\nSince a common use case for map functions is list extracting components, purrr provides a handful of shortcut functions for various uses of [[.\n\n\n\n\n\n\n\nInput\nbase R\npurrr\n\n\n\nExtract by name\nlapply(x, `[[`, \"a\")\nmap(x, \"a\")\n\n\nExtract by position\nlapply(x, `[[`, 3)\nmap(x, 3)\n\n\nExtract deeply\nlapply(x, \\(y) y[[1]][[\"x\"]][[3]])\nmap(x, list(1, \"x\", 3))\n\n\nExtract with default value\nlapply(x, function(y) tryCatch(y[[3]], error = function(e) NA))\nmap(x, 3, .default = NA)",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#assign函数",
    "href": "r_basic/loop.html#assign函数",
    "title": "循环",
    "section": "\n3.1 assign()函数",
    "text": "3.1 assign()函数\nassign函数能够将某个值赋值给指定名称，从而实现循环中将每次运行的结果保存到一个对象中，而不覆盖上一次运行的结果。\n\nx：变量名称/赋值对象/最后的新变量的名称\nvalue：需要赋给x的值\n\n下面的案例实现输出”A”, “B”, “C”, “D”四个变量，每个变量就是一次循环的结果：\n\nfor (x in c(\"A\", \"B\", \"C\", \"D\")){\n        y &lt;- paste0(x, x)\n        assign(x = x, value = y)\n}",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/loop.html#append函数",
    "href": "r_basic/loop.html#append函数",
    "title": "循环",
    "section": "\n3.2 append函数",
    "text": "3.2 append函数\nappend()函数被广泛应用于将新的向量添加到现有的向量、列表或数据框中。\n\n将新向量添加到已有向量中：\n\n\nv1 &lt;- c(1, 2, 3, 4, 5)\nv2 &lt;- c(6, 7, 8)\n\nv3 &lt;- append(v1, v2)\nv3\n\n[1] 1 2 3 4 5 6 7 8\n\n#等价于\nv3 &lt;- c(v1, v2)\n\n\n将新列表添加到已有列表中：\n\n\nlist1 &lt;- list(a = 1, b = 2, c = 3)\nlist2 &lt;- list(d = 4, e = 5, f = 6)\nlist3 &lt;- append(list1, list2)\nlist3\n\n$a\n[1] 1\n\n$b\n[1] 2\n\n$c\n[1] 3\n\n$d\n[1] 4\n\n$e\n[1] 5\n\n$f\n[1] 6\n\n\n实际应用场景：在批量读取构建Seurat对象时，通过append()函数将每次的Seurat对象添加到列表中，最终得到一个包含了所有样本的单细胞数据的列表：\n\nfor (file in file_list) {\n  # 拼接文件路径\n  data.path &lt;- paste0(\"data/other_single_cell_content/GSE234933_MGH_HNSCC_gex_raw_counts/\", file)\n  # 读取RDS文件数据\n  seurat_data &lt;- readRDS(data.path)\n  # 创建Seurat对象，并指定项目名称为文件名（去除后缀）\n  sample_name &lt;- file_path_sans_ext(file)\n  seurat_obj &lt;- CreateSeuratObject(counts = seurat_data,\n                                   project = sample_name,\n                                   min.features = 200,\n                                   min.cells = 3)\n  # 将Seurat对象添加到列表中\n  seurat_list &lt;- append(seurat_list, seurat_obj)\n}\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.4 purrr_1.0.2\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       cli_3.6.2         knitr_1.45        rlang_1.1.3      \n [5] xfun_0.41         generics_0.1.3    jsonlite_1.8.8    glue_1.7.0       \n [9] colorspace_2.1-0  htmltools_0.5.7   scales_1.3.0      fansi_1.0.6      \n[13] rmarkdown_2.25    grid_4.3.2        munsell_0.5.0     evaluate_0.23    \n[17] tibble_3.2.1      fastmap_1.1.1     yaml_2.3.8        lifecycle_1.0.4  \n[21] compiler_4.3.2    codetools_0.2-19  htmlwidgets_1.6.4 pkgconfig_2.0.3  \n[25] rstudioapi_0.15.0 digest_0.6.34     R6_2.5.1          tidyselect_1.2.0 \n[29] utf8_1.2.4        pillar_1.9.0      magrittr_2.0.3    gtable_0.3.4     \n[33] tools_4.3.2       ggplot2_3.4.4",
    "crumbs": [
      "Home",
      "R语言基础",
      "循环"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html",
    "href": "r_basic/dplyr.html",
    "title": "基于dplyr包的数据处理",
    "section": "",
    "text": "参考：\ndplyr官方文档\nData transformation chapter in R for Data Science",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#管道的基本用法",
    "href": "r_basic/dplyr.html#管道的基本用法",
    "title": "基于dplyr包的数据处理",
    "section": "\n2.1 管道的基本用法",
    "text": "2.1 管道的基本用法\n管道的用法就是通过管道符|&gt;或%&gt;%串联起来前后的两个函数调用，先计算管道符号左边的函数调用，然后将其结果自动传递给管道符号右边函数的第一个参数（默认），然后对运行这个函数，正如上面的例子中提到的一样。如果不想把值传递给第一个参数，则可以用占位符_（适用于|&gt;）或.（适用于%&gt;%）的形式指定把前面的运算结果传递给哪个参数。\n比如想在mtcars数据集的车名中寻找所有以“M”开头的车名，则可以通过如下方式寻找：\n\nmtcars |&gt; rownames() |&gt; grep(\"^M\", x = _)\n\n [1]  1  2  8  9 10 11 12 13 14 31\n\n#或用%&gt;%形式\nlibrary(magrittr) # 也可以直接加载dplyr或tidyverse包，便于后续调用其他tidyverse函数\nmtcars %&gt;%  rownames() %&gt;%  grep(pattern = \"^M\", x = .)\n\n [1]  1  2  8  9 10 11 12 13 14 31\n\n\n解释如下：在grep函数那里，由于我们想在车名（这里是行名）中找到符合特定pattern的车名位置，因此需要把车名传给grep的第二个参数x，所以就可以.或_的形式将前面的值传给grep的x。\n⚠️注意：传给其他位置的.必须是独立的，不能在一个表达式（函数）中，比如如下情况，我只想寻找前10个车名中以“M”开头的车名位置：\n\n# 错误 ---------------\nmtcars %&gt;% rownames %&gt;% grep(\"^M\", x = .[1:10])\n\nWarning in grep(., \"^M\", x = .[1:10]): argument 'pattern' has length &gt; 1 and\nonly the first element will be used\n\n\n[1] 1 2\n\n# 正确 ---------------\nmtcars[1:10, ] %&gt;% rownames %&gt;% grep(\"^M\", x = .)\n\n[1]  1  2  8  9 10\n\n\n上面的错误调用中，传递给grep的x参数的是一个表达式.[1:10]，不是一个单独的.了，因此失去了调整前面值的位置的作用，它就等价于如下调用：\n\n# 错误  ---------------\nmtcars %&gt;% rownames %&gt;% grep(\"^M\", x = .[1:10])\n\n# 等价于 --------------\n# 还是把前面的值传递给第一个参数：\nmtcars %&gt;% rownames %&gt;% grep(., \"^M\", x = .[1:10])",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#管道的进阶用法",
    "href": "r_basic/dplyr.html#管道的进阶用法",
    "title": "基于dplyr包的数据处理",
    "section": "\n2.2 管道的进阶用法\n",
    "text": "2.2 管道的进阶用法\n\n我们可以通过“{}”符号包裹后续函数，在“{}”内的代码，可以任意的使用多个占位符.去传递管道前的值。还是上面的例子：\n\nmtcars[1:10, ] %&gt;%  rownames() %&gt;%  grep(\"^M\", x = .) %&gt;% plot()\n\n# 用“{}”的形式 ---------------\nmtcars %&gt;% rownames %&gt;% {grep(\"^M\", x = .[1:10])} %&gt;% plot()\n\n⚠️注意，|&gt;不支持“{}”形式：\n\n# 错误：\nmtcars |&gt; rownames() |&gt; {grep(\"^M\", x = _[1:10])}\n\n这也反映出base包|&gt;功能的局限性。\n本质上“{}”是magrittr改写的一个匿名函数，只有唯一的一个参数，也就是. ：\n\nfunction(.) {\n  # any code\n}\n\n比如想要获取mtcars的前5行前5列，然后更改行名和列名后，再返回这个数据框：\n\ndf &lt;- mtcars %&gt;% .[1:5, 1:5] %&gt;%\n  {\n    rownames(.) &lt;- paste0(\"row\", 1:5)\n    colnames(.) &lt;- paste0(\"col\", 1:5)\n    . # &lt;---------- 不要忘了返回这个数据框\n  }\ndf\n\n     col1 col2 col3 col4 col5\nrow1 21.0    6  160  110 3.90\nrow2 21.0    6  160  110 3.90\nrow3 22.8    4  108   93 3.85\nrow4 21.4    6  258  110 3.08\nrow5 18.7    8  360  175 3.15\n\n\n⚠️注意，在整个“{}”包括的语句中，如果再使用管道要注意这时的占位符.代表的是“{}”内的对象。\n\nmtcars %&gt;% .[1:5, 1:5] %&gt;%\n  {\n    rownames(.) &lt;- paste0(\"row\", 1:5)\n    colnames(.) &lt;- paste0(\"col\", 1:5)\n    .[1:3, ] %&gt;% cbind(., .) # cbind里面的.不指代{}外面的值\n  }\n\n     col1 col2 col3 col4 col5 col1 col2 col3 col4 col5\nrow1 21.0    6  160  110 3.90 21.0    6  160  110 3.90\nrow2 21.0    6  160  110 3.90 21.0    6  160  110 3.90\nrow3 22.8    4  108   93 3.85 22.8    4  108   93 3.85\n\n# 等价：\nmtcars %&gt;% .[1:5, 1:5] %&gt;%\n  {\n    rownames(.) &lt;- paste0(\"row\", 1:5)\n    colnames(.) &lt;- paste0(\"col\", 1:5)\n    .\n  } %&gt;% \n  .[1:3, ] %&gt;% \n  cbind(., .)\n\n     col1 col2 col3 col4 col5 col1 col2 col3 col4 col5\nrow1 21.0    6  160  110 3.90 21.0    6  160  110 3.90\nrow2 21.0    6  160  110 3.90 21.0    6  160  110 3.90\nrow3 22.8    4  108   93 3.85 22.8    4  108   93 3.85",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#特殊管道符",
    "href": "r_basic/dplyr.html#特殊管道符",
    "title": "基于dplyr包的数据处理",
    "section": "\n2.3 特殊管道符",
    "text": "2.3 特殊管道符\nmagrittr包内除了%&gt;%管道符外，还提供了%$%、%&lt;&gt;%、%T&gt;%、%!&gt;%，他们的作用简述如下：\n%$%\n用于传递管道左侧数据的names：\n\ncolnames(mtcars)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n\n# mtcars的每个元素都可以被后面的函数所使用\nmtcars %$% plot(mpg, cyl)\n\n\n\n\n\n\n\n\n# 等价于\nmtcars %&gt;% {plot(.[,\"mpg\"], .[, \"cyl\"])}\n\n\n\n\n\n\nsum(mtcars$mpg, mtcars$cyl)\n\n[1] 840.9\n\n\n%&lt;&gt;%\n将管道的结果最终再赋值回最左侧的变量：\n\nset.seed(1234)\nx &lt;- rnorm(5)\nx\n\n[1] -1.2070657  0.2774292  1.0844412 -2.3456977  0.4291247\n\n# x排序后加上10，最后再赋值给x\nx %&lt;&gt;% sort() %&gt;% {. + 10}\nx\n\n[1]  7.654302  8.792934 10.277429 10.429125 11.084441\n\n\n\n# 等价于\nx &lt;- x %&gt;% sort() %&gt;% {. + 10}\n\n%T&gt;%\n分支管道，传入左侧的值并运算后将原始值而不是运算结果传递给后续管道。这在多个管道中间使用print()、plot()或summary()这些函数返回信息时非常有用。\n\n1:5 %&gt;% plot() %&gt;% sum() # 传递给sum()的是前面所有函数的运算结果，由于plot()不返回任何数值，所以sum()的结果为0\n\n[1] 0\n\n1:5 %T&gt;% plot() %&gt;% sum() # 传递给sum()的是1:5\n\n\n\n\n\n\n\n[1] 15\n\n# 另一个例子\nrnorm(200) %&gt;%\n  matrix(ncol = 2) %T&gt;%\n  plot %&gt;% \n  colSums() # 传递给colSums()的是“rnorm(200) %&gt;% matrix(ncol = 2)”\n\n\n\n\n\n\n\n[1] -15.23708   7.82692",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#filter",
    "href": "r_basic/dplyr.html#filter",
    "title": "基于dplyr包的数据处理",
    "section": "\n3.1 filter()\n",
    "text": "3.1 filter()\n\n\n用于提取满足某（些）条件的行，基本等同于subset()。\n\n# 查找所有晚点 120 分钟（两小时）以上起飞的航班：\nfilter(flights, dep_delay &gt; 120)\n\n# A tibble: 9,723 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      848           1835       853     1001           1950\n 2  2013     1     1      957            733       144     1056            853\n 3  2013     1     1     1114            900       134     1447           1222\n 4  2013     1     1     1540           1338       122     2020           1825\n 5  2013     1     1     1815           1325       290     2120           1542\n 6  2013     1     1     1842           1422       260     1958           1535\n 7  2013     1     1     1856           1645       131     2212           2005\n 8  2013     1     1     1934           1725       129     2126           1855\n 9  2013     1     1     1938           1703       155     2109           1823\n10  2013     1     1     1942           1705       157     2124           1830\n# ℹ 9,713 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n# 查找一月或二月起飞的航班\nfilter(flights, month %in% c(1, 2))\n\n# A tibble: 51,955 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 51,945 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#arrange",
    "href": "r_basic/dplyr.html#arrange",
    "title": "基于dplyr包的数据处理",
    "section": "\n3.2 arrange()\n",
    "text": "3.2 arrange()\n\n排序，以某列为依据对行进行排序（在前面的数据处理基本函数一章中已涉及该函数）。对应的功能在base包中是order()函数。如果提供的列名不止一个，则依次根据提供的列的顺序对数据进行排序。例如，下面的代码按航班出发时间排序，出发时间分布在四列中。我们首先得到最早的年份，然后在一年内得到最早的月份，依此类推。\n\narrange(flights, year, month, day, dep_time)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n可以加上desc()实现降序排列：\n\narrange(flights, desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#distinct",
    "href": "r_basic/dplyr.html#distinct",
    "title": "基于dplyr包的数据处理",
    "section": "\n3.3 distinct()\n",
    "text": "3.3 distinct()\n\n\n查找数据集中所有唯一的行。\n\n# 移除所有完全相同的行\ndistinct(flights)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n# 查找所有唯一的出发地和目的地配对\ndistinct(flights, origin, dest)\n\n# A tibble: 224 × 2\n   origin dest \n   &lt;chr&gt;  &lt;chr&gt;\n 1 EWR    IAH  \n 2 LGA    IAH  \n 3 JFK    MIA  \n 4 JFK    BQN  \n 5 LGA    ATL  \n 6 EWR    ORD  \n 7 EWR    FLL  \n 8 LGA    IAD  \n 9 JFK    MCO  \n10 LGA    ORD  \n# ℹ 214 more rows\n\n\n可以看到，如果根据某列或某几列为依据来查找非重复值，那么默认只输出这几列，我们可以通过加入.keep_all = TRUE参数来保留其他列。.表示 .keep_all 是函数的一个参数，而不另一个变量的名称。\n\ndistinct(flights, origin, dest, .keep_all = TRUE)\n\n# A tibble: 224 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 214 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n可以发现所有这些不同的航班都是在 1 月 1 日，这绝非巧合：distinct() 会在数据集中找到唯一值第一次出现的那一行，并舍弃其他行。\n如果要得到每种出发地和目的地配对出现的次数，可以将 distinct() 换成 count()，并可使用 sort = TRUE 参数按出现次数降序排列。count()同样来自dplyr包，用于快速统计一个或多个变量的唯一值的出现次数。\n\ncount(flights, origin, dest, sort = TRUE)\n\n# A tibble: 224 × 3\n   origin dest      n\n   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n 1 JFK    LAX   11262\n 2 LGA    ATL   10263\n 3 LGA    ORD    8857\n 4 JFK    SFO    8204\n 5 LGA    CLT    6168\n 6 EWR    ORD    6100\n 7 JFK    BOS    5898\n 8 LGA    MIA    5781\n 9 JFK    MCO    5464\n10 EWR    BOS    5327\n# ℹ 214 more rows",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#sec-mutate",
    "href": "r_basic/dplyr.html#sec-mutate",
    "title": "基于dplyr包的数据处理",
    "section": "\n4.1 mutate()\n",
    "text": "4.1 mutate()\n\n\nmutate()的作用是根据现有列计算并添加新列。\n\n# 计算延误航班在空中停留的时间（gain）以及平均速度（speed，英里/小时）：\nmutate(\n  flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60\n)\n\n# A tibble: 336,776 × 21\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, gain &lt;dbl&gt;, speed &lt;dbl&gt;\n\n\n默认情况下，mutate() 会在数据集的最右侧添加计算后的新列，因此很难看到这里发生了什么。我们可以使用 .before 参数将变量添加到数据集的左侧：\n\nmutate(\n  flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60,\n  .before = 1 # 添加到第一列\n)\n\n# A tibble: 336,776 × 21\n    gain speed  year month   day dep_time sched_dep_time dep_delay arr_time\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1    -9  370.  2013     1     1      517            515         2      830\n 2   -16  374.  2013     1     1      533            529         4      850\n 3   -31  408.  2013     1     1      542            540         2      923\n 4    17  517.  2013     1     1      544            545        -1     1004\n 5    19  394.  2013     1     1      554            600        -6      812\n 6   -16  288.  2013     1     1      554            558        -4      740\n 7   -24  404.  2013     1     1      555            600        -5      913\n 8    11  259.  2013     1     1      557            600        -3      709\n 9     5  405.  2013     1     1      557            600        -3      838\n10   -10  319.  2013     1     1      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n也可以使用 .after 指定新变量应该在哪个变量后添加，在 .before 和 .after 中，都可以使用变量名和列数两种方法指定新变量出现的位置。例如，我们可以在 “day” 之后添加新变量：\n\nmutate(\n  flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60,\n  .after = day # 添加到第一列\n)\n\n# A tibble: 336,776 × 21\n    year month   day  gain speed dep_time sched_dep_time dep_delay arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1  2013     1     1    -9  370.      517            515         2      830\n 2  2013     1     1   -16  374.      533            529         4      850\n 3  2013     1     1   -31  408.      542            540         2      923\n 4  2013     1     1    17  517.      544            545        -1     1004\n 5  2013     1     1    19  394.      554            600        -6      812\n 6  2013     1     1   -16  288.      554            558        -4      740\n 7  2013     1     1   -24  404.      555            600        -5      913\n 8  2013     1     1    11  259.      557            600        -3      709\n 9  2013     1     1     5  405.      557            600        -3      838\n10  2013     1     1   -10  319.      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n另外，也可以使用 .keep 参数来控制在计算新变量后哪些变量会被保留:\n\n.keep = \"all\"：默认。保留所有变量\n.keep = \"used\"：保留用于计算新变量的旧变量。这可以用于检查我们的新变量是否计算正确，因为它和原始变量一起展示。\n.keep = \"unused\"：保留其他不用于计算新变量的旧变量。\n\n例如，下面的输出将只包含旧变量 “dep_delay”、“arr_delay”、“distance”、“air_time”，以及新变量“gain”、“speed”：\n\nmutate(\n  flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60,\n  .keep = \"used\"\n)\n\n# A tibble: 336,776 × 6\n   dep_delay arr_delay air_time distance  gain speed\n       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1         2        11      227     1400    -9  370.\n 2         4        20      227     1416   -16  374.\n 3         2        33      160     1089   -31  408.\n 4        -1       -18      183     1576    17  517.\n 5        -6       -25      116      762    19  394.\n 6        -4        12      150      719   -16  288.\n 7        -5        19      158     1065   -24  404.\n 8        -3       -14       53      229    11  259.\n 9        -3        -8      140      944     5  405.\n10        -2         8      138      733   -10  319.\n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#select",
    "href": "r_basic/dplyr.html#select",
    "title": "基于dplyr包的数据处理",
    "section": "\n4.2 select()\n",
    "text": "4.2 select()\n\n\n选择并输出某几列。\n\n# 根据列名选择某几列\nselect(flights, year, month, day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n# 选择“year”和“day”及其之间的所有列\nselect(flights, year:day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n# 选择不在“year”和“day”及其之间的所有列\nselect(flights, !year:day)\n\n# A tibble: 336,776 × 16\n   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1      517            515         2      830            819        11 UA     \n 2      533            529         4      850            830        20 UA     \n 3      542            540         2      923            850        33 AA     \n 4      544            545        -1     1004           1022       -18 B6     \n 5      554            600        -6      812            837       -25 DL     \n 6      554            558        -4      740            728        12 UA     \n 7      555            600        -5      913            854        19 B6     \n 8      557            600        -3      709            723       -14 EV     \n 9      557            600        -3      838            846        -8 B6     \n10      558            600        -2      753            745         8 AA     \n# ℹ 336,766 more rows\n# ℹ 9 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;,\n#   air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n# 选择所有字符型的列\nselect(flights, where(is.character))\n\n# A tibble: 336,776 × 4\n   carrier tailnum origin dest \n   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n 1 UA      N14228  EWR    IAH  \n 2 UA      N24211  LGA    IAH  \n 3 AA      N619AA  JFK    MIA  \n 4 B6      N804JB  JFK    BQN  \n 5 DL      N668DN  LGA    ATL  \n 6 UA      N39463  EWR    ORD  \n 7 B6      N516JB  EWR    FLL  \n 8 EV      N829AS  LGA    IAD  \n 9 B6      N593JB  JFK    MCO  \n10 AA      N3ALAA  LGA    ORD  \n# ℹ 336,766 more rows\n\n\n在select()内有许多经常可以组合使用的函数：\n\nstarts_with(\"abc\"): 以特定字符开头的列名.\nends_with(\"xyz\"): 以特定字符结尾的列名.\ncontains(\"ijk\"): 包含特定字符的列名.\nnum_range(\"x\", 1:3): 列名x1, x2 和 x3.\n\n可以在选择变量的同时使用 = 对这些变量进行重命名。新变量名在 = 的左侧，旧变量名在右侧（new_name = old_name）：\n\nselect(flights, tail_num = tailnum)\n\n# A tibble: 336,776 × 1\n   tail_num\n   &lt;chr&gt;   \n 1 N14228  \n 2 N24211  \n 3 N619AA  \n 4 N804JB  \n 5 N668DN  \n 6 N39463  \n 7 N516JB  \n 8 N829AS  \n 9 N593JB  \n10 N3ALAA  \n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#sec-rename",
    "href": "r_basic/dplyr.html#sec-rename",
    "title": "基于dplyr包的数据处理",
    "section": "\n4.3 rename()\n",
    "text": "4.3 rename()\n\n重命名列。新变量名在 = 的左侧，旧变量名在右侧。\n\nrename(\n  flights, \n  years = year, \n  months = month\n  )\n\n# A tibble: 336,776 × 19\n   years months   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt;  &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013      1     1      517            515         2      830            819\n 2  2013      1     1      533            529         4      850            830\n 3  2013      1     1      542            540         2      923            850\n 4  2013      1     1      544            545        -1     1004           1022\n 5  2013      1     1      554            600        -6      812            837\n 6  2013      1     1      554            558        -4      740            728\n 7  2013      1     1      555            600        -5      913            854\n 8  2013      1     1      557            600        -3      709            723\n 9  2013      1     1      557            600        -3      838            846\n10  2013      1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n⚠️和其他dplyr中的函数一样，rename不会对原始数据进行修改，因此需要将rename后的数据重新赋值给新的对象或覆盖原来的对象以应用对变量名的修改。\n如果我们有一个提供了重命名依据的字符串向量，那么可以通过all_of()来基于这个字符串向量对数据集的列进行重命名：\n\nlookup &lt;- c(\n  years = \"year\", \n  months = \"month\"\n  )\nrename(flights, all_of(lookup))\n\n# A tibble: 336,776 × 19\n   years months   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt;  &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013      1     1      517            515         2      830            819\n 2  2013      1     1      533            529         4      850            830\n 3  2013      1     1      542            540         2      923            850\n 4  2013      1     1      544            545        -1     1004           1022\n 5  2013      1     1      554            600        -6      812            837\n 6  2013      1     1      554            558        -4      740            728\n 7  2013      1     1      555            600        -5      913            854\n 8  2013      1     1      557            600        -3      709            723\n 9  2013      1     1      557            600        -3      838            846\n10  2013      1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n如果提供重命名依据的字符串向量中有的变量是原数据集中不存在的，那么可以用 any_of()代替 all_of() 来实现：\n\nlookup &lt;- c(\n  years = \"year\", \n  months = \"month\",\n  new = \"unknown\"\n  )\nrename(flights, any_of(lookup))\n\n# A tibble: 336,776 × 19\n   years months   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt;  &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013      1     1      517            515         2      830            819\n 2  2013      1     1      533            529         4      850            830\n 3  2013      1     1      542            540         2      923            850\n 4  2013      1     1      544            545        -1     1004           1022\n 5  2013      1     1      554            600        -6      812            837\n 6  2013      1     1      554            558        -4      740            728\n 7  2013      1     1      555            600        -5      913            854\n 8  2013      1     1      557            600        -3      709            723\n 9  2013      1     1      557            600        -3      838            846\n10  2013      1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nrename_with()\n根据函数批量重命名列。\n\n# 将所有列名变为大写\nrename_with(flights, toupper)\n\n# A tibble: 336,776 × 19\n    YEAR MONTH   DAY DEP_TIME SCHED_DEP_TIME DEP_DELAY ARR_TIME SCHED_ARR_TIME\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: ARR_DELAY &lt;dbl&gt;, CARRIER &lt;chr&gt;, FLIGHT &lt;int&gt;,\n#   TAILNUM &lt;chr&gt;, ORIGIN &lt;chr&gt;, DEST &lt;chr&gt;, AIR_TIME &lt;dbl&gt;, DISTANCE &lt;dbl&gt;,\n#   HOUR &lt;dbl&gt;, MINUTE &lt;dbl&gt;, TIME_HOUR &lt;dttm&gt;\n\n# 将所有以“dep_\"开头的列名转换为大写\nrename_with(flights, toupper, .cols = starts_with(\"dep_\"))\n\n# A tibble: 336,776 × 19\n    year month   day DEP_TIME sched_dep_time DEP_DELAY arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n# 将列名中所有的\"_\"替换成“.”，并将所有列名转换成大写\nrename_with(\n  flights, \n  function(x) {\n    gsub(pattern = \"_\", replacement = \".\", x = x) %&gt;% \n    toupper()\n}\n)\n\n# A tibble: 336,776 × 19\n    YEAR MONTH   DAY DEP.TIME SCHED.DEP.TIME DEP.DELAY ARR.TIME SCHED.ARR.TIME\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: ARR.DELAY &lt;dbl&gt;, CARRIER &lt;chr&gt;, FLIGHT &lt;int&gt;,\n#   TAILNUM &lt;chr&gt;, ORIGIN &lt;chr&gt;, DEST &lt;chr&gt;, AIR.TIME &lt;dbl&gt;, DISTANCE &lt;dbl&gt;,\n#   HOUR &lt;dbl&gt;, MINUTE &lt;dbl&gt;, TIME.HOUR &lt;dttm&gt;\n\n# 匿名函数形式\nrename_with(flights, ~ gsub(pattern = \"_\", replacement = \".\", x= .x) %&gt;% toupper())\n\n# A tibble: 336,776 × 19\n    YEAR MONTH   DAY DEP.TIME SCHED.DEP.TIME DEP.DELAY ARR.TIME SCHED.ARR.TIME\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: ARR.DELAY &lt;dbl&gt;, CARRIER &lt;chr&gt;, FLIGHT &lt;int&gt;,\n#   TAILNUM &lt;chr&gt;, ORIGIN &lt;chr&gt;, DEST &lt;chr&gt;, AIR.TIME &lt;dbl&gt;, DISTANCE &lt;dbl&gt;,\n#   HOUR &lt;dbl&gt;, MINUTE &lt;dbl&gt;, TIME.HOUR &lt;dttm&gt;",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#relocate",
    "href": "r_basic/dplyr.html#relocate",
    "title": "基于dplyr包的数据处理",
    "section": "\n4.4 relocate()\n",
    "text": "4.4 relocate()\n\n调整列的顺序。\n\n# 将“day”和“year”放到最前面\nrelocate(flights, day, year)\n\n# A tibble: 336,776 × 19\n     day  year month dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1     1  2013     1      517            515         2      830            819\n 2     1  2013     1      533            529         4      850            830\n 3     1  2013     1      542            540         2      923            850\n 4     1  2013     1      544            545        -1     1004           1022\n 5     1  2013     1      554            600        -6      812            837\n 6     1  2013     1      554            558        -4      740            728\n 7     1  2013     1      555            600        -5      913            854\n 8     1  2013     1      557            600        -3      709            723\n 9     1  2013     1      557            600        -3      838            846\n10     1  2013     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n也可以和上面的[mutate()]一样通过.before 和 .after 参数指定放置位置：\n\n# 将“year”和“dep_time”及其之间的列放到“sched_dep_time”之后\nrelocate(flights, year:dep_time, .after = sched_dep_time)\n\n# A tibble: 336,776 × 19\n   sched_dep_time  year month   day dep_time dep_delay arr_time sched_arr_time\n            &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1            515  2013     1     1      517         2      830            819\n 2            529  2013     1     1      533         4      850            830\n 3            540  2013     1     1      542         2      923            850\n 4            545  2013     1     1      544        -1     1004           1022\n 5            600  2013     1     1      554        -6      812            837\n 6            558  2013     1     1      554        -4      740            728\n 7            600  2013     1     1      555        -5      913            854\n 8            600  2013     1     1      557        -3      709            723\n 9            600  2013     1     1      557        -3      838            846\n10            600  2013     1     1      558        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n# 将所有以“dep_”开头的列放到“sched_dep_time”之前\nrelocate(flights, starts_with(\"dep_\"), .before = sched_dep_time)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time dep_delay sched_dep_time arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;dbl&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517         2            515      830            819\n 2  2013     1     1      533         4            529      850            830\n 3  2013     1     1      542         2            540      923            850\n 4  2013     1     1      544        -1            545     1004           1022\n 5  2013     1     1      554        -6            600      812            837\n 6  2013     1     1      554        -4            558      740            728\n 7  2013     1     1      555        -5            600      913            854\n 8  2013     1     1      557        -3            600      709            723\n 9  2013     1     1      557        -3            600      838            846\n10  2013     1     1      558        -2            600      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#group_by",
    "href": "r_basic/dplyr.html#group_by",
    "title": "基于dplyr包的数据处理",
    "section": "\n5.1 group_by()\n",
    "text": "5.1 group_by()\n\n\n根据某一列或几列将数据分组，便于后续的分组统计/运算。\n\ngroup_by(flights, month)\n\n# A tibble: 336,776 × 19\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\ngroup_by()本身不会改变数据，除了在输出结果中出现了# Groups: month [12]，提示我们该数据集进行了分组。这意味着随后的操作将按不同的月份分别进行。group_by()向数据添加了这个分组特性（称为类），从而改变了接下来对数据应用的函数的行为。",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#summarize",
    "href": "r_basic/dplyr.html#summarize",
    "title": "基于dplyr包的数据处理",
    "section": "\n5.2 summarize()\n",
    "text": "5.2 summarize()\n\n分组汇总数据。根据某列或某几列的数据汇总一个包含了统计数据的新表。\n\n# 计算每月的平均起飞延误时间\ngroup_by(flights, month) |&gt; \n  summarise(avg_delay = mean(dep_delay))\n\n# A tibble: 12 × 2\n   month avg_delay\n   &lt;int&gt;     &lt;dbl&gt;\n 1     1        NA\n 2     2        NA\n 3     3        NA\n 4     4        NA\n 5     5        NA\n 6     6        NA\n 7     7        NA\n 8     8        NA\n 9     9        NA\n10    10        NA\n11    11        NA\n12    12        NA\n\n\n可以看到，这里出现了问题，所有的结果都是“NA”。这是因为一些航班在延误时间（dep_delay）列中有缺失数据，所以当我们计算包括这些缺失值的平均值时，得到了一个NA结果。所以需要在mean()中设置参数 na.rm = TRUE 来忽略所有缺失值：\n\n# 计算每月的平均起飞延误时间\ngroup_by(flights, month) |&gt; \n  summarise(avg_delay = mean(dep_delay, na.rm = TRUE))\n\n# A tibble: 12 × 2\n   month avg_delay\n   &lt;int&gt;     &lt;dbl&gt;\n 1     1     10.0 \n 2     2     10.8 \n 3     3     13.2 \n 4     4     13.9 \n 5     5     13.0 \n 6     6     20.8 \n 7     7     21.7 \n 8     8     12.6 \n 9     9      6.72\n10    10      6.24\n11    11      5.44\n12    12     16.6 \n\n\n可以在单次对summarize()的调用中创建任意数量的数据汇总。但其中一个非常有用的汇总函数是n()，它返回每个组中行数：\n\n# 计算每月的平均起飞延误时间和延误航班数量\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    n = n()\n  )\n\n# A tibble: 12 × 3\n   month avg_delay     n\n   &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;\n 1     1     10.0  27004\n 2     2     10.8  24951\n 3     3     13.2  28834\n 4     4     13.9  28330\n 5     5     13.0  28796\n 6     6     20.8  28243\n 7     7     21.7  29425\n 8     8     12.6  29327\n 9     9      6.72 27574\n10    10      6.24 28889\n11    11      5.44 27268\n12    12     16.6  28135",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#slice_系列函数",
    "href": "r_basic/dplyr.html#slice_系列函数",
    "title": "基于dplyr包的数据处理",
    "section": "\n5.3 slice_系列函数",
    "text": "5.3 slice_系列函数\n分组提取数据。\n\ndf |&gt; slice_head(n = 1) 从每一组中取前n行数据.\ndf |&gt; slice_tail(n = 1) 从每一组中取后n行数据.\ndf |&gt; slice_min(x, n = 1) 从每一组中取x列的值最小的n行数据.\ndf |&gt; slice_max(x, n = 1) 从每一组中取x列的值最大的n行数据.\ndf |&gt; slice_sample(n = 1) 从每一组中随机取n行数据.\n\n其中的n参数指定需要提取的行数，同时，也可以用prop参数指定从每组中提取多少比例的行。例如，prop = 0.1 表示从每组中提取10%的行。\n\n# 找出到达每个目的地的延误最严重的航班\nflights %&gt;%\n  group_by(dest) %&gt;% \n  slice_max(order_by = arr_delay, n = 1) %&gt;%\n  relocate(dest, arr_delay) %T&gt;% \n  print() %&gt;%\n  nrow()\n\n# A tibble: 108 × 19\n# Groups:   dest [105]\n   dest  arr_delay  year month   day dep_time sched_dep_time dep_delay arr_time\n   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1 ABQ         153  2013     7    22     2145           2007        98      132\n 2 ACK         221  2013     7    23     1139            800       219     1250\n 3 ALB         328  2013     1    25      123           2000       323      229\n 4 ANC          39  2013     8    17     1740           1625        75     2042\n 5 ATL         895  2013     7    22     2257            759       898      121\n 6 AUS         349  2013     7    10     2056           1505       351     2347\n 7 AVL         228  2013     8    13     1156            832       204     1417\n 8 BDL         266  2013     2    21     1728           1316       252     1839\n 9 BGR         238  2013    12     1     1504           1056       248     1628\n10 BHM         291  2013     4    10       25           1900       325      136\n# ℹ 98 more rows\n# ℹ 10 more variables: sched_arr_time &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n[1] 108\n\nnrow(flights)\n\n[1] 336776\n\n\n上面的例子中，relocate()函数后用到了分支管道[%T&gt;%]，先通过print()把分组统计的结果打印出来，然后通过nrow()返回分组统计数据的行数。结果发现有108行，和原来数据的105行不符合，这是因为有的目的地可能有几架次并列延误最严重的航班。例如，第22行和23行的航班信息：\n\nflights |&gt; \n  group_by(dest) |&gt; \n  slice_max(order_by = arr_delay, n = 1) |&gt; \n  relocate(dest, arr_delay) |&gt; \n  _[22:23,]\n\n# A tibble: 2 × 19\n# Groups:   dest [1]\n  dest  arr_delay  year month   day dep_time sched_dep_time dep_delay arr_time\n  &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n1 CHS         331  2013     3     8     1202            751       251     1530\n2 CHS         331  2013     9     2     1906           1359       307     2134\n# ℹ 10 more variables: sched_arr_time &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#多变量分组统计",
    "href": "r_basic/dplyr.html#多变量分组统计",
    "title": "基于dplyr包的数据处理",
    "section": "\n5.4 多变量分组统计",
    "text": "5.4 多变量分组统计\n例如分别统计每个日期（年+月+日）的航班数量：\n\ndaily &lt;- flights |&gt;  \n  group_by(year, month, day)\n\ndaily |&gt; \n  summarize(flights = n())\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day flights\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;\n 1  2013     1     1     842\n 2  2013     1     2     943\n 3  2013     1     3     914\n 4  2013     1     4     915\n 5  2013     1     5     720\n 6  2013     1     6     832\n 7  2013     1     7     933\n 8  2013     1     8     899\n 9  2013     1     9     902\n10  2013     1    10     932\n# ℹ 355 more rows\n\n\n需要注意到结果中的第一行提示我们 summarise() 后的数据按照“year”和“month”进行了group处理。这是因为summarise() 在处理超过一个分组的数据时，输出的结果默认去除最后一个分组依据。这一行为可以通过设定.groups参数进行修改：\n\n.groups = \"drop_last\"：默认。summarise()后丢掉最后一个分组依据。\n.groups = \"drop\"：summarise()后取消分组。\n.groups = \"keep\"：summarise()后保留原分组。\n\n\nflights |&gt;  \n  group_by(year, month, day) |&gt; \n  summarize(\n    flights = n(),\n    .groups = \"keep\"\n    ) \n\n# A tibble: 365 × 4\n# Groups:   year, month, day [365]\n    year month   day flights\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;\n 1  2013     1     1     842\n 2  2013     1     2     943\n 3  2013     1     3     914\n 4  2013     1     4     915\n 5  2013     1     5     720\n 6  2013     1     6     832\n 7  2013     1     7     933\n 8  2013     1     8     899\n 9  2013     1     9     902\n10  2013     1    10     932\n# ℹ 355 more rows",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#ungroup",
    "href": "r_basic/dplyr.html#ungroup",
    "title": "基于dplyr包的数据处理",
    "section": "\n5.5 ungroup()\n",
    "text": "5.5 ungroup()\n\n取消分组。\n\ndaily |&gt; \n  ungroup() |&gt;\n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  )\n\n# A tibble: 1 × 2\n  avg_delay flights\n      &lt;dbl&gt;   &lt;int&gt;\n1      12.6  336776",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "r_basic/dplyr.html#by",
    "href": "r_basic/dplyr.html#by",
    "title": "基于dplyr包的数据处理",
    "section": "\n5.6 .by\n",
    "text": "5.6 .by\n\n\ndplyr从1.1.0版本开始包括了一个新的实验性语法，用于直接在统计函数中指定分组依据，即 .by 参数。group_by() 和 ungroup() 不会消失，但现在也可以使用 .by 参数来在单个操作中进行分组：\n\nflights |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n(),\n    .by = month # 按“month”分组统计\n  ) |&gt; \n  arrange(month)\n\n# A tibble: 12 × 3\n   month avg_delay flights\n   &lt;int&gt;     &lt;dbl&gt;   &lt;int&gt;\n 1     1     10.0    27004\n 2     2     10.8    24951\n 3     3     13.2    28834\n 4     4     13.9    28330\n 5     5     13.0    28796\n 6     6     20.8    28243\n 7     7     21.7    29425\n 8     8     12.6    29327\n 9     9      6.72   27574\n10    10      6.24   28889\n11    11      5.44   27268\n12    12     16.6    28135\n\n# 等价于:\nflights |&gt; \n  group_by(month) |&gt; \n  summarise(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n    )\n\n# A tibble: 12 × 3\n   month avg_delay flights\n   &lt;int&gt;     &lt;dbl&gt;   &lt;int&gt;\n 1     1     10.0    27004\n 2     2     10.8    24951\n 3     3     13.2    28834\n 4     4     13.9    28330\n 5     5     13.0    28796\n 6     6     20.8    28243\n 7     7     21.7    29425\n 8     8     12.6    29327\n 9     9      6.72   27574\n10    10      6.24   28889\n11    11      5.44   27268\n12    12     16.6    28135\n\n# 支持指定多个分组依据\nflights |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n(),\n    .by = c(origin, dest)\n  ) |&gt; \n  arrange(origin, dest)\n\n# A tibble: 224 × 4\n   origin dest  avg_delay flights\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;int&gt;\n 1 EWR    ALB       23.6      439\n 2 EWR    ANC       12.9        8\n 3 EWR    ATL       15.5     5022\n 4 EWR    AUS       11.5      968\n 5 EWR    AVL        8.62     265\n 6 EWR    BDL       17.7      443\n 7 EWR    BNA       17.7     2336\n 8 EWR    BOS       12.5     5327\n 9 EWR    BQN       23.9      297\n10 EWR    BTV       17.8      931\n# ℹ 214 more rows\n\n# 等价于：\nflights |&gt; \n  group_by(origin, dest) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  ) |&gt; \n  ungroup()\n\n# A tibble: 224 × 4\n   origin dest  avg_delay flights\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;   &lt;int&gt;\n 1 EWR    ALB       23.6      439\n 2 EWR    ANC       12.9        8\n 3 EWR    ATL       15.5     5022\n 4 EWR    AUS       11.5      968\n 5 EWR    AVL        8.62     265\n 6 EWR    BDL       17.7      443\n 7 EWR    BNA       17.7     2336\n 8 EWR    BOS       12.5     5327\n 9 EWR    BQN       23.9      297\n10 EWR    BTV       17.8      931\n# ℹ 214 more rows\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 dplyr_1.1.4   \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.34     utf8_1.2.4        R6_2.5.1          codetools_0.2-19 \n [5] fastmap_1.1.1     tidyselect_1.2.0  xfun_0.41         glue_1.7.0       \n [9] tibble_3.2.1      knitr_1.45        pkgconfig_2.0.3   htmltools_0.5.7  \n[13] generics_0.1.3    rmarkdown_2.25    lifecycle_1.0.4   cli_3.6.2        \n[17] fansi_1.0.6       vctrs_0.6.5       withr_3.0.0       compiler_4.3.2   \n[21] rstudioapi_0.15.0 tools_4.3.2       pillar_1.9.0      evaluate_0.23    \n[25] yaml_2.3.8        rlang_1.1.3       jsonlite_1.8.8    htmlwidgets_1.6.4",
    "crumbs": [
      "Home",
      "R语言基础",
      "基于dplyr包的数据处理"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R语言学习笔记：从数据清洗到高级统计学和生物信息学",
    "section": "",
    "text": "制作这本学习笔记的初衷是归纳整理在医学科研领域利用R语言进行基本数据分析的技巧。计划涵盖包括数据清洗、基本统计分析、高级统计分析在内的内容。并进一步对涉及生物信息学的内容进行总结，汇总Gene Expression Omnibus（GEO）、The Cancer Genome Atlas Program（TCGA）数据库挖掘的代码，并扩展到以Seurat包为基础的单细胞分析流程。此外，也会对Quarto文档——由Posit开发的面相多编程语言的下一代R Markdown——的编写和发布进行简单总结。目前该项目处于最开始的阶段，这本书也处于刚刚搭建好框架的阶段，后续会不断更新和完善，最终实现上述的目标。敬请批评指正！",
    "crumbs": [
      "Home",
      "主页"
    ]
  },
  {
    "objectID": "index.html#r学习资源推荐",
    "href": "index.html#r学习资源推荐",
    "title": "R语言学习笔记：从数据清洗到高级统计学和生物信息学",
    "section": "R学习资源推荐",
    "text": "R学习资源推荐\n\n在线书籍：\n\nR Graphics Cookbook, 2nd edition：https://r-graphics.org\nR for Data Science (2e)：https://r4ds.hadley.nz\nQuarto Guide：https://quarto.org/docs/guide/\nHappy Git and GitHub for the useR：https://happygitwithr.com\nBookdown：https://bookdown.org\n\n\n\n论坛/网站：\n\n交互式R语言学习网站：https://www.codecademy.com/learn/learn-r\nR CODER：https://r-coder.com\nStack Overflow：https://stackoverflow.com\nR-Bloggers：https://www.r-bloggers.com\nPosit Cheatsheets：https://posit.co/resources/cheatsheets/\nKaggle：https://www.kaggle.com/code?language=R\nThe R Graph Gallery：https://r-graph-gallery.com\nPosit Community：https://community.rstudio.com",
    "crumbs": [
      "Home",
      "主页"
    ]
  },
  {
    "objectID": "quarto_foundation/images_settings.html",
    "href": "quarto_foundation/images_settings.html",
    "title": "图片设置",
    "section": "",
    "text": "图片可以通过复制粘贴直接插入，Quarto定义图像的基本语法是：\n![图片标题](images/crossref-figure.png){#fig-elephant width=\"290\"}。\n其中，方括号内的是对象的caption（可选），小括号内是图像所在目录，“{}”内的内容是图像的label以及其他可选设置，各参数间用空格进行分割。常用的图像设置如下：\n\nwidth和height：图像的宽、高。默认单位为像素。\nfig-align：图片的对齐方式，如”left”，“right”。\n可以在小括号内添加超链接，如[![](``images/crossref-figure.png``)](https://en.wikipedia.org/wiki/Elephant)，当点击该图像时会跳转该网站。\ncaption和label的设置会使该图像能够被交叉引用。\n\n.column-page：让图片以整个文档的宽度展示。需要首先建立一个Pandoc Div块（Figure 1）。然后在Pandoc Div块的参数项内填上{.column-page}。如下所示：\n\n:::{.column-page}\n![](images/elephant.jpg)\n:::\n\n这样这张图片就会以文档最大宽度显示：\n\n\n\n\n\n\n\n\n\n\n\n应用于代码块时为：#| column: page\n\n\n\n\n\n.column-screen：让图片占满整个网页的宽度。应用于代码块时为：#| column: screen。\n\n\n\n\n\n\ncolumn-screen-inset-shaded：让图片以整个文档的宽度展示，但是在后方加上一个网页宽度的阴影。应用于代码块时为：#| column: screen-inset-shaded。\n\n\n\n\n\n要容纳和排版组图，需要首先建立一个Pandoc Div块（Figure 1）。\n\n\n\n\n\nFigure 1: 建立Div块\n\n\nDiv块的图像排版基本语法如下：\n\n\n\n\n\nFigure 2: Div块的基本语法\n\n\n\n“{}”内为组图的label、排版设置。\n在所有图片最后可输入组图的总标题，如上图中的”交叉引用的设置”。\n\n设置图片的排版方式。\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如::: {layout-ncol=\"2\"}。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n其基本语法和 Section 2 一致。不同点在于需要在Div块开头的”{}“内设置，同时layout后要接”=“，并且注意加引号，例如：layout=\"[[1，1]，[1]]\"。通过设置layout可以完成对多图的复杂排版。layout属性是一个二维数组，其中第一维定义行，第二维定义列。layout=\"[[1，1]，[1]]\"表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组图复杂排版设置\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n关于图片设置的详细指南，参考：https://quarto.org/docs/authoring/figures.html。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "图片设置"
    ]
  },
  {
    "objectID": "quarto_foundation/images_settings.html#sec-Setting_of_group_figs",
    "href": "quarto_foundation/images_settings.html#sec-Setting_of_group_figs",
    "title": "图片设置",
    "section": "",
    "text": "要容纳和排版组图，需要首先建立一个Pandoc Div块（Figure 1）。\n\n\n\n\n\nFigure 1: 建立Div块\n\n\nDiv块的图像排版基本语法如下：\n\n\n\n\n\nFigure 2: Div块的基本语法\n\n\n\n“{}”内为组图的label、排版设置。\n在所有图片最后可输入组图的总标题，如上图中的”交叉引用的设置”。\n\n设置图片的排版方式。\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如::: {layout-ncol=\"2\"}。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "图片设置"
    ]
  },
  {
    "objectID": "quarto_foundation/images_settings.html#layout复杂排版",
    "href": "quarto_foundation/images_settings.html#layout复杂排版",
    "title": "图片设置",
    "section": "",
    "text": "其基本语法和 Section 2 一致。不同点在于需要在Div块开头的”{}“内设置，同时layout后要接”=“，并且注意加引号，例如：layout=\"[[1，1]，[1]]\"。通过设置layout可以完成对多图的复杂排版。layout属性是一个二维数组，其中第一维定义行，第二维定义列。layout=\"[[1，1]，[1]]\"表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组图复杂排版设置\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n关于图片设置的详细指南，参考：https://quarto.org/docs/authoring/figures.html。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "图片设置"
    ]
  },
  {
    "objectID": "quarto_foundation/images_settings.html#代码块组图输出设置",
    "href": "quarto_foundation/images_settings.html#代码块组图输出设置",
    "title": "图片设置",
    "section": "\n2.1 代码块组图输出设置",
    "text": "2.1 代码块组图输出设置\n如果一个代码块运行后可以生成多张图像，那么我们也可以和 Section 1.1 中一样，对这些图片进行组图排版。常用的参数包括：\n\nlayout-ncol和layout-nrow：设置组图的行和列分别排多少张图片。如layout-ncol: \"2\"。\nlabel：组图的标签。\nfig-cap：每张图的标题。通过”-“符号分别设置。效果如下所示：\n\n```{r}\n#| eval: true\n#| layout-ncol: 2\n#| label: fig-组图输出\n#| fig-cap:\n#|   - \"车辆的速度和停车距离\"\n#|   - \"汽压与温度的关系\"\n\nplot(cars)\nplot(pressure)\n```\n\n\n\n\n\n\n\n\nFigure 4: 车辆的速度和停车距离\n\n\n\n\n\n\n\n\n\nFigure 5: 汽压与温度的关系\n\n\n\n\n\n\n\nfig-subcap：每张图以小标题进行标注，如”(a) sub caption”、“(b) sub caption”。效果如下所示：\n\n```{r}\n#| eval: true\n#| label: fig-小标题组图输出\n#| fig-cap: \"小标题组图输出\"\n#| fig-subcap:\n#|   - \"汽车\"\n#|   - \"压力\"\n#| layout-ncol: 2\n\nplot(cars)\nplot(pressure)\n```\n\n\n\n\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n\nFigure 6: 小标题组图输出\n\n\n用layout进行复杂排版\nlayout属性是一个二维数组，其中第一维定义行，第二维定义列。如layout: \"[[1，1]，[1]]表示：创建两行，第一行有两列大小相等的列，第二行只有一列。\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片\n#| fig-cap: 复杂排版组图输出\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[1], [1, 1]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n\n\n\n\n(C) mtcars\n\n\n\n\n\n\nFigure 7: 复杂排版组图输出\n\n\n\nlayout后的”[]“中的数字大小表示各个图像的相对大小。所以可以用任何值来自定义：\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片2\n#| fig-cap: 复杂排版组图输出2\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[100], [30, 70]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n\n\n\n\n(A) 汽车\n\n\n\n\n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n\n\n\n\n(C) mtcars\n\n\n\n\n\n\nFigure 8: 复杂排版组图输出2\n\n\n\n如果我们输入负数，如下面的”-10”，则会在两个图之间加上相应的间距：\n\n```{r}\n#| eval: true\n#| label: fig-输出复杂排版图片3\n#| fig-cap: 复杂排版组图输出3\n#| fig-subcap:\n#|   - 汽车\n#|   - 压力\n#|   - mtcars\n#| layout: [[45,-10, 45], [100]]\n\nplot(cars)\nplot(pressure)\nplot(mtcars)\n```\n\n\n\n\n\n\n\n\n\n(A) 汽车\n\n\n\n\n \n\n\n\n\n\n\n\n(B) 压力\n\n\n\n\n\n\n\n\n\n\n\n(C) mtcars\n\n\n\n\n\n\nFigure 9: 复杂排版组图输出3",
    "crumbs": [
      "Home",
      "Quarto基础",
      "图片设置"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_foundation.html",
    "href": "quarto_foundation/quarto_foundation.html",
    "title": "Quarto基础",
    "section": "",
    "text": "Quarto是一个支持多种编程语言的新一代R Markdown，拥有多个新的特性和功能，同时能够兼容和渲染大多数现有的.rmd文件，而无需额外修改。Quarto可通过多种IDEs编辑，包括VS Code和RStudio。文档的后缀为.qmd。\n\n目前，Quarto还处于起步和不断发展的阶段，针对其的学习资源还十分有限，尤其是中文资源更加匮乏，因此有了汇总和编写本章的动机。本章内容主要参考了Quarto的官方指南，并提取了其中我认为在将来的编写中会经常使用的技巧并加以汇总。这本学习笔记即全程采用Quarto编写。\n本章的逻辑结构：\n\n首先介绍Quarto文档的全局设置，即YAML语法（YAML设置）；\n图片的设置，包括插入的图片和代码块运行后产生的图片；\n如何实现对图、表等的交叉引用；\n其他几种内容的插入；\n创建和编辑Quarto Books的方法（Quarto Books）；\n如何在Quarto文档中嵌入Shiny交互式应用程序；\n最后，介绍如何将Quarto项目的源代码通过Git上传到GitHub以及如何将编译好的Quarto Book通过GitHub Pages进行发布（发布到GitHub Pages）。\n\n有关Quarto的详细信息，参考：https://quarto.org.\n\n\n\n\n\n\n\nTip\n\n\n\n快捷键：\n\n插入代码块：Option+Command+I（macOS）；Ctrl+Alt+I（Windows）。\n插入各类对象：Command+/；或者当光标位于新的一行开头时，直接输入/。",
    "crumbs": [
      "Home",
      "Quarto基础"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html",
    "href": "quarto_foundation/quarto_books.html",
    "title": "Quarto Books",
    "section": "",
    "text": "Quarto Books能够将多个Quarto文档（章节）组合成一份文档。这样我们可以将所有的笔记、脚本文件汇总成一个完整的知识框架。\n在RStudio中创建一个Quarto Books的方法是首先新建一个项目，选择”New Directory”：\n项目类型选择”Quarto Book”：\n然后给项目起个名字，这个名字是最终项目文件夹和.Rproject文件的名字。选择项目的创建目录。如果需要将项目作为Git仓库同步到GitHub（详见后续章节）的话可以勾选上”Create a git repository”：\n现在就会在目标目录下创建一个新的项目文件夹。里面包含了Quarto自动创建好的示例qmd文件以及配置文件，相当于搭建好了Quarto Books的框架。\n其中后缀为.Rproject的文件即项目文件。index.qmd文件编译后是book的封面。由于Quarto Books一般编译为HTML文件，所以这个文件就是网页的首页。注意不要更改其文件名。references.qmd编译后为参考文献页面；references.bib为插入参考文献后自动生成的参BibTeX/Citation文件，里面包括了所有考文献的列表（详见YAML-参考文献设置）。\n_quarto.yml文件为YAML配置文件。要实现按照一定的格式将各个Quarto文档组合成一个完整的网页或Quarto Books，定义这个YAML配置文件是核心。YAML配置文件一般以”_quarto.yml”命名，并保存在项目的根目录中，在每次编译书籍时都会读取这个配置文件。实际上Quarto Books的YAML配置和此前独立的qmd文档的YAML配置有大量相似之处。最大的区别是Quarto Books需要通过chapter来将不同的qmd文件（章节）按照一定的顺序组合起来形成一本完整的书籍。下面主要介绍YAML配置文件的主要内容。各个章节即各个独立的qmd文件的编写方法参考之前的章节即可。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#标题作者日期信息",
    "href": "quarto_foundation/quarto_books.html#标题作者日期信息",
    "title": "Quarto Books",
    "section": "\n2.1 标题/作者/日期信息",
    "text": "2.1 标题/作者/日期信息\n\n---\nbook:\n  title: \"R语言数据科学\"\n  subtitle: \"从数据清洗到高级统计学和生物信息学\"\n  author: \"杜俊宏\"\n  date: 2023/11/10\n  date-format: \"YYYY[年]M[月]D[日]\"\n  cover-image: images/book_cover.png\n---\n\n\ntitle：标题。\nsubtitle：副标题。在标题下方以较小字号展示。\nauthor：作者姓名。\ndate：文档发行日期。日期既可以手动添加，如”2023/11/10”，也可以通过now（输出样式：2023年11月11日 19:01）或today（输出样式：2023年11月11日）自动生成日期。\ndate-format：日期格式（详见YAML设置）。\ncover-image：封面图片。\n\n\n\n\n\n\n\nTip\n\n\n\n上面列出的信息也可以在index.qmd文件中定义。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#chapter章节",
    "href": "quarto_foundation/quarto_books.html#chapter章节",
    "title": "Quarto Books",
    "section": "\n2.2 chapter章节",
    "text": "2.2 chapter章节\n章节的定义是Quarto Books的YAML配置的核心。通过chapter函数将多个不同的qmd文件（章节）按照指定的顺序结合起来就形成了一本书或者网站。\n\n---\nbook:\n  chapters:\n    - text: 主页\n      file: index.qmd\n    - intro.qmd\n    - text: \"---\" \n    - part: r_basic/r_basics.qmd\n      chapters:\n        - r_basic/environment_configuration.qmd\n        - r_basic/data_input_output.qmd\n    - part: bioinformatics/single_cell/r_single_cell.qmd\n      chapters:\n        - bioinformatics/single_cell/seurat_command_list.qmd\n        - bioinformatics/single_cell/seurat_tutorial.qmd\n        - bioinformatics/single_cell/data_visualization_methods_in_seurat.qmd\n        - bioinformatics/single_cell/sctransform.qmd\n        - bioinformatics/single_cell/integration.qmd\n    - part: quarto_foundation/quarto_foundation.qmd\n      chapters:\n        - quarto_foundation/yaml_settings.qmd\n        - quarto_foundation/images_settings.qmd\n        - quarto_foundation/cross_references.qmd\n        - quarto_foundation/insert_other_content.qmd\n        - quarto_foundation/quarto_books.qmd\n        - quarto_foundation/github_pages.qmd\n    - text: \"---\"\n    - part: \"参考文献\"\n      chapters:\n        - references.qmd\n---\n\n\n\npart：如果一本书有大量的qmd文件（章节），那么我们可以按照不同的主题将这些qmd文件分成不同的篇章。part可以用qmd文件或者字符定义。如果提供的是qmd文件，那么该qmd文件在编译后会是该篇章的首页，并以单独的一个页面显示。每个篇章可由多个不同的qmd文件（章节）组成。篇章的首页内容会以单独的一个页面显示，一般写该篇章的内容概要。如果提供的是字符，那么这个篇章只会反映在左侧导航栏上，而不会有单独的篇章首页。如上面的part: \"参考文献\"。\n\nchapters：章节。在其下方列出需要包含的所有qmd文件。part和chapters共同完成对章节的组织。\n\ntext： “—”：分隔符。会在导航栏对应位置上显示一条横线。\n\n上面的配置在编译后的效果：",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#sec-sidebar",
    "href": "quarto_foundation/quarto_books.html#sec-sidebar",
    "title": "Quarto Books",
    "section": "\n2.3 侧边栏",
    "text": "2.3 侧边栏\n侧边栏是传统意义上的总目录，默认在网页的左侧显示，其内容反映了上面chapter中定义的章节编排。通过sidebar对侧边栏的样式、内容等进行进一步的设定。\n\n---\nbook:\n  sidebar:\n    style: \"docked\" \n    collapse-level: 1 \n    search: true \n    logo: images/logo.png \n    tools:\n      - icon: twitter \n        href: https://twitter.com \n      - icon: youtube\n        href: https://youtube.com\n---\n\n\nstyle：侧边导航栏的风格。默认为docked，固定导航栏。也可以选择浮动导航栏，floating。\ncollapse-level：侧边导航栏初始显示到多少级标题，默认显示到一级标题，只有当浏览到某一篇章时才会展开该篇章下的2级标题。\nsearch：是否打开侧边栏上的搜索框。注意如果开启了顶栏（见下一节顶部导航栏），那么搜索按钮会默认在顶栏显示。\nlogo：在侧边导航栏上方显示图像。\ntools：定制侧边栏工具。语法同下一节顶部导航栏中的left和right内的定义类似。\n\n采用上述配置后的侧边栏样式：",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#sec-navbar",
    "href": "quarto_foundation/quarto_books.html#sec-navbar",
    "title": "Quarto Books",
    "section": "\n2.4 顶部导航栏",
    "text": "2.4 顶部导航栏\n除了添加侧边导航栏之外，还可以通过navbar参数添加顶部导航栏。\n\n---\nbook:\n  navbar:\n    logo: images/logo.jpg\n    background: \"#f1f1f3\" \n    foreground: \"black\" \n    search: true\n    left:\n      - text: \"Home\"\n        file: index.qmd\n      - file: intro.qmd\n      - text: \"Parts\"\n        menu:\n          - r_basic/r_basics.qmd\n          - bioinformatics/single_cell/r_single_cell.qmd\n          - quarto_foundation/quarto_foundation.qmd\n      - file: references.qmd\n    right:\n      - icon: book-fill\n        text: Bookdown\n        href: https://bookdown.org\n      - icon: github\n        text: GitHub\n        menu:\n          - text: Source Code\n            url: https://github.com/djhcod/r-notes\n          - text: Report a Bug\n            url: https://github.com/djhcod/r-notes/issues\n          - text: Pull Request\n            url: https://github.com/djhcod/r-notes/pulls\n---\n\n\nlogo：顶栏左侧的logo。\nbackground：顶栏背景色（默认为primary，网页主色）。\nforeground：顶栏字体颜色。\nsearch：是否在顶栏右侧显示搜索按钮。\n\nleft和right：分别定义顶栏左侧和右侧显示的内容：\n\nfile：qmd文件。qmd文件内的一级标题就是编译后显示在导航栏上的文字。\ntext：显示文字。在其下方添加qmd文件即可将文字链接到对应的qmd文件编译后的页面。这可以用于自定义某个qmd文件在导航栏上显示的文字。例如这里的index.qmd的标题是”主页”（title：主页），如果我们直接用file把它列出来，那么在导航栏上就会显示index.qmd的标题，即”主页”。但是我们通过text: \"Home\"，并在其下方接file: index.qmd，那么在编译后的HTML中顶栏上会显示”Home”文字，点击后还是链接到index.qmd编译后的首页。如果text下方提供的是url，那么点击该文字后就会跳转到指定网站。\nicon：图标，和text的作用类似。Quarto可以调用Bootstrap Icons图标库，只需指定图标在Bootstrap Icons网站中的的官方名字，如”github”、“twitter”，就可以直接调用该图标。\n\n\n\n\n\n\nFigure 1: Bootstrap Icons图标库\n\n\n\nmenu：下拉菜单。效果如 Figure 2 所示。\nurl和herf：效果类似，都是添加外部网址。\n\n\n\n\n\n\n\n\nFigure 2: 顶栏示例\n\n\n\n\n\n\n\n\nTip\n\n\n\n顶栏和侧边导航栏的更多设置，参考Quarto官方指南。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#sec-page_navigation",
    "href": "quarto_foundation/quarto_books.html#sec-page_navigation",
    "title": "Quarto Books",
    "section": "\n2.5 右侧页内导航",
    "text": "2.5 右侧页内导航\n右侧页内导航显示的是当前页面的目录。可在book内的page-navigation和format-html内的toc相关函数中共同配置。\n\n\n---\nbook:\n  page-navigation: true\n  repo-url: https://github.com/djhcod/r-notes \n  repo-actions: [source, issue, edit] \n---\n\n\npage-navigation：是否打开右侧的页内导航。\nrepo-url：（可选）GitHub仓库的链接。\nrepo-actions：（可选）在右侧页内导航的下方显示导航到GitHub仓库各板块的链接。可选的值有source、issue、edit。如果是source，repo-actions会首先根据当前所浏览的页面，在repo-url定义的URL后加上当前页面源码的后缀（如”/blob/main/quarto_foundation/quarto_books.qmd”），这样就会得到一个指向GitHub项目中编译该页面的源码的链接。如果是edit则会在此链接的基础上再加上编辑该页面源码的后缀（“/edit/main/quarto_foundation/quarto_books.qmd”）。如果是issue则会在GitHub仓库链接的基础上加上定位到问题报告的后缀（“/issues/new”）。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#搜索框设置",
    "href": "quarto_foundation/quarto_books.html#搜索框设置",
    "title": "Quarto Books",
    "section": "\n2.6 搜索框设置",
    "text": "2.6 搜索框设置\nsearch可以用来指定搜索按钮的样式。同时，对于既有顶栏又有左侧导航栏的book，可以通过search来指定搜索按钮出现的位置。\n\n---\nbook:\n  search:\n    location: sidebar\n    type: textbox\n---\n\n\nlocation：搜索按钮的位置。默认为出现在顶栏（ ）最右侧（navbar）；也可以定义为sidebar，让其在侧边栏（ Section 2.3 ）的上方显示。\ntype：搜索按钮的样式。可以仅搜索图标（overlay），也可以展示搜索框（textbox）。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#页脚设置",
    "href": "quarto_foundation/quarto_books.html#页脚设置",
    "title": "Quarto Books",
    "section": "\n2.7 页脚设置",
    "text": "2.7 页脚设置\n页脚出现在每个页面的最下面，通过page-footer统一配置。\n\n\n\n\n\nFigure 3: 页脚示例\n\n\n\n---\nbook:\n  page-footer:\n    left:\n      - text: \"This book was built with Quarto\"\n    center: \"Copyright 2023, Du Junhong\"\n    right:\n      - icon: github\n        href: https://github.com/djhcod\n    border: true  \n---\n\n页脚的配置和 Section 2.4 的语法基本一致，此处不再赘述。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#网站分享设置",
    "href": "quarto_foundation/quarto_books.html#网站分享设置",
    "title": "Quarto Books",
    "section": "\n2.8 网站分享设置",
    "text": "2.8 网站分享设置\n\n---\nbook:\n  favicon: images/logo.png # \n  sharing: [twitter, facebook] # \n  twitter-card: true\n  site-url: https://example.com\n---\n\n\n\nfavicon：网页的图标。会在标签页上显示。\n\n\n\n\nsharing：显示分享到社交网络图标。调用的是Bootstrap Icons图标库。效果如下：",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_books.html#comments用户批注及评论功能",
    "href": "quarto_foundation/quarto_books.html#comments用户批注及评论功能",
    "title": "Quarto Books",
    "section": "\n2.9 comments用户批注及评论功能",
    "text": "2.9 comments用户批注及评论功能\nQuarto Books编译后的HTML网页支持配置Hypothesis标注功能。配置后不同的读者在登录Hypothesis账号后可以在页面上进行标注和评论。效果如下：\n\nYAML配置文件如下（⚠️在YAML配置文件中，comments既可以放到html下，也可以放到book下或独立放置）：\n---\nhtml:\n  comments:\n    hypothesis:\n      theme: classic\n      openSidebar: false\n      showHighlights: always\n      enableExperimentalNewNoteButton: true\n---\n此外，还可以启用基于Utterances的评论功能。YAML配置如下：\n---\nhtml:\n  comments:\n    utterances:\n        repo: djhcod/r-notes\n---\n要实现该功能需要在GitHub中安装utterances app。其中的repo填写需要存储用户评论的存储库的位置，格式为“用户名/存储库名称”。配置好后，在页面下方会出现如下所示的评论框：\n\n当用户在其中提交评论时，会同步到项目的GitHub issues中。\n与之类似的工具还有Giscus app，该工具支持中文UI，通过过该工具发表的评论会被保存到GitHub项目的Discussion中。YAML配置如下：\n---\nhtml:\n  comments:\n    giscus:\n       repo: djhcod/r-notes\n       input-position: top\n---\ninput-position: top表示将评论框放置在其他评论的顶部。更多关于comments的参数和设置，参考Quarto官方文档。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "Quarto Books"
    ]
  },
  {
    "objectID": "quarto_foundation/cross_references.html",
    "href": "quarto_foundation/cross_references.html",
    "title": "交叉引用",
    "section": "",
    "text": "如果要使用交叉引用，则每个待引用对象需要有以下两个元素：\n拥有了这两个元素的对象会被自动加上序号，如Figure 1，并可以被交叉引用。 可引用的对象包括：图表、公式、章节、代码和定理等。注意在交叉引用时要在两端加上空格。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "交叉引用"
    ]
  },
  {
    "objectID": "quarto_foundation/cross_references.html#组图的交叉引用",
    "href": "quarto_foundation/cross_references.html#组图的交叉引用",
    "title": "交叉引用",
    "section": "\n2.1 组图的交叉引用",
    "text": "2.1 组图的交叉引用\n基本语法：\n\n案例：\n\n\n\n\n\n\n\n\n\n(A) 素描大象\n\n\n\n\n\n\n\n\n\n(B) 油画大象\n\n\n\n\n\n\nFigure 3: 组图的交叉引用\n\n\n现在，我们就可以将组图一起引用（Figure 3 ），或是单独引用组图内的某一张图（Figure 3 (B) ，Figure 3 (A) ）。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "交叉引用"
    ]
  },
  {
    "objectID": "quarto_foundation/cross_references.html#markdown表格的引用",
    "href": "quarto_foundation/cross_references.html#markdown表格的引用",
    "title": "交叉引用",
    "section": "\n3.1 Markdown表格的引用",
    "text": "3.1 Markdown表格的引用\n只需在表格后加上: My Caption {#tbl-letters}即可使该表格能够被引用。如下面的表格 Table 1 。\n\n\nTable 1: 表格的交叉引用示例\n\n\n\nCol1\nCol2\nCol3\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG",
    "crumbs": [
      "Home",
      "Quarto基础",
      "交叉引用"
    ]
  },
  {
    "objectID": "quarto_foundation/cross_references.html#代码输出表格的引用",
    "href": "quarto_foundation/cross_references.html#代码输出表格的引用",
    "title": "交叉引用",
    "section": "\n3.2 代码输出表格的引用",
    "text": "3.2 代码输出表格的引用\n\nlabel：tbl-：表格的标签。\ntbl-cap：表格的标题。\nknitr包提供了一个 kable() 函数可以用来把数据框或矩阵转化成有格式的表格，支持HTML、docx、LaTeX等格式。\n\n\n```{r}\n#| eval: true\n#| label: tbl-iris\n#| tbl-cap: \"Iris数据\"\n\nlibrary(knitr)\nkable(head(iris))\n```\n\n\nTable 2: Iris数据\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\n\n\n\n现在，就可以通过 Table 2 来引用该表格了。\n\n\n\n\n\n\nNote\n\n\n\n关于表格的详细指南，参考：https://quarto.org/docs/authoring/tables.html。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "交叉引用"
    ]
  },
  {
    "objectID": "quarto_foundation/github_pages.html",
    "href": "quarto_foundation/github_pages.html",
    "title": "发布到GitHub Pages",
    "section": "",
    "text": "Note\n\n\n\n本节内容参考Creating your personal website using Quarto 和 Happy Git and GitHub for the useR。\n本节内容基于macOS，在Windows系统下的具体操作存在较大差异。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "发布到GitHub Pages"
    ]
  },
  {
    "objectID": "quarto_foundation/github_pages.html#在-git-中忽略一个文件和文件夹",
    "href": "quarto_foundation/github_pages.html#在-git-中忽略一个文件和文件夹",
    "title": "发布到GitHub Pages",
    "section": "\n8.1 在 Git 中忽略一个文件和文件夹\n",
    "text": "8.1 在 Git 中忽略一个文件和文件夹\n\n如果只忽略一个特定的文件，需要提供该文件在项目根目录下的完整路径。例如，如果想忽略位于根目录下的”text.txt”文件，可以将以下信息添加到.gitignore文件中：\n\n/text.txt\n\n而如果想忽略一个位于根目录下的”test”文件夹中的”text.txt”文件，添加的信息是：\n\n/test/text.txt\n\n或者：\n\ntest/text.txt",
    "crumbs": [
      "Home",
      "Quarto基础",
      "发布到GitHub Pages"
    ]
  },
  {
    "objectID": "quarto_foundation/github_pages.html#忽略多个具有特定名称的文件和文件夹",
    "href": "quarto_foundation/github_pages.html#忽略多个具有特定名称的文件和文件夹",
    "title": "发布到GitHub Pages",
    "section": "\n8.2 忽略多个具有特定名称的文件和文件夹",
    "text": "8.2 忽略多个具有特定名称的文件和文件夹\n如果想忽略整个项目内所有具有特定名称的文件，只需要写出该文件的文件名及其后缀。例如，如果想忽略任何文件名为”text.txt”的文件，可以在.gitignore中添加以下内容：\n\ntext.txt\n\n注意区别/text.txt。如果前面有/表示只忽略根目录下文件名为”text.txt”的文件。\n如果要忽略某个文件夹，需要包括文件夹的位置及名称，并在最后加上斜线/：\n\ntest/\n\n这个命令将忽略项目中所有位置的名为”test”的文件夹。如前所述，如果我们写成下面这样：\n\ntest\n\n那么就会忽略项目中所有名称中含有”test”的文件和文件夹。\n忽略任何以特定单词开头的文件或目录。例如，忽略所有名称以”img”开头的文件和文件夹。需要指定想忽略的名称，后面跟着*通配符选择器，像这样：\n\nimg*\n\n如果想忽略所有以特定文件扩展名结尾的文件，同样需要使用*通配符选择器，后面跟你想忽略的文件扩展名。例如，如果你想忽略所有以”.md”文件扩展名结尾的markdown文件，你可以在你的.gitignore文件中添加以下内容：\n\n*.md",
    "crumbs": [
      "Home",
      "Quarto基础",
      "发布到GitHub Pages"
    ]
  },
  {
    "objectID": "quarto_foundation/github_pages.html#忽略以前提交的文件",
    "href": "quarto_foundation/github_pages.html#忽略以前提交的文件",
    "title": "发布到GitHub Pages",
    "section": "\n8.3 忽略以前提交的文件\n",
    "text": "8.3 忽略以前提交的文件\n\n当你创建一个新的仓库时，最好的做法是创建一个.gitignore文件，包含所有你想忽略的文件和不同的文件模式–在提交之前。Git 只能忽略尚未提交到仓库的未被追踪的文件。如果你过去已经提交了一个文件，但希望没有提交，会发生什么？比如你不小心提交了一个存储环境变量的”.env”文件。你首先需要更新.gitignore文件以包括”.env”文件：\n\n# 给 .gitignore 添加 .env 文件\necho \".env\" &gt;&gt; .gitignore\n\n现在，你需要告诉 Git 不要追踪这个文件，把它从索引中删除：\n\ngit rm --cached .env\n\ngit rm命令，连同--cached选项，从版本库中删除文件，但不删除实际的文件。这意味着该文件仍然在你的本地系统和工作目录中作为一个被忽略的文件。git status会显示该文件已不在版本库中，而输入ls命令会显示该文件存在于你的本地文件系统中。如果你想从版本库和你的本地系统中删除该文件，省略--cached选项。接下来，用git add命令将.gitignore添加到暂存区：\n\ngit add .gitignore\n\n最后，用git commit命令提交.gitignore文件：\n\ngit commit -m \"update ignored files\"",
    "crumbs": [
      "Home",
      "Quarto基础",
      "发布到GitHub Pages"
    ]
  },
  {
    "objectID": "quarto_foundation/github_pages.html#发布github-pages时常用的.gitignore文件配置",
    "href": "quarto_foundation/github_pages.html#发布github-pages时常用的.gitignore文件配置",
    "title": "发布到GitHub Pages",
    "section": "\n8.4 发布GitHub Pages时常用的.gitignore文件配置",
    "text": "8.4 发布GitHub Pages时常用的.gitignore文件配置\n最后回到本节的实际问题中来。如果我们想要发布GitHub Pages并上传源代码，我们一般期望不要将编译时产生的缓存文件（如果在YAML中开启了cache: true）、数据文件（.RData/.RDS等）以及程序运行后的输出数据文件（.RData/.RDS等）上传。它们体积都较大，很有可能因为超出单个文件大小的限制而导致Push时报错。因此，一下列出了一个用于发布发布GitHub Pages时的典型.gitignore文件配置：\n\n.Rproj.user\n.Rhistory\n.Rdata\n.httr-oauth\n.DS_Store\n.quarto\n/.quarto/\n*_cache\ndata/\noutput/\n\n\n.Rproj.user、.Rhistory、.Rdata、.httr-oauth、.DS_Store、.quarto、/.quarto/都是项目的隐藏文件。\n\n*_cache是编译后的缓存文件，它们的后缀为”_cache”：\n\n\ndata/是放置代码运行所需的数据文件的文件夹。\noutput/是存放代码运行后的输出数据的文件夹。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "发布到GitHub Pages"
    ]
  },
  {
    "objectID": "quarto_foundation/insert_other_content.html",
    "href": "quarto_foundation/insert_other_content.html",
    "title": "插入其他内容",
    "section": "",
    "text": "1 插入参考文献\n在插入菜单中选择”Citation”：\n\n\n\n\n\nFigure 1: 参考文献的引用\n\n\n然后通过DOI或标题检索参考文献，选择目标文献：\n\n\n\n\n\nFigure 2: 参考文献的选择\n\n\n现在就会出现参考文献的交叉引用，如： (Fujii et al. 2023) 、(Sprumont et al. 2023)。并且会在文档最后生成参考文献列表，同时YAML中会新增参考文献的配置选项：bibliography: references.bib。同时根目录下会生成一个名为”references.bib”的参考文献配置文件。\n如果想改变参考文献展示的位置，可以在YAML中设置，如：\n\n---\ncitation-location: margin\n---\n\n可用的值参见 ?@tbl-图表标题位置设置 。这份文档的参考文献就设置为了在页面最后展示（citation-location: document）。\n\n\n\n\n\n\nNote\n\n\n\n关于参考文献和脚注的详细指南，参考：https://quarto.org/docs/authoring/footnotes-and-citations.html。\n\n\n\n2 插入Callouts\nCallouts会生成一个标注框，可以用来标注重要内容：\n\n例如：\n\n\n\n\n\n\nTip\n\n\n\n这是一个Callouts示例。\n\n\n其样式包括：\n\n\ncallout-note\n\n\n\ncallout-tip\n\n\n\ncallout-important\n\n\n\ncallout-caution\n\n\n\ncallout-warning\n\n\n\n3 插入在线视频\n通过以下语法可以在输出文档中插入可直接播放的在线视频：\n\n{{&lt; video https://www.youtube.com/embed/wo9vZccmqwc &gt;}}\n\nReferences\n\n\nFujii, Kouichi, Jin Kikuchi, Masatoshi Uchida, Masanari Machida, Midori Tsuchiya, Kentaro Hayashi, Nana Maekawa, Hajime Houzumi, Arata Honda, and Koji Wake. 2023. “Tiger Attack at a Japanese Safari Park: A Case Report.” International Journal of Emergency Medicine 16 (1). https://doi.org/10.1186/s12245-023-00556-3.\n\n\nSprumont, Adrien, Ana Rodrigues, Simon J. McGowan, Colin Bannard, and Oliver Bannard. 2023. “Germinal Centers Output Clonally Diverse Plasma Cell Populations Expressing High- and Low-Affinity Antibodies.” Cell, November. https://doi.org/10.1016/j.cell.2023.10.022.",
    "crumbs": [
      "Home",
      "Quarto基础",
      "插入其他内容"
    ]
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html",
    "href": "quarto_foundation/yaml_settings.html",
    "title": "YAML设置",
    "section": "",
    "text": "Quarto主要由三大部分组成：metadata, text, 和 code。其中metadata是文档开头写在”—“之间的句子，它采用的是YAML语法，所以有时候也被叫做YAML metadata 或者 the YAML frontmatter。YAML定义了Quarto文档的各种属性，比如编译文件类型、主题、代码块的执行行为以及目录等。在YAML metadata中采用正确的缩进十分重要。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "YAML设置"
    ]
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-dateformat",
    "href": "quarto_foundation/yaml_settings.html#sec-dateformat",
    "title": "YAML设置",
    "section": "\n2.1 date-format的设置",
    "text": "2.1 date-format的设置\ndate-format通过以下关键词来定义日期格式：\n\n\n\n\n\n\n\nStyle\nDescription\nExample\n\n\n\nfull\nA full date that includes the weekday name\nMonday, March 7, 2005\n\n\nlong\nA long date that includes a wide month name\nMarch 7, 2005\n\n\nmedium\nA medium date\nMar 7, 2005\n\n\nshort\nA short date with a numeric month\n3/7/05\n\n\niso\nA short date in ISO format\n2005-03-07\n\n\n\n也可以通过以下语法更加灵活的定义日期格式：\n\n\n\n\n\n\n\normat String\nOutput\nDescription\n\n\n\nYY\n18\nTwo-digit year\n\n\nYYYY\n2018\n四位数年份\n\n\nM\n1-12\nThe month, beginning at 1\n\n\nMM\n01-12\n两位数月份\n\n\nMMM\nJan-Dec\nThe abbreviated month name\n\n\nMMMM\nJanuary-December\nThe full month name\n\n\nD\n1-31\nThe day of the month\n\n\nDD\n01-31\n两位数日期\n\n\nd\n0-6\nThe day of the week, with Sunday as 0\n\n\ndd\nSu-Sa\nThe min name of the day of the week\n\n\nddd\nSun-Sat\nThe short name of the day of the week\n\n\ndddd\nSunday-Saturday\nThe name of the day of the week\n\n\nH\n0-23\nThe hour\n\n\nHH\n00-23\n两位数小时，24小时制\n\n\nh\n1-12\nThe hour, 12-hour clock\n\n\nhh\n01-12\nThe hour, 12-hour clock, 2-digits\n\n\nm\n0-59\nThe minute\n\n\nmm\n00-59\n两位数分钟\n\n\ns\n0-59\nThe second\n\n\nss\n00-59\nThe second, 2-digits\n\n\nSSS\n000-999\nThe millisecond, 3-digits\n\n\nZ\n+05:00\nThe offset from UTC, ±HH:mm\n\n\nA\nAM PM\n\n\n\na\nam pm\n\n\n\nDo\n1st 2nd … 31st\nDay of Month with ordinal\n\n\n\n可以通过”[]“添加自定义字符。通过这些语法，可以定制符合中文语法的日期格式，如：date-format: \"YYYY[年]M[月]D[日] HH:mm\"\n\n\n\n\n\n\nTip\n\n\n\n关于日期的详细指南，详见：https://quarto.org/docs/reference/dates.html。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "YAML设置"
    ]
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#编译html",
    "href": "quarto_foundation/yaml_settings.html#编译html",
    "title": "YAML设置",
    "section": "\n10.1 编译HTML",
    "text": "10.1 编译HTML\n\n---\nformat: \n  html:\n    theme: \n      light: flatly \n      dark: darkly \n    embed-resources: false\n    code-tools: true\n    title-block-banner: images/banner.jpg \n    title-block-banner-color: \"black\"\n    toc: true\n    toc-title: 目录\n    toc-location: left\n    toc-depth: 2\n    toc-expand: 1\n    number-sections: true\n    number-depth: 3\n    anchor-sections: true\n    link-external-icon: true\n    link-external-newwindow: true\n    df-print: kable \n    code-link: true\n---\n\n\ntheme：主题。同 Section 3 。\nembed-resources：是否将所有源文件嵌入HTML文件以方便分享。默认为”false”。\ncode-tools：是否在网页右上角显示”&lt;code&gt;“按钮。点击该按钮可以看到Quarto文档的原始markdown代码。\n\ntitle-block-banner：标题横幅设置。title-block-banner有以下选项：\n\ntrue：将标题以网页横幅的形式展示，样式为them中所选样式的默认样式。\n具体颜色：如title-block-banner: \"#003262\"。\n图片路径：如title-block-banner: images/banner.jpeg。\n\n\ntoc相关设置：同 Section 4 。\nnumber-sections、number-depth：同 Section 5 。\nanchor-sections: 设置为true时，当鼠标移到各级标题上时会显示anchor link，方便我们复制直接定位到该标题的超链接。\nlink-external-icon：设置为true时会在外部链接上显示一个小图标。\nlink-external-newwindow：是否在新标签页打开外部链接。\ndf-print：表格输出样式\n\ncode-copy：设置代码复制按钮：\n\ntrue: 总是在代码块右上角显示代码复制按钮。\nfalse: 隐藏代码复制按钮。\nhover：（默认）当鼠标移过时显示代码复制按钮。\n\n\ncode-fold: 是否折叠代码。\ncode-link: 是否自动为函数加上超链接。该功能基于downlit包，可以自动为识别到的函数加上一个链接到官方文档的超链接。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "YAML设置"
    ]
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#sec-github-markdown",
    "href": "quarto_foundation/yaml_settings.html#sec-github-markdown",
    "title": "YAML设置",
    "section": "\n10.2 编译GitHub Flavored Markdown（GFM）",
    "text": "10.2 编译GitHub Flavored Markdown（GFM）\n我们可以将Quarto文档转换为GitHub风格的Markdown文档（GitHub Flavored Markdown，GFM）。这可以用来生成GitHub项目的README.md文档。\n\n---\ntitle: \"My Project\"\nformat: \n  gfm:\n    identifier-prefix: readme # 标识符\n    # preview-mode: raw # 预览原始markdown\n    keep-yaml: true\n    toc: true\n    toc-depth: 1\n    number-sections: true\n    citation-location: document\n    output-file: \"README.md\" # 输出文档的文件名\n---",
    "crumbs": [
      "Home",
      "Quarto基础",
      "YAML设置"
    ]
  },
  {
    "objectID": "quarto_foundation/yaml_settings.html#编译pdf",
    "href": "quarto_foundation/yaml_settings.html#编译pdf",
    "title": "YAML设置",
    "section": "\n10.3 编译PDF",
    "text": "10.3 编译PDF\n如果要在rmarkdown、bookdown中使用PDF输出功能， 可以在在R中安装tinytex扩展包并安装TinyTeX编译软件：\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n\n其中上面第一行命令安装R的tinytex扩展包， 第二行将下载LaTeX编译程序的服务器设置为清华大学tuna镜像站， 第三行安装LaTeX编译程序。\n如果安装成功， TinyTeX软件包在MS Windows系统中一般会安装在 C:\\Users\\用户名\\AppData\\Roaming\\TinyTeX目录中， 其中”用户名”应替换成系统当前用户名。 如果需要删除TinyTeX软件包， 只要直接删除那个子目录就可以。\n为了判断TinyTeX是否安装成功， 在RStudio中运行：\n\ntinytex::is_tinytex()\n\n结果应为TRUE, 出错或者结果为FALSE都说明安装不成功。\n当用户使用RMarkdown和tinytex包转换latex并编译为PDF时， 如果缺少某些latex宏包， tinytex会自动安装缺少的宏包。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "YAML设置"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_shiny.html",
    "href": "quarto_foundation/quarto_shiny.html",
    "title": "在Quarto中嵌入Shiny应用程序",
    "section": "",
    "text": "参考：R-shinylive app in Quarto!\n本节主要介绍如何在Quarto文档中嵌入Shiny交互式应用程序，而无需依赖服务器。这是一个Quarto的全新特性，感谢Barret Schloerke等人开发的shinylive包让这一特性得以实现。\nShinylive是一种非服务器依赖的Shiny，它使得Shiny应用程序能够在网页浏览器中直接运行 ，而不需要依赖后台服务器。在 2022 年的Posit大会上，第一次推出了基于 WebAssembly 和 Pyodide 的 Shinylive for Python。随后，在2023年的Posit大会上，首次推出了基于webR的R版本的shinylive。该包的第一个CRAN版本于2023年10月11日首次发布。\nshinylive视频教程《Creating a Serverless R Shiny App using Quarto with R Shinylive》：\n本节我们介绍第三种方法，即在Quarto文档中通过quarto-shinylive extension嵌入Shiny应用程序。",
    "crumbs": [
      "Home",
      "Quarto基础",
      "在Quarto中嵌入Shiny应用程序"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_shiny.html#案例一",
    "href": "quarto_foundation/quarto_shiny.html#案例一",
    "title": "在Quarto中嵌入Shiny应用程序",
    "section": "\n8.1 案例一",
    "text": "8.1 案例一\n下面是一个来自Shiny官方入门指南中的案例：\n#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\n\n# Define UI ----\nui &lt;- fluidPage(\n\n  # App title ----\n  titlePanel(\"Hello World!\"),\n\n  # Sidebar layout with input and output definitions ----\n  sidebarLayout(\n\n    # Sidebar panel for inputs ----\n    sidebarPanel(\n\n      # Input: Slider for the number of bins ----\n      sliderInput(inputId = \"bins\",\n                  label = \"Number of bins:\",\n                  min = 5,\n                  max = 50,\n                  value = 30)\n\n    ),\n\n    # Main panel for displaying outputs ----\n    mainPanel(\n\n      # Output: Histogram ----\n      plotOutput(outputId = \"distPlot\")\n\n    )\n  )\n)\n\n# Define server logic required to draw a histogram ----\nserver &lt;- function(input, output) {\n\n  # Histogram of the Old Faithful Geyser Data ----\n  # with requested number of bins\n  # This expression that generates a histogram is wrapped in a call\n  # to renderPlot to indicate that:\n  #\n  # 1. It is \"reactive\" and therefore should be automatically\n  #    re-executed when inputs (input$bins) change\n  # 2. Its output type is a plot\n  output$distPlot &lt;- renderPlot({\n\n    x    &lt;- faithful$waiting\n    bins &lt;- seq(min(x), max(x), length.out = input$bins + 1)\n\n    hist(x, breaks = bins, col = \"#007bc2\", border = \"orange\",\n         xlab = \"Waiting time to next eruption (in mins)\",\n         main = \"Histogram of waiting times\")\n\n    })\n\n}\n\n# Run the app ----\nshinyApp(ui = ui, server = server)\n代码：\n```{shinylive-r}\n#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\n\n# Define UI for app that draws a histogram ----\nui &lt;- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    numericInput(\"n\", \"Sample count\", 100),\n    checkboxInput(\"pause\", \"Pause\", FALSE),\n  ),\n  plotOutput(\"plot\", width=1100)\n)\n\nserver &lt;- function(input, output, session) {\n  data &lt;- reactive({\n    input$resample\n    if (!isTRUE(input$pause)) {\n      invalidateLater(1000)\n    }\n    rnorm(input$n)\n  })\n  \n  output$plot &lt;- renderPlot({\n    hist(data(),\n      breaks = 40,\n      xlim = c(-2, 2),\n      ylim = c(0, 1),\n      lty = \"blank\",\n      xlab = \"value\",\n      freq = FALSE,\n      main = \"\"\n    )\n    \n    x &lt;- seq(from = -2, to = 2, length.out = 500)\n    y &lt;- dnorm(x)\n    lines(x, y, lwd=1.5)\n    \n    lwd &lt;- 5\n    abline(v=0, col=\"red\", lwd=lwd, lty=2)\n    abline(v=mean(data()), col=\"blue\", lwd=lwd, lty=1)\n\n    legend(legend = c(\"Normal\", \"Mean\", \"Sample mean\"),\n      col = c(\"black\", \"red\", \"blue\"),\n      lty = c(1, 2, 1),\n      lwd = c(1, lwd, lwd),\n      x = 1,\n      y = 0.9\n    )\n  }, res=140)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)\n```",
    "crumbs": [
      "Home",
      "Quarto基础",
      "在Quarto中嵌入Shiny应用程序"
    ]
  },
  {
    "objectID": "quarto_foundation/quarto_shiny.html#案例二",
    "href": "quarto_foundation/quarto_shiny.html#案例二",
    "title": "在Quarto中嵌入Shiny应用程序",
    "section": "\n8.2 案例二",
    "text": "8.2 案例二\n来自：shinylive-in-book-test\n#| standalone: true\n#| viewerHeight: 500\n#| label: fig-shiny-spline\n\nlibrary(ggplot2)\nlibrary(htmltools)\n\nui &lt;- fluidPage(\n  \n  fluidRow(\n    column(8, \n           sliderInput(\n             \"deg_free\", \n             label = \"Spline degrees of freedom:\",\n             min = 3L, value = 3L, max = 8L, step = 1L\n           )\n    ),\n    \n    imageOutput(\"spline_contours\", height = \"400px\")\n  )\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n  # ------------------------------------------------------------------------\n  # Input data from remote locations on GitHub\n  \n  pred_path &lt;-\n    paste(                                                  \n      \"https://raw.githubusercontent.com\",                  \n      \"topepo\", \"shinylive-in-book-test\",                   \n      \"main\", \"predicted_values.RData\",                     \n      sep = \"/\"                                             \n    )                                                       \n  data_path &lt;-                                              \n    paste(                                                  \n      \"https://raw.githubusercontent.com\",                  \n      \"topepo\", \"shinylive-in-book-test\",                   \n      \"main\", \"sim_val.RData\",                              \n      sep = \"/\"                                             \n    )                                                       \n  \n  rdata_file &lt;- tempfile()\n  download.file(pred_path, destfile = rdata_file)           \n  load(rdata_file)                                          \n  download.file(data_path, destfile = rdata_file)           \n  load(rdata_file)                                          \n  \n  # Set some ranges for the plot\n  rngs &lt;- list(A = c(-3.3, 3.3), B = c(-4.4, 4.4))\n  \n  output$spline_contours &lt;-\n    renderImage({\n      \n      preds &lt;- predicted_values[predicted_values$deg_free == input$deg_free,]\n      \n      p &lt;-\n        ggplot(preds, aes(A, B)) +\n        # Plot the validation set\n        geom_point(\n          data = sim_val, \n          aes(col = class, pch = class), \n          alpha = 1 / 2,\n          cex = 3\n        ) +\n        # Show the class boundary\n        geom_contour(\n          aes(z = .pred_one),\n          breaks = 1 / 2,\n          linewidth = 3 / 2,\n          col = \"black\"\n        ) +\n        # Formatting\n        lims(x = rngs$A, y = rngs$B) +\n        theme_bw() + \n        theme(legend.position = \"top\")\n      \n      file &lt;-\n        htmltools::capturePlot(\n          print(p), \n          tempfile(fileext = \".svg\"),\n          grDevices::svg,\n          width = 4, \n          height = 4\n        )\n      list(src = file)\n    }, \n    deleteFile = TRUE)\n}\n\nshinyApp(ui = ui, server = server)\n代码：\n```{shinylive-r}\n#| standalone: true\n#| viewerHeight: 500\n#| label: fig-shiny-spline\n\nlibrary(ggplot2)\nlibrary(htmltools)\n\nui &lt;- fluidPage(\n  \n  fluidRow(\n    column(8, \n           sliderInput(\n             \"deg_free\", \n             label = \"Spline degrees of freedom:\",\n             min = 3L, value = 3L, max = 8L, step = 1L\n           )\n    ),\n    \n    imageOutput(\"spline_contours\", height = \"400px\")\n  )\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n  # ------------------------------------------------------------------------\n  # Input data from remote locations on GitHub\n  \n  pred_path &lt;-\n    paste(                                                  \n      \"https://raw.githubusercontent.com\",                  \n      \"topepo\", \"shinylive-in-book-test\",                   \n      \"main\", \"predicted_values.RData\",                     \n      sep = \"/\"                                             \n    )                                                       \n  data_path &lt;-                                              \n    paste(                                                  \n      \"https://raw.githubusercontent.com\",                  \n      \"topepo\", \"shinylive-in-book-test\",                   \n      \"main\", \"sim_val.RData\",                              \n      sep = \"/\"                                             \n    )                                                       \n  \n  rdata_file &lt;- tempfile()\n  download.file(pred_path, destfile = rdata_file)           \n  load(rdata_file)                                          \n  download.file(data_path, destfile = rdata_file)           \n  load(rdata_file)                                          \n  \n  # Set some ranges for the plot\n  rngs &lt;- list(A = c(-3.3, 3.3), B = c(-4.4, 4.4))\n  \n  output$spline_contours &lt;-\n    renderImage({\n      \n      preds &lt;- predicted_values[predicted_values$deg_free == input$deg_free,]\n      \n      p &lt;-\n        ggplot(preds, aes(A, B)) +\n        # Plot the validation set\n        geom_point(\n          data = sim_val, \n          aes(col = class, pch = class), \n          alpha = 1 / 2,\n          cex = 3\n        ) +\n        # Show the class boundary\n        geom_contour(\n          aes(z = .pred_one),\n          breaks = 1 / 2,\n          linewidth = 3 / 2,\n          col = \"black\"\n        ) +\n        # Formatting\n        lims(x = rngs$A, y = rngs$B) +\n        theme_bw() + \n        theme(legend.position = \"top\")\n      \n      file &lt;-\n        htmltools::capturePlot(\n          print(p), \n          tempfile(fileext = \".svg\"),\n          grDevices::svg,\n          width = 4, \n          height = 4\n        )\n      list(src = file)\n    }, \n    deleteFile = TRUE)\n}\n\nshinyApp(ui = ui, server = server)\n```\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.2    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.2       htmltools_0.5.7   rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.8    xfun_0.41        \n[13] digest_0.6.34     rlang_1.1.3       evaluate_0.23",
    "crumbs": [
      "Home",
      "Quarto基础",
      "在Quarto中嵌入Shiny应用程序"
    ]
  },
  {
    "objectID": "r_basic/environment_configuration.html",
    "href": "r_basic/environment_configuration.html",
    "title": "Rstudio环境配置",
    "section": "",
    "text": "在R原软件中逐个运行下面的代码（仅适用Windows系统）。macOS直接打开CRAN官网下载最新版本的R覆盖安装，重启RStudio即可完成R的更新，原R包都在。\n\ninstall.packages(\"installr\")\nlibrary(installr)\nupdateR()",
    "crumbs": [
      "Home",
      "R语言基础",
      "Rstudio环境配置"
    ]
  },
  {
    "objectID": "r_basic/environment_configuration.html#提高矢量大小上限",
    "href": "r_basic/environment_configuration.html#提高矢量大小上限",
    "title": "Rstudio环境配置",
    "section": "\n8.1 提高矢量大小上限",
    "text": "8.1 提高矢量大小上限\n在R语言中如果我们要处理的数据集较大，如在处理单细胞数据时，可能会出现如下报错：\nError: cannot allocate vector of size *** Mb\n这是因为 R 中有对象大小的限制（默认值为 500 1024 ^ 2 = 500 Mb）。可以通过如下代码进行调整：\n\n# 调整允许对象大小限制为6GB\noptions(future.globals.maxSize = 6 * 1024 * 1024^2)",
    "crumbs": [
      "Home",
      "R语言基础",
      "Rstudio环境配置"
    ]
  },
  {
    "objectID": "r_basic/environment_configuration.html#sec-Raising_memory_limit",
    "href": "r_basic/environment_configuration.html#sec-Raising_memory_limit",
    "title": "Rstudio环境配置",
    "section": "\n8.2 提高R内存分配上限（macOS）",
    "text": "8.2 提高R内存分配上限（macOS）\n如果在运行大量的数据处理时，出现如下报错：\nError: vector memory exhausted (limit reached?)\n那么说明脚本的运行超出了R语言内存分配的上限，这一般就是Mac的物理内存大小。但是，我们可以通过如下的方式来通过分配SWAP虚拟内存的方式，使得代码能够继续运行（来自stackoverflow上的这篇帖子）。\n【方法一：通过usethis包配置】\n在R中运行：\n\nusethis::edit_r_environ()\n\n\n\n\n\n\n\nTip\n\n\n\nusethis is a package that facilitates interactive workflows for R project creation and development\n\n\n运行后会在RStudio中以新标签页的方式打开一个.Renviron文件。在其中输入：\nR_MAX_VSIZE=50Gb\n\n\n\n\n\n\nCaution\n\n\n\n注意这里的内存数值包括了物理内存和虚拟内存，所以如果你的电脑的实际内存为16GB，那么在这里需要输入比16GB更大的数值，输入16GB是不会有帮助的。\n\n\n保存这个文件后，重启RStudio，这时候内存上限就被修改好了。\n\n\nRStudio调用虚拟内存执行脚本\n\n【方法二：通过终端配置】\n打开终端（Terminal），在其中输入：\ncd ~\ntouch .Renviron\nopen .Renviron\n这时会打开.Renviron文件，在其中输入：\nR_MAX_VSIZE=50Gb\n保存文件，重启RStudio。",
    "crumbs": [
      "Home",
      "R语言基础",
      "Rstudio环境配置"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html",
    "href": "r_basic/basic_data_function.html",
    "title": "数据处理基本函数",
    "section": "",
    "text": "载入示例数据：\n\nmydata &lt;- readRDS(\"data/r_basic/lms_ess.rds\")\n\n\n\nsummary(mydata)\n\n   year           year2          age            race                 marriage  \n 2010:111   2010-2011:216   Min.   :23.00   White :554   Married         :386  \n 2011:105   2012-2013:217   1st Qu.:48.00   Black : 99   Single/Unmarried:166  \n 2012:118   2014-2016:300   Median :55.00   Others: 76   Others          :148  \n 2013: 99                   Mean   :55.77   NA's  :  4   NA's            : 33  \n 2014:100                   3rd Qu.:64.00                                      \n 2015:101                   Max.   :95.00                                      \n 2016: 99                                                                      \n                                    grade            grade2      tumor_size   \n Well differentiated; Grade I          : 58   Low-grade :181   Min.   :  4.0  \n Moderately differentiated; Grade II   :123   High-grade:323   1st Qu.: 60.0  \n Poorly differentiated; Grade III      :105   Gx        :229   Median : 95.0  \n Undifferentiated; anaplastic; Grade IV:218                    Mean   :107.9  \n NA's                                  :229                    3rd Qu.:135.0  \n                                                               Max.   :950.0  \n                                                               NA's   :79     \n  his      T_stage   T_stage_plus N_stage    M_stage   figo       figo_plus  \n LMS:448   T1:499   T1b    :340   N0  :680   M0:628   I  :442   IB     :290  \n ESS:285   T2:131   T1a    :114   N1  : 49   M1:105   II : 82   IA     :109  \n           T3: 85   T2a    : 67   NA's:  4            III: 89   IVB    :105  \n           T4: 18   T3a    : 57                       IV :120   IIIA   : 39  \n                    T2b    : 55                                 IIIC   : 32  \n                    T1     : 45                                 (Other): 30  \n                    (Other): 55                                 NA's   :128  \n        peri         surg       alnd       plnd       lnd        rad     \n Negtive  :674   TH+BSO:629   No  :586   No  :417   No  :412   No  :609  \n Malignant: 59   TH    : 47   Yes :111   Yes :282   Yes :288   Yes :117  \n                 RH/EH : 57   NA's: 36   NA's: 34   NA's: 33   NA's:  7  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n   chem     dead     status         time                    income   \n No  :365   0:365   0   :365   Min.   :  2.00   &lt;$60,000       :186  \n Yes :314   1:368   1   :332   1st Qu.: 15.00   $60,000-$74,999:293  \n NA's: 54           2   : 29   Median : 43.00   &gt;$75,000       :254  \n                    NA's:  7   Mean   : 47.53                        \n                               3rd Qu.: 76.00                        \n                               Max.   :119.00                        \n                                                                     \n\n\n\n\n\ndim(mydata)[2]#dim()函数获取数据的维度，即行、列数。所以[1]输出行数，[2]输出列数\n\n[1] 26\n\nncol(mydata)#另一种方式\n\n[1] 26\n\n\n\n\ndim(mydata)[1]\n\n[1] 733\n\n#或者\nnrow(mydata)\n\n[1] 733\n\n\n\n\nprint(paste0(\"该数据集有 \",dim(mydata)[1],\" 个样本； \",dim(mydata)[2],\" 个变量\"))\n\n[1] \"该数据集有 733 个样本； 26 个变量\"\n\n\n\n\ncolnames(mydata)\n\n [1] \"year\"         \"year2\"        \"age\"          \"race\"         \"marriage\"    \n [6] \"grade\"        \"grade2\"       \"tumor_size\"   \"his\"          \"T_stage\"     \n[11] \"T_stage_plus\" \"N_stage\"      \"M_stage\"      \"figo\"         \"figo_plus\"   \n[16] \"peri\"         \"surg\"         \"alnd\"         \"plnd\"         \"lnd\"         \n[21] \"rad\"          \"chem\"         \"dead\"         \"status\"       \"time\"        \n[26] \"income\"      \n\n#或者通过dput函数将所有变量名输出为向量\ndput(names(mydata))\n\nc(\"year\", \"year2\", \"age\", \"race\", \"marriage\", \"grade\", \"grade2\", \n\"tumor_size\", \"his\", \"T_stage\", \"T_stage_plus\", \"N_stage\", \"M_stage\", \n\"figo\", \"figo_plus\", \"peri\", \"surg\", \"alnd\", \"plnd\", \"lnd\", \"rad\", \n\"chem\", \"dead\", \"status\", \"time\", \"income\")\n\n\n\n\n```{r}\n#| eval: false\nrownames(mydata)\n```\n\n\n\ntable(mydata$his)\n\n\nLMS ESS \n448 285 \n\nhist(mydata$age,col=\"coral\")#以直方图的形式展示\n\n\n\n\n\n\n\n\n加载案例数据：这里用VIM包内自带的sleep数据集为例进行演示。该数据集显示了两种安眠药对10名患者的影响(与对照组相比，睡眠时间的增加量)。其中就包含了很多缺失值。\n\ndata(sleep, package=\"VIM\")\nhead(sleep)\n\n   BodyWgt BrainWgt NonD Dream Sleep Span Gest Pred Exp Danger\n1 6654.000   5712.0   NA    NA   3.3 38.6  645    3   5      3\n2    1.000      6.6  6.3   2.0   8.3  4.5   42    3   1      3\n3    3.385     44.5   NA    NA  12.5 14.0   60    1   1      1\n4    0.920      5.7   NA    NA  16.5   NA   25    5   2      3\n5 2547.000   4603.0  2.1   1.8   3.9 69.0  624    3   5      4\n6   10.550    179.5  9.1   0.7   9.8 27.0  180    4   4      4\n\n\n首先展示缺失值的比例。\n\n左侧直方图展示单个变量的缺失比例，其中NonD缺失比例大于20%。\n右侧直方图展示各个变量的缺失模式。如第一行表示NonD、Dream和Span 3个变量共同缺失的比例为1.6%。NonD的缺失比例=1.6%+3.2%+3.2%+14.5%=22.5%。所有变量均无缺失值的个案占67.7%\n\n输出的结果部分同样展示了各个变量缺失的具体比例\n\nlibrary(VIM)\naggr_plot&lt;-aggr(sleep,\n                prop=T,\n                numbers=T,\n                sortVars=TRUE,\n                gap=2,\n                ylab=c(\"Histogram of missing data\",\"Pattern\"))\n\n\n\n\n\n\n\n\n Variables sorted by number of missings: \n Variable      Count\n     NonD 0.22580645\n    Dream 0.19354839\n    Sleep 0.06451613\n     Span 0.06451613\n     Gest 0.06451613\n  BodyWgt 0.00000000\n BrainWgt 0.00000000\n     Pred 0.00000000\n      Exp 0.00000000\n   Danger 0.00000000\n\n\n展示缺失值的数量。输出的结果部分展示了各个变量缺失的具体数量。\n\naggr_plot&lt;-aggr(sleep,\n                prop=F,\n                numbers=T,\n                sortVars=TRUE,\n                gap=2,\n                ylab=c(\"Histogram of missing data\",\"Pattern\"))\n\n\n\n\n\n\n\n\n Variables sorted by number of missings: \n Variable Count\n     NonD    14\n    Dream    12\n    Sleep     4\n     Span     4\n     Gest     4\n  BodyWgt     0\n BrainWgt     0\n     Pred     0\n      Exp     0\n   Danger     0\n\n\n以表格的形式展示各个变量的缺失模式（同右侧图形）\n\nsummary(aggr_plot)\n\n\n Missings per variable: \n Variable Count\n  BodyWgt     0\n BrainWgt     0\n     NonD    14\n    Dream    12\n    Sleep     4\n     Span     4\n     Gest     4\n     Pred     0\n      Exp     0\n   Danger     0\n\n Missings in combinations of variables: \n        Combinations Count   Percent\n 0:0:0:0:0:0:0:0:0:0    42 67.741935\n 0:0:0:0:0:0:1:0:0:0     3  4.838710\n 0:0:0:0:0:1:0:0:0:0     2  3.225806\n 0:0:0:0:0:1:1:0:0:0     1  1.612903\n 0:0:1:0:1:0:0:0:0:0     2  3.225806\n 0:0:1:1:0:0:0:0:0:0     9 14.516129\n 0:0:1:1:0:1:0:0:0:0     1  1.612903\n 0:0:1:1:1:0:0:0:0:0     2  3.225806\n\n\n通过marginplot分析缺失值。空心的湖蓝色圆圈表示非缺失值，红色实心圆圈表示缺失值，深红色实心圆圈表示两个变量均缺失。图左侧的红色箱型图显示了在保留NonD缺失值的情况下Dream的分布，蓝色箱型图显示了删除NonD缺失值后Dream的分布。图表底部的框图正好相反，反映了在保留和删除Dreamq缺失值的情况下NonD的分布情况。如果数据是完全随机缺失(MCAR : missing completely at random)，那么红色和蓝色箱型图将十分接近\n\nmarginplot(sleep[3:4])\n\n\n\n\n\n\n\n删除所有缺失值\n\nsleep&lt;-na.omit(sleep)",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#展示最大值最小值平均数中位数缺失值数量",
    "href": "r_basic/basic_data_function.html#展示最大值最小值平均数中位数缺失值数量",
    "title": "数据处理基本函数",
    "section": "",
    "text": "summary(mydata)\n\n   year           year2          age            race                 marriage  \n 2010:111   2010-2011:216   Min.   :23.00   White :554   Married         :386  \n 2011:105   2012-2013:217   1st Qu.:48.00   Black : 99   Single/Unmarried:166  \n 2012:118   2014-2016:300   Median :55.00   Others: 76   Others          :148  \n 2013: 99                   Mean   :55.77   NA's  :  4   NA's            : 33  \n 2014:100                   3rd Qu.:64.00                                      \n 2015:101                   Max.   :95.00                                      \n 2016: 99                                                                      \n                                    grade            grade2      tumor_size   \n Well differentiated; Grade I          : 58   Low-grade :181   Min.   :  4.0  \n Moderately differentiated; Grade II   :123   High-grade:323   1st Qu.: 60.0  \n Poorly differentiated; Grade III      :105   Gx        :229   Median : 95.0  \n Undifferentiated; anaplastic; Grade IV:218                    Mean   :107.9  \n NA's                                  :229                    3rd Qu.:135.0  \n                                                               Max.   :950.0  \n                                                               NA's   :79     \n  his      T_stage   T_stage_plus N_stage    M_stage   figo       figo_plus  \n LMS:448   T1:499   T1b    :340   N0  :680   M0:628   I  :442   IB     :290  \n ESS:285   T2:131   T1a    :114   N1  : 49   M1:105   II : 82   IA     :109  \n           T3: 85   T2a    : 67   NA's:  4            III: 89   IVB    :105  \n           T4: 18   T3a    : 57                       IV :120   IIIA   : 39  \n                    T2b    : 55                                 IIIC   : 32  \n                    T1     : 45                                 (Other): 30  \n                    (Other): 55                                 NA's   :128  \n        peri         surg       alnd       plnd       lnd        rad     \n Negtive  :674   TH+BSO:629   No  :586   No  :417   No  :412   No  :609  \n Malignant: 59   TH    : 47   Yes :111   Yes :282   Yes :288   Yes :117  \n                 RH/EH : 57   NA's: 36   NA's: 34   NA's: 33   NA's:  7  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n   chem     dead     status         time                    income   \n No  :365   0:365   0   :365   Min.   :  2.00   &lt;$60,000       :186  \n Yes :314   1:368   1   :332   1st Qu.: 15.00   $60,000-$74,999:293  \n NA's: 54           2   : 29   Median : 43.00   &gt;$75,000       :254  \n                    NA's:  7   Mean   : 47.53                        \n                               3rd Qu.: 76.00                        \n                               Max.   :119.00",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#展示变量数量和样本数量",
    "href": "r_basic/basic_data_function.html#展示变量数量和样本数量",
    "title": "数据处理基本函数",
    "section": "",
    "text": "dim(mydata)[2]#dim()函数获取数据的维度，即行、列数。所以[1]输出行数，[2]输出列数\n\n[1] 26\n\nncol(mydata)#另一种方式\n\n[1] 26\n\n\n\n\ndim(mydata)[1]\n\n[1] 733\n\n#或者\nnrow(mydata)\n\n[1] 733\n\n\n\n\nprint(paste0(\"该数据集有 \",dim(mydata)[1],\" 个样本； \",dim(mydata)[2],\" 个变量\"))\n\n[1] \"该数据集有 733 个样本； 26 个变量\"\n\n\n\n\ncolnames(mydata)\n\n [1] \"year\"         \"year2\"        \"age\"          \"race\"         \"marriage\"    \n [6] \"grade\"        \"grade2\"       \"tumor_size\"   \"his\"          \"T_stage\"     \n[11] \"T_stage_plus\" \"N_stage\"      \"M_stage\"      \"figo\"         \"figo_plus\"   \n[16] \"peri\"         \"surg\"         \"alnd\"         \"plnd\"         \"lnd\"         \n[21] \"rad\"          \"chem\"         \"dead\"         \"status\"       \"time\"        \n[26] \"income\"      \n\n#或者通过dput函数将所有变量名输出为向量\ndput(names(mydata))\n\nc(\"year\", \"year2\", \"age\", \"race\", \"marriage\", \"grade\", \"grade2\", \n\"tumor_size\", \"his\", \"T_stage\", \"T_stage_plus\", \"N_stage\", \"M_stage\", \n\"figo\", \"figo_plus\", \"peri\", \"surg\", \"alnd\", \"plnd\", \"lnd\", \"rad\", \n\"chem\", \"dead\", \"status\", \"time\", \"income\")\n\n\n\n\n```{r}\n#| eval: false\nrownames(mydata)\n```\n\n\n\ntable(mydata$his)\n\n\nLMS ESS \n448 285 \n\nhist(mydata$age,col=\"coral\")#以直方图的形式展示",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#展示缺失值的构成",
    "href": "r_basic/basic_data_function.html#展示缺失值的构成",
    "title": "数据处理基本函数",
    "section": "",
    "text": "加载案例数据：这里用VIM包内自带的sleep数据集为例进行演示。该数据集显示了两种安眠药对10名患者的影响(与对照组相比，睡眠时间的增加量)。其中就包含了很多缺失值。\n\ndata(sleep, package=\"VIM\")\nhead(sleep)\n\n   BodyWgt BrainWgt NonD Dream Sleep Span Gest Pred Exp Danger\n1 6654.000   5712.0   NA    NA   3.3 38.6  645    3   5      3\n2    1.000      6.6  6.3   2.0   8.3  4.5   42    3   1      3\n3    3.385     44.5   NA    NA  12.5 14.0   60    1   1      1\n4    0.920      5.7   NA    NA  16.5   NA   25    5   2      3\n5 2547.000   4603.0  2.1   1.8   3.9 69.0  624    3   5      4\n6   10.550    179.5  9.1   0.7   9.8 27.0  180    4   4      4\n\n\n首先展示缺失值的比例。\n\n左侧直方图展示单个变量的缺失比例，其中NonD缺失比例大于20%。\n右侧直方图展示各个变量的缺失模式。如第一行表示NonD、Dream和Span 3个变量共同缺失的比例为1.6%。NonD的缺失比例=1.6%+3.2%+3.2%+14.5%=22.5%。所有变量均无缺失值的个案占67.7%\n\n输出的结果部分同样展示了各个变量缺失的具体比例\n\nlibrary(VIM)\naggr_plot&lt;-aggr(sleep,\n                prop=T,\n                numbers=T,\n                sortVars=TRUE,\n                gap=2,\n                ylab=c(\"Histogram of missing data\",\"Pattern\"))\n\n\n\n\n\n\n\n\n Variables sorted by number of missings: \n Variable      Count\n     NonD 0.22580645\n    Dream 0.19354839\n    Sleep 0.06451613\n     Span 0.06451613\n     Gest 0.06451613\n  BodyWgt 0.00000000\n BrainWgt 0.00000000\n     Pred 0.00000000\n      Exp 0.00000000\n   Danger 0.00000000\n\n\n展示缺失值的数量。输出的结果部分展示了各个变量缺失的具体数量。\n\naggr_plot&lt;-aggr(sleep,\n                prop=F,\n                numbers=T,\n                sortVars=TRUE,\n                gap=2,\n                ylab=c(\"Histogram of missing data\",\"Pattern\"))\n\n\n\n\n\n\n\n\n Variables sorted by number of missings: \n Variable Count\n     NonD    14\n    Dream    12\n    Sleep     4\n     Span     4\n     Gest     4\n  BodyWgt     0\n BrainWgt     0\n     Pred     0\n      Exp     0\n   Danger     0\n\n\n以表格的形式展示各个变量的缺失模式（同右侧图形）\n\nsummary(aggr_plot)\n\n\n Missings per variable: \n Variable Count\n  BodyWgt     0\n BrainWgt     0\n     NonD    14\n    Dream    12\n    Sleep     4\n     Span     4\n     Gest     4\n     Pred     0\n      Exp     0\n   Danger     0\n\n Missings in combinations of variables: \n        Combinations Count   Percent\n 0:0:0:0:0:0:0:0:0:0    42 67.741935\n 0:0:0:0:0:0:1:0:0:0     3  4.838710\n 0:0:0:0:0:1:0:0:0:0     2  3.225806\n 0:0:0:0:0:1:1:0:0:0     1  1.612903\n 0:0:1:0:1:0:0:0:0:0     2  3.225806\n 0:0:1:1:0:0:0:0:0:0     9 14.516129\n 0:0:1:1:0:1:0:0:0:0     1  1.612903\n 0:0:1:1:1:0:0:0:0:0     2  3.225806\n\n\n通过marginplot分析缺失值。空心的湖蓝色圆圈表示非缺失值，红色实心圆圈表示缺失值，深红色实心圆圈表示两个变量均缺失。图左侧的红色箱型图显示了在保留NonD缺失值的情况下Dream的分布，蓝色箱型图显示了删除NonD缺失值后Dream的分布。图表底部的框图正好相反，反映了在保留和删除Dreamq缺失值的情况下NonD的分布情况。如果数据是完全随机缺失(MCAR : missing completely at random)，那么红色和蓝色箱型图将十分接近\n\nmarginplot(sleep[3:4])\n\n\n\n\n\n\n\n删除所有缺失值\n\nsleep&lt;-na.omit(sleep)",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#sec-排序",
    "href": "r_basic/basic_data_function.html#sec-排序",
    "title": "数据处理基本函数",
    "section": "\n2.1 排序",
    "text": "2.1 排序\n\nlibrary(dplyr)\nmydata &lt;- arrange(mydata, age)#按照某列升序排序\nmydata$age[1:10]\n\n [1] 23 24 24 24 26 27 27 27 27 28\n\nmydata &lt;- arrange(mydata, desc(age))#按照某列降序排序\nmydata$age[1:10]\n\n [1] 95 92 89 87 85 85 85 84 82 82\n\nmydata &lt;- arrange(mydata, his, tumor_size)#根据多列排序\nmydata[1:5,c(\"his\", \"tumor_size\")]\n\n  his tumor_size\n1 LMS         10\n2 LMS         12\n3 LMS         12\n4 LMS         15\n5 LMS         17\n\nmydata[445:455,c(\"his\", \"tumor_size\")]\n\n    his tumor_size\n445 LMS         NA\n446 LMS         NA\n447 LMS         NA\n448 LMS         NA\n449 ESS          4\n450 ESS          5\n451 ESS          5\n452 ESS          9\n453 ESS         10\n454 ESS         10\n455 ESS         12\n\n\n也可用自带base包内的order()函数排序：\n\nmydata &lt;- mydata[order(mydata$age),]\nmydata &lt;- mydata[order(-mydata$age),]\nmydata &lt;- mydata[order(mydata$age, mydata$his, mydata$tumor_size),]",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#重新命名行列",
    "href": "r_basic/basic_data_function.html#重新命名行列",
    "title": "数据处理基本函数",
    "section": "\n2.2 重新命名行、列",
    "text": "2.2 重新命名行、列\n重新命名变量（列）\n\nnames(mydata) &lt;- c(\"N\",\"patient_ID\",\"diagnosis\") # 连续命名\ncolnames(mydata)[2] &lt;- 'patient_ID'# 重新命名指定列名\n\n设置行名\n\nrownames(mydata) &lt;- mydata$ID # 将ID列设置为行名（注意不能有重复值）",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#数据筛选",
    "href": "r_basic/basic_data_function.html#数据筛选",
    "title": "数据处理基本函数",
    "section": "\n2.3 数据筛选",
    "text": "2.3 数据筛选\n提取某几列数据形成新的数据集\n\nvnumber &lt;- mydata[, 4:16] # 提取第4-16列的数据形成新的“vnumber”数据集\nvnumber &lt;- mydata[,c(2:12,16)] # 提取2-12列和第16列的数据\n\n提取指定行数的数据\n\nmydata_less &lt;- mydata[1:100, ]#提取1-100行的数据\n\n筛选数据\n筛选出低级别、接受了放疗的病例，并生成新的”new_data”数据集\n\n#方法一\nnew_data&lt;-subset(mydata,grade == \"Well differentiated; Grade I\" & rad == \"Yes\")\nnew_data[,c(\"grade\", \"rad\")]\n\n                           grade rad\n140 Well differentiated; Grade I Yes\n160 Well differentiated; Grade I Yes\n486 Well differentiated; Grade I Yes\n541 Well differentiated; Grade I Yes\n593 Well differentiated; Grade I Yes\n697 Well differentiated; Grade I Yes\n\n#也可用“｜”（或者），“！”（NOT）连接\n\n#方法二\nnew_data &lt;- mydata[which((mydata$grade == \"Well differentiated; Grade I\") &\n                           (mydata$rad == \"Yes\")),] \nnew_data[,c(\"grade\", \"rad\")]\n\n                           grade rad\n140 Well differentiated; Grade I Yes\n160 Well differentiated; Grade I Yes\n486 Well differentiated; Grade I Yes\n541 Well differentiated; Grade I Yes\n593 Well differentiated; Grade I Yes\n697 Well differentiated; Grade I Yes",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#合并两个数据集",
    "href": "r_basic/basic_data_function.html#合并两个数据集",
    "title": "数据处理基本函数",
    "section": "\n2.4 合并两个数据集",
    "text": "2.4 合并两个数据集\n纵向合并\n即增加个案，要求两个数据集具有相同的列名及列数\n\nrbind_data &lt;- rbind(mydata, mydata2)\n\n横向合并\n直接通过cbind()函数合并数据集，要求两个数据集具有相同的行数及顺序\n\ntotal &lt;- cbind(dataframeA, dataframeB)\n\n以某一列（如学号等）匹配两个数据集\n详细解读：https://blog.csdn.net/chongbaikaishi/article/details/115740560\n\n# 以\"probe_id\"为匹配标准匹配探针id和gene symbol\nexptab1 &lt;- merge(x = ids,\n                 y = expset1,#x、y为要合并的数据框或者对象\n                 by =\"probe_id\", #指定以哪一列为标准匹配两个数据集。\n                                 #如果有多个匹配项，则所有可能的匹配项各贡献一行。\n                 all.x=F,#是否将没有匹配到y数据集的行也保留下来，并以NA替代。\n                         #默认为FALSE，只有x与y数据框相匹配的行会被包含在输出结果中\n                 all.y=F)#与上面类似\n\n如果两个数据集要用来匹配的列的列名不同则可用by.x和by.y指定。如下面的代码就是用id2symbol数据集中的ENSEMBL列去匹配rawcount数据集中的GeneID列\n\nrawcount &lt;- merge(id2symbol,\n                  rawcount,\n                  by.x=\"ENSEMBL\",\n                  by.y=\"GeneID\",\n                  all.y=T)#对于没有匹配到的GeneID以NA替代",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#去重保留唯一值",
    "href": "r_basic/basic_data_function.html#去重保留唯一值",
    "title": "数据处理基本函数",
    "section": "\n2.5 去重（保留唯一值）",
    "text": "2.5 去重（保留唯一值）\n生成带有重复值的示例数据\n\nset.seed(123)\nmydata = data.frame(ID = c(1:10,9,4,4,9,9,2), y = rnorm(16))\nmydata &lt;- rbind(mydata, mydata)\nmydata\n\n   ID           y\n1   1 -0.56047565\n2   2 -0.23017749\n3   3  1.55870831\n4   4  0.07050839\n5   5  0.12928774\n6   6  1.71506499\n7   7  0.46091621\n8   8 -1.26506123\n9   9 -0.68685285\n10 10 -0.44566197\n11  9  1.22408180\n12  4  0.35981383\n13  4  0.40077145\n14  9  0.11068272\n15  9 -0.55584113\n16  2  1.78691314\n17  1 -0.56047565\n18  2 -0.23017749\n19  3  1.55870831\n20  4  0.07050839\n21  5  0.12928774\n22  6  1.71506499\n23  7  0.46091621\n24  8 -1.26506123\n25  9 -0.68685285\n26 10 -0.44566197\n27  9  1.22408180\n28  4  0.35981383\n29  4  0.40077145\n30  9  0.11068272\n31  9 -0.55584113\n32  2  1.78691314\n\n\n通过duplicated()函数检查某一列是否有重复值，及有多少重复值\n\ntable(duplicated(mydata$ID))\n\n\nFALSE  TRUE \n   10    22 \n\n\n通过unique()函数去除完全相同的行。unique()函数：一行的所有数据都相同认定为重复\n\nmydata &lt;- unique(mydata)\nmydata\n\n   ID           y\n1   1 -0.56047565\n2   2 -0.23017749\n3   3  1.55870831\n4   4  0.07050839\n5   5  0.12928774\n6   6  1.71506499\n7   7  0.46091621\n8   8 -1.26506123\n9   9 -0.68685285\n10 10 -0.44566197\n11  9  1.22408180\n12  4  0.35981383\n13  4  0.40077145\n14  9  0.11068272\n15  9 -0.55584113\n16  2  1.78691314\n\n\n通过distinct()函数，去除ID列重复的数据\n\nlibrary(dplyr)\nmydata &lt;- distinct(mydata, # 需要去重的数据集名称\n                   ID, # 按照哪一列去重（可为多个条件）\n                   .keep_all = T) # 去重后保留所有列\nmydata\n\n   ID           y\n1   1 -0.56047565\n2   2 -0.23017749\n3   3  1.55870831\n4   4  0.07050839\n5   5  0.12928774\n6   6  1.71506499\n7   7  0.46091621\n8   8 -1.26506123\n9   9 -0.68685285\n10 10 -0.44566197",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#变量的赋值替换",
    "href": "r_basic/basic_data_function.html#变量的赋值替换",
    "title": "数据处理基本函数",
    "section": "\n2.6 变量的赋值/替换",
    "text": "2.6 变量的赋值/替换\n\nsavdata$low &lt;- ifelse(savdata$low ==\"低出生体重\", 1, 0)#将结局变量low赋值为0和1\nmydata[is.na(mydata)] &lt;- \"Unknown\"#替换缺失值\n\n当需要对一个数据集的多个变量进行转换时，可通过within(data, {expression})函数将括号内的操作限定到当前数据集中，避免”$“的反复使用，简化代码。函数within()与函数with()类似，不同的是within()允许你修改数据框:\n\nmydata &lt;- within(mydata, {\n  ID &lt;- ifelse(ID &lt; 5, \"A\", \"B\")\n  y &lt;- ifelse(y &lt; 0, \"A\", \"B\")\n})\nmydata\n\n   ID y\n1   A A\n2   A A\n3   A B\n4   A B\n5   B B\n6   B B\n7   B B\n8   B A\n9   B A\n10  B A",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#转换变量类型",
    "href": "r_basic/basic_data_function.html#转换变量类型",
    "title": "数据处理基本函数",
    "section": "\n2.7 转换变量类型",
    "text": "2.7 转换变量类型\n将结局变量转换成因子变量,ordered=F,用于定义无序多分类变量，起到设置哑变量的作用；ordered=T用于定义有序多分类变量。如果变量的取值以英文字符表示，那么默认以变量首字母的顺序编号赋值；如果变量的取值已经转换成数字，那么默认按照编号的大小依次赋值。可以通过指定”levels”选项来覆盖默认排序。\n\nsavdata$stage &lt;- factor(savdata$stage, \n                        levels = c(1,2,3,4),\n                        labels = c(\"I\",\"II\",\"III\",\"IV\"),\n                        ordered = T)\nsavdata$stage &lt;- relevel(savdata$stage,ref=\"IV\") # 设置因子的参照水平，仅限无序因子变量\n\n通过lapply函数批量转换因子变量\n\nmydata[2:14] &lt;- lapply(mydata[2:14], factor) # 转换几个连续列的因子变量\n\n批量转换多个指定因子变量\n\ncatvars&lt;-c(\"year\", \"race\", \"single\", \"grade\", \"T_stage\", \"N_stage\", \"M_stage\",\n           \"surgery\", \"lymphadenectomy\", \"radiotherapy\", \"chemotherapy\")\nmydata[catvars] &lt;- lapply(mydata[catvars], factor)\n\n转换为数值型变量\n\nmydata$grade &lt;- as.numeric(mydata$grade)\nmydata = lapply(mydata, as.numeric) # 将所有的变量转换成数值型",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/basic_data_function.html#哑变量设置",
    "href": "r_basic/basic_data_function.html#哑变量设置",
    "title": "数据处理基本函数",
    "section": "\n2.8 哑变量设置",
    "text": "2.8 哑变量设置\n\n# 因种族为无序多分类变量，需要设置三个哑变量（race1～3）\nsavdata$race1 &lt;- ifelse(savdata$race == \"白种人\", 1, 0)\nsavdata$race2 &lt;- ifelse(savdata$race == \"黑种人\", 1, 0)\nsavdata$race3 &lt;- ifelse(savdata$race == \"其他种族\", 1, 0)",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据处理基本函数"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html",
    "href": "r_basic/data_input_output.html",
    "title": "数据的读取与输出",
    "section": "",
    "text": "read.csv或read.table均可\n\ncsvdata &lt;- read.csv(\n  file = \"ovary_data.csv\", \n  header = T, \n  sep = \",\", \n  stringsAsFactors = F\n) \n\n\nheader：第一行是否是列名\nsep：字段分隔符。文件每行上的值由此字符分隔。read.table的默认值为sep = “”，表示分隔符为‘空白’，即一个或多个空格、制表符、换行符或回车。read.csv的默认值为sep = \",\"，表示分隔符为英文逗号\nstringsAsFactors：是否将字符向量转换为因子\n\n\ncsvdata &lt;- read.table(\n  \"ovary_data.csv\",\n  header = T, \n  sep = \",\",\n  row.names = \"patientID\",\n  colClasses = c(\"character\", \"character\", \"character\", \"numeric\", \"numeric\", \"numeric\")\n) \n\n\n\ncolClasses: （可选）指定每一列的变量类型\n\nas.is：该参数用于确定read.table()函数读取字符型数据时是否转换为因子型变量。当其取值为FALSE时，该函数将把字符型数据转换为因子型数据，取值为TRUE时，仍将其保留为字符型数据。\n\n\nrefGene &lt;- read.table(\n  \"refGene.txt\",\n  header = F,\n  sep = \"\\t\"\n  )\n\n\nMacOS 首选 gdata 包（因自带perl语言）；Windows首选 xlsx 包\n\nlibrary(gdata)\nxlsdata &lt;- read.xls(\n  \"ovary_data.xlsx\", \n  sheet = 1 # 要读取的工作表的名称或编号\n  )\n\n\n.sav文件是SPSS的输出文件，可以通过foreign包的read.spss()函数来读取。\n\nlibrary(foreign)\nsavdata &lt;- read.spss(\n  \"lweight.sav\",\n  to.data.frame = T # 将.sav格式数据转换成数据框\n  ) \n\n\n\ndata(Arthritis, package=\"vcd\")\n\n#或\nmydata &lt;- vcd::Arthritis\n\n\n\n\nunzip(\n  zipfile = \"test.zip\",\n  files = \"ferroptosis_suppressor.csv\",\n  overwrite = T \n  )\n\n\nzipfile：压缩包的位置及文件名\nfiles：（可选）需要提取的文件的文件名，默认解压压缩包内的所有文件\noverwrite：解压后是否覆盖同名文件\n\n\nuntar(\n  \"test.tar\", # 压缩包的位置及文件名\n   files = \"ferroptosis_suppressor.csv\" # 提取指定文件，默认解压压缩包内的所有文件\n  ) \n\n\n这两个压缩文件与前面的相比比较特别，因为.gz或.bz2文件，可以称之为压缩文件，也可以直接作为一个数据文件进行读取。\n\n#下载gz文件\ndownload.file(\n  \"http://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/refGene.txt.gz\",\n  destfile = \"refGene.txt.gz\") # 目标下载位置，注意需要添加后缀名\n\n#直接以数据的形式读取.gz文件\nmydata &lt;- read.table(\"refGene.txt.gz\")\n\n\n\n\n\n\n\n列出指定目录中的文件\n\n\n\nlist.files()在批量读取文件时十分有用，因为它能够获取指定目录下的文件名\n\nlist.files(\n  path = \"folder_name\",\n  pattern = \".docx$\",\n  full.names = T\n  )\n\n\npath：需要列出的文件所在的路径，若忽略此项则列出当前工作路径下的所有文件\npattern：列出目录中包含指定字符的文件。如pattern = \"\\\\.docx$\"表示列出所有以“.docx”为后缀的文件；pattern = \"^G\"列出所有文件名以“G”开头的文件\nfull.names：FALSE：仅输出文件名；TRUE(默认)：输出路径+文件名\n\n\n\n\n\nframdata &lt;- data.frame(\n  y = c(6, 8, 12, 14, 14, 15, 17, 22, 24, 23),\n  x1 = c(2, 5, 4, 3, 4, 6, 7, 5, 8, 9),\n  x2 = c(14, 12, 12, 13, 7, 8, 7, 4, 6, 5)\n)\nframdata\n\n    y x1 x2\n1   6  2 14\n2   8  5 12\n3  12  4 12\n4  14  3 13\n5  14  4  7\n6  15  6  8\n7  17  7  7\n8  22  5  4\n9  24  8  6\n10 23  9  5\n\n\n\n# 使用文本编辑器直接在窗口中编辑数据。macOS需要安装XQuartz（www.xquartz.org）才能运行此代码。\nframdata &lt;- edit(framdata)",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#读取.csv数据文件",
    "href": "r_basic/data_input_output.html#读取.csv数据文件",
    "title": "数据的读取与输出",
    "section": "",
    "text": "read.csv或read.table均可\n\ncsvdata &lt;- read.csv(\n  file = \"ovary_data.csv\", \n  header = T, \n  sep = \",\", \n  stringsAsFactors = F\n) \n\n\nheader：第一行是否是列名\nsep：字段分隔符。文件每行上的值由此字符分隔。read.table的默认值为sep = “”，表示分隔符为‘空白’，即一个或多个空格、制表符、换行符或回车。read.csv的默认值为sep = \",\"，表示分隔符为英文逗号\nstringsAsFactors：是否将字符向量转换为因子\n\n\ncsvdata &lt;- read.table(\n  \"ovary_data.csv\",\n  header = T, \n  sep = \",\",\n  row.names = \"patientID\",\n  colClasses = c(\"character\", \"character\", \"character\", \"numeric\", \"numeric\", \"numeric\")\n) \n\n\n\ncolClasses: （可选）指定每一列的变量类型\n\nas.is：该参数用于确定read.table()函数读取字符型数据时是否转换为因子型变量。当其取值为FALSE时，该函数将把字符型数据转换为因子型数据，取值为TRUE时，仍将其保留为字符型数据。",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#读取.txt文件",
    "href": "r_basic/data_input_output.html#读取.txt文件",
    "title": "数据的读取与输出",
    "section": "",
    "text": "refGene &lt;- read.table(\n  \"refGene.txt\",\n  header = F,\n  sep = \"\\t\"\n  )",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#读取.xlsx.xls文件",
    "href": "r_basic/data_input_output.html#读取.xlsx.xls文件",
    "title": "数据的读取与输出",
    "section": "",
    "text": "MacOS 首选 gdata 包（因自带perl语言）；Windows首选 xlsx 包\n\nlibrary(gdata)\nxlsdata &lt;- read.xls(\n  \"ovary_data.xlsx\", \n  sheet = 1 # 要读取的工作表的名称或编号\n  )",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#读取.sav文件",
    "href": "r_basic/data_input_output.html#读取.sav文件",
    "title": "数据的读取与输出",
    "section": "",
    "text": ".sav文件是SPSS的输出文件，可以通过foreign包的read.spss()函数来读取。\n\nlibrary(foreign)\nsavdata &lt;- read.spss(\n  \"lweight.sav\",\n  to.data.frame = T # 将.sav格式数据转换成数据框\n  )",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#读取程序包中的案例数据集",
    "href": "r_basic/data_input_output.html#读取程序包中的案例数据集",
    "title": "数据的读取与输出",
    "section": "",
    "text": "data(Arthritis, package=\"vcd\")\n\n#或\nmydata &lt;- vcd::Arthritis",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#下载和读取压缩包",
    "href": "r_basic/data_input_output.html#下载和读取压缩包",
    "title": "数据的读取与输出",
    "section": "",
    "text": "unzip(\n  zipfile = \"test.zip\",\n  files = \"ferroptosis_suppressor.csv\",\n  overwrite = T \n  )\n\n\nzipfile：压缩包的位置及文件名\nfiles：（可选）需要提取的文件的文件名，默认解压压缩包内的所有文件\noverwrite：解压后是否覆盖同名文件\n\n\nuntar(\n  \"test.tar\", # 压缩包的位置及文件名\n   files = \"ferroptosis_suppressor.csv\" # 提取指定文件，默认解压压缩包内的所有文件\n  ) \n\n\n这两个压缩文件与前面的相比比较特别，因为.gz或.bz2文件，可以称之为压缩文件，也可以直接作为一个数据文件进行读取。\n\n#下载gz文件\ndownload.file(\n  \"http://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/refGene.txt.gz\",\n  destfile = \"refGene.txt.gz\") # 目标下载位置，注意需要添加后缀名\n\n#直接以数据的形式读取.gz文件\nmydata &lt;- read.table(\"refGene.txt.gz\")\n\n\n\n\n\n\n\n列出指定目录中的文件\n\n\n\nlist.files()在批量读取文件时十分有用，因为它能够获取指定目录下的文件名\n\nlist.files(\n  path = \"folder_name\",\n  pattern = \".docx$\",\n  full.names = T\n  )\n\n\npath：需要列出的文件所在的路径，若忽略此项则列出当前工作路径下的所有文件\npattern：列出目录中包含指定字符的文件。如pattern = \"\\\\.docx$\"表示列出所有以“.docx”为后缀的文件；pattern = \"^G\"列出所有文件名以“G”开头的文件\nfull.names：FALSE：仅输出文件名；TRUE(默认)：输出路径+文件名",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#sec-手动生成数据框",
    "href": "r_basic/data_input_output.html#sec-手动生成数据框",
    "title": "数据的读取与输出",
    "section": "",
    "text": "framdata &lt;- data.frame(\n  y = c(6, 8, 12, 14, 14, 15, 17, 22, 24, 23),\n  x1 = c(2, 5, 4, 3, 4, 6, 7, 5, 8, 9),\n  x2 = c(14, 12, 12, 13, 7, 8, 7, 4, 6, 5)\n)\nframdata\n\n    y x1 x2\n1   6  2 14\n2   8  5 12\n3  12  4 12\n4  14  3 13\n5  14  4  7\n6  15  6  8\n7  17  7  7\n8  22  5  4\n9  24  8  6\n10 23  9  5\n\n\n\n# 使用文本编辑器直接在窗口中编辑数据。macOS需要安装XQuartz（www.xquartz.org）才能运行此代码。\nframdata &lt;- edit(framdata)",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#读取.csv文件",
    "href": "r_basic/data_input_output.html#读取.csv文件",
    "title": "数据的读取与输出",
    "section": "\n2.1 读取.csv文件",
    "text": "2.1 读取.csv文件\n\n这里我们使用students.csv案例数据，该数据可以从此处下载。对于.csv文件，我们可以通过read_csv()读取：\n\nstudents &lt;- read_csv(\"data/r_basic/students.csv\")\n\n\n# 也可以直接从URL读取\nstudents &lt;- read_csv(\"https://pos.it/r4ds-students-csv\")\n\n当运行 read_csv() 时，它会打印出一条消息，报告数据的行数和列数、使用的分隔符和列类型。int 代表整数型数据，dbl 代表数值型数据，chr 代表字符型数据，dttm 代表日期时间型数据。这些变量非常重要，因为对列进行的操作在很大程度上取决于该列的 “类型”。它还告诉我们可以通过spec()来提取所有列的类型信息。\n\nstudents\n\n# A tibble: 6 × 6\n   ...1 `Student ID` `Full Name`      favourite.food     mealPlan          AGE  \n  &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;             &lt;chr&gt;\n1     1            1 Sunil Huffmann   Strawberry yoghurt Lunch only        4    \n2     2            2 Barclay Lynn     French fries       Lunch only        5    \n3     3            3 Jayendra Lyne    N/A                Breakfast and lu… 7    \n4     4            4 Leon Rossini     Anchovies          Lunch only        &lt;NA&gt; \n5     5            5 Chidiegwu Dunkel Pizza              Breakfast and lu… five \n6     6            6 Güvenç Attila    Ice cream          Lunch only        6    \n\n\n同时，我们注意到通过read_csv读取后的数据是一个 tibble，这是一种升级版的data.frame，被 tidyverse 用来避免一些data.frame的常见问题。Tibbles 和data.frame之间的一个重要的区别在于 tibbles 打印数据的方式：tibbles 是为大型数据集设计的，因此只显示前几行和适应屏幕宽度的列。可以使用 print(flights, width = Inf) 显示所有列，或者使用 glimpse()（见基于dplyr包的数据处理）。因为这里的数据本身只有6行6列，所以所有数据都被显示了出来。\n另一个问题是，“Student ID”和“Full Name”列名被单引号扩起来。这是因为这两列的列名中包含了空格，这不符合R语言列名规范，也体现了tibble不会改变原有列名的特点。如果是用read.csv()读取的话，这两列中间的空格会被”.”替换。下面我们将这两个列名中的空格用下划线“_”替换以符合规范：\n\nrename(\n    students,\n    student_id = `Student ID`,\n    full_name = `Full Name`\n  )\n\n# A tibble: 6 × 6\n   ...1 student_id full_name        favourite.food     mealPlan            AGE  \n  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n1     1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n2     2          2 Barclay Lynn     French fries       Lunch only          5    \n3     3          3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n4     4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n5     5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n6     6          6 Güvenç Attila    Ice cream          Lunch only          6    \n\n\nrename()要求新变量名在 = 的左侧，旧变量名在右侧。和其他dplyr中的函数一样，rename不会对原始数据进行修改，因此需要将rename后的数据重新赋值给新的对象或覆盖原来的对象以应用对变量名的修改（更多关于rename()的说明详见后续章节）。这里为了后续演示，没有重新赋值。\n另一种方法是使用 janitor 包中的 clean_names() 函数，一次性将不符合规范的列名规范化重命名：\n\njanitor::clean_names(students)\n\n定义缺失值\n通过检查该数据，发现”favourite.food“一列中有一个“N/A”字符，这在原始数据的录入时表示缺失值。但是read_csv()默认将空字符串（“”）识别为缺失值NA。我们可以在读取数据时添加额外的参数让read_csv()能够将“N/A”识别为缺失值：\n\nstudents &lt;- read_csv(\n  \"data/r_basic/students.csv\", \n  na = c(\"N/A\", \"\")\n  )\nstudents\n\n# A tibble: 6 × 5\n  `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n         &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n2            2 Barclay Lynn     French fries       Lunch only          5    \n3            3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n4            4 Leon Rossini     Anchovies          Lunch only          NA   \n5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n6            6 Güvenç Attila    Ice cream          Lunch only          6    \n\n\n定义列类别\n读入数据后的另一个常见操作是更改变量/列类型。例如，这个数据中“favourite_food”，“meal_plan”应该是因子型变量；“age”应该是数值型变量，因此我们需要对其进行转换。\n这里我们使用管道符|&gt;来简化代码，对其的详细说明参考后续章节。mutate()的作用是根据现有列计算并添加新列（见基于dplyr包的数据处理-mutate()）。对于因子变量的转换，使用base包的factor()，转换后的变量仍命名为“meal_plan”，所以它会覆盖原有的“meal_plan”变量。对于数值型变量的转换，这里用readr中的parse_number()函数：\n\nstudents |&gt; \n  janitor::clean_names() |&gt; \n  mutate(\n  favourite_food = factor(favourite_food),\n  meal_plan = factor(meal_plan),\n  age = parse_number(age)\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age = parse_number(age)`.\nCaused by warning:\n! 1 parsing failure.\nrow col expected actual\n  5  -- a number   five\n\n\n# A tibble: 6 × 5\n  student_id full_name        favourite_food     meal_plan             age\n       &lt;dbl&gt; &lt;chr&gt;            &lt;fct&gt;              &lt;fct&gt;               &lt;dbl&gt;\n1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n2          2 Barclay Lynn     French fries       Lunch only              5\n3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n4          4 Leon Rossini     Anchovies          Lunch only             NA\n5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch    NA\n6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n⚠️注意，此时的输出结果中出现了警告信息。提示部分“age”数据出现了解析失败，具体在第五行，是一个“five”值，它不能被解析成数值，所以我们对其进行以下处理：\n\nstudents &lt;- students |&gt; \n  janitor::clean_names() |&gt; \n  mutate(\n  favourite_food = factor(favourite_food),\n  meal_plan = factor(meal_plan),\n  age = parse_number(if_else(age == \"five\", \"5\", age))\n  )\nstudents\n\n# A tibble: 6 × 5\n  student_id full_name        favourite_food     meal_plan             age\n       &lt;dbl&gt; &lt;chr&gt;            &lt;fct&gt;              &lt;fct&gt;               &lt;dbl&gt;\n1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n2          2 Barclay Lynn     French fries       Lunch only              5\n3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n4          4 Leon Rossini     Anchovies          Lunch only             NA\n5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\nreadr提供了一系列函数用于转换变量类型：\n\n\nparse_factor()：类似于base包的factor()，但是如果通过levels参数指定了因子水平，并且该变量的某些值在这些水平中找不到，则会给出警告并将这些值转换成缺失值NA。而factor()则不会给出警告信息。\n\nx &lt;- c(\"cat\", \"dog\", \"caw\")\nanimals &lt;- c(\"cat\", \"dog\", \"cow\")\n\nfactor(x, levels = animals)\n\n[1] cat  dog  &lt;NA&gt;\nLevels: cat dog cow\n\nparse_factor(x, levels = animals)\n\n[1] cat  dog  &lt;NA&gt;\nattr(,\"problems\")\n# A tibble: 1 × 4\n    row   col expected           actual\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;              &lt;chr&gt; \n1     3    NA value in level set caw   \nLevels: cat dog cow\n\n\n\n\n\n\nparse_number()：转换数值型变量。这个函数会解析它找到的第一个数字，然后删除第一个数字之前的所有非数字字符和第一个数字之后的所有字符，同时也会忽略千分位分隔符“,”。\n\nparse_number(\"$1,000\") # leading `$` and grouping character `,` ignored\n\n[1] 1000\n\nparse_number(\"euro1,000\") # leading non-numeric euro ignored\n\n[1] 1000\n\nparse_number(\"t1000t1000\") # only parses first number found\n\n[1] 1000\n\nparse_number(\"1,234.56\")\n\n[1] 1234.56\n\n# explicit locale specifying European grouping and decimal marks\nparse_number(\"1.234,56\", locale = locale(decimal_mark = \",\", grouping_mark = \".\"))\n\n[1] 1234.56\n\n# SI/ISO 31-0 standard spaces for number grouping\nparse_number(\"1 234.56\", locale = locale(decimal_mark = \".\", grouping_mark = \" \"))\n\n[1] 1234.56\n\n\n\nparse_integer()：转换整数型变量。较少使用，因为整数型变量和数值型变量或称doubles型变量的本质是一样的。\n\nparse_datetime()：转换日期/时间变量。\n\nparse_datetime(\"01/02/2010\", \"%d/%m/%Y\")\n\n[1] \"2010-02-01 UTC\"\n\nparse_datetime(\"01/02/2010\", \"%m/%d/%Y\")\n\n[1] \"2010-01-02 UTC\"\n\nparse_datetime(\"2010/01/01 12:00 US/Central\", \"%Y/%m/%d %H:%M %Z\")\n\n[1] \"2010-01-01 18:00:00 UTC\"\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n这些变量类型转换函数都通过了缺失值定义参数，如：\n\n# Specifying strings for NAs\nparse_number(c(\"1\", \"2\", \"3\", \"NA\"))\n\n[1]  1  2  3 NA\n\nparse_number(c(\"1\", \"2\", \"3\", \"NA\", \"Nothing\"), na = c(\"NA\", \"Nothing\"))\n\n[1]  1  2  3 NA NA\n\n\n因此，既可以像上面的定义缺失值中一样在数据读取时就定义数据集中的缺失值，也可以在转换变量类型时分别定义每一列的缺失值。\n\n\n非标准数据的读取\n通常，read_csv()使用数据的第一行作为列名，这是一种非常常见的约定。但在有时候数据的顶部可能包含几行元数据。这时候可以通过添加skip参数让read_csv()跳过前n行，也可以通过comment参数让其跳过以特定字符（例如“#”）开头的所有行。\n\nread_csv(\n  \"The first line of metadata\n  The second line of metadata\n  x,y,z\n  1,2,3\",\n  skip = 2 \n)\n\n# A tibble: 1 × 3\n      x     y     z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n\nread_csv(\n  \"# A comment I want to skip\n  x,y,z\n  1,2,3\",\n  comment = \"#\" # 跳过以“#”开头的行\n)\n\n# A tibble: 1 × 3\n      x     y     z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n\n\n在其他情况下，数据可能没有列名。可以使用 col_names = FALSE 告知 read_csv() 不要将第一行视为列名，而是按从 “X1” 到 “Xn” 的顺序标记它们：\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = FALSE\n)\n\n# A tibble: 2 × 3\n     X1    X2    X3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n2     4     5     6\n\n\n或者，可以用 col_names 参数以包含列名的字符向量来自定义列名：\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = c(\"x\", \"y\", \"z\")\n)\n\n# A tibble: 2 × 3\n      x     y     z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n2     4     5     6",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#其他类型数据文件的读取",
    "href": "r_basic/data_input_output.html#其他类型数据文件的读取",
    "title": "数据的读取与输出",
    "section": "\n2.2 其他类型数据文件的读取",
    "text": "2.2 其他类型数据文件的读取\n一旦掌握了read_csv()的语法，其他数据格式的读取只需调用特定的函数即可，语法和read_csv()类似：\n\n\nread_csv2()：读取以分号“;”分隔的数据。\n\n\nread_tsv()和read_table()：读取以制表符分隔的数据。\n\nread_fwf()：读取固定宽度数据文件，其中列以空格分隔。\n\n\n\nread_delim()：读取以任意分隔符（例如“|”）分隔的数据。如果没有指定分隔符那么read_delim()会尝试自动猜测分隔符。",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#从多个文件读取数据",
    "href": "r_basic/data_input_output.html#从多个文件读取数据",
    "title": "数据的读取与输出",
    "section": "\n2.3 从多个文件读取数据",
    "text": "2.3 从多个文件读取数据\n有时，数据会拆分到多个文件中，而不是包含在单个文件中。例如，假设这里有多个月的销售数据，每个月的数据都在一个单独的文件中，分别是： 1月的销售数据“01-sales.csv”、2月的销售数据“02-sales.csv”和三月的销售数据“03-sales.csv”。通过使用 read_csv() ，可以一次读取这些数据，并合并成一个数据。\n\nlist.files(\n  \"data/r_basic\", \n  pattern = \"sales\\\\.csv$\", \n  full.names = TRUE\n  ) %&gt;% \n  read_csv(id = \"file\")\n\n# A tibble: 19 × 6\n   file                      month     year brand  item     n\n   &lt;chr&gt;                     &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 data/r_basic/01-sales.csv January   2019     1  1234     3\n 2 data/r_basic/01-sales.csv January   2019     1  8721     9\n 3 data/r_basic/01-sales.csv January   2019     1  1822     2\n 4 data/r_basic/01-sales.csv January   2019     2  3333     1\n 5 data/r_basic/01-sales.csv January   2019     2  2156     9\n 6 data/r_basic/01-sales.csv January   2019     2  3987     6\n 7 data/r_basic/01-sales.csv January   2019     2  3827     6\n 8 data/r_basic/02-sales.csv February  2019     1  1234     8\n 9 data/r_basic/02-sales.csv February  2019     1  8721     2\n10 data/r_basic/02-sales.csv February  2019     1  1822     3\n11 data/r_basic/02-sales.csv February  2019     2  3333     1\n12 data/r_basic/02-sales.csv February  2019     2  2156     3\n13 data/r_basic/02-sales.csv February  2019     2  3987     6\n14 data/r_basic/03-sales.csv March     2019     1  1234     3\n15 data/r_basic/03-sales.csv March     2019     1  3627     1\n16 data/r_basic/03-sales.csv March     2019     1  8820     3\n17 data/r_basic/03-sales.csv March     2019     2  7253     1\n18 data/r_basic/03-sales.csv March     2019     2  8766     3\n19 data/r_basic/03-sales.csv March     2019     2  8288     6\n\n\n这些数据可以从https://pos.it/r4ds-01-sales, https://pos.it/r4ds-02-sales, https://pos.it/r4ds-03-sales下载。下载后的数据被翻到了”data”文件夹下的“r_basic”子文件夹内。因此，我们可以通过list.files()并结合pattern参数列出我们需要的销售数据文件，pattern中应用了正则表达式，这在接下来的章节中会详细说明。read_csv中的id参数会在结果数据中添加一个新列，用于标识数据来自哪个文件。",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#手动生成tibble",
    "href": "r_basic/data_input_output.html#手动生成tibble",
    "title": "数据的读取与输出",
    "section": "\n2.4 手动生成tibble",
    "text": "2.4 手动生成tibble\n有时需要在R脚本中“手动”输入一些数据来生成一个tibble。有两个函数可以做到这一点，这两个函数的不同之处在于是按列还是按行布局tibble。其中 tibble() 按列工作，类似于base包中的data.fram()：\n\ntibble(\n  x = c(1, 2, 5), \n  y = c(\"h\", \"m\", \"g\"),\n  z = c(0.08, 0.83, 0.60)\n)\n\n# A tibble: 3 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 h      0.08\n2     2 m      0.83\n3     5 g      0.6 \n\n\n按列布局数据很难看到行之间是如何关联的，因此可以选择 tribble() ，这是“Transsposed Tibble”的缩写，它允许逐行布局数据。列标题以 ~ 开头，条目之间用逗号分隔。这使得以易于阅读的形式布局少量数据成为可能：\n\ntribble(\n  ~x, ~y, ~z,\n  1, \"h\", 0.08,\n  2, \"m\", 0.83,\n  5, \"g\", 0.60\n)\n\n# A tibble: 3 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 h      0.08\n2     2 m      0.83\n3     5 g      0.6",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#基于base包的数据导出",
    "href": "r_basic/data_input_output.html#基于base包的数据导出",
    "title": "数据的读取与输出",
    "section": "\n3.1 基于base包的数据导出",
    "text": "3.1 基于base包的数据导出\n导出.csv文件\n\nwrite.csv(\n  mydata,\n  row.names = F,#是否输出行名称\n  \"mydata.csv\"\n  )\n\n导出.xlsx/.xls文件\n\nlibrary(openxlsx2)\nwrite_xlsx(\n  coxtable1,\n  \"coxtable1.xlsx\"\n  )\n\n储存为.Rdata/.RDS文件\n在R中保存数据的更好的方法是通过save()将数据导出为.Rdata文件或通过saveRDS()保存为.RDS文件，它们以R的定制二进制格式存储数据。这意味着当重新加载这些对象时，加载的是与当时存储时的完全相同的R对象。它们能够最大程度的保持数据的原貌，如对变量类型的定义，同时可以将图像、列表等对象导出。\n\n# 保存为.Rdata文件\nsave(object1, object2, file = \"filepath/name.rdata\")\n# 保存目前环境中的所有对象\nsave(list = ls(), file = \"filepath/name.rdata\")\n\n# 保存为.RDS文件\nsaveRDS(object, file = \"filepath/name.rds\")\n\nsave()和saveRDS()的区别在于：\n\nsave()支持同时保存多个对象，而saveRDS()一次只能保存一个对象\n.Rdata文件的读取是通过load()函数，该函数不能对读取的对象重命名，它会保留当时在储存这些对象时原本的名称；而读取.RDS文件是通过readRDS()函数，支持重命名：\n\n\n# 载入.Rdata文件\nload(\"filepath/name.rdata\")\n\n# 载入.RDS文件\nnew_object &lt;- readRDS(\"filepath/name.rds\")",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/data_input_output.html#基于readr包的数据导出",
    "href": "r_basic/data_input_output.html#基于readr包的数据导出",
    "title": "数据的读取与输出",
    "section": "\n3.2 基于readr包的数据导出",
    "text": "3.2 基于readr包的数据导出\n导出.csv/.txt文件\nReadr提供了两个用于将数据写回磁盘的函数： write_csv() 和 write_tsv() 。这些函数最重要的参数是 x (要保存的数据集的名字)和 file (要保存的位置)。还可以使用 na 指定如何写入缺失值，以及通过 append 定义是否覆盖写入现有文件。\n现在我们将之前的“students”数据导出，然后重新读取：\n\nwrite_csv(students, file = \"output/r_basic/students.csv\")\nread_csv(\"output/r_basic/students.csv\")\n\n# A tibble: 6 × 5\n  student_id full_name        favourite_food     meal_plan             age\n       &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n2          2 Barclay Lynn     French fries       Lunch only              5\n3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n4          4 Leon Rossini     Anchovies          Lunch only             NA\n5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n用这种方式导出的文件无法保留我们定义的变量类型信息。因此，更好的方式是和上面一样保存为.Rdata文件或.RDS文件。和base包的saveRDS()和readRDS()对应的，readr包中也有两个函数，write_rds() 和 read_rds()：\n\nwrite_rds(students, \"output/r_basic/students.rds\")\nstudents &lt;- read_rds(\"output/r_basic/students.rds\")\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] janitor_2.2.0   lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.0    \n [9] tibble_3.2.1    ggplot2_3.4.4   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.3     hms_1.1.3        \n [5] digest_0.6.34     magrittr_2.0.3    evaluate_0.23     grid_4.3.2       \n [9] timechange_0.2.0  fastmap_1.1.1     jsonlite_1.8.8    fansi_1.0.6      \n[13] scales_1.3.0      codetools_0.2-19  cli_3.6.2         rlang_1.1.3      \n[17] crayon_1.5.2      bit64_4.0.5       munsell_0.5.0     withr_3.0.0      \n[21] yaml_2.3.8        tools_4.3.2       parallel_4.3.2    tzdb_0.4.0       \n[25] colorspace_2.1-0  vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4  \n[29] snakecase_0.11.1  htmlwidgets_1.6.4 bit_4.0.5         vroom_1.6.5      \n[33] pkgconfig_2.0.3   archive_1.1.7     pillar_1.9.0      gtable_0.3.4     \n[37] glue_1.7.0        xfun_0.41         tidyselect_1.2.0  rstudioapi_0.15.0\n[41] knitr_1.45        htmltools_0.5.7   rmarkdown_2.25    compiler_4.3.2",
    "crumbs": [
      "Home",
      "R语言基础",
      "数据的读取与输出"
    ]
  },
  {
    "objectID": "r_basic/r_basics.html",
    "href": "r_basic/r_basics.html",
    "title": "R语言基础",
    "section": "",
    "text": "本章主要介绍R语言的环境配置以及数据的导入、导出等R语言的基本操作。",
    "crumbs": [
      "Home",
      "R语言基础"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html",
    "href": "single_cell/sc_supplementary/read_sc_data.html",
    "title": "读取非标准格式的单细胞数据",
    "section": "",
    "text": "该案例来自文献 (Xu et al. 2022)。该研究为了系统地研究高级别浆膜上皮卵巢癌（HGSOC）的肿瘤内异质性，采用深层单细胞RNA测序技术(scRNA-seq)对7例初治HGSOC早期和晚期患者及5例年龄匹配的非恶性卵巢组织标本进行肿瘤分析。共获得59,324个HGSOC和非恶性卵巢组织的单细胞，其中，33264个细胞（56%）来⾃HGSOC肿瘤患者组织，26060个（44%）来⾃⾮恶性卵巢组织标本。原始数据：GSE184880。\n\n可以看到原始数据以10X格式提供:\n\n但是，没有按照标准的10X格式的三个文件命名，并且没有按照样本分别建立文件夹。所以需要对其进行整理：\n\n首先给每个样本建立文件夹\n然后将对应的10X标准格式的三个文件分别复制到各个样本文件夹内\n最后将文件重命名为10X格式要求的标准形式，即“barcodes.tsv.gz”、“features.tsv.gz”、“matrix.mtx.gz”\n\n\nlibrary(Seurat)\nlibrary(stringr)\n\n\n# 给每个样本建立文件夹\nfiles &lt;- list.files(\"data/sc_supplementary/GSE184880_RAW\")\nfiles\n\n [1] \"GSM5599220_Norm1\"                   \"GSM5599220_Norm1.barcodes.tsv.gz\"  \n [3] \"GSM5599220_Norm1.genes.tsv.gz\"      \"GSM5599220_Norm1.matrix.mtx.gz\"    \n [5] \"GSM5599221_Norm2\"                   \"GSM5599221_Norm2.barcodes.tsv.gz\"  \n [7] \"GSM5599221_Norm2.genes.tsv.gz\"      \"GSM5599221_Norm2.matrix.mtx.gz\"    \n [9] \"GSM5599222_Norm3\"                   \"GSM5599222_Norm3.barcodes.tsv.gz\"  \n[11] \"GSM5599222_Norm3.genes.tsv.gz\"      \"GSM5599222_Norm3.matrix.mtx.gz\"    \n[13] \"GSM5599223_Norm4\"                   \"GSM5599223_Norm4.barcodes.tsv.gz\"  \n[15] \"GSM5599223_Norm4.genes.tsv.gz\"      \"GSM5599223_Norm4.matrix.mtx.gz\"    \n[17] \"GSM5599224_Norm5\"                   \"GSM5599224_Norm5.barcodes.tsv.gz\"  \n[19] \"GSM5599224_Norm5.genes.tsv.gz\"      \"GSM5599224_Norm5.matrix.mtx.gz\"    \n[21] \"GSM5599225_Cancer1\"                 \"GSM5599225_Cancer1.barcodes.tsv.gz\"\n[23] \"GSM5599225_Cancer1.genes.tsv.gz\"    \"GSM5599225_Cancer1.matrix.mtx.gz\"  \n[25] \"GSM5599226_Cancer2\"                 \"GSM5599226_Cancer2.barcodes.tsv.gz\"\n[27] \"GSM5599226_Cancer2.genes.tsv.gz\"    \"GSM5599226_Cancer2.matrix.mtx.gz\"  \n[29] \"GSM5599227_Cancer3\"                 \"GSM5599227_Cancer3.barcodes.tsv.gz\"\n[31] \"GSM5599227_Cancer3.genes.tsv.gz\"    \"GSM5599227_Cancer3.matrix.mtx.gz\"  \n[33] \"GSM5599228_Cancer4\"                 \"GSM5599228_Cancer4.barcodes.tsv.gz\"\n[35] \"GSM5599228_Cancer4.genes.tsv.gz\"    \"GSM5599228_Cancer4.matrix.mtx.gz\"  \n[37] \"GSM5599229_Cancer5\"                 \"GSM5599229_Cancer5.barcodes.tsv.gz\"\n[39] \"GSM5599229_Cancer5.genes.tsv.gz\"    \"GSM5599229_Cancer5.matrix.mtx.gz\"  \n[41] \"GSM5599230_Cancer6\"                 \"GSM5599230_Cancer6.barcodes.tsv.gz\"\n[43] \"GSM5599230_Cancer6.genes.tsv.gz\"    \"GSM5599230_Cancer6.matrix.mtx.gz\"  \n[45] \"GSM5599231_Cancer7\"                 \"GSM5599231_Cancer7.barcodes.tsv.gz\"\n[47] \"GSM5599231_Cancer7.genes.tsv.gz\"    \"GSM5599231_Cancer7.matrix.mtx.gz\"  \n\ndirnames &lt;- gsub(pattern = \".barcodes.tsv.gz|.genes.tsv.gz|.matrix.mtx.gz\", \n                 replacement = \"\", \n                 x = files) %&gt;%  \n  unique() %&gt;% \n  paste0(\"data/sc_supplementary/GSE184880_RAW/\", .)\ndirnames\n\n [1] \"data/sc_supplementary/GSE184880_RAW/GSM5599220_Norm1\"  \n [2] \"data/sc_supplementary/GSE184880_RAW/GSM5599221_Norm2\"  \n [3] \"data/sc_supplementary/GSE184880_RAW/GSM5599222_Norm3\"  \n [4] \"data/sc_supplementary/GSE184880_RAW/GSM5599223_Norm4\"  \n [5] \"data/sc_supplementary/GSE184880_RAW/GSM5599224_Norm5\"  \n [6] \"data/sc_supplementary/GSE184880_RAW/GSM5599225_Cancer1\"\n [7] \"data/sc_supplementary/GSE184880_RAW/GSM5599226_Cancer2\"\n [8] \"data/sc_supplementary/GSE184880_RAW/GSM5599227_Cancer3\"\n [9] \"data/sc_supplementary/GSE184880_RAW/GSM5599228_Cancer4\"\n[10] \"data/sc_supplementary/GSE184880_RAW/GSM5599229_Cancer5\"\n[11] \"data/sc_supplementary/GSE184880_RAW/GSM5599230_Cancer6\"\n[12] \"data/sc_supplementary/GSE184880_RAW/GSM5599231_Cancer7\"\n\n\n\nlapply(dirnames, dir.create, showWarnings = FALSE)\n\n\nlapply(files, function(files) {\n  # 复制相应的10X文件到各个样本文件夹内\n  new_dir &lt;- gsub(pattern = \".barcodes.tsv.gz|.genes.tsv.gz|.matrix.mtx.gz\", \n                  replacement = \"\", \n                  x = files) %&gt;%  \n    paste0(\"data/sc_supplementary/GSE184880_RAW/\", .)\n  file.copy(from = paste0(\"data/sc_supplementary/GSE184880_RAW/\", files), \n            to = new_dir)\n  # 重命名3个10X文件\n  new_filename &lt;- ifelse(grepl(pattern = \"barcodes\", x = files), \"barcodes.tsv.gz\", \n                         ifelse(grepl(pattern = \"genes\", x = files), \"features.tsv.gz\", \n                         \"matrix.mtx.gz\"))\n  file.rename(from = paste(new_dir, files, sep  = \"/\"),\n              to = paste(new_dir, new_filename, sep = \"/\"))\n  })\n\n\n\n\n\n\n\n用setwd简化对文件路径的定义\n\n\n\n\n\n由于在渲染本文档时，knitr会将工作目录恢复为Rproject根目录，所以不能使用getwd指定工作目录。在实际应用中，可以设置工作目录到目标数据文件夹下以简化对文件路径的定义：\n\nroot_dir &lt;- getwd()\nsetwd(\"data/sc_supplementary/GSE184880_RAW\")\n\n\n# 给每个样本建立文件夹\nfiles &lt;- list.files()\nfiles\ndirnames &lt;- gsub(pattern = \".barcodes.tsv.gz|.genes.tsv.gz|.matrix.mtx.gz\", \n                 replacement = \"\", \n                 x = files) |&gt; unique()\ndirnames\nlapply(dirnames, dir.create)\n\n\nlapply(files, function(files) {\n  # 复制相应的10X文件到各个样本文件夹内\n  new_dir &lt;- gsub(pattern = \".barcodes.tsv.gz|.genes.tsv.gz|.matrix.mtx.gz\", \n                      replacement = \"\", \n                      x = files) \n  file.copy(from = files, \n            to = new_dir)\n  # 重命名3个10X文件\n  new_filename &lt;- ifelse(grepl(pattern = \"barcodes\", x = files), \"barcodes.tsv.gz\", \n                         ifelse(grepl(pattern = \"genes\", x = files), \"features.tsv.gz\", \n                         \"matrix.mtx.gz\"))\n  file.rename(from = paste(new_dir, files, sep  = \"/\"),\n              to = paste(new_dir, new_filename, sep = \"/\"))\n  })\n\n\nseurat_list &lt;- lapply(dirnames, function(dirnames) {\n  print(dirnames)\n  sce &lt;- CreateSeuratObject(counts =  Read10X(dirnames),\n                            project =  str_split(string = dirnames, \n                                                 pattern = \"_\", \n                                                 simplify = T)[,2],\n                            min.cells = 5,\n                            min.features = 500)\n  return(sce)\n})\nmerged_seurat &lt;- merge(x = seurat_list[[1]],\n                       y = seurat_list[-1],\n                       add.cell.ids = str_split(string = dirnames, \n                                                pattern = \"_\", \n                                                simplify = T)[,2])\n\nmerged_seurat\nmerged_seurat &lt;- JoinLayers(merged_seurat)\nmerged_seurat\nhead(merged_seurat)\ntail(merged_seurat)\nunique(merged_seurat$orig.ident)\n\n# 将样本信息添加到meta.data的新的一列“sample”中:\nmerged_seurat$sample &lt;- merged_seurat$orig.ident\n\n后续如有需要可以随时将工作目录恢复为Rproject根目录：\n\nsetwd(root_dir)\n\n\n\n\n接下来，就可以进行常规的Seurat对象构建：\n\nseurat_list &lt;- lapply(dirnames, function(dirnames) {\n  print(dirnames)\n  sce &lt;- CreateSeuratObject(counts =  Read10X(dirnames),\n                            project =  str_split(string = dirnames, \n                                                 pattern = \"_\", \n                                                 simplify = T)[,4],\n                            min.cells = 5,\n                            min.features = 500)\n  return(sce)\n})\n\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599220_Norm1\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599221_Norm2\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599222_Norm3\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599223_Norm4\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599224_Norm5\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599225_Cancer1\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599226_Cancer2\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599227_Cancer3\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599228_Cancer4\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599229_Cancer5\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599230_Cancer6\"\n[1] \"data/sc_supplementary/GSE184880_RAW/GSM5599231_Cancer7\"\n\nmerged_seurat &lt;- merge(x = seurat_list[[1]],\n                       y = seurat_list[-1],\n                       add.cell.ids = str_split(string = dirnames, \n                                                pattern = \"_\", \n                                                simplify = T)[,4])\n\nmerged_seurat\n\nAn object of class Seurat \n21454 features across 60886 samples within 1 assay \nActive assay: RNA (21454 features, 0 variable features)\n 12 layers present: counts.Norm1, counts.Norm2, counts.Norm3, counts.Norm4, counts.Norm5, counts.Cancer1, counts.Cancer2, counts.Cancer3, counts.Cancer4, counts.Cancer5, counts.Cancer6, counts.Cancer7\n\nmerged_seurat &lt;- JoinLayers(merged_seurat)\nmerged_seurat\n\nAn object of class Seurat \n21454 features across 60886 samples within 1 assay \nActive assay: RNA (21454 features, 0 variable features)\n 1 layer present: counts\n\nhead(merged_seurat)\n\n                         orig.ident nCount_RNA nFeature_RNA\nNorm1_AAACCCAAGGACAGCT-1      Norm1       8191         2218\nNorm1_AAACCCAAGGTATCTC-1      Norm1       8720         2396\nNorm1_AAACCCACAAGTGCAG-1      Norm1       8554         2518\nNorm1_AAACCCACACCCTCTA-1      Norm1       7650         2697\nNorm1_AAACCCACACTCCGGA-1      Norm1       9231         2370\nNorm1_AAACCCACAGAGGTTG-1      Norm1       5701         1619\nNorm1_AAACCCAGTACTTCCC-1      Norm1      10002         2421\nNorm1_AAACCCATCTACCACC-1      Norm1       2934         1135\nNorm1_AAACGAAAGTAGGCCA-1      Norm1       6955         2198\nNorm1_AAACGAAAGTCACACT-1      Norm1       7742         1891\n\ntail(merged_seurat)\n\n                           orig.ident nCount_RNA nFeature_RNA\nCancer7_TTTGGAGTCGTGAGAG-1    Cancer7       3568         1525\nCancer7_TTTGGTTAGGATCATA-1    Cancer7       3720         1402\nCancer7_TTTGGTTAGTTGGCTT-1    Cancer7       2591         1112\nCancer7_TTTGGTTGTCACCCTT-1    Cancer7      27107         5367\nCancer7_TTTGGTTGTTCCTACC-1    Cancer7      55055         7556\nCancer7_TTTGGTTGTTTCGCTC-1    Cancer7      66262         7369\nCancer7_TTTGGTTTCCACAAGT-1    Cancer7       2342         1143\nCancer7_TTTGTTGCATCCTAAG-1    Cancer7       3498         1440\nCancer7_TTTGTTGGTGACCTGC-1    Cancer7      74316         8182\nCancer7_TTTGTTGGTGATCATC-1    Cancer7       4245          508\n\nunique(merged_seurat$orig.ident)\n\n [1] \"Norm1\"   \"Norm2\"   \"Norm3\"   \"Norm4\"   \"Norm5\"   \"Cancer1\" \"Cancer2\"\n [8] \"Cancer3\" \"Cancer4\" \"Cancer5\" \"Cancer6\" \"Cancer7\"\n\n# 将样本信息添加到meta.data的新的一列“sample”中:\nmerged_seurat$sample &lt;- merged_seurat$orig.ident",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html#sec-read_raw_counts",
    "href": "single_cell/sc_supplementary/read_sc_data.html#sec-read_raw_counts",
    "title": "读取非标准格式的单细胞数据",
    "section": "\n2.1 读取raw_counts矩阵",
    "text": "2.1 读取raw_counts矩阵\n\nrm(list = ls())\nlibrary(Seurat)\nlibrary(stringr)\nlibrary(tibble)\n\n\n# 获取所有rds文件的列表\nfile_list &lt;- list.files(\"data/sc_supplementary/GSE234933/GSE234933_MGH_HNSCC_gex_raw_counts\", pattern = \".rds\")\nfile_list\n\n [1] \"HN1_gex_raw_counts.rds\"       \"HN13_gex_raw_counts.rds\"     \n [3] \"HN14_gex_raw_counts.rds\"      \"HN17_gex_raw_counts.rds\"     \n [5] \"HN2_gex_raw_counts.rds\"       \"HN20_gex_raw_counts.rds\"     \n [7] \"HN21_gex_raw_counts.rds\"      \"HN22_gex_raw_counts.rds\"     \n [9] \"HN23_gex_raw_counts.rds\"      \"HN25_gex_raw_counts.rds\"     \n[11] \"HN26_gex_raw_counts.rds\"      \"HN27_gex_raw_counts.rds\"     \n[13] \"HN28_gex_raw_counts.rds\"      \"HN29_gex_raw_counts.rds\"     \n[15] \"HN30_gex_raw_counts.rds\"      \"HN31TS_gex_raw_counts.rds\"   \n[17] \"HN32T_gex_raw_counts.rds\"     \"HN33_gex_raw_counts.rds\"     \n[19] \"HN34_gex_raw_counts.rds\"      \"HN35_gex_raw_counts.rds\"     \n[21] \"HN37_gex_raw_counts.rds\"      \"HN38_gex_raw_counts.rds\"     \n[23] \"HN39_gex_raw_counts.rds\"      \"HN40-3-05_gex_raw_counts.rds\"\n[25] \"HN42_gex_raw_counts.rds\"      \"HN43_gex_raw_counts.rds\"     \n[27] \"HN45_gex_raw_counts.rds\"      \"HN46_gex_raw_counts.rds\"     \n[29] \"HN49_gex_raw_counts.rds\"      \"HN50_gex_raw_counts.rds\"     \n[31] \"HN52_gex_raw_counts.rds\"      \"HN55_gex_raw_counts.rds\"     \n[33] \"HN57-1_gex_raw_counts.rds\"    \"HN58_gex_raw_counts.rds\"     \n[35] \"HN59_gex_raw_counts.rds\"      \"HN60_gex_raw_counts.rds\"     \n[37] \"HN61_gex_raw_counts.rds\"      \"HN63_gex_raw_counts.rds\"     \n[39] \"HN64_gex_raw_counts.rds\"      \"HN66_gex_raw_counts.rds\"     \n[41] \"HN67_gex_raw_counts.rds\"      \"HN68_gex_raw_counts.rds\"     \n[43] \"HN7_gex_raw_counts.rds\"       \"HN70_gex_raw_counts.rds\"     \n[45] \"HN71_gex_raw_counts.rds\"      \"HN72_gex_raw_counts.rds\"     \n[47] \"HN73_gex_raw_counts.rds\"      \"HN74_gex_raw_counts.rds\"     \n[49] \"HN75_gex_raw_counts.rds\"      \"HN76_gex_raw_counts.rds\"     \n[51] \"HN77_gex_raw_counts.rds\"      \"HN8_gex_raw_counts.rds\"      \n\n# 循环读取每个rds文件的数据并创建Seurat对象\nseurat_list &lt;- lapply(file_list, function(file) {\n  # 拼接文件路径\n  data.path &lt;- paste0(\"data/sc_supplementary/GSE234933/GSE234933_MGH_HNSCC_gex_raw_counts/\", file)\n  # 创建Seurat对象\n  seurat_obj &lt;- CreateSeuratObject(counts = readRDS(data.path),\n                                   min.features = 200,\n                                   min.cells = 3)\n  return(seurat_obj)\n})\n\n# 合并Seurat对象\nseurat_combined &lt;- merge(seurat_list[[1]],\n                         y = seurat_list[-1],\n                         add.cell.ids = str_split(string = file_list, \n                                                  pattern = \"_\", \n                                                  simplify = T)[,1])\nseurat_combined\n\nAn object of class Seurat \n26734 features across 330385 samples within 1 assay \nActive assay: RNA (26734 features, 0 variable features)\n 52 layers present: counts.1, counts.2, counts.3, counts.4, counts.5, counts.6, counts.7, counts.8, counts.9, counts.10, counts.11, counts.12, counts.13, counts.14, counts.15, counts.16, counts.17, counts.18, counts.19, counts.20, counts.21, counts.22, counts.23, counts.24, counts.25, counts.26, counts.27, counts.28, counts.29, counts.30, counts.31, counts.32, counts.33, counts.34, counts.35, counts.36, counts.37, counts.38, counts.39, counts.40, counts.41, counts.42, counts.43, counts.44, counts.45, counts.46, counts.47, counts.48, counts.49, counts.50, counts.51, counts.52\n\nhead(seurat_combined) # 可以看到这个案例实际上不需要添加cell.ids\n\n                           orig.ident nCount_RNA nFeature_RNA\nHN1_HN1_AAACCTGAGTATTGGA-1        HN1        948          574\nHN1_HN1_AAACCTGAGTTGCAGG-1        HN1       6745          257\nHN1_HN1_AAACCTGCAATAGCAA-1        HN1        677          320\nHN1_HN1_AAACCTGCATTTCACT-1        HN1       4540         1129\nHN1_HN1_AAACCTGTCGGCGGTT-1        HN1        909          444\nHN1_HN1_AAACCTGTCTCGTTTA-1        HN1        633          352\nHN1_HN1_AAACGGGAGCAGCCTC-1        HN1       1262          633\nHN1_HN1_AAACGGGAGCCCAGCT-1        HN1        513          275\nHN1_HN1_AAACGGGAGTACGCGA-1        HN1       1152          416\nHN1_HN1_AAACGGGCACATTTCT-1        HN1        426          249\n\nunique(seurat_combined$orig.ident)\n\n [1] \"HN1\"       \"HN13\"      \"HN14\"      \"HN17\"      \"HN2\"       \"HN20\"     \n [7] \"HN21\"      \"HN22\"      \"HN23\"      \"HN25\"      \"HN26\"      \"HN27\"     \n[13] \"HN28\"      \"HN29\"      \"HN30\"      \"HN31TS\"    \"HN32T\"     \"HN33\"     \n[19] \"HN34\"      \"HN35\"      \"HN37\"      \"HN38\"      \"HN39\"      \"HN40-3-05\"\n[25] \"HN42\"      \"HN43\"      \"HN45\"      \"HN46\"      \"HN49\"      \"HN50\"     \n[31] \"HN52\"      \"HN55\"      \"HN57-1\"    \"HN58\"      \"HN59\"      \"HN60\"     \n[37] \"HN61\"      \"HN63\"      \"HN64\"      \"HN66\"      \"HN67\"      \"HN68\"     \n[43] \"HN7\"       \"HN70\"      \"HN71\"      \"HN72\"      \"HN73\"      \"HN74\"     \n[49] \"HN75\"      \"HN76\"      \"HN77\"      \"HN8\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html#添加样本信息",
    "href": "single_cell/sc_supplementary/read_sc_data.html#添加样本信息",
    "title": "读取非标准格式的单细胞数据",
    "section": "\n2.2 添加样本信息",
    "text": "2.2 添加样本信息\n\nsample_anno &lt;- read.table(\"data/sc_supplementary/GSE234933/GSE234933_MGH_HNSCC_sample_annotation.txt\", \n                          sep = \"\\t\", \n                          header = T)\nhead(sample_anno)\n\n  Sample    Sex Age HPV.Status Smoking.history Original.anatomic.site\n1    HN1   Male  37   Negative             Yes            Oral cavity\n2    HN2   Male  55   Negative             Yes            Oral cavity\n3    HN7   Male  90   Negative              No            Oral cavity\n4    HN8   Male  89   Negative             Yes     Larynx/Hypopharynx\n5   HN13 Female  64   Negative             Yes     Larynx/Hypopharynx\n6   HN14 Female  53   Negative             Yes             Oropharynx\n  Anatomic.location.of.scRNA.seq.specimen\n1                                 Primary\n2               Distant metastasis (Lung)\n3                                 Primary\n4            Distant metastasis (sternum)\n5               Distant metastasis (skin)\n6             Distant metastasis (pleura)\n\nsample_anno$Sample\n\n [1] \"HN1\"       \"HN2\"       \"HN7\"       \"HN8\"       \"HN13\"      \"HN14\"     \n [7] \"HN17\"      \"HN20\"      \"HN21\"      \"HN22\"      \"HN23\"      \"HN25\"     \n[13] \"HN26\"      \"HN27\"      \"HN28\"      \"HN29\"      \"HN30\"      \"HN31TS\"   \n[19] \"HN32T\"     \"HN33\"      \"HN34\"      \"HN35\"      \"HN37\"      \"HN38\"     \n[25] \"HN39\"      \"HN40-3-05\" \"HN42\"      \"HN43\"      \"HN45\"      \"HN46\"     \n[31] \"HN49\"      \"HN50\"      \"HN52\"      \"HN55\"      \"HN57-1\"    \"HN58\"     \n[37] \"HN59\"      \"HN60\"      \"HN61\"      \"HN63\"      \"HN64\"      \"HN66\"     \n[43] \"HN67\"      \"HN68\"      \"HN70\"      \"HN71\"      \"HN72\"      \"HN73\"     \n[49] \"HN74\"      \"HN75\"      \"HN76\"      \"HN77\"     \n\nold_meta.data &lt;- rownames_to_column(seurat_combined@meta.data, var = \"cell_id\")\nnew_meta.data &lt;- merge(x = old_meta.data,\n                       y = sample_anno,\n                       by.x = \"orig.ident\",\n                       by.y = \"Sample\",\n                       all.x = T) \nnew_meta.data$sample &lt;- new_meta.data$orig.ident\nhead(new_meta.data)\n\n  orig.ident                    cell_id nCount_RNA nFeature_RNA  Sex Age\n1        HN1 HN1_HN1_AAACCTGAGTATTGGA-1        948          574 Male  37\n2        HN1 HN1_HN1_AAACCTGAGTTGCAGG-1       6745          257 Male  37\n3        HN1 HN1_HN1_AAACCTGCAATAGCAA-1        677          320 Male  37\n4        HN1 HN1_HN1_AAACCTGCATTTCACT-1       4540         1129 Male  37\n5        HN1 HN1_HN1_AAACCTGTCGGCGGTT-1        909          444 Male  37\n6        HN1 HN1_HN1_AAACCTGTCTCGTTTA-1        633          352 Male  37\n  HPV.Status Smoking.history Original.anatomic.site\n1   Negative             Yes            Oral cavity\n2   Negative             Yes            Oral cavity\n3   Negative             Yes            Oral cavity\n4   Negative             Yes            Oral cavity\n5   Negative             Yes            Oral cavity\n6   Negative             Yes            Oral cavity\n  Anatomic.location.of.scRNA.seq.specimen sample\n1                                 Primary    HN1\n2                                 Primary    HN1\n3                                 Primary    HN1\n4                                 Primary    HN1\n5                                 Primary    HN1\n6                                 Primary    HN1\n\nrownames(new_meta.data) &lt;- new_meta.data$cell_id\nnew_meta.data$cell_id &lt;- NULL\nnew_meta.data[,c(4, 6:10)] &lt;- lapply(new_meta.data[,c(4, 5, 7:10)], as.factor)\nsummary(new_meta.data)\n\n  orig.ident          nCount_RNA      nFeature_RNA      Sex        \n Length:330385      Min.   :   215   Min.   : 184   Female: 65737  \n Class :character   1st Qu.:   897   1st Qu.: 471   Male  :264648  \n Mode  :character   Median :  1886   Median : 845                  \n                    Mean   :  3439   Mean   :1107                  \n                    3rd Qu.:  3537   3rd Qu.:1348                  \n                    Max.   :126539   Max.   :8839                  \n                                                                   \n      Age          HPV.Status     Smoking.history        Original.anatomic.site\n Min.   :31.00   64     : 29808   No :177238      Larynx/Hypopharynx: 68470    \n 1st Qu.:56.00   76     : 25982   Yes:153147      Nasopharynx       : 30573    \n Median :64.00   70     : 23193                   Oral cavity       :107833    \n Mean   :63.42   44     : 21985                   Oropharynx        :115022    \n 3rd Qu.:71.00   67     : 21053                   Unknown           :  8487    \n Max.   :91.00   55     : 19302                                                \n                 (Other):189062                                                \n                 Anatomic.location.of.scRNA.seq.specimen     sample      \n Primary                             :190573             HN63   : 25501  \n Locoregional recurrence             : 59176             HN76   : 15798  \n Distant metastasis (Lung)           : 34541             HN68   : 14851  \n Distant metastasis (Liver)          : 23083             HN77   : 13892  \n Unknown primary of the head and neck:  8487             HN42   : 12062  \n Distant metastasis (skin)           :  7073             HN74   : 11863  \n (Other)                             :  7452             (Other):236418  \n\nseurat_combined@meta.data &lt;- new_meta.data",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html#加载包",
    "href": "single_cell/sc_supplementary/read_sc_data.html#加载包",
    "title": "读取非标准格式的单细胞数据",
    "section": "\n4.1 加载包",
    "text": "4.1 加载包\n\nrm(list = ls())\nlibrary(data.table)\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(Seurat)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html#数据读取",
    "href": "single_cell/sc_supplementary/read_sc_data.html#数据读取",
    "title": "读取非标准格式的单细胞数据",
    "section": "\n4.2 数据读取",
    "text": "4.2 数据读取\n下载数据之后，首先按照通常做法通过data.table包的fread()函数尝试读取之后，发现无法正确读取列名，即cell barcode：\n\ncounts &lt;- fread(\"data/sc_supplementary/GSE150430_npc_scRNA_hg19_processed_data.txt\",\n                data.table = F)\n\n\n而用read.table()函数读取这个文件是可以正确读取列名的:\n\ncounts &lt;- read.table(\"data/sc_supplementary/GSE150430_npc_scRNA_hg19_processed_data.txt\")\n\n读取后的数据如下：\n\n可以发现该表达矩阵行名为基因，列为cell barcode，同时有代表样本的前缀。但是第一行为作者注释的细胞类型，因此，可能是由于这样的表头结构导致fread不能正确的读取这个数据。但是用基础的read.table读取这种大型数据非常耗时间，因此下面首先用read.table读取前两行的数据，即cell barcode和细胞类型；然后通过fread读取剩余的表达矩阵；最后将cell barcode和表达矩阵进行合并以构建Seurat对象。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html#数据整理",
    "href": "single_cell/sc_supplementary/read_sc_data.html#数据整理",
    "title": "读取非标准格式的单细胞数据",
    "section": "\n4.3 数据整理",
    "text": "4.3 数据整理\n\n# 单独读取表头\nhead &lt;- read.table(\"data/sc_supplementary/GSE150430_npc_scRNA_hg19_processed_data.txt\",\n                   nrows = 1,\n                   header = T)\n\n\n\n# 读取表达矩阵\ncounts &lt;- fread(\"data/sc_supplementary/GSE150430_npc_scRNA_hg19_processed_data.txt\",\n                data.table = F, \n                skip = 2) # 跳过前两行\n\n\n\n# 将第一列（基因名）作为行名\nrownames(counts) &lt;- counts[,1]\ncounts &lt;- counts[,-1]\n\n# 添加列名（cell barcode）\ncolnames(counts) &lt;- colnames(head)\n\n\n\n此时，我们就得到了一个满足Seurat对象构建的counts矩阵了。但是，当我们直接用CreateSeuratObject()去创建Seurat对象时，由于该数据包含了所有样本的单细胞测序数据，导致其体积过大超出了R的内存上限。因此，接下来，我们将这个数据根据样本拆分成不同的RDS文件，然后再用上面类似的方法依次读取这些RDS文件，避免一次性读取导致的内存溢出。\n\n\n# 提取样本标签\nsamples &lt;-  str_split(string = colnames(counts), \n                      pattern = \"_\", \n                      simplify = T)[,1] %&gt;% \n  unique()\nsamples\n\n\n# [1] \"N01\" \"P01\" \"P03\" \"P05\" \"P06\" \"P09\" \"P11\" \"P12\" \"P13\" \"P14\" \"P15\" \"P02\"\n# [13] \"P04\" \"P07\" \"P08\" \"P10\"\n\n\n# 逐一提取不同样本的测序数据，分别导出为RDS文件\nmap(samples, function(sample) {\n  print(sample)\n  sub_exp &lt;- grep(pattern = sample, \n                  x = colnames(counts)) %&gt;% \n    counts[,.]\n  saveRDS(sub_exp, \n          file = paste0(\"output/sc_supplementary/GSE150430/\", sample, \".rds\"))\n})",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/read_sc_data.html#构建seurat对象",
    "href": "single_cell/sc_supplementary/read_sc_data.html#构建seurat对象",
    "title": "读取非标准格式的单细胞数据",
    "section": "\n4.4 构建Seurat对象",
    "text": "4.4 构建Seurat对象\n\nfilenames &lt;- list.files(\"output/sc_supplementary/GSE150430\")\nfilenames\n\n\n#  [1] \"N01.rds\" \"P01.rds\" \"P02.rds\" \"P03.rds\" \"P04.rds\" \"P05.rds\" \"P06.rds\"\n#  [8] \"P07.rds\" \"P08.rds\" \"P09.rds\" \"P10.rds\" \"P11.rds\" \"P12.rds\" \"P13.rds\"\n# [15] \"P14.rds\" \"P15.rds\"\n\n\n# 循环读取每个rds文件的数据并创建Seurat对象\nseurat_list &lt;- lapply(filenames, function(file) {\n  # 拼接文件路径\n  data.path &lt;- paste0(\"output/sc_supplementary/GSE150430/\", file)\n  # 创建Seurat对象\n  seurat_obj &lt;- CreateSeuratObject(counts = readRDS(data.path))\n  return(seurat_obj)\n})\n\n# 合并Seurat对象\nmerged_seurat &lt;- merge(seurat_list[[1]],\n                       y = seurat_list[-1])\nmerged_seurat\n\n\n# An object of class Seurat \n# 24720 features across 48584 samples within 1 assay \n# Active assay: RNA (24720 features, 0 variable features)\n#  16 layers present: counts.1, counts.2, counts.3, counts.4, counts.5, counts.6, counts.7, counts.8, counts.9, counts.10, counts.11, counts.12, counts.13, counts.14, counts.15, counts.16\n\n\nhead(merged_seurat) \n\n\n\n# 添加样本列\nmerged_seurat$samples &lt;- merged_seurat$orig.ident\n\n# 保存\nsaveRDS(merged_seurat, file = \"output/sc_supplementary/GSE150430_merged_seurat.rds\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "读取非标准格式的单细胞数据"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "",
    "text": "参考：单细胞多数据集整合示例\n有时候，为了扩大数据量和得到更加可靠的结论，我们可能获取和下载了多个单细胞数据集。如果我们只关注某一细胞类型，如T cells或B cells或髓系细胞，那么就需要合并分析这些数据集，提取感兴趣的细胞亚群。这时候有两种方法可以选择：\n这个部分怎么分析并没有一个特定的答案或者规则，具体还是得看数据集适合以上提出的哪种分析顺序。\n例如(Gong et al. 2023)就用了第二种方法。选取了三个鼻咽癌单细胞转录组数据： GSE150825, GSE150430, GSE162025。首先对三组数据进行整合，然后选取其中的一部分T细胞进行进一步分析。\n这里我们介绍第一种方式，即对各数据集分别降维分群，然后提取并整合各个数据集的感兴趣细胞亚群。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#评估细胞周期的影响",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#评估细胞周期的影响",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n4.1 评估细胞周期的影响",
    "text": "4.1 评估细胞周期的影响\n\n# Load cell cycle markers\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\n# Score cells for cell cycle\nmerged_seurat &lt;- CellCycleScoring(merged_seurat, \n                                  g2m.features = g2m.genes, \n                                  s.features = s.genes)\n\n# 现在的meta.data中多出了细胞周期评分“S.Score”和“G2M.Score”，以及推断的细胞所处的周期“Phase”\nhead(merged_seurat@meta.data)\n\n                       orig.ident nCount_RNA nFeature_RNA samples\nN01_CAGAATCAGTAATCCC.1        N01   3470.970         4173     N01\nN01_TGCGGGTAGTACGTAA.1        N01   3155.725         2994     N01\nN01_AAACCTGAGGGTTTCT.1        N01   2347.034         1946     N01\nN01_AAACCTGAGTTCCACA.1        N01   2362.495         1993     N01\nN01_AAACCTGGTTCTCATT.1        N01   2130.465         1459     N01\nN01_AAACGGGGTCCTCCAT.1        N01   2772.010         2573     N01\n                       log10GenesPerUMI   mitoRatio                  cells\nN01_CAGAATCAGTAATCCC.1        1.0225953 0.008644269 N01_CAGAATCAGTAATCCC.1\nN01_TGCGGGTAGTACGTAA.1        0.9934705 0.009895666 N01_TGCGGGTAGTACGTAA.1\nN01_AAACCTGAGGGTTTCT.1        0.9758564 0.015183419 N01_AAACCTGAGGGTTTCT.1\nN01_AAACCTGAGTTCCACA.1        0.9781039 0.014965958 N01_AAACCTGAGTTCCACA.1\nN01_AAACCTGGTTCTCATT.1        0.9506023 0.017437508 N01_AAACCTGGTTCTCATT.1\nN01_AAACGGGGTCCTCCAT.1        0.9906021 0.011233365 N01_AAACGGGGTCCTCCAT.1\n                       nCount_SCT nFeature_SCT     S.Score    G2M.Score Phase\nN01_CAGAATCAGTAATCCC.1       1840         1674 -0.05179250 -0.070444626    G1\nN01_TGCGGGTAGTACGTAA.1       2840         2604 -0.04341940 -0.074302336    G1\nN01_AAACCTGAGGGTTTCT.1       2443         1931 -0.02396942 -0.007239586    G1\nN01_AAACCTGAGTTCCACA.1       2488         1972 -0.01294260 -0.021167805    G1\nN01_AAACCTGGTTCTCATT.1       2104         1451 -0.05440456 -0.049531592    G1\nN01_AAACGGGGTCCTCCAT.1       2892         2520 -0.10189203 -0.087537749    G1\n\n# 查看一下细胞周期的分布情况\ntable(merged_seurat$Phase)\n\n\n   G1   G2M     S \n33941  5147  9496 \n\n# 执行PCA\nmerged_seurat &lt;- RunPCA(merged_seurat)\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(merged_seurat,\n              reduction = \"pca\",\n              group.by= \"Phase\")\np2 &lt;- DimPlot(merged_seurat,\n              reduction = \"pca\",\n              group.by= \"Phase\",\n              split.by = \"Phase\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\n\n可以看到细胞周期不是变异来源。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#评估线粒体基因的影响",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#评估线粒体基因的影响",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n4.2 评估线粒体基因的影响\n",
    "text": "4.2 评估线粒体基因的影响\n\n\n# Check quartile values\nmito_sum &lt;- summary(merged_seurat$mitoRatio)\nmito_sum\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0006859 0.0106660 0.0127552 0.0129526 0.0150420 0.0407058 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nmerged_seurat$mitoFr &lt;- cut(merged_seurat$mitoRatio, \n                            breaks=c(-Inf, mito_sum[2], mito_sum[3], mito_sum[5], Inf),\n                            labels=c(\"Low\", \"Medium\", \"Medium high\", \"High\"))\nplot(merged_seurat$mitoFr)\n\n\n\n\n\n\n\n\n# Plot the PCA colored by cell cycle phase\np1 &lt;- DimPlot(merged_seurat,\n              reduction = \"pca\",\n              group.by= \"mitoFr\")\np2 &lt;- DimPlot(merged_seurat,\n              reduction = \"pca\",\n              group.by= \"mitoFr\",\n              split.by = \"mitoFr\")\nplot_grid(p1, p2, ncol = 2, labels = \"AUTO\")\n\n\n\n\n\n\n\n可以看到线粒体基因比例不是变异来源。\n由于细胞周期和线粒体基因比例都不是非期望变异来源，所以我们这里不需要再次运行SCTransform来回归这些变量。接下来，直接进入数据整合环节。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#不进行整合时检验细胞分群情况",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#不进行整合时检验细胞分群情况",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n5.1 不进行整合时检验细胞分群情况\n",
    "text": "5.1 不进行整合时检验细胞分群情况\n\n\n# 查看降维信息\nnames(merged_seurat@reductions)\n\n[1] \"pca\"\n\n# Run UMAP\nmerged_seurat &lt;- RunUMAP(merged_seurat, \n                         dims = 1:40, \n                         reduction = \"pca\",\n                         reduction.name = \"umap.unintegrated\"); beep()\n\n# 分群\n# Determine the K-nearest neighbor graph\nmerged_seurat &lt;- FindNeighbors(merged_seurat, \n                               dims = 1:40, \n                               reduction = \"pca\")\nmerged_seurat &lt;- FindClusters(merged_seurat, \n                              cluster.name = \"unintegrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 48584\nNumber of edges: 1937300\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9298\nNumber of communities: 38\nElapsed time: 7 seconds\n\n# Plot UMAP\np1 &lt;- DimPlot(merged_seurat, \n              reduction = \"umap.unintegrated\",\n              group.by = \"samples\")\np2 &lt;- DimPlot(merged_seurat, \n              reduction = \"umap.unintegrated\",\n              split.by = \"samples\")\nplot_grid(p1, p2, \n          ncol = 1, labels = \"AUTO\")\n\n\n\n\n\n\n# 由于样本数较多，我们再按照样本类型“Normal” vs. “Cancer”画一下UMAP图\nmerged_seurat$groups &lt;- ifelse(merged_seurat$samples == \"N01\", \"Normal\", \"Cancer\")\np1a &lt;- DimPlot(merged_seurat, \n               reduction = \"umap.unintegrated\",\n               group.by = \"groups\")\np2a &lt;- DimPlot(merged_seurat, \n               reduction = \"umap.unintegrated\",\n               split.by = \"groups\")\nplot_grid(p1a, p2a, \n          ncol = 1, labels = \"AUTO\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#整合",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#整合",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n5.2 整合",
    "text": "5.2 整合\n这里我们用Harmony整合算法。\n\n# 整合，比较耗时间，进度条会一直显示0%直至运算完成\nseurat_integrated &lt;- IntegrateLayers(object = merged_seurat,\n                                     method = HarmonyIntegration,\n                                     assay = \"SCT\", # Integrating SCTransformed data\n                                     orig.reduction = \"pca\",\n                                     verbose = FALSE); beep()\n\n\n# 整合后合并RNA layer\nseurat_integrated[[\"RNA\"]] &lt;- JoinLayers(seurat_integrated[[\"RNA\"]])\n\n# 查看整合后的降维信息\nnames(seurat_integrated@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"harmony\"",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#整合后检验细胞分群情况",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#整合后检验细胞分群情况",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n5.3 整合后检验细胞分群情况\n",
    "text": "5.3 整合后检验细胞分群情况\n\n\nset.seed(123456)\n# Run UMAP\nseurat_integrated &lt;- RunUMAP(seurat_integrated, \n                             dims = 1:40,\n                             reduction = \"harmony\", # 更改降维来源为整合后的\"harmony\"\n                             reduction.name = \"umap.integrated\"); beep()\nnames(seurat_integrated@reductions)\n\n[1] \"pca\"               \"umap.unintegrated\" \"harmony\"          \n[4] \"umap.integrated\"  \n\n# 分群\nseurat_integrated &lt;- FindNeighbors(seurat_integrated, \n                                   dims = 1:40, \n                                   reduction = \"harmony\") #更改降维来源为\"harmony\"\nseurat_integrated &lt;- FindClusters(seurat_integrated, \n                                  cluster.name = \"integrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 48584\nNumber of edges: 2161498\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9121\nNumber of communities: 24\nElapsed time: 8 seconds\n\ncolnames(seurat_integrated@meta.data)\n\n [1] \"orig.ident\"            \"nCount_RNA\"            \"nFeature_RNA\"         \n [4] \"samples\"               \"log10GenesPerUMI\"      \"mitoRatio\"            \n [7] \"cells\"                 \"nCount_SCT\"            \"nFeature_SCT\"         \n[10] \"S.Score\"               \"G2M.Score\"             \"Phase\"                \n[13] \"mitoFr\"                \"unintegrated_clusters\" \"seurat_clusters\"      \n[16] \"groups\"                \"integrated_clusters\"  \n\n# Plot UMAP                             \np3 &lt;- DimPlot(seurat_integrated, \n              reduction = \"umap.integrated\", \n              group.by = \"samples\")\np4 &lt;- DimPlot(seurat_integrated, \n              reduction = \"umap.integrated\", \n              split.by = \"samples\")\nplot_grid(p1, p3, p2, p4, \n          ncol = 1, \n          labels = c(\"Before Harmony\", \"After Harmony\", \n                     \"Before Harmony\", \"After Harmony\"))\n\n\n\n\n\n\n# 保存\nsaveRDS(seurat_integrated, \n        file = \"output/sc_supplementary/GSE150430_seurat_integrated.RDS\"); beep()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#分析样本类型是否影响细胞分群",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#分析样本类型是否影响细胞分群",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n7.1 分析样本类型是否影响细胞分群\n",
    "text": "7.1 分析样本类型是否影响细胞分群\n\n\n# 先简单查看不同cluster的细胞数\ntable(seurat_integrated@active.ident)\n\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n10830  5756  5526  5321  4161  3765  2388  2365  1952  1478   986   792   759 \n   13    14    15    16    17    18    19    20 \n  707   398   388   232   214   198   189   179 \n\n# 查看不同样本类型中的细胞分群情况\nDimPlot(seurat_integrated, \n        reduction = \"umap.integrated\",\n        label = TRUE, \n        split.by = \"groups\") + \n  NoLegend()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#分析细胞周期是否影响细胞分群",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#分析细胞周期是否影响细胞分群",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n7.2 分析细胞周期是否影响细胞分群\n",
    "text": "7.2 分析细胞周期是否影响细胞分群\n\n\n# Explore whether clusters segregate by cell cycle phase\nDimPlot(seurat_integrated,\n        reduction = \"umap.integrated\",\n        label = TRUE, \n        split.by = \"Phase\") + \n  NoLegend()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#分析其他非期望变异来源是否会影响细胞分群",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#分析其他非期望变异来源是否会影响细胞分群",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n7.3 分析其他非期望变异来源是否会影响细胞分群\n",
    "text": "7.3 分析其他非期望变异来源是否会影响细胞分群\n\n\n# Determine metrics to plot present in seurat_clustered@meta.data\nmetrics &lt;-  c(\"nCount_RNA\", \"nFeature_RNA\", \"S.Score\", \"G2M.Score\", \"mitoRatio\")\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap.integrated\", \n            features = metrics,\n            pt.size = 0.4, \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#保存",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#保存",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n7.4 保存",
    "text": "7.4 保存\n\nsaveRDS(seurat_integrated, \n        file = \"output/sc_supplementary/GSE150430_seurat_clustered.RDS\"); beep()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#探索cell-type-markers的表达",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#探索cell-type-markers的表达",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n8.1 探索cell type markers的表达",
    "text": "8.1 探索cell type markers的表达\n这里的marker基因选用此前章节中的细胞初步分群通用marker。\n\nrm(list = ls())\ngc()\n\n             used   (Mb) gc trigger    (Mb) limit (Mb)   max used    (Mb)\nNcells    8508819  454.5   15695064   838.3         NA   15695064   838.3\nVcells 1006102702 7676.0 3232710770 24663.7     102400 3232709930 24663.7\n\nseurat_clustered &lt;- readRDS(\"output/sc_supplementary/GSE150430_seurat_clustered.RDS\")\n\ngenes_to_check = c('PTPRC', \n                   \"CD163\",\"AIF1\", \n                   'CD3D', 'CD3E', 'CD4', 'CD8A', \n                   'CD19', 'CD79A', 'MS4A1', \"SDC1\", \"CD27\", \"CD38\",\n                   'IGHG1', 'MZB1', 'SDC1', \"JCHAIN\", \n                   'CD68', 'CD163', 'CD14', \n                   'S100A9', 'S100A8', 'MMP19',\n                   'C1QA',  'C1QB', \n                   'TPSAB1', 'TPSB2', \n                   'KLRB1', \"KLRD1\", 'NCR1', \"GNLY\", \"NKG7\", \n                   'FGF7', 'MME', 'ACTA2', \"COL3A1\", \n                   'PECAM1', 'VWF', \n                   'EPCAM', 'KRT19', 'PROM1', 'ALDH1A1') |&gt; unique()\n\nDotPlot(seurat_clustered, \n        features = genes_to_check) + \n  coord_flip()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#手动注释",
    "href": "single_cell/sc_supplementary/integrated_analysis_multiple_single_cell_datasets_1.html#手动注释",
    "title": "多个单细胞数据集整合分析（上）",
    "section": "\n8.2 手动注释",
    "text": "8.2 手动注释\n\nseurat_clustered &lt;- RenameIdents(seurat_clustered, \n                                 \"0\" = \"B cells\",\n                                 \"1\" = \"T cells\",\n                                 \"2\" = \"Epithelial/cancer\",\n                                 \"3\" = \"T cells\",\n                                 \"4\" = \"T cells\",\n                                 \"5\" = \"Macrophages\",\n                                 \"6\" = \"T cells\",\n                                 \"7\" = \"Plasma cells\",\n                                 \"8\" = \"B cells\",\n                                 \"9\" = \"Epithelial/cancer\",\n                                 \"10\" = \"B cells\",\n                                 \"11\" = \"B cells\",\n                                 \"12\" = \"Unknown\",\n                                 \"13\" = \"NK cells\",\n                                 \"14\" = \"Unknown\",\n                                 \"15\" = \"Epithelial/cancer\",\n                                 \"16\" = \"Myeloid (unspecific)\",\n                                 \"17\" = \"Epithelial/cancer\",\n                                 \"18\" = \"Epithelial/cancer\",\n                                 \"19\" = \"Epithelial/cancer\",\n                                 \"20\" = \"B cells\")\ntable(Idents(seurat_clustered))\n\n\n             B cells              T cells    Epithelial/cancer \n               14739                17626                 7993 \n         Macrophages         Plasma cells              Unknown \n                3765                 2365                 1157 \n            NK cells Myeloid (unspecific) \n                 707                  232 \n\n# Plot the UMAP\nDimPlot(seurat_clustered, \n        reduction = \"umap.integrated\", \n        label = T)\n\n\n\n\n\n\n\n在注释好的数据中再次检查marker基因的表达情况：\n\nDotPlot(seurat_clustered, \n        features = genes_to_check) + \n  coord_flip() +\n  theme(axis.text.x = element_text(angle = 30,vjust = 0.85,hjust = 0.75)\n) \n\n\n\n\n\n\n\n因为接下来我们要提取髓系细胞进一步分析，所以通过几种可视化方法检查一下髓系细胞通用marker（CD163和AIF1）的表达情况：\n\nRidgePlot(seurat_clustered, features = c(\"CD163\", \"AIF1\"), ncol = 1)\n\n\n\n\n\n\n\n\nVlnPlot(seurat_clustered, features = c(\"CD163\", \"AIF1\"))\n\n\n\n\n\n\n\n\nFeaturePlot(seurat_clustered, features = c(\"CD163\", \"AIF1\"), label = T)\n\n\n\n\n\n\n\n保存\n\nsaveRDS(seurat_clustered, \n        file = \"output/sc_supplementary/GSE150430_seurat_annotated.RDS\"); beep()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞补充内容",
      "多个单细胞数据集整合分析（上）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html",
    "title": "细胞聚类（clustering analysis）",
    "section": "",
    "text": "Learning Objectives:\n\n\n\n\nDescribe methods for evaluating the number of principal components used for clustering\nPerform clustering of cells based on significant principal components\nNow that we have our high quality cells integrated, we want to know the different cell types present within our population of cells.\nGoals:\nChallenges:\nRecommendations:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#通过热图判断需要包括的主成分",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#通过热图判断需要包括的主成分",
    "title": "细胞聚类（clustering analysis）",
    "section": "\n2.1 通过热图判断需要包括的主成分",
    "text": "2.1 通过热图判断需要包括的主成分\nOne way of exploring the PCs is using a heatmap to visualize the most variant genes for select PCs with the genes and cells ordered by PCA scores. The idea here is to look at the PCs and determine whether the genes driving them make sense for differentiating the different cell types.\nThe cells argument specifies the number of cells with the most negative or postive PCA scores to use for the plotting. The idea is that we are looking for a PC where the heatmap starts to look more “fuzzy”, i.e. where the distinctions between the groups of genes is not so distinct.\n\n# Explore heatmap of PCs\nDimHeatmap(seurat_integrated, \n           dims = 1:9, \n           cells = 500, \n           balanced = TRUE)\n\n\n\n\n\n\n\nThis method can be slow and hard to visualize individual genes if we would like to explore a large number of PCs. In the same vein and to explore a large number of PCs, we could print out the top 10 (or more) positive and negative genes by PCA scores driving the PCs.\n\n# Printing out the most variable genes driving PCs\nprint(x = seurat_integrated[[\"pca\"]], \n      dims = 1:10, \n      nfeatures = 5)\n\nPC_ 1 \nPositive:  IGKC, GNLY, RPL3, RPL13, RPS18 \nNegative:  FTL, CCL2, CCL8, CXCL10, TIMP1 \nPC_ 2 \nPositive:  GNLY, CCL5, GZMB, NKG7, PRF1 \nNegative:  IGKC, IGHM, CD74, HLA-DRA, CD79A \nPC_ 3 \nPositive:  PABPC1, RPS18, RPL13, RPL10, RPS6 \nNegative:  GNLY, IGKC, GZMB, CCL5, NKG7 \nPC_ 4 \nPositive:  CCL4, CCL3, CCL4L2, CCL2, CCL8 \nNegative:  FTL, TIMP1, GNLY, HLA-DRA, VMO1 \nPC_ 5 \nPositive:  CCL4, CCL3, CCL4L2, TIMP1, VMO1 \nNegative:  CCL2, CCL7, CCL8, IGKC, GNLY \nPC_ 6 \nPositive:  FTL, CXCL8, CCL4L2, CXCL3, S100A8 \nNegative:  CXCL10, CCL8, ISG15, IGLC2, APOBEC3A \nPC_ 7 \nPositive:  IGKC, CXCL10, VMO1, TIMP1, FCGR3A \nNegative:  IGLC2, IGLC3, IGHM, CD74, HLA-DRA \nPC_ 8 \nPositive:  HBB, HBA2, HBA1, SNCA, HBG2 \nNegative:  IGLC2, PPBP, HLA-DRA, CD74, IGLC3 \nPC_ 9 \nPositive:  PPBP, PF4, GNG11, CAVIN2, TUBB1 \nNegative:  GNLY, FTL, TXN, RPL10, RPL3 \nPC_ 10 \nPositive:  TXN, HSPB1, HSPA1A, HSPA1B, HLA-DRA \nNegative:  IGLC2, TIMP1, VMO1, PPBP, IGHM",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#通过肘图elbow-plot判断需要包括的主成分",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#通过肘图elbow-plot判断需要包括的主成分",
    "title": "细胞聚类（clustering analysis）",
    "section": "\n2.2 通过肘图（elbow plot）判断需要包括的主成分",
    "text": "2.2 通过肘图（elbow plot）判断需要包括的主成分\nThe elbow plot is another helpful way to determine how many PCs to use for clustering so that we are capturing majority of the variation in the data. The elbow plot visualizes the standard deviation of each PC, and we are looking for where the standard deviations begins to plateau. Essentially, where the elbow appears is usually the threshold for identifying the majority of the variation. However, this method can be quite subjective.\nLet’s draw an elbow plot using the top 40 PCs:\n\n# Plot the elbow plot\nElbowPlot(object = seurat_integrated, \n          ndims = 40)\n\n\n\n\n\n\n\nBased on this plot, we could roughly determine the majority of the variation by where the elbow occurs around PC8 - PC10, or one could argue that it should be when the data points start to get close to the X-axis, PC30 or so. This gives us a very rough idea of the number of PCs needed to be included, we can extract the information visualized here in a more quantitative manner, which may be a bit more reliable.\nWhile the above 2 methods were used a lot more with older methods from Seurat for normalization and identification of variable genes, they are no longer as important as they used to be. This is because the SCTransform method is more accurate than older methods，基于SCTransform的标准化流程中不再需要判断纳入的主成分数量，可以纳入更多的主成分（见Seurat-基于SCTransform的单细胞数据标准化）.\n\n\n\n\n\n\nWhy is selection of PCs more important for older methods?\n\n\n\nThe older methods incorporated some technical sources of variation into some of the higher PCs, so selection of PCs was more important. SCTransform estimates the variance better and does not frequently include these sources of technical variation in the higher PCs.\nIn theory, with SCTransform, the more PCs we choose the more variation is accounted for when performing the clustering, but it takes a lot longer to perform the clustering. Therefore for this analysis, we will use the first 40 PCs to generate the clusters.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#find-neighbors",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#find-neighbors",
    "title": "细胞聚类（clustering analysis）",
    "section": "\n3.1 Find neighbors",
    "text": "3.1 Find neighbors\nThe first step is to construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space.\n\n\nImage source: Analysis of Single cell RNA-seq data\n\n\nEdges are drawn between cells with similar features expression patterns.\nEdge weights are refined between any two cells based on shared overlap in their local neighborhoods.\n\nThis is done in Seurat by using the FindNeighbors() function（这里不需要运行，因为在上一节中我们已经在整合后运行了FindNeighbors）:\n\n# Determine the K-nearest neighbor graph（不需运行）\nseurat_integrated &lt;- FindNeighbors(seurat_integrated, \n                                   dims = 1:40, \n                                   reduction = \"integrated.cca\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#find-clusters",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#find-clusters",
    "title": "细胞聚类（clustering analysis）",
    "section": "\n3.2 Find clusters",
    "text": "3.2 Find clusters\nNext, Seurat will iteratively group cells together with the goal of optimizing the standard modularity function.\nWe will use the FindClusters() function to perform the graph-based clustering. The resolution is an important argument that sets the “granularity” of the downstream clustering and will need to be optimized for every individual experiment. For datasets of 3,000 - 5,000 cells, the resolution set between 0.4-1.4 generally yields good clustering. Increased resolution values lead to a greater number of clusters, which is often required for larger datasets.\nThe FindClusters() function allows us to enter a series of resolutions and will calculate the “granularity” of the clustering. This is very helpful for testing which resolution works for moving forward without having to run the function for each resolution.\n\n# Determine the clusters for various resolutions                                \nseurat_integrated &lt;- FindClusters(object = seurat_integrated,\n                                  resolution = c(0.4, 0.6, 0.8, 1.0, 1.4))\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1128935\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9211\nNumber of communities: 14\nElapsed time: 4 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1128935\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9019\nNumber of communities: 17\nElapsed time: 4 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1128935\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8864\nNumber of communities: 22\nElapsed time: 4 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1128935\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8727\nNumber of communities: 26\nElapsed time: 4 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1128935\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8511\nNumber of communities: 28\nElapsed time: 4 seconds",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#sec-Load_case_data",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#sec-Load_case_data",
    "title": "细胞聚类（clustering analysis）",
    "section": "\n4.1 载入案例数据",
    "text": "4.1 载入案例数据\nHow does your UMAP plot compare to the one above?\nIt is possible that there is some variability in the way your clusters look compared to the image in this lesson. In particular you may see a difference in the labeling of clusters. This is an unfortunate consequence of slight variations in the versions of packages (mostly Seurat dependencies).\nIf your clusters look identical to what’s in the lesson, please go ahead to the next section.\n\nIf your clusters do look different from what we have in the lesson, please follow the instructions provided below.\nInside your data folder you will see a folder called additional_data. It contains the seurat_integrated object that we have created for the class. Let’s load in the object to your R session and overwrite the existing one:\n\nload(bzfile(\"data/scRNA-seq_online/additional_data/seurat_integrated.RData.bz2\"))\nseurat_integrated\n\nAn object of class Seurat \n31130 features across 29629 samples within 3 assays \nActive assay: integrated (3000 features, 3000 variable features)\n 2 layers present: data, scale.data\n 2 other assays present: RNA, SCT\n 2 dimensional reductions calculated: pca, umap\n\nhead(seurat_integrated, 5)\n\n                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1       ctrl       2344          874\nctrl_AAACATACATTTCC-1       ctrl       3124          895\nctrl_AAACATACCAGAAA-1       ctrl       2578          725\nctrl_AAACATACCAGCTA-1       ctrl       3260          978\nctrl_AAACATACCATGCA-1       ctrl        746          362\n                                      seq_folder nUMI nGene log10GenesPerUMI\nctrl_AAACATACAATGCC-1 ctrl_raw_feature_bc_matrix 2344   874        0.8728630\nctrl_AAACATACATTTCC-1 ctrl_raw_feature_bc_matrix 3125   896        0.8447596\nctrl_AAACATACCAGAAA-1 ctrl_raw_feature_bc_matrix 2578   725        0.8384933\nctrl_AAACATACCAGCTA-1 ctrl_raw_feature_bc_matrix 3261   979        0.8512622\nctrl_AAACATACCATGCA-1 ctrl_raw_feature_bc_matrix  746   362        0.8906861\n                       mitoRatio                 cells sample     S.Score\nctrl_AAACATACAATGCC-1 0.01962457 ctrl_AAACATACAATGCC-1   ctrl  0.04330502\nctrl_AAACATACATTTCC-1 0.01792000 ctrl_AAACATACATTTCC-1   ctrl  0.02661900\nctrl_AAACATACCAGAAA-1 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl -0.04670650\nctrl_AAACATACCAGCTA-1 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl -0.05832833\nctrl_AAACATACCATGCA-1 0.02144772 ctrl_AAACATACCATGCA-1   ctrl  0.03929605\n                        G2M.Score Phase      mitoFr nCount_SCT nFeature_SCT\nctrl_AAACATACAATGCC-1  0.05422631   G2M      Medium       1572          829\nctrl_AAACATACATTTCC-1  0.05159679   G2M      Medium       1572          718\nctrl_AAACATACCAGAAA-1 -0.04841661    G1      Medium       1553          648\nctrl_AAACATACCAGCTA-1  0.05045960   G2M         Low       1576          756\nctrl_AAACATACCATGCA-1 -0.02995512     S Medium high       1075          363\n                      integrated_snn_res.0.4 integrated_snn_res.0.6\nctrl_AAACATACAATGCC-1                      2                      1\nctrl_AAACATACATTTCC-1                      0                      2\nctrl_AAACATACCAGAAA-1                      0                      3\nctrl_AAACATACCAGCTA-1                      0                      3\nctrl_AAACATACCATGCA-1                      5                      6\n                      integrated_snn_res.0.8 integrated_snn_res.1\nctrl_AAACATACAATGCC-1                      2                    2\nctrl_AAACATACATTTCC-1                      1                    0\nctrl_AAACATACCAGAAA-1                      3                   15\nctrl_AAACATACCAGCTA-1                      3                    3\nctrl_AAACATACCATGCA-1                      4                   12\n                      integrated_snn_res.1.4 seurat_clusters\nctrl_AAACATACAATGCC-1                      5               5\nctrl_AAACATACATTTCC-1                      0               0\nctrl_AAACATACCAGAAA-1                     19              19\nctrl_AAACATACCAGCTA-1                      3               3\nctrl_AAACATACCATGCA-1                     13              13\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n由于这里的案例数据是基于Seurat V5之前的版本创建的，所以数据结构和基于Seurat V5的结果有所差异。比较重要的区别是，这里的Seurat对象的没有layer结构；同时有一个“integrated” assay，用于存放整合后的信息，其类型仍属于SCT assay。而一个典型的经过SCTransform和整合的Seurat V5对象如下图所示（来自Seurat-整合）：\n\n可以看到没有“integrated” assay，因此，为了和最新的Seurat V5流程保持一致，我们后续把本案例中的“integrated” assay看作整合后的Seurat V5的“SCT” assay。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#再次检查不同分辨率下的细胞分群情况",
    "href": "single_cell/scRNA-seq_online/07_SC_clustering_cells_SCT.html#再次检查不同分辨率下的细胞分群情况",
    "title": "细胞聚类（clustering analysis）",
    "section": "\n4.2 再次检查不同分辨率下的细胞分群情况",
    "text": "4.2 再次检查不同分辨率下的细胞分群情况\nAfter loading seurat_integrated.RData.bz2, we now re-check the object clusters with different resolution (0.4, 0.6, 0.8, 1.0, 1.4).\n\n# 查看不同分辨率下的细胞分群情况\napply(seurat_integrated@meta.data[ ,grep(\"integrated_snn_res.\", \n                                         colnames(seurat_integrated@meta.data))], \n      2, \n      table)\n\n$integrated_snn_res.0.4\n\n   0    1   10   11   12    2    3    4    5    6    7    8    9 \n6715 5899  456  280  124 3661 2680 2377 2166 2143 1217 1177  734 \n\n$integrated_snn_res.0.6\n\n   0    1   10   11   12   13   14    2    3    4    5    6    7    8    9 \n5443 3667 1176  467  464  288  124 3403 3306 2631 2382 2137 1679 1249 1213 \n\n$integrated_snn_res.0.8\n\n   0    1   10   11   12   13   14   15   16    2    3    4    5    6    7    8 \n4220 3718 1208 1174  858  468  459  289  124 3649 3004 2164 1959 1810 1646 1504 \n   9 \n1375 \n\n$integrated_snn_res.1\n\n   0    1   10   11   12   13   14   15   16   17   18   19    2   20   21    3 \n3392 3269 1158 1152  952  876  873  650  520  462  282  176 3041  124   23 2668 \n   4    5    6    7    8    9 \n2508 1881 1643 1509 1261 1209 \n\n$integrated_snn_res.1.4\n\n   0    1   10   11   12   13   14   15   16   17   18   19    2   20   21   22 \n2886 2497 1211 1174  874  838  832  802  766  657  655  629 2130  468  459  357 \n  23   24   25   26    3    4    5    6    7    8    9 \n 292  175  124   23 2011 1884 1827 1646 1587 1489 1336 \n\n\n\n# 批量绘制不同分辨率下的UMAP图\nlibrary(ggplot2)\nlibrary(patchwork)\nlapply(grep(\"integrated_snn_res.\",\n            colnames(seurat_integrated@meta.data), \n            value = TRUE),\n       function(res) {\n         Idents(seurat_integrated) &lt;-  res\n         DimPlot(seurat_integrated,\n                 reduction = \"umap\",\n                 label = FALSE,\n                 label.size = 4) +\n           ggtitle(res) +\n           theme_bw()\n         }) |&gt;\n  wrap_plots(ncol = 2)\n\n\n\n\n\n\n\n\nWe will now continue with the 0.8 resolution to check the quality control metrics and known markers for the anticipated cell types.\n\n# Assign identity of clusters\nIdents(seurat_integrated) &lt;- \"integrated_snn_res.0.8\"\n\n# Plot the UMAP\nDimPlot(seurat_integrated,\n        reduction = \"umap\",\n        label = TRUE,\n        label.size = 6)\n\n\n\n\n\n\n\n\nsaveRDS(seurat_integrated, file = \"output/scRNA-seq_online/seurat_clustered.rds\")\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] patchwork_1.2.0    ggplot2_3.4.4      Seurat_5.0.1       SeuratObject_5.0.1\n[5] sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-2           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.3            magrittr_2.0.3         RcppAnnoy_0.0.21      \n  [7] spatstat.geom_3.2-7    matrixStats_1.2.0      ggridges_0.5.5        \n [10] compiler_4.3.2         png_0.1-8              vctrs_0.6.5           \n [13] reshape2_1.4.4         stringr_1.5.1          pkgconfig_2.0.3       \n [16] fastmap_1.1.1          ellipsis_0.3.2         labeling_0.4.3        \n [19] utf8_1.2.4             promises_1.2.1         rmarkdown_2.25        \n [22] purrr_1.0.2            xfun_0.41              jsonlite_1.8.8        \n [25] goftest_1.2-3          later_1.3.2            spatstat.utils_3.0-4  \n [28] irlba_2.3.5.1          parallel_4.3.2         cluster_2.1.6         \n [31] R6_2.5.1               ica_1.0-3              stringi_1.8.3         \n [34] RColorBrewer_1.1-3     spatstat.data_3.0-4    reticulate_1.34.0     \n [37] parallelly_1.36.0      lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.12            knitr_1.45             tensor_1.5            \n [43] future.apply_1.11.1    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.13          Matrix_1.6-5           splines_4.3.2         \n [49] igraph_1.6.0           tidyselect_1.2.0       abind_1.4-5           \n [52] rstudioapi_0.15.0      yaml_2.3.8             spatstat.random_3.2-2 \n [55] codetools_0.2-19       miniUI_0.1.1.1         spatstat.explore_3.2-5\n [58] listenv_0.9.0          lattice_0.22-5         tibble_3.2.1          \n [61] plyr_1.8.9             withr_3.0.0            shiny_1.8.0           \n [64] ROCR_1.0-11            evaluate_0.23          Rtsne_0.17            \n [67] future_1.33.1          fastDummies_1.7.3      survival_3.5-7        \n [70] polyclip_1.10-6        fitdistrplus_1.1-11    pillar_1.9.0          \n [73] KernSmooth_2.23-22     plotly_4.10.4          generics_0.1.3        \n [76] RcppHNSW_0.5.0         munsell_0.5.0          scales_1.3.0          \n [79] globals_0.16.2         xtable_1.8-4           glue_1.7.0            \n [82] lazyeval_0.2.2         tools_4.3.2            data.table_1.14.10    \n [85] RSpectra_0.16-1        RANN_2.6.1             leiden_0.4.3.1        \n [88] dotCall64_1.1-1        cowplot_1.1.2          grid_4.3.2            \n [91] tidyr_1.3.0            colorspace_2.1-0       nlme_3.1-164          \n [94] cli_3.6.2              spatstat.sparse_3.0-3  spam_2.10-0           \n [97] fansi_1.0.6            viridisLite_0.4.2      dplyr_1.1.4           \n[100] uwot_0.1.16            gtable_0.3.4           digest_0.6.34         \n[103] progressr_0.14.0       ggrepel_0.9.5          farver_2.1.1          \n[106] htmlwidgets_1.6.4      htmltools_0.5.7        lifecycle_1.0.4       \n[109] httr_1.4.7             mime_0.12              MASS_7.3-60.0.1",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "细胞聚类（clustering analysis）"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html",
    "title": "数据导入与Seurat对象构建",
    "section": "",
    "text": "After quantifying gene expression we need to bring this data into R to generate metrics for performing QC. In this lesson we will talk about the format(s) count data can be expected in, and how to read it into R so we can move on to the QC step in the workflow. We will also discuss the dataset we will be using and the associated metadata.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "数据导入与Seurat对象构建"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#raw-data",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#raw-data",
    "title": "数据导入与Seurat对象构建",
    "section": "\n1.1 Raw data",
    "text": "1.1 Raw data\nThis dataset is available on GEO (GSE96583), however the available counts matrix lacked mitochondrial reads, so we downloaded the BAM files from the SRA (SRP102802). These BAM files were converted back to FASTQ files, then run through Cell Ranger to obtain the count data that we will be using.\n\nNOTE: The count data for this dataset is also freely available from 10X Genomics and is used in the Seurat tutorial.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "数据导入与Seurat对象构建"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#metadata",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#metadata",
    "title": "数据导入与Seurat对象构建",
    "section": "\n1.2 Metadata",
    "text": "1.2 Metadata\nIn addition to the raw data, we also need to collect information about the data; this is known as metadata. There is often a temptation to just start exploring the data, but it is not very meaningful if we know nothing about the samples that this data originated from.\nSome relevant metadata for our dataset is provided below:\n\nThe libraries were prepared using 10X Genomics version 2 chemistry\nThe samples were sequenced on the Illumina NextSeq 500\n\nPBMC samples from eight individual lupus patients were separated into two aliquots each.\n\nOne aliquot of PBMCs was activated by 100 U/mL of recombinant IFN-β for 6 hours.\nThe second aliquot was left untreated.\nAfter 6 hours, the eight samples for each condition were pooled together in two final pools (stimulated cells and control cells). We will be working with these two, pooled samples. (We did not demultiplex the samples because SNP genotype information was used to demultiplex in the paper and the barcodes/sample IDs were not readily available for this data. Generally, you would demultiplex and perform QC on each individual sample rather than pooling the samples.)\n\n\n12,138 and 12,167 cells were identified (after removing doublets) for control and stimulated pooled samples, respectively.\n\nSince the samples are PBMCs, we will expect immune cells, such as:\n\nB cells\nT cells\nNK cells\nmonocytes\nmacrophages\npossibly megakaryocytes\n\n\n\nIt is recommended that you have some expectation regarding the cell types you expect to see in a dataset prior to performing the QC. This will inform you if you have any cell types with low complexity (lots of transcripts from a few genes) or cells with higher levels of mitochondrial expression. This will enable us to account for these biological factors during the analysis workflow.\nNone of the above cell types are expected to be low complexity or anticipated to have high mitochondrial content.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "数据导入与Seurat对象构建"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#首先尝试读取单个样本",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#首先尝试读取单个样本",
    "title": "数据导入与Seurat对象构建",
    "section": "\n2.1 首先尝试读取单个样本",
    "text": "2.1 首先尝试读取单个样本\nIf we had a single sample, we could generate the count matrix and then subsequently create a Seurat object:\n\nlibrary(Seurat)\n# Read in 10X data for a single sample (output is a sparse matrix)\nctrl_counts &lt;- Read10X(data.dir = \"data/scRNA-seq_online/original_10x/ctrl_raw_feature_bc_matrix\")\n\n# Turn count matrix into a Seurat object (output is a Seurat object)\nctrl &lt;- CreateSeuratObject(counts = ctrl_counts,\n                           project = \"pbmc_ctrl\",\n                           min.features = 100)\nctrl\n\nAn object of class Seurat \n33538 features across 15688 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe min.features argument specifies the minimum number of genes that need to be detected per cell. This argument will filter out poor quality cells that likely just have random barcodes encapsulated without any cell present. Usually, cells with less than 100 genes detected are not considered for analysis.\n\n\nSeurat automatically creates some metadata for each of the cells when you use the Read10X() function to read in data. This information is stored in the meta.data slot within the Seurat object.\n\n# Explore the metadata\nhead(ctrl@meta.data)\n\n                 orig.ident nCount_RNA nFeature_RNA\nAAACATACAATGCC-1  pbmc_ctrl       2344          874\nAAACATACATTTCC-1  pbmc_ctrl       3125          896\nAAACATACCAGAAA-1  pbmc_ctrl       2578          725\nAAACATACCAGCTA-1  pbmc_ctrl       3261          979\nAAACATACCATGCA-1  pbmc_ctrl        746          362\nAAACATACCTCGCT-1  pbmc_ctrl       3519          866\n\n\nWhat do the columns of metadata mean?\n\n\norig.ident: this often contains the sample identity if known。通过CreateSeuratObject中的project参数可以指定，默认是”SeuratProject”\n\nnCount_RNA: number of UMIs per cell\n\nnFeature_RNA: number of genes detected per cell",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "数据导入与Seurat对象构建"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#读取所有样本",
    "href": "single_cell/scRNA-seq_online/03_SC_quality_control-setup.html#读取所有样本",
    "title": "数据导入与Seurat对象构建",
    "section": "\n2.2 读取所有样本",
    "text": "2.2 读取所有样本\n\n首先通过list.dirs()函数列出数据文件夹“original_10x”下所有子文件夹的相对路径，并形成一个包含了所有子文件夹相对路径的字符向量“files”\n然后通过Read10X()读取每个子文件夹。Read10X函数支持批量读取多个文件夹。\n最后，通过CreateSeuratObject构建Seurat对象。\n\n\n\n\n\n\n\nCaution\n\n\n\n这里利用了Read10X函数支持批量读取多个文件夹的特性，直接创建一个合并后的Seurat对象“merged_seurat”。但是，这只适用于读取以标准10X格式保存的数据，即每个样本为一个文件夹，每个文件夹内有三个文件，文件名为：“barcodes.tsv.gz”、“features.tsv.gz”、“matrix.mtx.gz”。\n另外一种更通用的方法是通过循环依次读取每个文件夹内的3个10X文件，得到一个Seurat对象列表，然后通过merge()函数合并这些Seurat对象，详见：读取非标准10X格式文件。\n\n\n\n# 列出数据文件夹下所有子文件夹的相对路径\nlist.dirs(\"data/scRNA-seq_online/original_10x\")\n\n[1] \"data/scRNA-seq_online/original_10x\"                           \n[2] \"data/scRNA-seq_online/original_10x/ctrl_raw_feature_bc_matrix\"\n[3] \"data/scRNA-seq_online/original_10x/stim_raw_feature_bc_matrix\"\n\nfiles &lt;- list.dirs(\"data/scRNA-seq_online/original_10x\")[-1]\n\n# 构建Seurat对象\nmerged_seurat &lt;- CreateSeuratObject(Read10X(files),\n                                    min.features = 100, \n                                    project = \"GSE96583\")\nmerged_seurat\n\nAn object of class Seurat \n33538 features across 31444 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n# Check that the merged object has the appropriate sample-specific prefixes\nhead(merged_seurat)\n\n                   orig.ident nCount_RNA nFeature_RNA\n1_AAACATACAATGCC-1          1       2344          874\n1_AAACATACATTTCC-1          1       3125          896\n1_AAACATACCAGAAA-1          1       2578          725\n1_AAACATACCAGCTA-1          1       3261          979\n1_AAACATACCATGCA-1          1        746          362\n1_AAACATACCTCGCT-1          1       3519          866\n1_AAACATACCTGGTA-1          1       3328         1137\n1_AAACATACCTGTAG-1          1        484          281\n1_AAACATACGATGAA-1          1       1991          650\n1_AAACATACGCCAAT-1          1       1186          447\n\ntail(merged_seurat)\n\n                   orig.ident nCount_RNA nFeature_RNA\n2_TTTGCATGCATGAC-1          2       1395          492\n2_TTTGCATGCCTGAA-1          2       1102          483\n2_TTTGCATGCCTGTC-1          2       2334          841\n2_TTTGCATGCCTTAT-1          2       2766          856\n2_TTTGCATGCGACAT-1          2        620          295\n2_TTTGCATGCTAAGC-1          2       1641          545\n2_TTTGCATGGGACGA-1          2       1233          518\n2_TTTGCATGGTGAGG-1          2       1084          469\n2_TTTGCATGGTTTGG-1          2        818          432\n2_TTTGCATGTCTTAC-1          2       1104          438\n\n\n可以发现，此时的细胞barcode按照我们读取10X文件的顺序，被分别赋予“1, 2, 3…”的前缀。为了后续便于识别细胞来自哪个样本，我们需要通过gsub()将这些前缀更改为样本名称（“ctrl” 和 “stim”）。\n\ncolnames(merged_seurat) &lt;- gsub(pattern = \"^1_\", \n                                x = colnames(merged_seurat), \n                                replacement = \"ctrl_\")\ncolnames(merged_seurat) &lt;- gsub(pattern = \"^2_\", \n                                x = colnames(merged_seurat), \n                                replacement = \"stim_\")\n\n# Re-check that the merged object has the appropriate sample-specific prefixes\nhead(merged_seurat)\n\n                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1          1       2344          874\nctrl_AAACATACATTTCC-1          1       3125          896\nctrl_AAACATACCAGAAA-1          1       2578          725\nctrl_AAACATACCAGCTA-1          1       3261          979\nctrl_AAACATACCATGCA-1          1        746          362\nctrl_AAACATACCTCGCT-1          1       3519          866\nctrl_AAACATACCTGGTA-1          1       3328         1137\nctrl_AAACATACCTGTAG-1          1        484          281\nctrl_AAACATACGATGAA-1          1       1991          650\nctrl_AAACATACGCCAAT-1          1       1186          447\n\ntail(merged_seurat)\n\n                      orig.ident nCount_RNA nFeature_RNA\nstim_TTTGCATGCATGAC-1          2       1395          492\nstim_TTTGCATGCCTGAA-1          2       1102          483\nstim_TTTGCATGCCTGTC-1          2       2334          841\nstim_TTTGCATGCCTTAT-1          2       2766          856\nstim_TTTGCATGCGACAT-1          2        620          295\nstim_TTTGCATGCTAAGC-1          2       1641          545\nstim_TTTGCATGGGACGA-1          2       1233          518\nstim_TTTGCATGGTGAGG-1          2       1084          469\nstim_TTTGCATGGTTTGG-1          2        818          432\nstim_TTTGCATGTCTTAC-1          2       1104          438\n\n\n现在可以看到细胞barcode的前缀已被更改成了样本名称。接下来我们还可以进一步将样本信息添加到meta.data的新的一列“sample”中:\n\n# Create sample column\nlibrary(stringr)\nmerged_seurat$sample &lt;- str_split(rownames(merged_seurat@meta.data),\n                                  \"_\",\n                                  simplify = TRUE)\nhead(merged_seurat)\n\n                      orig.ident nCount_RNA nFeature_RNA sample\nctrl_AAACATACAATGCC-1          1       2344          874   ctrl\nctrl_AAACATACATTTCC-1          1       3125          896   ctrl\nctrl_AAACATACCAGAAA-1          1       2578          725   ctrl\nctrl_AAACATACCAGCTA-1          1       3261          979   ctrl\nctrl_AAACATACCATGCA-1          1        746          362   ctrl\nctrl_AAACATACCTCGCT-1          1       3519          866   ctrl\nctrl_AAACATACCTGGTA-1          1       3328         1137   ctrl\nctrl_AAACATACCTGTAG-1          1        484          281   ctrl\nctrl_AAACATACGATGAA-1          1       1991          650   ctrl\nctrl_AAACATACGCCAAT-1          1       1186          447   ctrl\n\ntable(merged_seurat$sample)\n\n\n ctrl  stim \n15688 15756",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "数据导入与Seurat对象构建"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html",
    "title": "Single-cell RNA-seq Clustering Workflow",
    "section": "",
    "text": "Learning Objectives:\nNow that we have our high quality cells, we can move forward with the workflow. Ultimately, we want to cluster cells and identify different potential celltypes however there are a few steps to walk-through before we get there. The green boxes in our workflow schematic below correspond to the steps taken post-QC and together consistute the clustering workflow.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Single-cell RNA-seq Clustering Workflow"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html#explore-sources-of-unwanted-variation",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html#explore-sources-of-unwanted-variation",
    "title": "Single-cell RNA-seq Clustering Workflow",
    "section": "1. Explore sources of unwanted variation",
    "text": "1. Explore sources of unwanted variation\nThe first step in the workflow is to see if our data contains any unwanted variability. The most common biological effect that is evaluated in single-cell RNA-seq data is the effect of cell cycle on the transcriptome. Another known biological effect is mitochondrial gene expression, which is interpreted as an indication of cell stress. This step of the workflow involves exploring our data to identify which covariates we would like to regress out.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Single-cell RNA-seq Clustering Workflow"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html#normalization-and-regressing-out-sources-of-unwanted-variation",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html#normalization-and-regressing-out-sources-of-unwanted-variation",
    "title": "Single-cell RNA-seq Clustering Workflow",
    "section": "2. Normalization and regressing out sources of unwanted variation",
    "text": "2. Normalization and regressing out sources of unwanted variation\nSeurat recently introduced a new method called sctransform which performs multiple processing steps on scRNA-seq data. Normalization is required to scale the raw count data to obtain correct relative gene expression abundances between cells. The sctransform function implements an advanced normalization and variance stabilization of the data. The sctransform function also regresses out sources of unwanted variation in our data. In the previous step, we had identified these sources of variability, and here we specify what those covariates are.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Single-cell RNA-seq Clustering Workflow"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html#integration",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html#integration",
    "title": "Single-cell RNA-seq Clustering Workflow",
    "section": "3. Integration",
    "text": "3. Integration\nOften with single cell RNA-seq we are working with multiple samples which correspond to different sample groups, multiple experiments or different modalities. If we want to ultimately compare celltype expression between groups it is recommended to integrate the data. Integration is a powerful method that uses these shared sources of greatest variation to identify shared sub-populations across conditions or datasets. There are several steps involved in performing intergration in Seurat. Once complete, we use visualization methods to ensure a good integration before we proceed to cluster cells.\n\n\n\n\n\n\nCaution\n\n\n\nIntegration is optional. We recommend going through the workflow without integration to decide whether or not it is necessary for your data.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Single-cell RNA-seq Clustering Workflow"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html#clustering-cells",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html#clustering-cells",
    "title": "Single-cell RNA-seq Clustering Workflow",
    "section": "4. Clustering cells",
    "text": "4. Clustering cells\nClusters of cells are obtained by grouping cells based on the similarity of their gene expression profiles. Expression profile similarity is determined via distance metrics, which often take dimensionality‐reduced representations as input. Seurat assigns cells to clusters based on their PCA scores derived from the expression of the integrated most variable genes.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Single-cell RNA-seq Clustering Workflow"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/postQC_workflow.html#cluster-quality-evaluation",
    "href": "single_cell/scRNA-seq_online/postQC_workflow.html#cluster-quality-evaluation",
    "title": "Single-cell RNA-seq Clustering Workflow",
    "section": "5. Cluster quality evaluation",
    "text": "5. Cluster quality evaluation\nThe clusters identified in our data represent groups of cells that presumably belong to a similar cell type. Before we can confirm the celltype of a group of member cells, the following steps are taken:\n\na. Check to see that clusters are not influenced by sources of uninteresting variation.\nb. Check to see whether the major principal components are driving the different clusters.\nc. Explore the cell type identities by looking at the expression for known markers across the clusters.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "Single-cell RNA-seq Clustering Workflow"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/05_theory_of_PCA.html",
    "href": "single_cell/scRNA-seq_online/05_theory_of_PCA.html",
    "title": "PCA原理",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nExplain how similarity between cells/samples can be evaluated by the Principal Components Analysis (PCA)\n\n\n\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for “dimensionality reduction”. We will briefly go over PCA in this lesson (adapted from StatQuests/Josh Starmer’s YouTube video), but we strongly encourage you to explore the video StatQuest’s video for a more thorough explanation/understanding：\n\n\n1 PCA基本原理\nLet’s say you had quantified the expression of four genes in two samples (or cells), you could plot the expression values of those genes with one sample represented on the x-axis and the other sample on the y-axis as shown below:\n\nYou could draw a line through the data in the direction representing the most variation, which is on the diagonal in this example. The maximum variation in the dataset is between the genes that make up the two endpoints of this line.\nWe also see the genes vary somewhat above and below the line. We could draw another line through the data representing the second most amount of variation in the data, since this plot is in 2D (2 axes).\n\nThe genes near the ends of each line would be those with the highest variation; these genes have the greatest influence on the direction of the line, mathematically.\n\nFor example, a small change in the value of Gene C would greatly change the direction of the longer line, whereas a small change in Gene A or Gene D would have little affect on it.\n\nWe could also rotate the entire plot and view the lines representing the variation as left-to-right and up-and-down. We see most of the variation in the data is left-to-right (longer line) and the second most variation in the data is up-and-down (shorter line). You can now think of these lines as the axes that represent the variation. These axes are essentially the “Principal Components”, with PC1 representing the most variation in the data and PC2 representing the second most variation in the data.\n\nNow, what if we had three samples/cells, then we would have an extra direction in which we could have variation (3D). Therefore, if we have N samples/cells we would have N-directions of variation or N principal components (PCs)! Once these PCs have been calculated, the PC that deals with the largest variation in the dataset is designated PC1, and the next one is designated PC2 and so on.\nOnce the PCs have been determined for an dataset, we have to figure out how each sample/cell fits back into that context to enable us to visualize the similarities/dissimilarities in an intuitive manner. The question here is “what is sample_X’s score for a given PC based on the gene expression in sample_X?”. This is the actual step where the dimensionality is reduced, since you plot PC scores for each sample/cell on the final PCA plot.\nPC scores are calculated for all sample-PC pairs as described in the steps and schematic below:\n\nFirst, each gene is assigned an “influence” score based on how much it influenced each PC. Genes that did not have any influence on a given PC get scores near zero, while genes with more influence receive larger scores. Genes on the ends of a PC line will have a larger influence, so they would receive larger scores but with opposite signs.\n\nOnce the influence has been determined, the score for each sample is calculated using the following equation:\nSample1 PC1 score = (read count * influence) + … for all genes\nFor our 2-sample example, the following is how the scores would be calculated:\n## Sample1\nPC1 score = (4 * -2) + (1 * -10) + (8 * 8) + (5 * 1) = 51\nPC2 score = (4 * 0.5) + (1 * 1) + (8 * -5) + (5 * 6) = -7\n\n## Sample2\nPC1 score = (5 * -2) + (4 * -10) + (8 * 8) + (7 * 1) = 21\nPC2 score = (5 * 0.5) + (4 * 1) + (8 * -5) + (7 * 6) = 8.5\nHere is a schematic that goes over the first 2 steps:\n\nOnce these scores are calculated for all the PCs, they can be plotted on a simple scatter plot. Below is the plot for the example here, going from the 2D matrix to a 2D plot:\n1.1 \n\n\n\n\n2 PCA在单细胞数据降维中的应用\nLet’s say you are working with a single-cell RNA-seq dataset with 12,000 cells and you have quantified the expression of 20,000 genes. The schematic below demonstrates how you would go from a cell x gene matrix to principal component (PC) scores for each inividual cell.\n\nAfter the PC scores have been calculated, you are looking at a matrix of 12,000 x 12,000 that represents the information about relative gene expression in all the cells. You can select the PC1 and PC2 columns and plot that in a 2D way.\n\nYou can also use the PC scores from the first 40 PCs for downstream analysis like clustering, marker identification etc., since these represent the majority of the variation in the data. We will be talking a lot more about this later in this workshop.\n\nFor datasets with a larger number of cells, only the PC1 and PC2 scores for each cell are usually plotted, or used for visualization. Since these PCs explain the most variation in the dataset, the expectation is that the cells that are more similar to each other will cluster together with PC1 and PC2.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "PCA原理"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html",
    "title": "寻找marker基因+细胞注释",
    "section": "",
    "text": "Learning Objectives:\n\n\n\n\nDescribe how to determine markers of individual clusters\nDiscuss the iterative processes of clustering and marker identification\nNow that we have identified our desired clusters, we can move on to marker identification, which will allow us to verify the identity of certain clusters and help surmise the identity of any unknown clusters.\nGoals:\nChallenges:\nRecommendations:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#寻找cluster-0和cluster-10的conserved-markers",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#寻找cluster-0和cluster-10的conserved-markers",
    "title": "寻找marker基因+细胞注释",
    "section": "\n3.1 寻找cluster 0和cluster 10的conserved markers",
    "text": "3.1 寻找cluster 0和cluster 10的conserved markers\n我们首先通过寻找cluster 0和cluster 10的conserved markers来初步学习FindConservedMarkers函数的用法。\nfor FindConservedMarkers, you will recognize some of the arguments we described previously for the FindAllMarkers() function; this is because internally it is using that function to first find markers within each group. Here, we list some additional arguments which provide for when using FindConservedMarkers():\n\n\nident.1: this function only evaluates one cluster at a time; here you would specify the cluster of interest.\n\ngrouping.var: the variable (column header) in your metadata which specifies the separation of cells into groups\n\nFindConservedMarkers函数会调用metap包，metap包需要multtest包，所以需要先安装这两个依赖包：\n\nBiocManager::install('multtest')\ninstall.packages('metap')\n\n寻找cluster 0的conserved markers\nFor our analysis we will be fairly lenient and use only the log fold change threshold greater than 0.25. We will also specify to return only the positive markers for each cluster.\nLet’s test it out on cluster 0 to see how it works:\n\ncluster0_conserved_markers &lt;- FindConservedMarkers(seurat_clustered_qc,\n                                                   ident.1 = 0,\n                                                   grouping.var = \"sample\",\n                                                   only.pos = TRUE,\n                                                   logfc.threshold = 0.25)\nhead(cluster0_conserved_markers)\n\n       stim_p_val stim_avg_log2FC stim_pct.1 stim_pct.2 stim_p_val_adj\nCCR7            0        1.481347      0.927      0.430              0\nSELL            0        1.724888      0.832      0.370              0\nLDHB            0        1.720061      0.732      0.304              0\nGIMAP7          0        1.463588      0.934      0.507              0\nLTB             0        1.538317      0.702      0.295              0\nRPL10A          0        1.216299      0.966      0.664              0\n          ctrl_p_val ctrl_avg_log2FC ctrl_pct.1 ctrl_pct.2 ctrl_p_val_adj\nCCR7    0.000000e+00       1.4694462      0.839      0.368   0.000000e+00\nSELL    0.000000e+00       2.0273581      0.610      0.186   0.000000e+00\nLDHB   2.056415e-293       1.4530062      0.734      0.356  2.892347e-289\nGIMAP7  0.000000e+00       1.4612133      0.804      0.380   0.000000e+00\nLTB     0.000000e+00       1.5963402      0.770      0.327   0.000000e+00\nRPL10A  0.000000e+00       0.9640366      0.969      0.809   0.000000e+00\n            max_pval minimump_p_val\nCCR7    0.000000e+00              0\nSELL    0.000000e+00              0\nLDHB   2.056415e-293              0\nGIMAP7  0.000000e+00              0\nLTB     0.000000e+00              0\nRPL10A  0.000000e+00              0\n\n\nThe output from the FindConservedMarkers function, is a matrix containing a ranked list of putative markers listed by gene ID for the cluster we specified, and associated statistics. Note that the same set of statistics are computed for each group (in our case, Ctrl and Stim) and the last two columns (max_pval和minimump_p_val) correspond to the combined p-value across the two groups. We describe some of these columns below:\n\n\ngene: gene symbol\n\ncondition_p_val(即本例中的“stim_p_val”和“ctrl_p_val”列，后面同理): p-value not adjusted for multiple test correction for condition\n\ncondition_avg_log2FC: average log fold change for condition. Positive values indicate that the gene is more highly expressed in the cluster.\n\ncondition_pct.1: percentage of cells where the gene is detected in the cluster for condition\n\ncondition_pct.2: percentage of cells where the gene is detected on average in the other clusters for condition\n\ncondition_p_val_adj: adjusted p-value for condition, based on bonferroni correction using all genes in the dataset, used to determine significance\n\nmax_pval: largest p value of p value calculated by each group/condition\n\nminimump_p_val: combined p value\n\n\n\n\n\n\n\nTip\n\n\n\nThe condition_p_val, condition_avg_log2FC, condition_pct.1, condition_pct.2, and condition_p_val_adj mean the same thing as they do in FindMarkers, just restricted to only the cells present in group X. The max_pval is the maximum p-value across all groups. The mimimump_p_val represents one way of doing a meta-analysis of significance values (combining p-values across different tests).\n(来自：https://github.com/satijalab/seurat/issues/1164)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nSince each cell is being treated as a replicate this will result in inflated p-values within each group! A gene may have an incredibly low p-value &lt; 1e-50 but that doesn’t translate as a highly reliable marker gene.\n\n\nWhen looking at the output, we suggest looking for markers with large differences in expression between pct.1 and pct.2 and larger fold changes. For instance if pct.1 = 0.90 and pct.2 = 0.80, it may not be as exciting of a marker. However, if pct.2 = 0.1 instead, the bigger difference would be more convincing. Also, of interest is if the majority of cells expressing the marker is in my cluster of interest. If pct.1 is low, such as 0.3, it may not be as interesting. Both of these are also possible parameters to include when running the function, as described above.\n添加基因注释信息\nIt can be helpful to add columns with gene annotation information. In order to do that we will load in an annotation file located in your data folder, using the code provided below:\n\nannotations &lt;- readRDS(\"data/scRNA-seq_online/annotations.rds\")\nhead(annotations, 3)\n\n          gene_id gene_name seq_name                       gene_biotype\n1 ENSG00000290825   DDX11L2        1                             lncRNA\n6 ENSG00000223972   DDX11L1        1 transcribed_unprocessed_pseudogene\n7 ENSG00000227232    WASH7P        1             unprocessed_pseudogene\n                                                                                    description\n1 DEAD/H-box helicase 11 like 2 (pseudogene) [Source:NCBI gene (formerly Entrezgene);Acc:84771]\n6                DEAD/H-box helicase 11 like 1 (pseudogene) [Source:HGNC Symbol;Acc:HGNC:37102]\n7                         WASP family homolog 7, pseudogene [Source:HGNC Symbol;Acc:HGNC:38034]\n\n\n该数据的”description”列即对基因的注释，下面我们把这一列通过匹配基因名将其添加到cluster0_conserved_markers数据框中。\n\n\n\n\n\n\n获取基因注释信息的方法\n\n\n\n\n\n首先从BiocManager安装AnnotationHub包和ensembldb包：\n\nBiocManager::install(\"AnnotationHub\")\nBiocManager::install(\"ensembldb\")\n\n从AnnotationHub下载并提取所需的注释信息数据库:\nTo access the various annotations available from Ensembl for human, we need to first connect to AnnotationHub, then specify the organism and database we are interested in.\n\n# 从AnnotationHub下载注释信息数据库\nlibrary(AnnotationHub)\nah &lt;- AnnotationHub()\nah\n\nAnnotationHub with 70762 records\n# snapshotDate(): 2023-10-20\n# $dataprovider: Ensembl, BroadInstitute, UCSC, ftp://ftp.ncbi.nlm.nih.gov/g...\n# $species: Homo sapiens, Mus musculus, Drosophila melanogaster, Bos taurus,...\n# $rdataclass: GRanges, TwoBitFile, BigWigFile, EnsDb, Rle, OrgDb, SQLiteFil...\n# additional mcols(): taxonomyid, genome, description,\n#   coordinate_1_based, maintainer, rdatadateadded, preparerclass, tags,\n#   rdatapath, sourceurl, sourcetype \n# retrieve records with, e.g., 'object[[\"AH5012\"]]' \n\n             title                              \n  AH5012   | Chromosome Band                    \n  AH5013   | STS Markers                        \n  AH5014   | FISH Clones                        \n  AH5015   | Recomb Rate                        \n  AH5016   | ENCODE Pilot                       \n  ...        ...                                \n  AH116159 | org.Aegialitis_vocifera.eg.sqlite  \n  AH116160 | org.Charadrius_vociferous.eg.sqlite\n  AH116161 | org.Charadrius_vociferus.eg.sqlite \n  AH116162 | org.Oxyechus_vociferus.eg.sqlite   \n  AH116163 | org.Drosophila_erecta.eg.sqlite    \n\nhead(unique(ah$species))\n\n[1] \"Homo sapiens\"         \"Vicugna pacos\"        \"Dasypus novemcinctus\"\n[4] \"Otolemur garnettii\"   \"Papio hamadryas\"      \"Papio anubis\"     \n\n# Access the Ensembl database for organism\nahDb &lt;- query(ah, \n              pattern = c(\"Homo sapiens\", \"EnsDb\"), \n              ignore.case = TRUE)\nahDb\n\nAnnotationHub with 25 records\n# snapshotDate(): 2023-10-20\n# $dataprovider: Ensembl\n# $species: Homo sapiens\n# $rdataclass: EnsDb\n# additional mcols(): taxonomyid, genome, description,\n#   coordinate_1_based, maintainer, rdatadateadded, preparerclass, tags,\n#   rdatapath, sourceurl, sourcetype \n# retrieve records with, e.g., 'object[[\"AH53211\"]]' \n\n             title                             \n  AH53211  | Ensembl 87 EnsDb for Homo Sapiens \n  AH53715  | Ensembl 88 EnsDb for Homo Sapiens \n  AH56681  | Ensembl 89 EnsDb for Homo Sapiens \n  AH57757  | Ensembl 90 EnsDb for Homo Sapiens \n  AH60773  | Ensembl 91 EnsDb for Homo Sapiens \n  ...        ...                               \n  AH100643 | Ensembl 106 EnsDb for Homo sapiens\n  AH104864 | Ensembl 107 EnsDb for Homo sapiens\n  AH109336 | Ensembl 108 EnsDb for Homo sapiens\n  AH109606 | Ensembl 109 EnsDb for Homo sapiens\n  AH113665 | Ensembl 110 EnsDb for Homo sapiens\nNext, we acquire the latest annotation files from this Ensembl database.\nWe can first check which annotation versions are available. Since we want the most recent, we will return the AnnotationHub ID for this database:\n\n# Acquire the latest annotation files\nid &lt;- ahDb |&gt;\n  mcols() |&gt;\n  rownames() |&gt;\n  tail(n = 1)\nid\n\n[1] \"AH113665\"\nFinally, we can use the AnnotationHub connection to download the appropriate Ensembl database.\n\n# Download the appropriate Ensembldb database\n# 需要开启全局代理\nedb &lt;- ah[[id]]\nedb\n\nEnsDb for Ensembl:\n|Backend: SQLite\n|Db type: EnsDb\n|Type of Gene ID: Ensembl Gene ID\n|Supporting package: ensembldb\n|Db created by: ensembldb package from Bioconductor\n|script_version: 0.3.10\n|Creation time: Mon Aug  7 09:02:07 2023\n|ensembl_version: 110\n|ensembl_host: 127.0.0.1\n|Organism: Homo sapiens\n|taxonomy_id: 9606\n|genome_build: GRCh38\n|DBSCHEMAVERSION: 2.2\n|common_name: human\n|species: homo_sapiens\n| No. of genes: 71440.\n| No. of transcripts: 278545.\n|Protein data available.\n提取并保存注释信息：\nAnd to extract gene-level information we can use the Ensembldb function genes() to return a data frame of annotations.\n\n# Extract gene-level information from database\nannotations &lt;- genes(edb, return.type = \"data.frame\")\ncolnames(annotations)\n\n[1] \"gene_id\"              \"gene_name\"            \"gene_biotype\"        \n[4] \"gene_seq_start\"       \"gene_seq_end\"         \"seq_name\"            \n[7] \"seq_strand\"           \"seq_coord_system\"     \"description\"         \n[10] \"gene_id_version\"      \"canonical_transcript\" \"symbol\"              \n[13] \"entrezid\"   \nWe aren’t interested in all of the information present in this annotations file, so we are going to extract that which is useful to us.\n\n# Select annotations of interest\nlibrary(dplyr)\nannotations &lt;- annotations |&gt;\n  select(gene_id, gene_name, seq_name, gene_biotype, description)\n\n保存到本地:\n\nsaveRDS(annotations, file = \"data/scRNA-seq_online/annotations.rds\")\n\n\n\n\nFirst, we will turn the row names with gene identifiers into its own columns. Then we will merge this annotation file with our results from the FindConservedMarkers():\n\n首先通过tibble包的rownames_to_column函数将“cluster0_conserved_markers”数据框的行名（基因symbol）转换成新的一列“gene”\n然后，通过dplyr包的left_join函数合并“cluster0_conserved_markers”数据（x）和“annotations”数据框的 “description”列（y）。通过匹配“cluster0_conserved_markers”数据中的“gene”列（上一步生成）和“annotations”数据的“gene_name”列来进行合并。同时，left_join会保留x（这里即上一步添加了“gene列”的“cluster0_conserved_markers”数据框）中的所有值；而删除y（“annotations”数据框）中用于匹配的那一列（即“gene_name”）\n\n\n# Combine markers with gene descriptions \nlibrary(tibble) # 调用rownames_to_column函数\nlibrary(dplyr) # 调用left_join函数\ncluster0_ann_markers &lt;- cluster0_conserved_markers |&gt;\n  rownames_to_column(var = \"gene\") |&gt; \n  # left_join保留x中的所有观测\n  left_join(y = unique(annotations[, c(\"gene_name\", \"description\")]),\n            by = c(\"gene\" = \"gene_name\"))\nhead(cluster0_ann_markers, 3)\n\n  gene stim_p_val stim_avg_log2FC stim_pct.1 stim_pct.2 stim_p_val_adj\n1 CCR7          0        1.481347      0.927      0.430              0\n2 SELL          0        1.724888      0.832      0.370              0\n3 LDHB          0        1.720061      0.732      0.304              0\n     ctrl_p_val ctrl_avg_log2FC ctrl_pct.1 ctrl_pct.2 ctrl_p_val_adj\n1  0.000000e+00        1.469446      0.839      0.368   0.000000e+00\n2  0.000000e+00        2.027358      0.610      0.186   0.000000e+00\n3 2.056415e-293        1.453006      0.734      0.356  2.892347e-289\n       max_pval minimump_p_val\n1  0.000000e+00              0\n2  0.000000e+00              0\n3 2.056415e-293              0\n                                                        description\n1 C-C motif chemokine receptor 7 [Source:HGNC Symbol;Acc:HGNC:1608]\n2                    selectin L [Source:HGNC Symbol;Acc:HGNC:10720]\n3        lactate dehydrogenase B [Source:HGNC Symbol;Acc:HGNC:6541]\n\n\n寻找cluster 10的conserved markers\nIn the previous lesson, we identified cluster 10 as FCGR3A+ monocytes by inspecting the expression of known cell markers FCGR3A and MS4A7.\n\nFeaturePlot(seurat_clustered_qc, \n            reduction = \"umap\", \n            features = c(\"FCGR3A\", \"MS4A7\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nNow, we use FindConservedMarkers() function to find conserved markers for cluster 10.\n\ncluster10_conserved_markers &lt;- FindConservedMarkers(seurat_clustered_qc,\n                                                    ident.1 = 10,\n                                                    grouping.var = \"sample\",\n                                                    only.pos = TRUE,\n                                                    logfc.threshold = 0.25)\n\ncluster10_ann_markers &lt;- cluster10_conserved_markers |&gt; \n  rownames_to_column(var=\"gene\") |&gt; \n  left_join(y = unique(annotations[, c(\"gene_name\", \"description\")]),\n            by = c(\"gene\" = \"gene_name\"))\nhead(cluster10_ann_markers)\n\n    gene stim_p_val stim_avg_log2FC stim_pct.1 stim_pct.2 stim_p_val_adj\n1 FCGR3A          0        5.208580      0.988      0.101              0\n2 MS4A4A          0        5.106558      0.893      0.051              0\n3  MS4A7          0        4.313442      0.995      0.159              0\n4 CXCL16          0        4.097853      0.924      0.108              0\n5   VMO1          0        7.808405      0.758      0.016              0\n6   LST1          0        3.195206      0.873      0.148              0\n  ctrl_p_val ctrl_avg_log2FC ctrl_pct.1 ctrl_pct.2 ctrl_p_val_adj max_pval\n1          0        4.391965      0.980      0.141              0        0\n2          0        5.623548      0.577      0.016              0        0\n3          0        4.307014      0.962      0.122              0        0\n4          0        3.467690      0.945      0.148              0        0\n5          0        6.478637      0.850      0.039              0        0\n6          0        3.288439      0.932      0.165              0        0\n  minimump_p_val\n1              0\n2              0\n3              0\n4              0\n5              0\n6              0\n                                                                   description\n1                    Fc gamma receptor IIIa [Source:HGNC Symbol;Acc:HGNC:3619]\n2          membrane spanning 4-domains A4A [Source:HGNC Symbol;Acc:HGNC:13371]\n3           membrane spanning 4-domains A7 [Source:HGNC Symbol;Acc:HGNC:13378]\n4          C-X-C motif chemokine ligand 16 [Source:HGNC Symbol;Acc:HGNC:16642]\n5 vitelline membrane outer layer 1 homolog [Source:HGNC Symbol;Acc:HGNC:30387]\n6          leukocyte specific transcript 1 [Source:HGNC Symbol;Acc:HGNC:14189]\n\n\n\n可以发现cluster10的FCGR3A和MS4A7的表达比例显著高于其他cluster。符合此前的判断。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#sec-function_to_find_markers",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#sec-function_to_find_markers",
    "title": "寻找marker基因+细胞注释",
    "section": "\n3.2 批量寻找多个clusters的conserved markers",
    "text": "3.2 批量寻找多个clusters的conserved markers\nThe function FindConservedMarkers() accepts a single cluster at a time, and we could run this function as many times as we have clusters. However, this is not very efficient. Instead we will first create a function to find the conserved markers including all the parameters we want to include. We will also add a few lines of code to modify the output. Our function will:\n\nRun the FindConservedMarkers() function\nTransfer row names to a column using rownames_to_column() function\nMerge in annotations\nCreate the column of cluster IDs using the cbind() function\n\n\n# Create function to get conserved markers for any given cluster\nget_conserved &lt;- function(cluster) {\n  FindConservedMarkers(seurat_clustered_qc,\n                       ident.1 = cluster,\n                       grouping.var = \"sample\",\n                       only.pos = TRUE) %&gt;%\n    rownames_to_column(var = \"gene\") %&gt;%\n    left_join(y = unique(annotations[, c(\"gene_name\", \"description\")]),\n               by = c(\"gene\" = \"gene_name\")) %&gt;%\n    cbind(cluster_id = cluster, .)\n  }\n\nNow that we have this function created we can use it as an argument to the appropriate map function. We want the output of the map family of functions to be a dataframe with each cluster output bound together by rows. （map函数输出的为一个list，通过list_rbind函数按照行组合列表中的每一个对象，并输出为数据框）\nNow, let’s try this function to find the conserved markers for the clusters that were identified as CD4+ T cells (4, 0, 6, 2) from our use of known marker genes.\n\nFeaturePlot(seurat_clustered_qc, \n            reduction = \"umap\", \n            features = c(\"CD3D\", \"IL7R\", \"CCR7\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\n\n\n\nLet’s see what genes we identify and of there are overlaps or obvious differences that can help us tease this apart a bit more.\n\nlibrary(purrr)\nconserved_markers &lt;- map(c(4, 0, 6, 2), get_conserved) |&gt; list_rbind()\n\n\n\n\n\n\n\nFinding markers for all clusters\n\n\n\nFor your data, you may want to run this function on all clusters, in which case you could input 0:20 instead of c(4,0,6,2). Also, it is possible that when you run this function on all clusters, in some cases you will have clusters that do not have enough cells for a particular group - and your function will fail. For these clusters you will need to use FindAllMarkers().\n\n\n获取top marker基因\nWe would like to use these gene lists to see of we can identify which celltypes these clusters identify with. Let’s take a look at the top genes for each of the clusters and see if that gives us any hints. We can view the top 10 markers by average fold change across the two groups, for each cluster for a quick perusal:\n\n首先通过dplyr包的mutate函数计算新的变量“avg_fc”，计算依据为：avg_fc = (ctrl_avg_log2FC + stim_avg_log2FC) /2\n然后通过dplyr包的group_by函数以“cluster_id”列为依据进行分组计算\n最后，通过dplyr包的slice_max函数取“avg_fc”（order_by = avg_fc）最大的前10行数据（n = 10）。由于group_by定义了分组计算，所以会输出每个cluster的前10个marker基因\n\n\n# 获取每个cluster的前10个marker基因\ntop_conserved_markers &lt;- conserved_markers %&gt;% \n  mutate(avg_fc = (ctrl_avg_log2FC + stim_avg_log2FC) /2) %&gt;% \n  group_by(cluster_id) %&gt;% \n  slice_max(n = 10, order_by = avg_fc)\n\n\n\n\n\n\n\n待解决的问题\n\n\n\n这里基于Seurat V5的运行结果和原教程的top markers结果不一致。原教程的top_conserved_markers如下：\n\n可能的原因：\n\n“In addition, in Seurat v5 we implement a pseudocount (when calculating log-FC) at the group level instead of the cell level. As a result, users will observe higher logFC estimates in v5 - but should note that these estimates may be more unstable - particularly for genes that are very lowly expressed in one of the two groups” ——Changes in Seurat v5\n\n这一小节的后续内容暂时以原教程的marker基因结果为准。\n\n\n根据top marker基因重新评估细胞群的注释结果\nWhen we look at the entire list, we see clusters 0 and 6 have some overlapping genes, like CCR7 and SELL which correspond to markers of memory T cells.\nIt is possible that these two clusters are more similar to one another and could be merged together as naive T cells. On the other hand, with cluster 2 we observe CREM as one of our top genes; a marker gene of activation. This suggests that perhaps cluster 2 represents activated T cells.\n\n\nCell State\nMarker\n\n\n\nNaive T cells\nCCR7, SELL\n\n\nActivated T cells\nCREM, CD69\n\n\n\nFor cluster 4, we see a lot of heat shock and DNA damage genes appear in the top gene list. Based on these markers, it is likely that these are stressed or dying cells. However, if we explore the quality metrics for these cells in more detail (i.e. mitoRatio and nUMI overlayed on the cluster) we don’t really support for this argument：\n\n# Visualize the distribution of mitochondrial gene expression detected per cell\n# cluster 4中每个细胞检测到的线粒体基因表达分布情况\nlibrary(ggplot2)\nseurat_clustered_qc %&gt;% \n  subset(idents = 4) %&gt;% \n  .@meta.data %&gt;% \n  ggplot(aes(color = sample, x = mitoRatio, fill = sample)) + \n  geom_density(alpha = 0.2) + \n  scale_x_log10() + \n  theme_classic() +\n  geom_vline(xintercept = 0.2)\n\n\n\n\n\n\n\n\nThere is a breadth of research supporting the association of heat shock proteins with reactive T cells in the induction of anti‐inflammatory cytokines in chronic inflammation. This is a cluster for which we would need a deeper understanding of immune cells to really tease apart the results and make a final conclusion.\n\nTo get a better idea of cell type identity for cluster 4 we can explore the expression of different identified markers by cluster using the FeaturePlot() function.\n\n# Plot interesting marker gene expression for cluster 4\nFeaturePlot(seurat_clustered_qc, \n            features = c(\"HSPH1\", \"HSPE1\", \"DNAJB1\"),\n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE,\n            repel = TRUE)\n\n\n\n\n\n\n# 提取cluster 4，并单独查看interesting marker gene在其中的表达情况\nsubset(seurat_clustered_qc, idents = 4) %&gt;% \n  FeaturePlot(\n            features = c(\"HSPH1\", \"HSPE1\", \"DNAJB1\"),\n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE,\n            repel = TRUE)\n\n\n\n\n\n\n\n\nWe see that only a subset of cluster 4 are highly expressing these genes.\n\nWe can also explore the range in expression of specific markers by using violin plots:\n\n# Vln plot - cluster 4\nVlnPlot(seurat_clustered_qc, \n        features = c(\"HSPH1\", \"HSPE1\", \"DNAJB1\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nViolin plots\n\n\n\n\n\nViolin plots are similar to box plots, except that they also show the probability density of the data at different values, usually smoothed by a kernel density estimator. A violin plot is more informative than a plain box plot. While a box plot only shows summary statistics such as mean/median and interquartile ranges, the violin plot shows the full distribution of the data. The difference is particularly useful when the data distribution is multimodal (more than one peak). In this case a violin plot shows the presence of different peaks, their position and relative amplitude.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#提取感兴趣细胞亚群进一步细分explore-a-subset-of-the-cell-types-to-discover-subclusters-of-cells",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#提取感兴趣细胞亚群进一步细分explore-a-subset-of-the-cell-types-to-discover-subclusters-of-cells",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.1 提取感兴趣细胞亚群进一步细分（Explore a subset of the cell types to discover subclusters of cells）",
    "text": "6.1 提取感兴趣细胞亚群进一步细分（Explore a subset of the cell types to discover subclusters of cells）\n鉴定完细胞类型后，接下来就是对鉴定的目标细胞群进行深入的研究。一般是提取目标亚群，然后在进一步细分。细胞再分群的意义在于进一步分析细胞的组成成分。见多个单细胞数据集整合分析（下）。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#单细胞差异分析perform-differential-expression-analysis-between-conditions",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#单细胞差异分析perform-differential-expression-analysis-between-conditions",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.2 单细胞差异分析（Perform differential expression analysis between conditions）\n",
    "text": "6.2 单细胞差异分析（Perform differential expression analysis between conditions）\n\n在实际研究中，往往需要研究两类细胞之间的差异，或者是某类细胞在不同处理样本间的差异基因情况，因此需要将待比较的细胞群单独拿出来进行分析。后面，我们在此前的章节中对如何寻找不同样本类型/条件间同一细胞类型内的差异基因进行了探索。\n除了分析细胞内基因表达的差异，也可以采用最常见的GO和KEGG富集分析，还可以进行GSEA、GSVA、SCENIC等分析，从功能、通路、基因调控网络等方面进行探究。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#免疫类群分析",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#免疫类群分析",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.3 免疫类群分析",
    "text": "6.3 免疫类群分析\n很多疾病的发生、发展都和免疫细胞有关，一般病灶组织内或者附近的免疫细胞较正常的组织会更丰富。为了将疾病中免疫反应描绘出来，可以采用以下分析策略：①对免疫细胞再分群，得到更多功能更加精细化的免疫细胞亚群；②免疫细胞类群在不同分组中的分布变化；③免疫细胞类群拟时序分析，探究不同疾病程度、不同发育阶段或者不同生理状态下的免疫反应机制。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#关键细胞的分化轨迹",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#关键细胞的分化轨迹",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.4 关键细胞的分化轨迹",
    "text": "6.4 关键细胞的分化轨迹\n最开始拿到的单细胞转录组测序数据，并未直接告诉我们每个细胞处在什么状态。因此，需要借助一些分析方法来实现轨迹上的排序，比如Monocle2拟时序分析/轨迹推断，ScVelo RNA速度分析等，推断潜在的细胞分化方向性，挖掘一些稀少的中间状态细胞，解析细胞分化过程中起调控作用的关键基因；也可以比较实验组/对照组中分化的差异。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#探索细胞-细胞互作",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#探索细胞-细胞互作",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.5 探索细胞-细胞互作",
    "text": "6.5 探索细胞-细胞互作\n每个细胞都能分泌细胞因子或者激素，这些细胞因子能够被周围细胞上的受体接收并用于调节相应的生理活动，细胞与细胞之间有相互联系，致病细胞可能是由于大类中某一种亚类细胞分化或者演化过来的；那么这些演化过程可能是由于其他细胞的细胞因子导致的。\n在锁定目标细胞类群之后，通过CellphoneDB细胞通讯分析、受体-配体分析等，找到与目标细胞相互作用的其他细胞类型，找到“直接”和“间接”的细胞调控网络。当然，对于已经筛选出目标基因了，也可以通过PPI分析找到基因/蛋白间的互作关系。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#挖掘关键调控转录因子",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#挖掘关键调控转录因子",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.6 挖掘关键调控转录因子",
    "text": "6.6 挖掘关键调控转录因子\n细胞异质性以及这种异质性是如何发展和维持的，在很大程度上是由潜在的基因调控网络决定的，特定转录因子（transcription factor，TF）集合的协同表达驱动各自靶标基因的表达，从而建立特定的基因表达谱；SCENIC是用来研究和破译基因调控的工具，能从单细胞转录组数据中推断TF、基因调控网络和细胞类型。其基本原理是基于共表达和DNA调控保守序列（motif）分析推断基因调控网络，然后在每个细胞中分析网络活性以鉴定细胞状态。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#湿实验验证探索潜在机制experimentally-validate-intriguing-markers-for-our-identified-cell-types",
    "href": "single_cell/scRNA-seq_online/09_merged_SC_marker_identification.html#湿实验验证探索潜在机制experimentally-validate-intriguing-markers-for-our-identified-cell-types",
    "title": "寻找marker基因+细胞注释",
    "section": "\n6.7 湿实验验证，探索潜在机制（Experimentally validate intriguing markers for our identified cell types）",
    "text": "6.7 湿实验验证，探索潜在机制（Experimentally validate intriguing markers for our identified cell types）\n除了以上单细胞测序数据相关分析以外，湿实验验证已逐渐成为单细胞分析的有力补充。比如用RT-qPCR/FISH等在RNA层面进行验证，用WB/免疫荧光/免疫组化/流式分析等在蛋白层面进行验证，还可以利用组织芯片或者TCGA数据库信息，进行临床水平的验证；也可以用细胞谱系示踪技术标记细胞 , 对关键细胞类群及其后代所有细胞的增殖、分化和迁移等活动进行追踪观察等；甚至可以利用流式分选出感兴趣的细胞群，然后对目的细胞群进行基因操作（上调/下调/敲除等），进行更深入的机制研究。总之，根据具体的实验目的，进行更完善的实验设计。\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.4      purrr_1.0.2        tibble_3.2.1       dplyr_1.1.4       \n[5] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] mathjaxr_1.6-0         RColorBrewer_1.1-3     rstudioapi_0.15.0     \n  [4] jsonlite_1.8.8         magrittr_2.0.3         ggbeeswarm_0.7.2      \n  [7] TH.data_1.1-2          spatstat.utils_3.0-4   farver_2.1.1          \n [10] rmarkdown_2.25         vctrs_0.6.5            multtest_2.58.0       \n [13] ROCR_1.0-11            spatstat.explore_3.2-5 htmltools_0.5.7       \n [16] plotrix_3.8-4          sctransform_0.4.1      parallelly_1.36.0     \n [19] KernSmooth_2.23-22     htmlwidgets_1.6.4      ica_1.0-3             \n [22] sandwich_3.1-0         plyr_1.8.9             plotly_4.10.4         \n [25] zoo_1.8-12             igraph_1.6.0           mime_0.12             \n [28] lifecycle_1.0.4        pkgconfig_2.0.3        Matrix_1.6-5          \n [31] R6_2.5.1               fastmap_1.1.1          rbibutils_2.2.16      \n [34] fitdistrplus_1.1-11    future_1.33.1          shiny_1.8.0           \n [37] numDeriv_2016.8-1.1    digest_0.6.34          colorspace_2.1-0      \n [40] patchwork_1.2.0        tensor_1.5             RSpectra_0.16-1       \n [43] irlba_2.3.5.1          labeling_0.4.3         progressr_0.14.0      \n [46] fansi_1.0.6            spatstat.sparse_3.0-3  httr_1.4.7            \n [49] TFisher_0.2.0          polyclip_1.10-6        abind_1.4-5           \n [52] compiler_4.3.2         withr_3.0.0            mutoss_0.1-13         \n [55] fastDummies_1.7.3      MASS_7.3-60.0.1        tools_4.3.2           \n [58] vipor_0.4.7            lmtest_0.9-40          beeswarm_0.4.0        \n [61] metap_1.9              httpuv_1.6.13          future.apply_1.11.1   \n [64] qqconf_1.3.2           goftest_1.2-3          glue_1.7.0            \n [67] nlme_3.1-164           promises_1.2.1         grid_4.3.2            \n [70] Rtsne_0.17             cluster_2.1.6          reshape2_1.4.4        \n [73] generics_0.1.3         gtable_0.3.4           spatstat.data_3.0-4   \n [76] tidyr_1.3.0            sn_2.1.1               data.table_1.14.10    \n [79] utf8_1.2.4             BiocGenerics_0.48.1    spatstat.geom_3.2-7   \n [82] RcppAnnoy_0.0.21       ggrepel_0.9.5          RANN_2.6.1            \n [85] pillar_1.9.0           stringr_1.5.1          spam_2.10-0           \n [88] RcppHNSW_0.5.0         limma_3.58.1           later_1.3.2           \n [91] splines_4.3.2          lattice_0.22-5         survival_3.5-7        \n [94] deldir_2.0-2           tidyselect_1.2.0       miniUI_0.1.1.1        \n [97] pbapply_1.7-2          knitr_1.45             gridExtra_2.3         \n[100] scattermore_1.2        stats4_4.3.2           xfun_0.41             \n[103] Biobase_2.62.0         statmod_1.5.0          matrixStats_1.2.0     \n[106] stringi_1.8.3          lazyeval_0.2.2         yaml_2.3.8            \n[109] evaluate_0.23          codetools_0.2-19       cli_3.6.2             \n[112] uwot_0.1.16            xtable_1.8-4           reticulate_1.34.0     \n[115] Rdpack_2.6             munsell_0.5.0          Rcpp_1.0.12           \n[118] globals_0.16.2         spatstat.random_3.2-2  png_0.1-8             \n[121] ggrastr_1.0.2          parallel_4.3.2         ellipsis_0.3.2        \n[124] presto_1.0.0           dotCall64_1.1-1        listenv_0.9.0         \n[127] viridisLite_0.4.2      mvtnorm_1.2-4          scales_1.3.0          \n[130] ggridges_0.5.5         leiden_0.4.3.1         rlang_1.1.3           \n[133] multcomp_1.4-25        mnormt_2.1.1           cowplot_1.1.2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "scRNA-seq_online学习材料",
      "寻找marker基因+细胞注释"
    ]
  },
  {
    "objectID": "single_cell/generation_of_count_matrix.html",
    "href": "single_cell/generation_of_count_matrix.html",
    "title": "单细胞RNA测序—从raw data到count matrix",
    "section": "",
    "text": "本节内容参考：Generation of count matrix\nDepending on the library preparation method used, the RNA sequences (also referred to as reads or tags), will be derived either from the 3’ ends (or 5’ ends) of the transcripts (10X Genomics, CEL-seq2, Drop-seq, inDrops) or from full-length transcripts (Smart-seq).\nThe choice of method involves the biological question of interest. The following advantages are listed below for the methods:\nMany of the same analysis steps need to occur for 3’-end sequencing as for full-length, but 3’ protocols have been increasing in popularity and consist of a few more steps in the analysis. Therefore, our materials are going to detail the analysis of data from these 3’ protocols with a focus on the droplet-based methods (inDrops, Drop-seq, 10X Genomics).",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞RNA测序---从raw data到count matrix"
    ]
  },
  {
    "objectID": "single_cell/generation_of_count_matrix.html#formatting-reads-and-filtering-noisy-cellular-barcodes",
    "href": "single_cell/generation_of_count_matrix.html#formatting-reads-and-filtering-noisy-cellular-barcodes",
    "title": "单细胞RNA测序—从raw data到count matrix",
    "section": "3.1 1. Formatting reads and filtering noisy cellular barcodes",
    "text": "3.1 1. Formatting reads and filtering noisy cellular barcodes\nThe FASTQ files can then be used to parse out the cell barcodes, UMIs, and sample barcodes. For droplet-based methods, many of the cellular barcodes will match a low number of reads (&lt; 1000 reads) due to:\n\nencapsulation of free floating RNA from dying cells\nsimple cells (RBCs, etc.) expressing few genes\ncells that failed for some reason\n\nThese excess barcodes need to be filtered out of the sequence data prior to read alignment. To do this filtering, the ‘cellular barcode’ and the ‘molecular barcode’ are extracted and saved for each cell. For example, if using ‘umis’ tools, the information is added to the header line for each read, with the following format:\n@HWI-ST808:130:H0B8YADXX:1:1101:2088:2222:CELL_GGTCCA:UMI_CCCT\nAGGAAGATGGAGGAGAGAAGGCGGTGAAAGAGACCTGTAAAAAGCCACCGN\n+\n@@@DDBD&gt;=AFCF+&lt;CAFHDECII:DGGGHGIGGIIIEHGIIIGIIDHII#\nKnown cellular barcodes used in the library preparation method should be known, and unknown barcodes would be dropped, while allowing for an acceptable number of mismatches to the known cellular barcodes.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞RNA测序---从raw data到count matrix"
    ]
  },
  {
    "objectID": "single_cell/generation_of_count_matrix.html#demultiplexing-sample-reads",
    "href": "single_cell/generation_of_count_matrix.html#demultiplexing-sample-reads",
    "title": "单细胞RNA测序—从raw data到count matrix",
    "section": "3.2 2. Demultiplexing sample reads",
    "text": "3.2 2. Demultiplexing sample reads\nThe next step of the process is to demultiplex the samples, if sequencing more than a single sample. This is the one step of this process not handled by the ‘umis’ tools, but is accomplished by ‘zUMIs’. We would need to parse the reads to determine the sample barcode associated with each cell.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞RNA测序---从raw data到count matrix"
    ]
  },
  {
    "objectID": "single_cell/generation_of_count_matrix.html#mappingpseudo-mapping-to-cdnas",
    "href": "single_cell/generation_of_count_matrix.html#mappingpseudo-mapping-to-cdnas",
    "title": "单细胞RNA测序—从raw data到count matrix",
    "section": "3.3 3. Mapping/pseudo-mapping to cDNAs",
    "text": "3.3 3. Mapping/pseudo-mapping to cDNAs\nTo determine which gene the read originated from, the reads are aligned using traditional (STAR) or light-weight methods (Kallisto/RapMap).",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞RNA测序---从raw data到count matrix"
    ]
  },
  {
    "objectID": "single_cell/generation_of_count_matrix.html#collapsing-umis-and-quantification-of-reads",
    "href": "single_cell/generation_of_count_matrix.html#collapsing-umis-and-quantification-of-reads",
    "title": "单细胞RNA测序—从raw data到count matrix",
    "section": "3.4 4. Collapsing UMIs and quantification of reads",
    "text": "3.4 4. Collapsing UMIs and quantification of reads\nThe duplicate UMIs are collapsed, and only the unique UMIs are quantified using a tool like Kallisto or featureCounts. The resulting output is a cell by gene matrix of counts:\n\n\nImage credit: (Lafzi et al. 2018)\n\nEach value in the matrix represents the number of reads in a cell originating from the corresponding gene. Using the count matrix, we can explore and filter the data, keeping only the higher quality cells.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞RNA测序---从raw data到count matrix"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html",
    "href": "single_cell/scRNA-seq_intro.html",
    "title": "单细胞测序技术介绍",
    "section": "",
    "text": "本节内容参考：\nIntroduction to single-cell RNA-seq\n单细胞转录组测序技术(scRNA-seq)及细胞分离技术分类汇总",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#细胞分离技术",
    "href": "single_cell/scRNA-seq_intro.html#细胞分离技术",
    "title": "单细胞测序技术介绍",
    "section": "2.1 细胞分离技术",
    "text": "2.1 细胞分离技术\n进行单细胞测序前，首先需要分离单个的细胞，不同类型的单细胞转录组测序技术，使用的细胞分离技术可能不一样。总的来说，目前主要有以下几类细胞分离技术：\n\nMicropipetting micromanipulation（口吸管技术）；\nLaser capture microdissection（激光捕获显微切割技术）；\nFluorescence activated Cell Sorting，FACS（流式细胞仪技术）；\nMicrodroplets（微滴技术）；\nMicrofluidics（微流体技术）；\n\nFACS是比较常用的方法，它可以获得随机样品，可以利用荧光标记的抗体获得细胞表面特异marker的细胞亚群，进而探究细胞亚群。允许将细胞分选到96或384孔板中进行后续的单细胞测序，但是FACS需要较大的细胞量，并且会出现一孔多个或一孔没有细胞的现象。另外，显微操作可以在特定位置对少量细胞进行获取，但是它耗费人力，高通量受限；微流控可以对整个分选过程进行监测，但是依赖固定的微流控芯片。\n这几类技术的优缺点具体如下图所示：\n\n\n单细胞转录组测序细胞分离技术分类及各自的优缺点(Kolodziejczyk et al. Molecular Cell, 2015)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#单细胞转录组测序技术",
    "href": "single_cell/scRNA-seq_intro.html#单细胞转录组测序技术",
    "title": "单细胞测序技术介绍",
    "section": "2.2 单细胞转录组测序技术",
    "text": "2.2 单细胞转录组测序技术\n单细胞转录组测序技术种类根据测序捕获的转录本序列范围主要可分为：\n\n测全长转录本（full-length transcript sequencing）的技术（如Smart-seq2、MATQ-seq 、SUPeR-seq等）\n\n优点：可测转录本的全长，基因数多，测序深度大，可进行各种类型的转录组测序数据分析\n缺点：细胞通量少，价格较贵\n\n只测转录本 3′ 或5′ 端（3′或5′-end sequencing）的技术（如10X Genomics, CEL-seq2, Drop-seq, inDrops等）\n优点：细胞通量高，价格便宜；\n缺点：只测转录本的一端，检测基因表达灵敏度较低，不适合进行可变剪接、等位基因表达等分析。\n\nSmart-seq2和10X Genomics是目前最主流的建库技术。Smart-seq2的重点是”测的少，但测得长“。它以单个细胞或10pg的RNA为模板，将Oligo(dT) VN Primer作为逆转录引物，利用逆转录酶的模板转换（Template-switching）活性，在cDNA的3’端添加一段接头序列，通过该接头序列进行后续PCR扩增，可以获得全长cDNA扩增产物。它对RNA质量要求高，RNA降解对引起5’端信息丢失。\n目前已有的主要单细胞转录组测序技术具体如下表所示 (Chen et al. Frontiers in Genetics, 2019)：",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#large-volume-of-data",
    "href": "single_cell/scRNA-seq_intro.html#large-volume-of-data",
    "title": "单细胞测序技术介绍",
    "section": "3.1 Large volume of data",
    "text": "3.1 Large volume of data\nExpression data from scRNA-seq experiments represent tens or hundreds of thousands of reads for thousands of cells. The data output is much larger, requiring higher amounts of memory to analyze, larger storage requirements, and more time to run the analyses.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#low-depth-of-sequencing-per-cell",
    "href": "single_cell/scRNA-seq_intro.html#low-depth-of-sequencing-per-cell",
    "title": "单细胞测序技术介绍",
    "section": "3.2 Low depth of sequencing per cell",
    "text": "3.2 Low depth of sequencing per cell\nFor the droplet-based methods of scRNA-seq, the depth of sequencing is shallow, often detecting only 10-50% of the transcriptome per cell. This results in cells showing zero counts for many of the genes. However, in a particular cell, a zero count for a gene could either mean that the gene was not being expressed or the transcripts were just not detected. Across cells, genes with higher levels of expression tend to have fewer zeros. Due to this feature, many genes will not be detected in any cell and gene expression will be highly variable between cells.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#zero-inflated",
    "href": "single_cell/scRNA-seq_intro.html#zero-inflated",
    "title": "单细胞测序技术介绍",
    "section": "3.3 Zero-inflated?",
    "text": "3.3 Zero-inflated?\nscRNA-seq data is often referred to as zero-inflated; however, recent analyses suggest that it does not contain more zeros than what would be expected given the sequencing depth (Valentine Svensson’s blog post). A more recent paper discussing modeling of scRNA-seq data is also available (Sarkar and Stephens 2021).",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#biological-variability-across-cellssamples",
    "href": "single_cell/scRNA-seq_intro.html#biological-variability-across-cellssamples",
    "title": "单细胞测序技术介绍",
    "section": "3.4 Biological variability across cells/samples",
    "text": "3.4 Biological variability across cells/samples\nUninteresting sources of biological variation can result in gene expression between cells being more similar/different than the actual biological cell types/states, which can obscure the cell type identities. Uninteresting sources of biological variation (unless part of the experiment’s study) include:\n\nTranscriptional bursting: Gene transcription is not turned on all of the time for all genes. Time of harvest will determine whether gene is on or off in each cell.\nVarying rates of RNA processing: Different RNAs are processed at different rates.\nContinuous or discrete cell identities (e.g. the pro-inflammatory potential of each individual T cell): Continuous phenotypes are by definition variable in gene expression, and separating the continuous from the discrete can sometimes be difficult.\nEnvironmental stimuli: The local environment of the cell can influence the gene expression depending on spatial position, signaling molecules, etc.\nTemporal changes: Fundamental fluxuating cellular processes, such as cell cycle, can affect the gene expression profiles of individual cells.\n\n\n\nImage credit: (Wagner, Regev, and Yosef 2016)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/scRNA-seq_intro.html#technical-variability-across-cellssamples",
    "href": "single_cell/scRNA-seq_intro.html#technical-variability-across-cellssamples",
    "title": "单细胞测序技术介绍",
    "section": "3.5 Technical variability across cells/samples",
    "text": "3.5 Technical variability across cells/samples\nTechnical sources of variation can result in gene expression between cells being more similar/different based on technical sources instead of biological cell types/states, which can obscure the cell type identities. Technical sources of variation include:\n\nCell-specific capture efficiency: Different cells will have differing numbers of transcripts captured resulting in differences in sequencing depth (e.g. 10-50% of transcriptome).\nLibrary quality: Degraded RNA, low viability/dying cells, lots of free floating RNA, poorly dissociated cells, and inaccurate quantitation of cells can result in low quality metrics\nAmplification bias: During the amplification step of library preparation, not all transcripts are amplified to the same level.\nBatch effects: Batch effects are a significant issue for scRNA-Seq analyses, since you can see significant differences in expression due solely to the batch effect.\n\n\nImage credit: (Hicks et al. 2017)\n\nTo explore the issues generated by poor batch study design, they are highlighted nicely in (Gilad and Mizrahi-Man 2015).\n\n\n\n\n\n\nHow to know whether you have batches?\n\n\n\n\nWere all RNA isolations performed on the same day?\nWere all library preparations performed on the same day?\nDid the same person perform the RNA isolation/library preparation for all samples?\nDid you use the same reagents for all samples?\nDid you perform the RNA isolation/library preparation in the same location?\n\nIf any of the answers is ‘No’, then you have batches.\n\n\nBest practices regarding batches:\n\nDesign the experiment in a way to avoid batches, if possible.\nIf unable to avoid batches:\n\nDo NOT confound your experiment by batch:\n\n\nImage credit: (Hicks et al. 2017)\n\nDO split replicates of the different sample groups across batches (在不同批次中对不同的样品组进行拆分重复). The more replicates the better (definitely more than 2), if doing DE across conditions or making conclusions at the population level. If using inDrops, which prepares a single library at a time, alternate the sample groups (e.g. don’t prepare all control libraries first, then prepare all treatment libraries).\n\n\nImage credit: (Hicks et al. 2017)\n\nDO include batch information in your experimental metadata. During the analysis, we can regress out variation due to batch or integrate across batches, so it doesn’t affect our results if we have that information.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "单细胞测序技术介绍"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html",
    "href": "single_cell/seurat/seurat_command_list.html",
    "title": "Seurat常用函数清单",
    "section": "",
    "text": "原文：Seurat Command List\n原文发布日期：2023年10月31日\n为了演示各函数的效果，这里的案例数据选取了在Seurat细胞分群官方教程中用到的包含了2700个细胞的外周血单核细胞数据（pbmc）。数据可在此链接下载。\nlibrary(Seurat)\n\n# 读取PBMC数据集\ncounts &lt;- Read10X(data.dir = \"data/seurat_official/filtered_gene_bc_matrices/hg19\")\n# Initialize the Seurat object with the raw (non-normalized data).\npbmc &lt;- CreateSeuratObject(counts = counts, \n                           project = \"pbmc3k\", \n                           min.cells = 3, \n                           min.features = 200)\npbmc\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 0 variable features)\n 1 layer present: counts",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat常用函数清单"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html#标准seurat流程基本函数",
    "href": "single_cell/seurat/seurat_command_list.html#标准seurat流程基本函数",
    "title": "Seurat常用函数清单",
    "section": "\n1 标准Seurat流程基本函数",
    "text": "1 标准Seurat流程基本函数\n见Seurat细胞分群官方教程。\n\npbmc &lt;- NormalizeData(object = pbmc)\npbmc &lt;- FindVariableFeatures(object = pbmc)\npbmc &lt;- ScaleData(object = pbmc)\npbmc &lt;- RunPCA(object = pbmc)\npbmc &lt;- FindNeighbors(object = pbmc, dims = 1:30)\npbmc &lt;- FindClusters(object = pbmc)\npbmc &lt;- RunUMAP(object = pbmc, dims = 1:30)\nDimPlot(object = pbmc, reduction = \"umap\")\n\n采用SCtransform标准化时的流程：\n详见基于SCTransform的单细胞数据标准化。\n\npbmc &lt;- SCTransform(object = pbmc, verbose = F)\npbmc &lt;- RunPCA(object = pbmc, verbose = F)\npbmc &lt;- FindNeighbors(object = pbmc, dims = 1:30, verbose = F)\npbmc &lt;- FindClusters(object = pbmc, verbose = F)\npbmc &lt;- RunUMAP(object = pbmc, dims = 1:30, verbose = F)\nDimPlot(object = pbmc, reduction = \"umap\")\n\n\n\n\n\n\n\n或者通过管道函数：\n\npbmc &lt;- SCTransform(pbmc) %&gt;%\n    RunPCA() %&gt;%\n    FindNeighbors(dims = 1:30) %&gt;%\n    FindClusters() %&gt;%\n    RunUMAP(dims = 1:30)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat常用函数清单"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html#提取seurat对象内的各数据",
    "href": "single_cell/seurat/seurat_command_list.html#提取seurat对象内的各数据",
    "title": "Seurat常用函数清单",
    "section": "\n2 提取Seurat对象内的各数据",
    "text": "2 提取Seurat对象内的各数据\n获取细胞、基因、assays、layers名称\n获取细胞的barcode：\n\ncolnames(pbmc)[1:10]\n\n [1] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\"\n [5] \"AAACCGTGTATGCG-1\" \"AAACGCACTGGTAC-1\" \"AAACGCTGACCAGT-1\" \"AAACGCTGGTTCTT-1\"\n [9] \"AAACGCTGTAGCCA-1\" \"AAACGCTGTTTCTG-1\"\n\nCells(pbmc)[1:10] # 效果同上\n\n [1] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\"\n [5] \"AAACCGTGTATGCG-1\" \"AAACGCACTGGTAC-1\" \"AAACGCTGACCAGT-1\" \"AAACGCTGGTTCTT-1\"\n [9] \"AAACGCTGTAGCCA-1\" \"AAACGCTGTTTCTG-1\"\n\n\n获取基因（feature）名。\n\nFeatures(pbmc)[1:10]\n\n [1] \"AL627309.1\"    \"RP11-206L10.2\" \"LINC00115\"     \"NOC2L\"        \n [5] \"KLHL17\"        \"PLEKHN1\"       \"HES4\"          \"ISG15\"        \n [9] \"AGRN\"          \"C1orf159\"     \n\nrownames(pbmc)[1:10] # 同上\n\n [1] \"AL627309.1\"    \"RP11-206L10.2\" \"LINC00115\"     \"NOC2L\"        \n [5] \"KLHL17\"        \"PLEKHN1\"       \"HES4\"          \"ISG15\"        \n [9] \"AGRN\"          \"C1orf159\"     \n\n\n可以指定提取哪一个assay下的基因名，如果未指定，则提取默认assay内的基因名。这里的pbmc数据经过了SCTransform，所以有两个assay，默认的归一化之后的“SCT”assay，另一个是原始的“RNA”assay。\n\n# 获取“SCT” assay下的基因名\nFeatures(pbmc[[\"SCT\"]])[1:10]\n\n [1] \"AL627309.1\"    \"RP11-206L10.2\" \"LINC00115\"     \"NOC2L\"        \n [5] \"KLHL17\"        \"PLEKHN1\"       \"HES4\"          \"ISG15\"        \n [9] \"AGRN\"          \"C1orf159\"     \n\n# 获取“RNA” assay下的基因名\nFeatures(pbmc[[\"RNA\"]])[1:10]\n\n [1] \"AL627309.1\"    \"AP006222.2\"    \"RP11-206L10.2\" \"RP11-206L10.9\"\n [5] \"LINC00115\"     \"NOC2L\"         \"KLHL17\"        \"PLEKHN1\"      \n [9] \"RP11-54O7.17\"  \"HES4\"         \n\n# 或\nFeatures(pbmc, assay = \"RNA\")[1:10]\n\n [1] \"AL627309.1\"    \"AP006222.2\"    \"RP11-206L10.2\" \"RP11-206L10.9\"\n [5] \"LINC00115\"     \"NOC2L\"         \"KLHL17\"        \"PLEKHN1\"      \n [9] \"RP11-54O7.17\"  \"HES4\"         \n\n\n也可以通过添加layer参数，提取指定layer下的基因名：\n\n# 提取“counts” layer下的基因名\nFeatures(pbmc, layer = \"counts\")[1:10]\n\n [1] \"AL627309.1\"    \"RP11-206L10.2\" \"LINC00115\"     \"NOC2L\"        \n [5] \"KLHL17\"        \"PLEKHN1\"       \"HES4\"          \"ISG15\"        \n [9] \"AGRN\"          \"C1orf159\"     \n\n# 提取\"scale.data\"的基因名\nFeatures(pbmc, layer = \"scale.data\")[1:10]\n\n [1] \"NOC2L\"    \"HES4\"     \"ISG15\"    \"TNFRSF18\" \"TNFRSF4\"  \"CPSF3L\"  \n [7] \"MRPL20\"   \"ATAD3C\"   \"SSU72\"    \"MIB2\"    \n\n\n获取细胞和基因的数量：\n\nncol(pbmc) # 细胞数量\n\n[1] 2700\n\nnrow(pbmc) # 基因（feature）数量\n\n[1] 12572\n\n\n获取高变基因列表\n详见识别高变基因（highly variable features）。\n\nVariableFeatures(pbmc)[1:10]\n\n [1] \"S100A9\" \"GNLY\"   \"LYZ\"    \"S100A8\" \"NKG7\"   \"FTL\"    \"GZMB\"   \"IGLL5\" \n [9] \"FTH1\"   \"CCL5\"  \n\n\n列出layers\n\n# 列出所有的layers\nLayers(pbmc)\n\n[1] \"counts\"     \"data\"       \"scale.data\"\n\n\n获取/设定assay：\n列出所有的assay，如”RNA” assay、运行SCTransform之后的”SCT” assay。一个Seurat对象可以包括多个assay对象，但是在某个时刻，只有一个assay对象是默认激活的。\n实际应用场景见此章节。\n\n# 列出所有的assay\nAssays(pbmc)\n\n[1] \"RNA\" \"SCT\"\n\n# 获取目前的默认assay名称\nDefaultAssay(pbmc)\n\n[1] \"SCT\"\n\n# 设定默认assay\nDefaultAssay(pbmc) &lt;- \"RNA\"\nDefaultAssay(pbmc) &lt;- \"SCT\"\n\n转换不同版本的Seurat对象：\n上面我们使用的pbmc对象使用V5版本的Seurat包创建的，可以通过如下命令查看：\n\n# 查看Seurat对象是用哪个版本的Seurat包创建的\npbmc@version\n\n[1] '5.0.1'\n\n\n这里我们导入在后续章节中用到的案例数据，这个Seurat对象是使用V4版本的Seurat包创建的。\n\nload(bzfile(\"data/scRNA-seq_online/additional_data/seurat_integrated.RData.bz2\"))\nseurat_integrated\n\nAn object of class Seurat \n31130 features across 29629 samples within 3 assays \nActive assay: integrated (3000 features, 3000 variable features)\n 2 layers present: data, scale.data\n 2 other assays present: RNA, SCT\n 2 dimensional reductions calculated: pca, umap\n\nseurat_integrated@version\n\n[1] '4.1.0'\n\n\n\n可以看到，这个seurat_integrated对象的“RNA” assay没有layers结构，是典型的V5版本之前的Seurat对象的结构。我们可以通过as()函数将V4或V3版本的“RNA” assay转换成V5版本的“RNA” assay：\n\n# convert a v4 or v3 assay to a v5 assay\nseurat_integrated[[\"RNA5\"]] &lt;- as(object = seurat_integrated[[\"RNA\"]], \n                                  Class = \"Assay5\")\nDefaultAssay(seurat_integrated) = \"RNA5\"\n\n\n转换后seurat_integrated[[“RNA5”]]里面是V5版的Seurat结构。如果不想要原来的“RNA” assay可以将其删除：\n\nseurat_integrated[[\"RNA\"]] &lt;- NULL\n\n也可以将V5版本的“RNA” assay转换成V4或V3版本的“RNA” assay：\n\n# convert a v5 assay to a v4 or v3 assay\npbmc[[\"RNA3\"]] &lt;- as(object = pbmc[[\"RNA\"]], Class = \"Assay\")\n\n\n获取细胞注释信息（cell identities）\n查看cell identities：\n即细胞的类型，在Seurat对象中，细胞可能有好几种不同方法注释的类型，但是在某一时刻，只有一种细胞类型是默认激活的。\n\nIdents(pbmc)[1:5]\n\nAAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n               4                2                0                5 \nAAACCGTGTATGCG-1 \n               6 \nLevels: 0 1 2 3 4 5 6 7 8 9 10 11 12\n\ntable(Idents(pbmc))\n\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12 \n491 485 361 316 229 182 157 153 138 100  42  34  12 \n\n# 查看目前cell identities的水平\nlevels(pbmc)\n\n [1] \"0\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n设定细胞identities：\n实际应用场景见后续章节。\n\n# 将meta.data中的\"seurat_clusters\"列设置为cell identities\nIdents(pbmc) &lt;- \"seurat_clusters\"\n\n# 重命名细胞注释标签或重新排序细胞类型标签\nIdents(pbmc) &lt;- factor(Idents(pbmc), \n                       levels = levels(pbmc),\n                       labels = c(\"pDC\", \"Mk\", \"DC\", \"CD14 Mono\", \"CD16 Mono\", \n                                  \"B Activated\", \"B\", \"CD8 T\", \"NK\", \"T activated\", \n                                  \"CD4 Naive T\", \"CD4 Memory T\", \"epi\"))\nIdents(pbmc) |&gt; unique()\n\n [1] CD16 Mono    DC           pDC          B Activated  B           \n [6] CD8 T        Mk           CD14 Mono    T activated  CD4 Naive T \n[11] CD4 Memory T NK           epi         \n13 Levels: pDC Mk DC CD14 Mono CD16 Mono B Activated B CD8 T NK ... epi\n\n\n将目前的cell identities保存到meta.data新的一列中：\n\n# 将目前的cell identities储存到meta.data的\"old.ident\"列中\npbmc[[\"old.ident\"]] &lt;- Idents(pbmc) \n\n重命名某个cell identities：\n\npbmc &lt;- RenameIdents(pbmc, \n                     \"B\" = \"B cell\")\nIdents(pbmc) |&gt; unique()\n\n [1] CD16 Mono    DC           pDC          B Activated  B cell      \n [6] CD8 T        Mk           CD14 Mono    T activated  CD4 Naive T \n[11] CD4 Memory T NK           epi         \n13 Levels: B cell pDC Mk DC CD14 Mono CD16 Mono B Activated CD8 T ... epi\n\n\n获取meta.data\n\n# View metadata data frame, stored in object@meta.data\npbmc@meta.data |&gt; head()\n\n                 orig.ident nCount_RNA nFeature_RNA nCount_SCT nFeature_SCT\nAAACATACAACCAC-1     pbmc3k       2419          779       2275          769\nAAACATTGAGCTAC-1     pbmc3k       4903         1352       2597         1126\nAAACATTGATCAGC-1     pbmc3k       3147         1129       2469         1111\nAAACCGTGCTTCCG-1     pbmc3k       2639          960       2343          942\nAAACCGTGTATGCG-1     pbmc3k        980          521       1901          551\nAAACGCACTGGTAC-1     pbmc3k       2163          781       2148          767\n                 SCT_snn_res.0.8 seurat_clusters nCount_RNA3 nFeature_RNA3\nAAACATACAACCAC-1               4               4        2419           779\nAAACATTGAGCTAC-1               2               2        4903          1352\nAAACATTGATCAGC-1               0               0        3147          1129\nAAACCGTGCTTCCG-1               5               5        2639           960\nAAACCGTGTATGCG-1               6               6         980           521\nAAACGCACTGGTAC-1               0               0        2163           781\n                   old.ident\nAAACATACAACCAC-1   CD16 Mono\nAAACATTGAGCTAC-1          DC\nAAACATTGATCAGC-1         pDC\nAAACCGTGCTTCCG-1 B Activated\nAAACCGTGTATGCG-1           B\nAAACGCACTGGTAC-1         pDC\n\n# 或\npbmc[[]] |&gt; head()\n\n                 orig.ident nCount_RNA nFeature_RNA nCount_SCT nFeature_SCT\nAAACATACAACCAC-1     pbmc3k       2419          779       2275          769\nAAACATTGAGCTAC-1     pbmc3k       4903         1352       2597         1126\nAAACATTGATCAGC-1     pbmc3k       3147         1129       2469         1111\nAAACCGTGCTTCCG-1     pbmc3k       2639          960       2343          942\nAAACCGTGTATGCG-1     pbmc3k        980          521       1901          551\nAAACGCACTGGTAC-1     pbmc3k       2163          781       2148          767\n                 SCT_snn_res.0.8 seurat_clusters nCount_RNA3 nFeature_RNA3\nAAACATACAACCAC-1               4               4        2419           779\nAAACATTGAGCTAC-1               2               2        4903          1352\nAAACATTGATCAGC-1               0               0        3147          1129\nAAACCGTGCTTCCG-1               5               5        2639           960\nAAACCGTGTATGCG-1               6               6         980           521\nAAACGCACTGGTAC-1               0               0        2163           781\n                   old.ident\nAAACATACAACCAC-1   CD16 Mono\nAAACATTGAGCTAC-1          DC\nAAACATTGATCAGC-1         pDC\nAAACCGTGCTTCCG-1 B Activated\nAAACCGTGTATGCG-1           B\nAAACGCACTGGTAC-1         pDC\n\n# 如果是展示前6行的话也可以直接这样写：\nhead(pbmc)\n\n                 orig.ident nCount_RNA nFeature_RNA nCount_SCT nFeature_SCT\nAAACATACAACCAC-1     pbmc3k       2419          779       2275          769\nAAACATTGAGCTAC-1     pbmc3k       4903         1352       2597         1126\nAAACATTGATCAGC-1     pbmc3k       3147         1129       2469         1111\nAAACCGTGCTTCCG-1     pbmc3k       2639          960       2343          942\nAAACCGTGTATGCG-1     pbmc3k        980          521       1901          551\nAAACGCACTGGTAC-1     pbmc3k       2163          781       2148          767\nAAACGCTGACCAGT-1     pbmc3k       2175          782       2158          764\nAAACGCTGGTTCTT-1     pbmc3k       2260          790       2204          773\nAAACGCTGTAGCCA-1     pbmc3k       1275          532       1905          523\nAAACGCTGTTTCTG-1     pbmc3k       1103          550       1988          557\n                 SCT_snn_res.0.8 seurat_clusters nCount_RNA3 nFeature_RNA3\nAAACATACAACCAC-1               4               4        2419           779\nAAACATTGAGCTAC-1               2               2        4903          1352\nAAACATTGATCAGC-1               0               0        3147          1129\nAAACCGTGCTTCCG-1               5               5        2639           960\nAAACCGTGTATGCG-1               6               6         980           521\nAAACGCACTGGTAC-1               0               0        2163           781\nAAACGCTGACCAGT-1               4               4        2175           782\nAAACGCTGGTTCTT-1               4               4        2260           790\nAAACGCTGTAGCCA-1               4               4        1275           532\nAAACGCTGTTTCTG-1               7               7        1103           550\n                   old.ident\nAAACATACAACCAC-1   CD16 Mono\nAAACATTGAGCTAC-1          DC\nAAACATTGATCAGC-1         pDC\nAAACCGTGCTTCCG-1 B Activated\nAAACCGTGTATGCG-1           B\nAAACGCACTGGTAC-1         pDC\nAAACGCTGACCAGT-1   CD16 Mono\nAAACGCTGGTTCTT-1   CD16 Mono\nAAACGCTGTAGCCA-1   CD16 Mono\nAAACGCTGTTTCTG-1       CD8 T\n\n# Retrieve specific values from the metadata\npbmc$nCount_RNA[1:5]\n\nAAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n            2419             4903             3147             2639 \nAAACCGTGTATGCG-1 \n             980 \n\npbmc[[c(\"nCount_RNA\", \"nFeature_RNA\")]][1:5,]\n\n                 nCount_RNA nFeature_RNA\nAAACATACAACCAC-1       2419          779\nAAACATTGAGCTAC-1       4903         1352\nAAACATTGATCAGC-1       3147         1129\nAAACCGTGCTTCCG-1       2639          960\nAAACCGTGTATGCG-1        980          521\n\n# Add metadata, see ?AddMetaData\nrandom_group_labels &lt;- c(rep(\"Cancer\", nrow(pbmc@meta.data)/2), \n                         rep(\"Control\", nrow(pbmc@meta.data)/2))\npbmc$groups &lt;- random_group_labels\n\n获取表达量信息 (stored as layers in Seurat v5)\n\n# Retrieve data in an expression matrix RNA counts matrix\npbmc[[\"RNA\"]]$counts[1:5, 1:5]\n\n5 x 5 sparse Matrix of class \"dgCMatrix\"\n              AAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1\nAL627309.1                   .                .                .\nAP006222.2                   .                .                .\nRP11-206L10.2                .                .                .\nRP11-206L10.9                .                .                .\nLINC00115                    .                .                .\n              AAACCGTGCTTCCG-1 AAACCGTGTATGCG-1\nAL627309.1                   .                .\nAP006222.2                   .                .\nRP11-206L10.2                .                .\nRP11-206L10.9                .                .\nLINC00115                    .                .\n\n# 或\nLayerData(pbmc, assay = \"RNA\", layer = \"counts\")[1:5, 1:5]\n\n5 x 5 sparse Matrix of class \"dgCMatrix\"\n              AAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1\nAL627309.1                   .                .                .\nAP006222.2                   .                .                .\nRP11-206L10.2                .                .                .\nRP11-206L10.9                .                .                .\nLINC00115                    .                .                .\n              AAACCGTGCTTCCG-1 AAACCGTGTATGCG-1\nAL627309.1                   .                .\nAP006222.2                   .                .\nRP11-206L10.2                .                .\nRP11-206L10.9                .                .\nLINC00115                    .                .\n\n\n\n# Set expression data assume new.data is a new expression matrix\npbmc[[\"RNA\"]]$counts &lt;- new.data\n# 或\nLayerData(pbmc, assay = \"RNA\", layer = \"counts\") &lt;- new.data\n\n获取PCA降维信息\n实际应用场景见分析主成分（PCs）对细胞分群的影响。\n\n# 获取细胞在所有主成分上的评分（坐标）\nEmbeddings(pbmc, reduction = \"pca\")[1:5, 1:5]\n\n                       PC_1       PC_2       PC_3       PC_4        PC_5\nAAACATACAACCAC-1 -10.165852   1.087645   5.471643 -0.4546899  0.41257085\nAAACATTGAGCTAC-1  -5.814405 -11.244759 -13.092125 -0.4389098  0.05922870\nAAACATTGATCAGC-1  -8.565823   1.643337   5.732506  2.4871682  2.55774745\nAAACCGTGCTTCCG-1  25.632631  -1.695688  -2.335731  3.8829838  0.02413971\nAAACCGTGTATGCG-1  -2.536685  21.282498  -9.103048 -5.1031745 -2.71944035\n\n# 或\npbmc[['pca']]@cell.embeddings[1:5, 1:5]\n\n                       PC_1       PC_2       PC_3       PC_4        PC_5\nAAACATACAACCAC-1 -10.165852   1.087645   5.471643 -0.4546899  0.41257085\nAAACATTGAGCTAC-1  -5.814405 -11.244759 -13.092125 -0.4389098  0.05922870\nAAACATTGATCAGC-1  -8.565823   1.643337   5.732506  2.4871682  2.55774745\nAAACCGTGCTTCCG-1  25.632631  -1.695688  -2.335731  3.8829838  0.02413971\nAAACCGTGTATGCG-1  -2.536685  21.282498  -9.103048 -5.1031745 -2.71944035\n\n# 获取基因在所有主成分上的评分（坐标）\nLoadings(pbmc, reduction = \"pca\")[1:5, 1:5]\n\n              PC_1         PC_2        PC_3        PC_4         PC_5\nS100A9  0.19825859 -0.008571611  0.09650808 -0.28883733 -0.005721886\nGNLY   -0.02330150  0.195582622 -0.10436066 -0.06562367 -0.093134754\nLYZ     0.23833773 -0.023491803  0.06414334 -0.26984270 -0.010442604\nS100A8  0.16884448 -0.007179440  0.09962703 -0.29729996 -0.001143372\nNKG7   -0.04601942  0.296816129 -0.13906341 -0.08608150 -0.061192287\n\n# 或\npbmc[[\"pca\"]]@feature.loadings[1:5, 1:5]\n\n              PC_1         PC_2        PC_3        PC_4         PC_5\nS100A9  0.19825859 -0.008571611  0.09650808 -0.28883733 -0.005721886\nGNLY   -0.02330150  0.195582622 -0.10436066 -0.06562367 -0.093134754\nLYZ     0.23833773 -0.023491803  0.06414334 -0.26984270 -0.010442604\nS100A8  0.16884448 -0.007179440  0.09962703 -0.29729996 -0.001143372\nNKG7   -0.04601942  0.296816129 -0.13906341 -0.08608150 -0.061192287\n\n# 提取PCA信息中的第二主成分，并展示对该主成分影响最大的前5个基因名\nprint(pbmc[[\"pca\"]], dims = 2, nfeatures = 5)\n\nPC_ 2 \nPositive:  NKG7, CCL5, GZMB, GNLY, GZMA \nNegative:  HLA-DRA, CD74, CD79A, HLA-DPB1, HLA-DQA1 \n\n\n\n# Create custom dimensional reduction loadings matrix is optional\nnew_reduction &lt;- CreateDimReducObject(embeddings = new.embeddings, \n                                      loadings = new.loadings, \n                                      key = \"custom_pca\")\n# 或\npbmc[[\"custom_pca\"]] &lt;- new_reduction\n\n通过FetchData从Seurat对象中获取任意信息\nFetchData can access anything from expression matrices, cell embeddings, or metadata use the previously listed commands to access entire matrices。通过FetchData可以提取包括表达量数据、PCA分数以及meta.data内的任何变量并形成一个数据框。实际应用场景见分析主成分（PCs）对细胞分群的影响。\n\nFetchData(object = pbmc, \n          vars = c(\"PC_1\", \"nFeature_RNA\", \"MS4A1\"), \n          layer = \"counts\") |&gt; head()\n\n                       PC_1 nFeature_RNA MS4A1\nAAACATACAACCAC-1 -10.165852          779     0\nAAACATTGAGCTAC-1  -5.814405         1352     4\nAAACATTGATCAGC-1  -8.565823         1129     0\nAAACCGTGCTTCCG-1  25.632631          960     0\nAAACCGTGTATGCG-1  -2.536685          521     0\nAAACGCACTGGTAC-1  -6.559842          781     0",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat常用函数清单"
    ]
  },
  {
    "objectID": "single_cell/seurat/seurat_command_list.html#seurat对象取子集和合并",
    "href": "single_cell/seurat/seurat_command_list.html#seurat对象取子集和合并",
    "title": "Seurat常用函数清单",
    "section": "\n3 Seurat对象取子集和合并",
    "text": "3 Seurat对象取子集和合并\n取子集\n实际应用见过滤细胞。\n\n# 根据meta data中的信息取子集\nsubset(x = pbmc, subset = groups == \"Cancer\")\n\nAn object of class Seurat \n40000 features across 1350 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n# 提取特定cell identities, also see ?SubsetData\nsubset(x = pbmc, idents = \"B cell\")\n\nAn object of class Seurat \n40000 features across 157 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n# 反选\nsubset(x = pbmc, idents = c(\"CD4 Naive T\", \"CD8 T\"), invert = TRUE)\n\nAn object of class Seurat \n40000 features across 2505 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n# 根据特定gene/feature表达水平取子集\nsubset(x = pbmc, subset = S100A9 &gt; 1.5)\n\nAn object of class Seurat \n40000 features across 519 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n# 采用多个标准取子集\nsubset(x = pbmc, subset = S100A9 &gt; 1.5 & PC_1 &gt; 5)\n\nAn object of class Seurat \n40000 features across 517 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\nsubset(x = pbmc, subset = S100A9 &gt; 1.5, idents = \"CD8 T\")\n\nAn object of class Seurat \n40000 features across 45 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n# Downsample the number of cells per identity class\nsubset(x = pbmc, downsample = 100)\n\nAn object of class Seurat \n40000 features across 1088 samples within 3 assays \nActive assay: SCT (12572 features, 3000 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: RNA, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n\n分割layers\nIn Seurat v5, users can now split in object directly into different layers keeps expression data in one object, but splits multiple samples into layers can proceed directly to integration workflow after splitting layers。实际应用场景见数据整合。\n\nDefaultAssay(pbmc) &lt;- \"RNA\"\n# 按照meta.data中的stim列分割layer\npbmc[[\"RNA\"]] &lt;- split(pbmc[[\"RNA\"]], f = pbmc$groups)\n\n\n如果需要，例如在整合之后，可以将各layers再次合并在一起：\n\npbmc[[\"RNA\"]] &lt;- JoinLayers(pbmc[[\"RNA\"]])\n\n分割Seurat\nIn line with prior workflows, you can also split your Seurat object into a list of multiple objects based on a metadata column creates a list of two objects。通过SplitObject()分割Seurat之后生成的是包含多个Seurat对象的列表。\n\nseurat_list &lt;- SplitObject(pbmc, split.by = \"groups\")\nseurat_list\n\n$Cancer\nAn object of class Seurat \n40000 features across 1350 samples within 3 assays \nActive assay: RNA (13714 features, 0 variable features)\n 1 layer present: counts\n 2 other assays present: SCT, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n$Control\nAn object of class Seurat \n40000 features across 1350 samples within 3 assays \nActive assay: RNA (13714 features, 0 variable features)\n 1 layer present: counts\n 2 other assays present: SCT, RNA3\n 2 dimensional reductions calculated: pca, umap\n\n\n\nMerge objects (without integration)\nIn Seurat v5, merging creates a single object, but keeps the expression information split into different layers for integration. If not proceeding with integration, rejoin the layers after merging. 实际应用场景，见后续章节。\n\n# Merge two Seurat objects\nmerged_pbmc &lt;- merge(x = seurat_list[[\"Control\"]], \n                     y = seurat_list[[\"Cancer\"]])\n\n\n\n# Example to merge more than two Seurat objects\nmerge(x = pbmc1, \n      y = list(pbmc2, pbmc3))\n\nMerge objects (with integration)\n关于单细胞数据的整合，参考后续章节。\n\nmerged_pbmc &lt;- NormalizeData(merged_pbmc, verbose = F)\nmerged_pbmc &lt;- FindVariableFeatures(merged_pbmc, verbose = F)\nmerged_pbmc &lt;- ScaleData(merged_pbmc, verbose = F)\nmerged_pbmc &lt;- RunPCA(merged_pbmc, verbose = F)\nmerged_pbmc &lt;- IntegrateLayers(object = merged_pbmc, \n                               method = RPCAIntegration, \n                               orig.reduction = \"pca\", \n                               new.reduction = \"integrated.rpca\",\n                               verbose = FALSE)\n\n# now that integration is complete, rejoin layers\nmerged_pbmc[[\"RNA\"]] &lt;- JoinLayers(merged_pbmc[[\"RNA\"]])\nmerged_pbmc\n\nAn object of class Seurat \n40000 features across 2700 samples within 3 assays \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: data, counts, scale.data\n 2 other assays present: SCT, RNA3\n 2 dimensional reductions calculated: pca, integrated.rpca\n\n\n\n\n\n\n\n\n\nAdditional resources\n\n\n\nUsers who are particularly interested in some of the technical changes to data storage in Seurat v5 can explore the following resources:\n\nSeuratObject manual\nSeurat v5 and Assay5 introductory vignette\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.8              magrittr_2.0.3             \n  [5] spatstat.utils_3.0-4        farver_2.1.1               \n  [7] rmarkdown_2.25              zlibbioc_1.48.0            \n  [9] vctrs_0.6.5                 ROCR_1.0-11                \n [11] DelayedMatrixStats_1.24.0   spatstat.explore_3.2-5     \n [13] RCurl_1.98-1.14             S4Arrays_1.2.0             \n [15] htmltools_0.5.7             SparseArray_1.2.3          \n [17] sctransform_0.4.1           parallelly_1.36.0          \n [19] KernSmooth_2.23-22          htmlwidgets_1.6.4          \n [21] ica_1.0-3                   plyr_1.8.9                 \n [23] plotly_4.10.4               zoo_1.8-12                 \n [25] igraph_1.6.0                mime_0.12                  \n [27] lifecycle_1.0.4             pkgconfig_2.0.3            \n [29] Matrix_1.6-5                R6_2.5.1                   \n [31] fastmap_1.1.1               GenomeInfoDbData_1.2.11    \n [33] MatrixGenerics_1.14.0       fitdistrplus_1.1-11        \n [35] future_1.33.1               shiny_1.8.0                \n [37] digest_0.6.34               colorspace_2.1-0           \n [39] patchwork_1.2.0             S4Vectors_0.40.2           \n [41] tensor_1.5                  RSpectra_0.16-1            \n [43] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [45] labeling_0.4.3              progressr_0.14.0           \n [47] fansi_1.0.6                 spatstat.sparse_3.0-3      \n [49] httr_1.4.7                  polyclip_1.10-6            \n [51] abind_1.4-5                 compiler_4.3.2             \n [53] withr_3.0.0                 fastDummies_1.7.3          \n [55] R.utils_2.12.3              MASS_7.3-60.0.1            \n [57] DelayedArray_0.28.0         tools_4.3.2                \n [59] lmtest_0.9-40               httpuv_1.6.13              \n [61] future.apply_1.11.1         goftest_1.2-3              \n [63] R.oo_1.25.0                 glmGamPoi_1.14.0           \n [65] glue_1.7.0                  nlme_3.1-164               \n [67] promises_1.2.1              grid_4.3.2                 \n [69] Rtsne_0.17                  cluster_2.1.6              \n [71] reshape2_1.4.4              generics_0.1.3             \n [73] gtable_0.3.4                spatstat.data_3.0-4        \n [75] R.methodsS3_1.8.2           tidyr_1.3.0                \n [77] data.table_1.14.10          XVector_0.42.0             \n [79] utf8_1.2.4                  BiocGenerics_0.48.1        \n [81] spatstat.geom_3.2-7         RcppAnnoy_0.0.21           \n [83] ggrepel_0.9.5               RANN_2.6.1                 \n [85] pillar_1.9.0                stringr_1.5.1              \n [87] spam_2.10-0                 RcppHNSW_0.5.0             \n [89] later_1.3.2                 splines_4.3.2              \n [91] dplyr_1.1.4                 lattice_0.22-5             \n [93] survival_3.5-7              deldir_2.0-2               \n [95] tidyselect_1.2.0            miniUI_0.1.1.1             \n [97] pbapply_1.7-2               knitr_1.45                 \n [99] gridExtra_2.3               IRanges_2.36.0             \n[101] SummarizedExperiment_1.32.0 scattermore_1.2            \n[103] stats4_4.3.2                xfun_0.41                  \n[105] Biobase_2.62.0              matrixStats_1.2.0          \n[107] stringi_1.8.3               lazyeval_0.2.2             \n[109] yaml_2.3.8                  evaluate_0.23              \n[111] codetools_0.2-19            tibble_3.2.1               \n[113] cli_3.6.2                   uwot_0.1.16                \n[115] xtable_1.8-4                reticulate_1.34.0          \n[117] munsell_0.5.0               Rcpp_1.0.12                \n[119] GenomeInfoDb_1.38.5         globals_0.16.2             \n[121] spatstat.random_3.2-2       png_0.1-8                  \n[123] parallel_4.3.2              ellipsis_0.3.2             \n[125] ggplot2_3.4.4               dotCall64_1.1-1            \n[127] sparseMatrixStats_1.14.0    bitops_1.0-7               \n[129] listenv_0.9.0               viridisLite_0.4.2          \n[131] scales_1.3.0                ggridges_0.5.5             \n[133] crayon_1.5.2                leiden_0.4.3.1             \n[135] purrr_1.0.2                 rlang_1.1.3                \n[137] cowplot_1.1.2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat常用函数清单"
    ]
  },
  {
    "objectID": "single_cell/seurat/sctransform.html",
    "href": "single_cell/seurat/sctransform.html",
    "title": "基于SCTransform的单细胞数据标准化",
    "section": "",
    "text": "原文：Using sctransform in Seurat\n原文发布日期：2023年10月31日\nBiological heterogeneity in single-cell RNA-seq data is often confounded by technical factors including sequencing depth. The number of molecules detected in each cell can vary significantly between cells, even within the same celltype. Interpretation of scRNA-seq data requires effective pre-processing and normalization to remove this technical variability.\nIn our manuscript we introduce a modeling framework for the normalization and variance stabilization of molecular count data from scRNA-seq experiments. This procedure omits the need for heuristic steps including pseudocount addition or log-transformation and improves common downstream analytical tasks such as variable gene selection, dimensional reduction, and differential expression. We named this methodsctransform.\nInspired by important and rigorous work from Lause et al (Lause, Berens, and Kobak 2021), we released an updated manuscript (Choudhary and Satija 2022) and updated the sctransform software to a v2 version, which is now the default in Seurat v5.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于SCTransform的单细胞数据标准化"
    ]
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#小提琴图",
    "href": "single_cell/seurat/sctransform.html#小提琴图",
    "title": "基于SCTransform的单细胞数据标准化",
    "section": "\n6.1 小提琴图：",
    "text": "6.1 小提琴图：\n\nVlnPlot(pbmc, \n        features = c(\"CD8A\", \"GZMK\", \"CCL5\", \"S100A4\", \"ANXA1\", \"CCR7\", \"ISG15\", \"CD3D\"),\n    pt.size = 0.2, \n    ncol = 4)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于SCTransform的单细胞数据标准化"
    ]
  },
  {
    "objectID": "single_cell/seurat/sctransform.html#umap图",
    "href": "single_cell/seurat/sctransform.html#umap图",
    "title": "基于SCTransform的单细胞数据标准化",
    "section": "\n6.2 UMAP图：",
    "text": "6.2 UMAP图：\n\nFeaturePlot(pbmc, \n            features = c(\"CD8A\", \"GZMK\", \"CCL5\", \"S100A4\", \"ANXA1\", \"CCR7\"), \n            pt.size = 0.2,\n            ncol = 3)\n\n\n\n\n\n\n\n\nFeaturePlot(pbmc, \n            features = c(\"CD3D\", \"ISG15\", \"TCL1A\", \"FCER2\", \"XCL1\", \"FCGR3A\"), \n            pt.size = 0.2,\n            ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.8              magrittr_2.0.3             \n  [5] ggbeeswarm_0.7.2            spatstat.utils_3.0-4       \n  [7] farver_2.1.1                rmarkdown_2.25             \n  [9] zlibbioc_1.48.0             vctrs_0.6.5                \n [11] ROCR_1.0-11                 DelayedMatrixStats_1.24.0  \n [13] spatstat.explore_3.2-5      RCurl_1.98-1.14            \n [15] S4Arrays_1.2.0              htmltools_0.5.7            \n [17] SparseArray_1.2.3           sctransform_0.4.1          \n [19] parallelly_1.36.0           KernSmooth_2.23-22         \n [21] htmlwidgets_1.6.4           ica_1.0-3                  \n [23] plyr_1.8.9                  plotly_4.10.4              \n [25] zoo_1.8-12                  igraph_1.6.0               \n [27] mime_0.12                   lifecycle_1.0.4            \n [29] pkgconfig_2.0.3             Matrix_1.6-5               \n [31] R6_2.5.1                    fastmap_1.1.1              \n [33] GenomeInfoDbData_1.2.11     MatrixGenerics_1.14.0      \n [35] fitdistrplus_1.1-11         future_1.33.1              \n [37] shiny_1.8.0                 digest_0.6.34              \n [39] colorspace_2.1-0            patchwork_1.2.0            \n [41] S4Vectors_0.40.2            tensor_1.5                 \n [43] RSpectra_0.16-1             irlba_2.3.5.1              \n [45] GenomicRanges_1.54.1        labeling_0.4.3             \n [47] progressr_0.14.0            fansi_1.0.6                \n [49] spatstat.sparse_3.0-3       httr_1.4.7                 \n [51] polyclip_1.10-6             abind_1.4-5                \n [53] compiler_4.3.2              withr_3.0.0                \n [55] fastDummies_1.7.3           R.utils_2.12.3             \n [57] MASS_7.3-60.0.1             DelayedArray_0.28.0        \n [59] tools_4.3.2                 vipor_0.4.7                \n [61] lmtest_0.9-40               beeswarm_0.4.0             \n [63] httpuv_1.6.13               future.apply_1.11.1        \n [65] goftest_1.2-3               R.oo_1.25.0                \n [67] glmGamPoi_1.14.0            glue_1.7.0                 \n [69] nlme_3.1-164                promises_1.2.1             \n [71] grid_4.3.2                  Rtsne_0.17                 \n [73] cluster_2.1.6               reshape2_1.4.4             \n [75] generics_0.1.3              gtable_0.3.4               \n [77] spatstat.data_3.0-4         R.methodsS3_1.8.2          \n [79] tidyr_1.3.0                 data.table_1.14.10         \n [81] XVector_0.42.0              utf8_1.2.4                 \n [83] BiocGenerics_0.48.1         spatstat.geom_3.2-7        \n [85] RcppAnnoy_0.0.21            ggrepel_0.9.5              \n [87] RANN_2.6.1                  pillar_1.9.0               \n [89] stringr_1.5.1               spam_2.10-0                \n [91] RcppHNSW_0.5.0              later_1.3.2                \n [93] splines_4.3.2               dplyr_1.1.4                \n [95] lattice_0.22-5              survival_3.5-7             \n [97] deldir_2.0-2                tidyselect_1.2.0           \n [99] miniUI_0.1.1.1              pbapply_1.7-2              \n[101] knitr_1.45                  gridExtra_2.3              \n[103] IRanges_2.36.0              SummarizedExperiment_1.32.0\n[105] scattermore_1.2             stats4_4.3.2               \n[107] xfun_0.41                   Biobase_2.62.0             \n[109] matrixStats_1.2.0           stringi_1.8.3              \n[111] lazyeval_0.2.2              yaml_2.3.8                 \n[113] evaluate_0.23               codetools_0.2-19           \n[115] tibble_3.2.1                cli_3.6.2                  \n[117] uwot_0.1.16                 xtable_1.8-4               \n[119] reticulate_1.34.0           munsell_0.5.0              \n[121] Rcpp_1.0.12                 GenomeInfoDb_1.38.5        \n[123] globals_0.16.2              spatstat.random_3.2-2      \n[125] png_0.1-8                   ggrastr_1.0.2              \n[127] parallel_4.3.2              ellipsis_0.3.2             \n[129] ggplot2_3.4.4               dotCall64_1.1-1            \n[131] sparseMatrixStats_1.14.0    bitops_1.0-7               \n[133] listenv_0.9.0               viridisLite_0.4.2          \n[135] scales_1.3.0                ggridges_0.5.5             \n[137] crayon_1.5.2                leiden_0.4.3.1             \n[139] purrr_1.0.2                 rlang_1.1.3                \n[141] cowplot_1.1.2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "基于SCTransform的单细胞数据标准化"
    ]
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html",
    "title": "Seurat v5单细胞数据整合分析",
    "section": "",
    "text": "原文：Integrative analysis in Seurat v5\n原文发布日期：2023年10月31日\nIntegration of single-cell sequencing datasets, for example across experimental batches, donors, or conditions, is often an important step in scRNA-seq workflows. Integrative analysis can help to match shared cell types and states across datasets, which can boost statistical power, and most importantly, facilitate accurate comparative analysis across datasets.\nIn previous versions of Seurat we introduced methods for integrative analysis, including our ‘anchor-based’ integration workflow. Many labs have also published powerful and pioneering methods, including Harmony and scVI, for integrative analysis. We recognize that while the goal of matching shared cell types across datasets may be important for many problems, users may also be concerned about which method to use, or that integration could result in a loss of biological resolution.\nIn Seurat v5, we introduce more flexible and streamlined infrastructure to run different integration algorithms with a single line of code. This makes it easier to explore the results of different integration methods, and to compare these results to a workflow that excludes integration steps.\nFor this vignette, we use a dataset of human PBMC profiled with seven different technologies (Ding et al. 2020), profiled as part of a systematic comparative analysis (pbmcsca). The data is available as part of our SeuratData package.",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat v5单细胞数据整合分析"
    ]
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#标准化找高变基因归一化降维",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#标准化找高变基因归一化降维",
    "title": "Seurat v5单细胞数据整合分析",
    "section": "\n4.1 标准化、找高变基因、归一化、降维",
    "text": "4.1 标准化、找高变基因、归一化、降维\nWe can now run a standard scRNA-seq analysis (i.e. without integration). Note that since the data is split into layers, normalization and variable feature identification is performed for each batch independently (a consensus set of variable features is automatically identified).\n\nobj &lt;- NormalizeData(obj)\nobj &lt;- FindVariableFeatures(obj)\nobj &lt;- ScaleData(obj)\nobj &lt;- RunPCA(obj)\nobj &lt;- RunUMAP(obj, \n               dims = 1:30, \n               reduction = \"pca\", \n               reduction.name = \"umap.unintegrated\") # name to store dimensional reduction in the Seurat object",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat v5单细胞数据整合分析"
    ]
  },
  {
    "objectID": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#聚类可视化",
    "href": "single_cell/seurat/integrative_analysis_in_seurat_v5.html#聚类可视化",
    "title": "Seurat v5单细胞数据整合分析",
    "section": "\n4.2 聚类、可视化",
    "text": "4.2 聚类、可视化\nWe can now visualize the results of a standard analysis without integration. Note that cells are grouping both by cell type and by underlying method. While a UMAP analysis is just a visualization of this, clustering this dataset would return predominantly batch-specific clusters. Especially if previous cell-type annotations were not available, this would make downstream analysis extremely challenging.\n\nobj &lt;- FindNeighbors(obj, dims = 1:30, reduction = \"pca\")\nobj &lt;- FindClusters(obj, resolution = 2, cluster.name = \"unintegrated_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10434\nNumber of edges: 412660\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8981\nNumber of communities: 48\nElapsed time: 0 seconds\n\nDimPlot(obj, \n        reduction = \"umap.unintegrated\", \n        group.by = c(\"Method\", \"CellType\"))\n\n\n\n\n\n\n\n可以看到，不同的测序技术间的细胞类型差异较大。因此需要对数据进行整合。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat v5单细胞数据整合分析"
    ]
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html",
    "title": "Seurat中的数据可视化方法",
    "section": "",
    "text": "原文：Data visualization methods in Seurat\n原文发布日期：2023-10-31\nWe’ll demonstrate visualization techniques in Seurat using our previously computed Seurat object from the 2,700 PBMC tutorial. You can download this dataset from SeuratData。官方教程是通过SeuratData包的InstallData函数来下载案例数据，可能需要开启全局代理才能下载：\n```{r}\n#| eval: false\ndevtools::install_github('satijalab/seurat-data')\nSeuratData::InstallData(\"pbmc3k\")\n```\n```{r}\n#| eval: false\nlibrary(SeuratData)\npbmc3k.final &lt;- LoadData(\"pbmc3k\", type = \"pbmc3k.final\")\npbmc3k.final$groups &lt;- sample(c(\"group1\", \n                                \"group2\"), \n                              size = ncol(pbmc3k.final), \n                              replace = TRUE)\npbmc3k.final\n```\n这里我将下载下来的数据保存起来：\n```{r}\n#| eval: false\nsaveRDS(pbmc3k.final, file = \"data/seurat_official/pbmc3k.final.rds\")\n```\n后面我们直接从本地读取这个Seurat对象：\npbmc3k.final &lt;- readRDS(\"data/seurat_official/pbmc3k.final.rds\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat中的数据可视化方法"
    ]
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#ridge-plots",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#ridge-plots",
    "title": "Seurat中的数据可视化方法",
    "section": "\n1.1 Ridge plots",
    "text": "1.1 Ridge plots\nRidge plots - from ggridges. Visualize single cell expression distributions in each cluster\n\nlibrary(Seurat)\nRidgePlot(pbmc3k.final, features = features, ncol = 2)",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat中的数据可视化方法"
    ]
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#violin-plot",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#violin-plot",
    "title": "Seurat中的数据可视化方法",
    "section": "\n1.2 Violin plot",
    "text": "1.2 Violin plot\n\nVlnPlot(pbmc3k.final, features = features)\n\n\n\n\n\n\n\nViolin plots can be split on some variable. Simply add the splitting variable to object metadata and pass it to the split.by argument. 通过添加split.by参数，展示marker gene在不同的样本组别中的表达。\n\nVlnPlot(pbmc3k.final, \n        features = \"percent.mt\", \n        split.by = \"groups\")",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat中的数据可视化方法"
    ]
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#feature-plot",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#feature-plot",
    "title": "Seurat中的数据可视化方法",
    "section": "\n1.3 Feature plot",
    "text": "1.3 Feature plot\nVisualize feature expression in low-dimensional space\n\nFeaturePlot(pbmc3k.final, features = features)\n\n\n\n\n\n\n\n对FeaturePlot的进一步修饰\n原始图像：\n\nFeaturePlot(pbmc3k.final, features = \"MS4A1\")\n\n\n\n\n\n\n\nAdjust the contrast in the plot。通过min.cutoff和max.cutoff调整颜色范围。\n\nFeaturePlot(pbmc3k.final, features = \"MS4A1\", \n            min.cutoff = 1, max.cutoff = 3)\n\n\n\n\n\n\n\n调整颜色：\n\nFeaturePlot(pbmc3k.final, features = \"MS4A1\", cols = c(\"lightblue\", \"red\"))\n\n\n\n\n\n\n# 通过RColorBrewer包取色\nlibrary(RColorBrewer)\nFeaturePlot(pbmc3k.final, features = \"MS4A1\", cols = brewer.pal(n = 10, name = \"RdBu\"))\n\n\n\n\n\n\n\n也可以通过ggplot语法修改颜色：\n\nlibrary(ggplot2)\nFeaturePlot(pbmc3k.final, features = \"MS4A1\") +\n  scale_colour_gradientn(colours = rev(brewer.pal(n = 10, name = \"RdBu\")))\n\n\n\n\n\n\n\nCalculate feature-specific contrast levels based on quantiles of non-zero expression. Particularly useful when plotting multiple markers。\n\nFeaturePlot(pbmc3k.final, \n            features = c(\"MS4A1\", \"PTPRCAP\"), \n            min.cutoff = \"q10\", \n            max.cutoff = \"q90\")\n\n\n\n\n\n\n\n多基因FeaturePlot：\n通过添加split.by参数，来按照不同的样本组别来分别展示marker gene的表达。\n\nFeaturePlot(pbmc3k.final, \n            features = c(\"CD3D\", \"MS4A1\", \"CD79A\"), \n            split.by = \"groups\")\n\n\n\n\n\n\n\nFeaturePlot()中还提供了blend 参数，来可视化两个基因的共表达情况（添加blend = TRUE）。注意blend = TRUE只能适用于2个基因，多个基因会报错 。\n\nFeaturePlot(pbmc3k.final, \n            features = c(\"MS4A1\", \"CD79A\"), \n            blend = TRUE)\n\n\n\n\n\n\n\n如果想实现多个基因的话，可以使用scCustomize包中的Plot_Density_Joint_Only()函数绘制多基因联合密度图。该函数还依赖于Nebulosa包，因此还需要先从BiocManager安装该包：\n\ninstall.packages(\"scCustomize\")\nBiocManager::install(\"Nebulosa\")\n\n\nlibrary(scCustomize)\nPlot_Density_Joint_Only(seurat_object = pbmc3k.final, \n                        features = c(\"CD3D\", \"MS4A1\", \"CD79A\"),\n                        custom_palette = BlueAndRed())",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat中的数据可视化方法"
    ]
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#dot-plots",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#dot-plots",
    "title": "Seurat中的数据可视化方法",
    "section": "\n1.4 Dot plots",
    "text": "1.4 Dot plots\nThe size of the dot corresponds to the percentage of cells expressing the feature in each cluster. The color represents the average expression level\n\nDotPlot(pbmc3k.final, \n        features = features) + \n  RotatedAxis()\n\n\n\n\n\n\n\n通过添加split.by参数，来按照不同的样本组别来分别展示marker gene的表达。\n\nDotPlot(pbmc3k.final, \n        features = features, \n        split.by = \"groups\") + \n  RotatedAxis()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat中的数据可视化方法"
    ]
  },
  {
    "objectID": "single_cell/seurat/data_visualization_methods_in_seurat.html#heatmap",
    "href": "single_cell/seurat/data_visualization_methods_in_seurat.html#heatmap",
    "title": "Seurat中的数据可视化方法",
    "section": "\n1.5 Heatmap",
    "text": "1.5 Heatmap\n\nDoHeatmap(subset(pbmc3k.final, downsample = 100), \n          features = features, \n          size = 3)\n\n\n\n\n\n\n\nDoHeatmap now shows a grouping bar, splitting the heatmap into groups or clusters. This can be changed with the group.by parameter. 默认的group.by为细胞分群信息，即按照细胞的分群作为分组依据来绘制热图：\n\nDoHeatmap(pbmc3k.final, \n          features = VariableFeatures(pbmc3k.final)[1:30], \n          cells = 1:1000, \n          size = 4, # 分组文字的大小\n          angle = 45) +  # 分组文字角度\n  NoLegend()\n\n\n\n\n\n\n\n我们用meta.data中的任何列作为分群依据。例如这里的”groups”列：\n\ncolnames(pbmc3k.final@meta.data)\n\n[1] \"orig.ident\"         \"nCount_RNA\"         \"nFeature_RNA\"      \n[4] \"seurat_annotations\" \"percent.mt\"         \"RNA_snn_res.0.5\"   \n[7] \"seurat_clusters\"    \"groups\"            \n\nDoHeatmap(pbmc3k.final, \n          features = VariableFeatures(pbmc3k.final)[1:30], \n          group.by = \"groups\",\n          cells = 1:1000, \n          size = 4, # 分组文字的大小\n          angle = 0) +  # 分组文字角度\n  NoLegend()",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "Seurat中的数据可视化方法"
    ]
  },
  {
    "objectID": "single_cell/seurat/integration.html",
    "href": "single_cell/seurat/integration.html",
    "title": "整合（integration）",
    "section": "",
    "text": "原文：Introduction to scRNA-seq integration\n原文发布日期：2023年10月31日\nIntegration of single-cell sequencing datasets, for example across experimental batches, donors, or conditions, is often an important step in scRNA-seq workflows. Integrative analysis can help to match shared cell types and states across datasets, which can boost statistical power, and most importantly, facilitate accurate comparative analysis across datasets. In previous versions of Seurat we introduced methods for integrative analysis, including our ‘anchor-based’ integration workflow. Many labs have also published powerful and pioneering methods, including Harmony and scVI, for integrative analysis.\n数据整合的目标：\nThe following tutorial is designed to give you an overview of the kinds of comparative analyses on complex cell types that are possible using the Seurat integration procedure. Here, we address a few key goals:",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "整合（integration）"
    ]
  },
  {
    "objectID": "single_cell/seurat/integration.html#整合后重新聚类降维",
    "href": "single_cell/seurat/integration.html#整合后重新聚类降维",
    "title": "整合（integration）",
    "section": "\n3.1 整合后重新聚类、降维",
    "text": "3.1 整合后重新聚类、降维\n\n# 重新聚类\nifnb_integrated &lt;- FindNeighbors(ifnb_integrated, \n                                 reduction = \"integrated.cca\", #更改降维来源为\"integrated.cca\"\n                                 dims = 1:30)\nifnb_integrated &lt;- FindClusters(ifnb_integrated, resolution = 1)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 13999\nNumber of edges: 590406\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8448\nNumber of communities: 18\nElapsed time: 1 seconds\n\n# 重新降维\nifnb_integrated &lt;- RunUMAP(ifnb_integrated, \n                           dims = 1:30, \n                           reduction = \"integrated.cca\") #更改降维来源为\"integrated.cca\"\n\n# Visualization：\nDimPlot(ifnb_integrated, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\n\n\n\nFigure 2: 整合后的细胞分群情况（左：按照刺激条件着色；右：按照细胞聚类情况着色）\n\n\n\n\n可以看到和 Figure 1 相比，在整合后，细胞就只按照细胞类型进行聚类了。\n也可以按照刺激条件（“stim”）绘制分面图，分别展示刺激组和对照组的细胞分群情况：\n\nDimPlot(ifnb_integrated, reduction = \"umap\", split.by = \"stim\")\n\n\n\n\n\n\n\n可以看到，和上面的结论一致，两种条件下的细胞分群基本一致。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "整合（integration）"
    ]
  },
  {
    "objectID": "single_cell/seurat/integration.html#不进行整合的情况下的数据分析",
    "href": "single_cell/seurat/integration.html#不进行整合的情况下的数据分析",
    "title": "整合（integration）",
    "section": "\n4.1 不进行整合的情况下的数据分析",
    "text": "4.1 不进行整合的情况下的数据分析\n\nrm(list = ls())\n\n# 重新载入原始的Seurat对象ifnb\nlibrary(Seurat)\nifnb &lt;- readRDS(\"data/seurat_official/pbmc_ifnb.rds\")\n\n# 同样先拆分数据集，然后进行无整合情况下的降维\nifnb[[\"RNA\"]] &lt;- split(ifnb[[\"RNA\"]], f = ifnb$stim)\nifnb &lt;- SCTransform(ifnb, verbose = FALSE)\nifnb &lt;- RunPCA(ifnb)\nifnb &lt;- RunUMAP(ifnb, dims = 1:30)\nDimPlot(ifnb, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\n\n\n\nFigure 3: 未整合时的细胞分群情况（左：按照刺激条件着色；右：按照细胞聚类情况着色）\n\n\n\n\n可以看到，如果不进行整合，不同样本（STIM vs. STIM）的细胞类型差异很大。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "整合（integration）"
    ]
  },
  {
    "objectID": "single_cell/seurat/integration.html#sec-integration_after_sct",
    "href": "single_cell/seurat/integration.html#sec-integration_after_sct",
    "title": "整合（integration）",
    "section": "\n4.2 进行整合",
    "text": "4.2 进行整合\n同样通过IntegrateLayers函数进行数据整合，只不过需要将默认的标准化方法由”LogNormalize”指定为”SCT”（normalization.method = \"SCT\"）：\n\nifnb_integrated &lt;- IntegrateLayers(ifnb, \n                                   method = CCAIntegration, \n                                   normalization.method = \"SCT\", \n                                   verbose = F)\n# 整合后重新合并RNA的layers\nLayers(ifnb_integrated[[\"RNA\"]])\n\n[1] \"counts.CTRL\" \"counts.STIM\" \"data.CTRL\"   \"data.STIM\"  \n\nifnb_integrated[[\"RNA\"]] &lt;- JoinLayers(ifnb_integrated[[\"RNA\"]])\nLayers(ifnb_integrated[[\"RNA\"]])\n\n[1] \"data\"   \"counts\"\n\n\n\n可以看到经过整合的Seurat对象的降维（“reduction”）信息中多出了整合后的降维（“integrated.dr”）。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "整合（integration）"
    ]
  },
  {
    "objectID": "single_cell/seurat/integration.html#整合后聚类",
    "href": "single_cell/seurat/integration.html#整合后聚类",
    "title": "整合（integration）",
    "section": "\n4.3 整合后聚类",
    "text": "4.3 整合后聚类\n\nifnb_integrated &lt;- FindNeighbors(ifnb_integrated, \n                                 reduction = \"integrated.dr\", #更改降维来源为\"integrated.dr\"\n                                 dims = 1:30)\nifnb_integrated &lt;- FindClusters(ifnb_integrated, \n                                resolution = 0.6)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 13999\nNumber of edges: 527905\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9058\nNumber of communities: 19\nElapsed time: 1 seconds\n\nifnb_integrated &lt;- RunUMAP(ifnb_integrated, \n                           dims = 1:30, \n                           reduction = \"integrated.dr\")\nDimPlot(ifnb_integrated, \n        reduction = \"umap\", \n        group.by = c(\"stim\", \"seurat_annotations\"))\n\n\n\n\n\n\n\n可以看到和 Figure 3 相比，整合后在样本间的细胞类型基本均匀分布。",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "整合（integration）"
    ]
  },
  {
    "objectID": "single_cell/seurat/integration.html#保存整合后的seurat对象",
    "href": "single_cell/seurat/integration.html#保存整合后的seurat对象",
    "title": "整合（integration）",
    "section": "\n4.4 保存整合后的Seurat对象",
    "text": "4.4 保存整合后的Seurat对象\n\nsaveRDS(ifnb_integrated, file = \"output/seurat_official/ifnb_integrated.rds\")\n\n\n\n\n\n\n\n\nSession Info\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3          rstudioapi_0.15.0          \n  [3] jsonlite_1.8.8              magrittr_2.0.3             \n  [5] spatstat.utils_3.0-4        farver_2.1.1               \n  [7] rmarkdown_2.25              zlibbioc_1.48.0            \n  [9] vctrs_0.6.5                 ROCR_1.0-11                \n [11] DelayedMatrixStats_1.24.0   spatstat.explore_3.2-5     \n [13] RCurl_1.98-1.14             S4Arrays_1.2.0             \n [15] htmltools_0.5.7             SparseArray_1.2.3          \n [17] sctransform_0.4.1           parallelly_1.36.0          \n [19] KernSmooth_2.23-22          htmlwidgets_1.6.4          \n [21] ica_1.0-3                   plyr_1.8.9                 \n [23] plotly_4.10.4               zoo_1.8-12                 \n [25] igraph_1.6.0                mime_0.12                  \n [27] lifecycle_1.0.4             pkgconfig_2.0.3            \n [29] Matrix_1.6-5                R6_2.5.1                   \n [31] fastmap_1.1.1               GenomeInfoDbData_1.2.11    \n [33] MatrixGenerics_1.14.0       fitdistrplus_1.1-11        \n [35] future_1.33.1               shiny_1.8.0                \n [37] digest_0.6.34               colorspace_2.1-0           \n [39] patchwork_1.2.0             S4Vectors_0.40.2           \n [41] tensor_1.5                  RSpectra_0.16-1            \n [43] irlba_2.3.5.1               GenomicRanges_1.54.1       \n [45] labeling_0.4.3              progressr_0.14.0           \n [47] fansi_1.0.6                 spatstat.sparse_3.0-3      \n [49] httr_1.4.7                  polyclip_1.10-6            \n [51] abind_1.4-5                 compiler_4.3.2             \n [53] withr_3.0.0                 fastDummies_1.7.3          \n [55] MASS_7.3-60.0.1             DelayedArray_0.28.0        \n [57] tools_4.3.2                 lmtest_0.9-40              \n [59] httpuv_1.6.13               future.apply_1.11.1        \n [61] goftest_1.2-3               glmGamPoi_1.14.0           \n [63] glue_1.7.0                  nlme_3.1-164               \n [65] promises_1.2.1              grid_4.3.2                 \n [67] Rtsne_0.17                  cluster_2.1.6              \n [69] reshape2_1.4.4              generics_0.1.3             \n [71] gtable_0.3.4                spatstat.data_3.0-4        \n [73] tidyr_1.3.0                 data.table_1.14.10         \n [75] XVector_0.42.0              utf8_1.2.4                 \n [77] BiocGenerics_0.48.1         spatstat.geom_3.2-7        \n [79] RcppAnnoy_0.0.21            ggrepel_0.9.5              \n [81] RANN_2.6.1                  pillar_1.9.0               \n [83] stringr_1.5.1               spam_2.10-0                \n [85] RcppHNSW_0.5.0              later_1.3.2                \n [87] splines_4.3.2               dplyr_1.1.4                \n [89] lattice_0.22-5              survival_3.5-7             \n [91] deldir_2.0-2                tidyselect_1.2.0           \n [93] miniUI_0.1.1.1              pbapply_1.7-2              \n [95] knitr_1.45                  gridExtra_2.3              \n [97] IRanges_2.36.0              SummarizedExperiment_1.32.0\n [99] scattermore_1.2             stats4_4.3.2               \n[101] xfun_0.41                   Biobase_2.62.0             \n[103] matrixStats_1.2.0           stringi_1.8.3              \n[105] lazyeval_0.2.2              yaml_2.3.8                 \n[107] evaluate_0.23               codetools_0.2-19           \n[109] tibble_3.2.1                cli_3.6.2                  \n[111] uwot_0.1.16                 xtable_1.8-4               \n[113] reticulate_1.34.0           munsell_0.5.0              \n[115] Rcpp_1.0.12                 GenomeInfoDb_1.38.5        \n[117] globals_0.16.2              spatstat.random_3.2-2      \n[119] png_0.1-8                   parallel_4.3.2             \n[121] ellipsis_0.3.2              ggplot2_3.4.4              \n[123] dotCall64_1.1-1             sparseMatrixStats_1.14.0   \n[125] bitops_1.0-7                listenv_0.9.0              \n[127] viridisLite_0.4.2           scales_1.3.0               \n[129] ggridges_0.5.5              crayon_1.5.2               \n[131] leiden_0.4.3.1              purrr_1.0.2                \n[133] rlang_1.1.3                 cowplot_1.1.2",
    "crumbs": [
      "Home",
      "单细胞数据分析",
      "Seurat v5官方文档",
      "整合（integration）"
    ]
  }
]